{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee4a9863",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten,Dropout\n",
    "from tensorflow.keras.layers import Conv1D,Conv2D,BatchNormalization,MaxPooling1D,MaxPooling2D,Reshape, Dense, Embedding, LSTM,GRU, Bidirectional, TimeDistributed\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import optimizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.compat.v1.keras.layers import CuDNNLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec120b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "64996a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    X_test = np.load(\"X_test.npy\")\n",
    "    y_test = np.load(\"y_test.npy\")\n",
    "    person_train_valid = np.load(\"person_train_valid.npy\")\n",
    "    X_train_valid = np.load(\"X_train_valid.npy\")\n",
    "    y_train_valid = np.load(\"y_train_valid.npy\")\n",
    "    person_test = np.load(\"person_test.npy\")\n",
    "\n",
    "    return X_test,y_test,person_train_valid,X_train_valid,y_train_valid,person_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "25f63796",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prep(X,y,sub_sample,average,noise):\n",
    "    \n",
    "    total_X = None\n",
    "    total_y = None\n",
    "    \n",
    "    X = X[:,:,0:500]\n",
    "    \n",
    "    # Maxpooling the data \n",
    "    X_max = np.max(X.reshape(X.shape[0], X.shape[1], -1, sub_sample), axis=3)\n",
    "    \n",
    "    \n",
    "    total_X = X_max\n",
    "    total_y = y\n",
    "    \n",
    "    # Averaging + noise \n",
    "    X_average = np.mean(X.reshape(X.shape[0], X.shape[1], -1, average),axis=3)\n",
    "    X_average = X_average + np.random.normal(0.0, 0.5, X_average.shape)\n",
    "    \n",
    "    total_X = np.vstack((total_X, X_average))\n",
    "    total_y = np.hstack((total_y, y))\n",
    "    \n",
    "    # Subsampling\n",
    "    \n",
    "    for i in range(sub_sample):\n",
    "        \n",
    "        X_subsample = X[:, :, i::sub_sample] + \\\n",
    "                            (np.random.normal(0.0, 0.5, X[:, :,i::sub_sample].shape) if noise else 0.0)\n",
    "            \n",
    "        total_X = np.vstack((total_X, X_subsample))\n",
    "        total_y = np.hstack((total_y, y))\n",
    "    \n",
    "    return total_X,total_y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f6cc1a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(y_train_valid, y_test, X_train_valid, X_test):\n",
    "    y_train_valid -= 769\n",
    "    y_test -= 769\n",
    "\n",
    "    X_train_valid_prep,y_train_valid_prep = data_prep(X_train_valid,y_train_valid,2,2,True)\n",
    "    X_test_prep,y_test_prep = data_prep(X_test,y_test,2,2,True)\n",
    "\n",
    "    ## Random splitting and reshaping the data\n",
    "    total_size = y_train_valid_prep.shape[0]\n",
    "    num_samples = int(total_size*0.1773)\n",
    "\n",
    "    # First generating the training and validation indices using random splitting\n",
    "    ind_valid = np.random.choice(total_size, num_samples, replace=False)\n",
    "    ind_train = np.array(list(set(range(total_size)).difference(set(ind_valid))))\n",
    "\n",
    "    # Creating the training and validation sets using the generated indices\n",
    "    (x_train, x_valid) = X_train_valid_prep[ind_train], X_train_valid_prep[ind_valid] \n",
    "    (y_train, y_valid) = y_train_valid_prep[ind_train], y_train_valid_prep[ind_valid]\n",
    "\n",
    "\n",
    "    # Converting the labels to categorical variables for multiclass classification\n",
    "    y_train = to_categorical(y_train, 4)\n",
    "    y_valid = to_categorical(y_valid, 4)\n",
    "    y_test = to_categorical(y_test_prep, 4)\n",
    "\n",
    "    # Adding width of the segment to be 1\n",
    "    x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
    "    x_valid = x_valid.reshape(x_valid.shape[0], x_valid.shape[1], x_train.shape[2], 1)\n",
    "    x_test = X_test_prep.reshape(X_test_prep.shape[0], X_test_prep.shape[1], X_test_prep.shape[2], 1)\n",
    "\n",
    "\n",
    "    # Reshaping the training and validation dataset\n",
    "    x_train = np.swapaxes(x_train, 1,3)\n",
    "    x_train = np.swapaxes(x_train, 1,2)\n",
    "    x_valid = np.swapaxes(x_valid, 1,3)\n",
    "    x_valid = np.swapaxes(x_valid, 1,2)\n",
    "    x_test = np.swapaxes(x_test, 1,3)\n",
    "    x_test = np.swapaxes(x_test, 1,2)\n",
    "    \n",
    "    return y_train, y_valid, y_test, x_train, x_valid, x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "46329b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 250, 1, 25)        5525      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 84, 1, 25)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 84, 1, 25)         100       \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 84, 1, 25)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 84, 1, 50)         12550     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 28, 1, 50)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 28, 1, 50)         200       \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 28, 1, 50)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 28, 1, 100)        50100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 10, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 10, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 10, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4)                 4004      \n",
      "=================================================================\n",
      "Total params: 72,879\n",
      "Trainable params: 72,529\n",
      "Non-trainable params: 350\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Building the CNN model using sequential class\n",
    "from tensorflow.keras import layers\n",
    "def get_3layermodel():\n",
    "    basic_cnn_model = Sequential()\n",
    "\n",
    "    # Conv. block 1\n",
    "    basic_cnn_model.add(layers.Conv2D(filters=25, kernel_size=(10,1), padding='same', activation='elu', input_shape=(250,1,22)))\n",
    "    basic_cnn_model.add(layers.MaxPooling2D(pool_size=(3,1), padding='same')) # Read the keras documentation\n",
    "    basic_cnn_model.add(layers.BatchNormalization())\n",
    "    basic_cnn_model.add(layers.Dropout(0.5))\n",
    "\n",
    "    # Conv. block 2\n",
    "    basic_cnn_model.add(layers.Conv2D(filters=50, kernel_size=(10,1), padding='same', activation='elu'))\n",
    "    basic_cnn_model.add(layers.MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "    basic_cnn_model.add(layers.BatchNormalization())\n",
    "    basic_cnn_model.add(layers.Dropout(0.5))\n",
    "\n",
    "    # Conv. block 3\n",
    "    basic_cnn_model.add(layers.Conv2D(filters=100, kernel_size=(10,1), padding='same', activation='elu'))\n",
    "    basic_cnn_model.add(layers.MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "    basic_cnn_model.add(layers.BatchNormalization())\n",
    "    basic_cnn_model.add(layers.Dropout(0.5))\n",
    "\n",
    "    # Output layer with Softmax activation\n",
    "    basic_cnn_model.add(Flatten()) # Flattens the input\n",
    "    basic_cnn_model.add(Dense(4, activation='softmax')) # Output FC layer with softmax activation\n",
    "\n",
    "    return basic_cnn_model\n",
    "\n",
    "basic_cnn_model = get_3layermodel()\n",
    "# Printing the model summary\n",
    "basic_cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d8d0e912",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_results(model, x_train, y_train, x_valid, y_valid, x_test, y_test): \n",
    "    \n",
    "    # Model parameters\n",
    "    learning_rate = 1.5e-3\n",
    "    epochs = 50\n",
    "    optimizer = optimizers.Adam(learning_rate)\n",
    "    \n",
    "    # Compiling the model\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "         optimizer=optimizer,\n",
    "         metrics=['accuracy'])\n",
    "\n",
    "    # Training and validating the model\n",
    "    model_results = model.fit(x_train,\n",
    "             y_train,\n",
    "             batch_size=200,\n",
    "             epochs=epochs,\n",
    "             validation_data=(x_valid, y_valid), verbose=True)\n",
    "\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    return score[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "60df0b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6960, 250, 1, 22)\n",
      "(6960, 4)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0406eea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_by_subjects_random_sampling(subject_id=0):\n",
    "    X_test,y_test,person_train_valid,X_train_valid,y_train_valid,person_test = load_data()\n",
    "    \n",
    "    X_train_valid = X_train_valid[np.where(person_train_valid!=subject_id)[0],:,:]\n",
    "    y_train_valid = y_train_valid[np.where(person_train_valid!=subject_id)[0]]\n",
    "    \n",
    "    X_test_left_subject = X_train_valid[np.where(person_test==subject_id)[0],:,:]\n",
    "    y_test_left_subject = y_train_valid[np.where(person_test==subject_id)[0]]\n",
    "    \n",
    "    yt1 = np.copy(y_test)\n",
    "    yt2 = np.copy(y_train_valid)\n",
    "    \n",
    "    y_train, y_valid, y_test_left_subject, x_train, x_valid, x_test_left_subject = preprocessing(y_train_valid, y_test_left_subject, X_train_valid, X_test_left_subject)\n",
    "    \n",
    "    y_train, y_valid, y_test, x_train, x_valid, x_test = preprocessing(yt2, yt1, X_train_valid, X_test)\n",
    "\n",
    "    best_cnn_model = get_3layermodel()  \n",
    "    \n",
    "    acc_left_subject = get_model_results(best_cnn_model, x_train, y_train, x_valid, y_valid, x_test_left_subject, y_test_left_subject)\n",
    "    \n",
    "    acc_test = best_cnn_model.evaluate(x_test, y_test, verbose=0)[1]\n",
    "    \n",
    "    return acc_left_subject, acc_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a8897633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6181 samples, validate on 1331 samples\n",
      "Epoch 1/50\n",
      "6181/6181 [==============================] - 4s 610us/sample - loss: 1.9501 - accuracy: 0.3341 - val_loss: 1.5673 - val_accuracy: 0.4057\n",
      "Epoch 2/50\n",
      "6181/6181 [==============================] - 3s 547us/sample - loss: 1.5497 - accuracy: 0.3988 - val_loss: 1.2042 - val_accuracy: 0.4786\n",
      "Epoch 3/50\n",
      "6181/6181 [==============================] - 3s 496us/sample - loss: 1.3437 - accuracy: 0.4527 - val_loss: 1.0266 - val_accuracy: 0.5575\n",
      "Epoch 4/50\n",
      "6181/6181 [==============================] - 5s 810us/sample - loss: 1.1923 - accuracy: 0.5082 - val_loss: 0.9223 - val_accuracy: 0.6116\n",
      "Epoch 5/50\n",
      "6181/6181 [==============================] - 4s 591us/sample - loss: 1.0756 - accuracy: 0.5593 - val_loss: 0.8951 - val_accuracy: 0.6334\n",
      "Epoch 6/50\n",
      "6181/6181 [==============================] - 4s 577us/sample - loss: 1.0100 - accuracy: 0.5920 - val_loss: 0.8123 - val_accuracy: 0.6717\n",
      "Epoch 7/50\n",
      "6181/6181 [==============================] - 4s 595us/sample - loss: 0.9500 - accuracy: 0.6151 - val_loss: 0.7909 - val_accuracy: 0.6852\n",
      "Epoch 8/50\n",
      "6181/6181 [==============================] - 4s 634us/sample - loss: 0.9230 - accuracy: 0.6242 - val_loss: 0.7529 - val_accuracy: 0.6995\n",
      "Epoch 9/50\n",
      "6181/6181 [==============================] - 4s 578us/sample - loss: 0.8809 - accuracy: 0.6446 - val_loss: 0.7269 - val_accuracy: 0.7235\n",
      "Epoch 10/50\n",
      "6181/6181 [==============================] - 4s 582us/sample - loss: 0.8743 - accuracy: 0.6488 - val_loss: 0.7545 - val_accuracy: 0.6935\n",
      "Epoch 11/50\n",
      "6181/6181 [==============================] - 4s 603us/sample - loss: 0.8308 - accuracy: 0.6636 - val_loss: 0.7278 - val_accuracy: 0.7062\n",
      "Epoch 12/50\n",
      "6181/6181 [==============================] - 4s 572us/sample - loss: 0.8229 - accuracy: 0.6651 - val_loss: 0.6644 - val_accuracy: 0.7340\n",
      "Epoch 13/50\n",
      "6181/6181 [==============================] - 3s 556us/sample - loss: 0.7714 - accuracy: 0.6856 - val_loss: 0.6716 - val_accuracy: 0.7168\n",
      "Epoch 14/50\n",
      "6181/6181 [==============================] - 4s 657us/sample - loss: 0.7698 - accuracy: 0.6874 - val_loss: 0.6138 - val_accuracy: 0.7641\n",
      "Epoch 15/50\n",
      "6181/6181 [==============================] - 4s 607us/sample - loss: 0.7307 - accuracy: 0.7085 - val_loss: 0.5701 - val_accuracy: 0.7829\n",
      "Epoch 16/50\n",
      "6181/6181 [==============================] - 4s 596us/sample - loss: 0.7131 - accuracy: 0.7175 - val_loss: 0.5719 - val_accuracy: 0.7799\n",
      "Epoch 17/50\n",
      "6181/6181 [==============================] - 4s 590us/sample - loss: 0.7090 - accuracy: 0.7188 - val_loss: 0.5696 - val_accuracy: 0.7784\n",
      "Epoch 18/50\n",
      "6181/6181 [==============================] - 4s 595us/sample - loss: 0.6728 - accuracy: 0.7345 - val_loss: 0.5473 - val_accuracy: 0.7776\n",
      "Epoch 19/50\n",
      "6181/6181 [==============================] - 4s 619us/sample - loss: 0.6848 - accuracy: 0.7345 - val_loss: 0.4966 - val_accuracy: 0.8129\n",
      "Epoch 20/50\n",
      "6181/6181 [==============================] - 4s 589us/sample - loss: 0.6457 - accuracy: 0.7413 - val_loss: 0.4983 - val_accuracy: 0.7949\n",
      "Epoch 21/50\n",
      "6181/6181 [==============================] - 3s 541us/sample - loss: 0.6468 - accuracy: 0.7473 - val_loss: 0.4748 - val_accuracy: 0.8264\n",
      "Epoch 22/50\n",
      "6181/6181 [==============================] - 4s 598us/sample - loss: 0.6399 - accuracy: 0.7523 - val_loss: 0.4357 - val_accuracy: 0.8430\n",
      "Epoch 23/50\n",
      "6181/6181 [==============================] - 4s 598us/sample - loss: 0.6186 - accuracy: 0.7675 - val_loss: 0.4533 - val_accuracy: 0.8204\n",
      "Epoch 24/50\n",
      "6181/6181 [==============================] - 4s 576us/sample - loss: 0.5913 - accuracy: 0.7719 - val_loss: 0.4486 - val_accuracy: 0.8279\n",
      "Epoch 25/50\n",
      "6181/6181 [==============================] - 4s 608us/sample - loss: 0.6090 - accuracy: 0.7589 - val_loss: 0.4082 - val_accuracy: 0.8490\n",
      "Epoch 26/50\n",
      "6181/6181 [==============================] - 4s 614us/sample - loss: 0.5760 - accuracy: 0.7753 - val_loss: 0.3963 - val_accuracy: 0.8535\n",
      "Epoch 27/50\n",
      "6181/6181 [==============================] - 4s 602us/sample - loss: 0.5619 - accuracy: 0.7816 - val_loss: 0.3875 - val_accuracy: 0.8573\n",
      "Epoch 28/50\n",
      "6181/6181 [==============================] - 4s 582us/sample - loss: 0.5602 - accuracy: 0.7775 - val_loss: 0.3530 - val_accuracy: 0.8730\n",
      "Epoch 29/50\n",
      "6181/6181 [==============================] - 4s 606us/sample - loss: 0.5669 - accuracy: 0.7811 - val_loss: 0.4000 - val_accuracy: 0.8482\n",
      "Epoch 30/50\n",
      "6181/6181 [==============================] - 3s 546us/sample - loss: 0.5465 - accuracy: 0.7858 - val_loss: 0.3897 - val_accuracy: 0.8505\n",
      "Epoch 31/50\n",
      "6181/6181 [==============================] - 3s 520us/sample - loss: 0.5393 - accuracy: 0.7939 - val_loss: 0.4209 - val_accuracy: 0.8287\n",
      "Epoch 32/50\n",
      "6181/6181 [==============================] - 3s 526us/sample - loss: 0.5112 - accuracy: 0.8068 - val_loss: 0.3268 - val_accuracy: 0.8805\n",
      "Epoch 33/50\n",
      "6181/6181 [==============================] - 4s 672us/sample - loss: 0.4952 - accuracy: 0.8115 - val_loss: 0.3209 - val_accuracy: 0.8790\n",
      "Epoch 34/50\n",
      "6181/6181 [==============================] - 4s 604us/sample - loss: 0.5052 - accuracy: 0.8067 - val_loss: 0.3198 - val_accuracy: 0.8835\n",
      "Epoch 35/50\n",
      "6181/6181 [==============================] - 4s 585us/sample - loss: 0.5003 - accuracy: 0.8057 - val_loss: 0.2846 - val_accuracy: 0.9061\n",
      "Epoch 36/50\n",
      "6181/6181 [==============================] - 4s 600us/sample - loss: 0.4922 - accuracy: 0.8123 - val_loss: 0.2735 - val_accuracy: 0.9136\n",
      "Epoch 37/50\n",
      "6181/6181 [==============================] - 4s 616us/sample - loss: 0.4691 - accuracy: 0.8149 - val_loss: 0.2847 - val_accuracy: 0.9001\n",
      "Epoch 38/50\n",
      "6181/6181 [==============================] - 4s 602us/sample - loss: 0.4813 - accuracy: 0.8097 - val_loss: 0.2930 - val_accuracy: 0.8918\n",
      "Epoch 39/50\n",
      "6181/6181 [==============================] - 4s 594us/sample - loss: 0.4667 - accuracy: 0.8146 - val_loss: 0.2763 - val_accuracy: 0.8941\n",
      "Epoch 40/50\n",
      "6181/6181 [==============================] - 4s 597us/sample - loss: 0.4623 - accuracy: 0.8225 - val_loss: 0.2762 - val_accuracy: 0.9038\n",
      "Epoch 41/50\n",
      "6181/6181 [==============================] - 4s 612us/sample - loss: 0.4613 - accuracy: 0.8248 - val_loss: 0.2572 - val_accuracy: 0.9121\n",
      "Epoch 42/50\n",
      "6181/6181 [==============================] - 4s 589us/sample - loss: 0.4701 - accuracy: 0.8220 - val_loss: 0.2437 - val_accuracy: 0.9196\n",
      "Epoch 43/50\n",
      "6181/6181 [==============================] - 4s 605us/sample - loss: 0.4337 - accuracy: 0.8351 - val_loss: 0.2331 - val_accuracy: 0.9204\n",
      "Epoch 44/50\n",
      "6181/6181 [==============================] - 4s 599us/sample - loss: 0.4363 - accuracy: 0.8327 - val_loss: 0.2449 - val_accuracy: 0.9091\n",
      "Epoch 45/50\n",
      "6181/6181 [==============================] - 4s 612us/sample - loss: 0.4346 - accuracy: 0.8368 - val_loss: 0.2301 - val_accuracy: 0.9249\n",
      "Epoch 46/50\n",
      "6181/6181 [==============================] - 3s 550us/sample - loss: 0.4323 - accuracy: 0.8398 - val_loss: 0.2208 - val_accuracy: 0.9286\n",
      "Epoch 47/50\n",
      "6181/6181 [==============================] - 3s 528us/sample - loss: 0.4368 - accuracy: 0.8358 - val_loss: 0.2013 - val_accuracy: 0.9316\n",
      "Epoch 48/50\n",
      "6181/6181 [==============================] - 5s 750us/sample - loss: 0.4184 - accuracy: 0.8356 - val_loss: 0.1864 - val_accuracy: 0.9452\n",
      "Epoch 49/50\n",
      "6181/6181 [==============================] - 4s 657us/sample - loss: 0.4151 - accuracy: 0.8355 - val_loss: 0.1839 - val_accuracy: 0.9452\n",
      "Epoch 50/50\n",
      "6181/6181 [==============================] - 4s 591us/sample - loss: 0.4214 - accuracy: 0.8359 - val_loss: 0.1924 - val_accuracy: 0.9459\n",
      "Train on 6184 samples, validate on 1332 samples\n",
      "Epoch 1/50\n",
      "6184/6184 [==============================] - 4s 721us/sample - loss: 2.0376 - accuracy: 0.3197 - val_loss: 1.4532 - val_accuracy: 0.4369\n",
      "Epoch 2/50\n",
      "6184/6184 [==============================] - 4s 574us/sample - loss: 1.5693 - accuracy: 0.3994 - val_loss: 1.5205 - val_accuracy: 0.4242\n",
      "Epoch 3/50\n",
      "6184/6184 [==============================] - 4s 599us/sample - loss: 1.3489 - accuracy: 0.4507 - val_loss: 1.0150 - val_accuracy: 0.5923\n",
      "Epoch 4/50\n",
      "6184/6184 [==============================] - 4s 628us/sample - loss: 1.1971 - accuracy: 0.5024 - val_loss: 0.9330 - val_accuracy: 0.6291\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6184/6184 [==============================] - 3s 546us/sample - loss: 1.1028 - accuracy: 0.5501 - val_loss: 0.9328 - val_accuracy: 0.6269\n",
      "Epoch 6/50\n",
      "6184/6184 [==============================] - 4s 608us/sample - loss: 1.0366 - accuracy: 0.5796 - val_loss: 0.8756 - val_accuracy: 0.6764\n",
      "Epoch 7/50\n",
      "6184/6184 [==============================] - 4s 619us/sample - loss: 1.0031 - accuracy: 0.5935 - val_loss: 0.8553 - val_accuracy: 0.6779\n",
      "Epoch 8/50\n",
      "6184/6184 [==============================] - 5s 754us/sample - loss: 0.9410 - accuracy: 0.6229 - val_loss: 0.8526 - val_accuracy: 0.6742\n",
      "Epoch 9/50\n",
      "6184/6184 [==============================] - 3s 499us/sample - loss: 0.8859 - accuracy: 0.6368 - val_loss: 0.7718 - val_accuracy: 0.7117\n",
      "Epoch 10/50\n",
      "6184/6184 [==============================] - 3s 529us/sample - loss: 0.8494 - accuracy: 0.6645 - val_loss: 0.7336 - val_accuracy: 0.7492\n",
      "Epoch 11/50\n",
      "6184/6184 [==============================] - 3s 527us/sample - loss: 0.8369 - accuracy: 0.6640 - val_loss: 0.7426 - val_accuracy: 0.7275\n",
      "Epoch 12/50\n",
      "6184/6184 [==============================] - 4s 610us/sample - loss: 0.7912 - accuracy: 0.6882 - val_loss: 0.6652 - val_accuracy: 0.7605\n",
      "Epoch 13/50\n",
      "6184/6184 [==============================] - 4s 588us/sample - loss: 0.7708 - accuracy: 0.6966 - val_loss: 0.6547 - val_accuracy: 0.7650\n",
      "Epoch 14/50\n",
      "6184/6184 [==============================] - 4s 635us/sample - loss: 0.7469 - accuracy: 0.7036 - val_loss: 0.6074 - val_accuracy: 0.7823\n",
      "Epoch 15/50\n",
      "6184/6184 [==============================] - 4s 650us/sample - loss: 0.7237 - accuracy: 0.7126 - val_loss: 0.5895 - val_accuracy: 0.7875\n",
      "Epoch 16/50\n",
      "6184/6184 [==============================] - 4s 652us/sample - loss: 0.7051 - accuracy: 0.7270 - val_loss: 0.5799 - val_accuracy: 0.7943\n",
      "Epoch 17/50\n",
      "6184/6184 [==============================] - 4s 608us/sample - loss: 0.6925 - accuracy: 0.7299 - val_loss: 0.5426 - val_accuracy: 0.8056\n",
      "Epoch 18/50\n",
      "6184/6184 [==============================] - 4s 578us/sample - loss: 0.6731 - accuracy: 0.7350 - val_loss: 0.5658 - val_accuracy: 0.7845\n",
      "Epoch 19/50\n",
      "6184/6184 [==============================] - 4s 601us/sample - loss: 0.6509 - accuracy: 0.7403 - val_loss: 0.5064 - val_accuracy: 0.8153\n",
      "Epoch 20/50\n",
      "6184/6184 [==============================] - 4s 606us/sample - loss: 0.6365 - accuracy: 0.7523 - val_loss: 0.5103 - val_accuracy: 0.8063\n",
      "Epoch 21/50\n",
      "6184/6184 [==============================] - 4s 602us/sample - loss: 0.6205 - accuracy: 0.7621 - val_loss: 0.4689 - val_accuracy: 0.8303\n",
      "Epoch 22/50\n",
      "6184/6184 [==============================] - 4s 585us/sample - loss: 0.6242 - accuracy: 0.7565 - val_loss: 0.4449 - val_accuracy: 0.8453\n",
      "Epoch 23/50\n",
      "6184/6184 [==============================] - 4s 600us/sample - loss: 0.5875 - accuracy: 0.7775 - val_loss: 0.4463 - val_accuracy: 0.8438\n",
      "Epoch 24/50\n",
      "6184/6184 [==============================] - 4s 604us/sample - loss: 0.5962 - accuracy: 0.7705 - val_loss: 0.4705 - val_accuracy: 0.8348\n",
      "Epoch 25/50\n",
      "6184/6184 [==============================] - 4s 591us/sample - loss: 0.5771 - accuracy: 0.7762 - val_loss: 0.4194 - val_accuracy: 0.8551\n",
      "Epoch 26/50\n",
      "6184/6184 [==============================] - 4s 613us/sample - loss: 0.5859 - accuracy: 0.7717 - val_loss: 0.3933 - val_accuracy: 0.8649\n",
      "Epoch 27/50\n",
      "6184/6184 [==============================] - 4s 601us/sample - loss: 0.5677 - accuracy: 0.7801 - val_loss: 0.3799 - val_accuracy: 0.8604\n",
      "Epoch 28/50\n",
      "6184/6184 [==============================] - 4s 571us/sample - loss: 0.5446 - accuracy: 0.7901 - val_loss: 0.3597 - val_accuracy: 0.8836\n",
      "Epoch 29/50\n",
      "6184/6184 [==============================] - 3s 519us/sample - loss: 0.5434 - accuracy: 0.7888 - val_loss: 0.3619 - val_accuracy: 0.8664\n",
      "Epoch 30/50\n",
      "6184/6184 [==============================] - 4s 597us/sample - loss: 0.5353 - accuracy: 0.7951 - val_loss: 0.3462 - val_accuracy: 0.8926\n",
      "Epoch 31/50\n",
      "6184/6184 [==============================] - 4s 672us/sample - loss: 0.5141 - accuracy: 0.7996 - val_loss: 0.3517 - val_accuracy: 0.8776\n",
      "Epoch 32/50\n",
      "6184/6184 [==============================] - 3s 528us/sample - loss: 0.5091 - accuracy: 0.8050 - val_loss: 0.3321 - val_accuracy: 0.8821\n",
      "Epoch 33/50\n",
      "6184/6184 [==============================] - 3s 552us/sample - loss: 0.4925 - accuracy: 0.8123 - val_loss: 0.3297 - val_accuracy: 0.8851\n",
      "Epoch 34/50\n",
      "6184/6184 [==============================] - 4s 686us/sample - loss: 0.4883 - accuracy: 0.8126 - val_loss: 0.3224 - val_accuracy: 0.8889\n",
      "Epoch 35/50\n",
      "6184/6184 [==============================] - 4s 622us/sample - loss: 0.4712 - accuracy: 0.8207 - val_loss: 0.3060 - val_accuracy: 0.8949\n",
      "Epoch 36/50\n",
      "6184/6184 [==============================] - 4s 583us/sample - loss: 0.4505 - accuracy: 0.8326 - val_loss: 0.2867 - val_accuracy: 0.9092\n",
      "Epoch 37/50\n",
      "6184/6184 [==============================] - 4s 590us/sample - loss: 0.4818 - accuracy: 0.8152 - val_loss: 0.3005 - val_accuracy: 0.8994\n",
      "Epoch 38/50\n",
      "6184/6184 [==============================] - 4s 617us/sample - loss: 0.4585 - accuracy: 0.8231 - val_loss: 0.2677 - val_accuracy: 0.9002\n",
      "Epoch 39/50\n",
      "6184/6184 [==============================] - 4s 620us/sample - loss: 0.4730 - accuracy: 0.8155 - val_loss: 0.2771 - val_accuracy: 0.9092\n",
      "Epoch 40/50\n",
      "6184/6184 [==============================] - 4s 579us/sample - loss: 0.4264 - accuracy: 0.8376 - val_loss: 0.2696 - val_accuracy: 0.9099\n",
      "Epoch 41/50\n",
      "6184/6184 [==============================] - 4s 590us/sample - loss: 0.4540 - accuracy: 0.8300 - val_loss: 0.2555 - val_accuracy: 0.9167\n",
      "Epoch 42/50\n",
      "6184/6184 [==============================] - 4s 609us/sample - loss: 0.4289 - accuracy: 0.8339 - val_loss: 0.2571 - val_accuracy: 0.9182\n",
      "Epoch 43/50\n",
      "6184/6184 [==============================] - 4s 619us/sample - loss: 0.4103 - accuracy: 0.8433 - val_loss: 0.2210 - val_accuracy: 0.9309\n",
      "Epoch 44/50\n",
      "6184/6184 [==============================] - 4s 571us/sample - loss: 0.4094 - accuracy: 0.8436 - val_loss: 0.2471 - val_accuracy: 0.9212\n",
      "Epoch 45/50\n",
      "6184/6184 [==============================] - 4s 596us/sample - loss: 0.4301 - accuracy: 0.8372 - val_loss: 0.2550 - val_accuracy: 0.9174\n",
      "Epoch 46/50\n",
      "6184/6184 [==============================] - 3s 534us/sample - loss: 0.4106 - accuracy: 0.8472 - val_loss: 0.2167 - val_accuracy: 0.9347\n",
      "Epoch 47/50\n",
      "6184/6184 [==============================] - 5s 762us/sample - loss: 0.4242 - accuracy: 0.8381 - val_loss: 0.2194 - val_accuracy: 0.9294\n",
      "Epoch 48/50\n",
      "6184/6184 [==============================] - 4s 611us/sample - loss: 0.3995 - accuracy: 0.8456 - val_loss: 0.2341 - val_accuracy: 0.9174\n",
      "Epoch 49/50\n",
      "6184/6184 [==============================] - 4s 589us/sample - loss: 0.4035 - accuracy: 0.8511 - val_loss: 0.2254 - val_accuracy: 0.9189\n",
      "Epoch 50/50\n",
      "6184/6184 [==============================] - 4s 602us/sample - loss: 0.3881 - accuracy: 0.8499 - val_loss: 0.2155 - val_accuracy: 0.9332\n",
      "Train on 6184 samples, validate on 1332 samples\n",
      "Epoch 1/50\n",
      "6184/6184 [==============================] - 5s 758us/sample - loss: 1.9336 - accuracy: 0.3305 - val_loss: 1.4213 - val_accuracy: 0.4459\n",
      "Epoch 2/50\n",
      "6184/6184 [==============================] - 4s 598us/sample - loss: 1.5448 - accuracy: 0.4039 - val_loss: 1.4847 - val_accuracy: 0.4527\n",
      "Epoch 3/50\n",
      "6184/6184 [==============================] - 4s 575us/sample - loss: 1.3468 - accuracy: 0.4468 - val_loss: 0.9575 - val_accuracy: 0.6194\n",
      "Epoch 4/50\n",
      "6184/6184 [==============================] - 3s 521us/sample - loss: 1.1782 - accuracy: 0.5179 - val_loss: 0.9057 - val_accuracy: 0.6209\n",
      "Epoch 5/50\n",
      "6184/6184 [==============================] - 4s 675us/sample - loss: 1.1128 - accuracy: 0.5450 - val_loss: 0.8996 - val_accuracy: 0.6419\n",
      "Epoch 6/50\n",
      "6184/6184 [==============================] - 3s 510us/sample - loss: 1.0444 - accuracy: 0.5679 - val_loss: 0.8848 - val_accuracy: 0.6261\n",
      "Epoch 7/50\n",
      "6184/6184 [==============================] - 4s 666us/sample - loss: 0.9940 - accuracy: 0.5977 - val_loss: 0.8887 - val_accuracy: 0.6194\n",
      "Epoch 8/50\n",
      "6184/6184 [==============================] - 4s 622us/sample - loss: 0.9737 - accuracy: 0.6028 - val_loss: 0.8249 - val_accuracy: 0.6674\n",
      "Epoch 9/50\n",
      "6184/6184 [==============================] - 4s 610us/sample - loss: 0.9343 - accuracy: 0.6164 - val_loss: 0.7604 - val_accuracy: 0.7057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50\n",
      "6184/6184 [==============================] - 4s 594us/sample - loss: 0.8973 - accuracy: 0.6405 - val_loss: 0.7609 - val_accuracy: 0.6989\n",
      "Epoch 11/50\n",
      "6184/6184 [==============================] - 3s 558us/sample - loss: 0.8779 - accuracy: 0.6431 - val_loss: 0.7966 - val_accuracy: 0.6794\n",
      "Epoch 12/50\n",
      "6184/6184 [==============================] - 4s 597us/sample - loss: 0.8550 - accuracy: 0.6533 - val_loss: 0.7090 - val_accuracy: 0.7117\n",
      "Epoch 13/50\n",
      "6184/6184 [==============================] - 4s 616us/sample - loss: 0.8200 - accuracy: 0.6701 - val_loss: 0.6662 - val_accuracy: 0.7530\n",
      "Epoch 14/50\n",
      "6184/6184 [==============================] - 4s 575us/sample - loss: 0.7946 - accuracy: 0.6790 - val_loss: 0.6365 - val_accuracy: 0.7508\n",
      "Epoch 15/50\n",
      "6184/6184 [==============================] - 4s 567us/sample - loss: 0.7831 - accuracy: 0.6895 - val_loss: 0.6132 - val_accuracy: 0.7755\n",
      "Epoch 16/50\n",
      "6184/6184 [==============================] - 4s 603us/sample - loss: 0.7738 - accuracy: 0.6863 - val_loss: 0.6070 - val_accuracy: 0.7650\n",
      "Epoch 17/50\n",
      "6184/6184 [==============================] - 4s 612us/sample - loss: 0.7477 - accuracy: 0.7015 - val_loss: 0.5748 - val_accuracy: 0.7853\n",
      "Epoch 18/50\n",
      "6184/6184 [==============================] - 3s 546us/sample - loss: 0.7418 - accuracy: 0.7007 - val_loss: 0.5975 - val_accuracy: 0.7748\n",
      "Epoch 19/50\n",
      "6184/6184 [==============================] - 3s 515us/sample - loss: 0.7213 - accuracy: 0.7099 - val_loss: 0.5310 - val_accuracy: 0.8093\n",
      "Epoch 20/50\n",
      "6184/6184 [==============================] - 3s 529us/sample - loss: 0.6860 - accuracy: 0.7324 - val_loss: 0.5290 - val_accuracy: 0.8048\n",
      "Epoch 21/50\n",
      "6184/6184 [==============================] - 4s 616us/sample - loss: 0.6827 - accuracy: 0.7311 - val_loss: 0.4914 - val_accuracy: 0.8258\n",
      "Epoch 22/50\n",
      "6184/6184 [==============================] - 4s 621us/sample - loss: 0.6584 - accuracy: 0.7375 - val_loss: 0.4673 - val_accuracy: 0.8266\n",
      "Epoch 23/50\n",
      "6184/6184 [==============================] - 4s 599us/sample - loss: 0.6427 - accuracy: 0.7447 - val_loss: 0.4726 - val_accuracy: 0.8393\n",
      "Epoch 24/50\n",
      "6184/6184 [==============================] - 4s 611us/sample - loss: 0.6396 - accuracy: 0.7442 - val_loss: 0.4600 - val_accuracy: 0.8348\n",
      "Epoch 25/50\n",
      "6184/6184 [==============================] - 4s 577us/sample - loss: 0.6312 - accuracy: 0.7529 - val_loss: 0.4598 - val_accuracy: 0.8281\n",
      "Epoch 26/50\n",
      "6184/6184 [==============================] - 4s 601us/sample - loss: 0.6053 - accuracy: 0.7642 - val_loss: 0.4343 - val_accuracy: 0.8423\n",
      "Epoch 27/50\n",
      "6184/6184 [==============================] - 4s 606us/sample - loss: 0.5954 - accuracy: 0.7668 - val_loss: 0.4145 - val_accuracy: 0.8514\n",
      "Epoch 28/50\n",
      "6184/6184 [==============================] - 4s 585us/sample - loss: 0.5847 - accuracy: 0.7718 - val_loss: 0.3900 - val_accuracy: 0.8611\n",
      "Epoch 29/50\n",
      "6184/6184 [==============================] - 4s 575us/sample - loss: 0.5862 - accuracy: 0.7739 - val_loss: 0.3953 - val_accuracy: 0.8521\n",
      "Epoch 30/50\n",
      "6184/6184 [==============================] - 4s 622us/sample - loss: 0.5734 - accuracy: 0.7704 - val_loss: 0.3662 - val_accuracy: 0.8656\n",
      "Epoch 31/50\n",
      "6184/6184 [==============================] - 4s 589us/sample - loss: 0.5475 - accuracy: 0.7872 - val_loss: 0.3612 - val_accuracy: 0.8709\n",
      "Epoch 32/50\n",
      "6184/6184 [==============================] - 4s 595us/sample - loss: 0.5490 - accuracy: 0.7838 - val_loss: 0.3286 - val_accuracy: 0.8889\n",
      "Epoch 33/50\n",
      "6184/6184 [==============================] - 4s 648us/sample - loss: 0.5340 - accuracy: 0.7914 - val_loss: 0.3219 - val_accuracy: 0.8881\n",
      "Epoch 34/50\n",
      "6184/6184 [==============================] - 4s 699us/sample - loss: 0.5344 - accuracy: 0.7977 - val_loss: 0.3185 - val_accuracy: 0.8979\n",
      "Epoch 35/50\n",
      "6184/6184 [==============================] - 3s 541us/sample - loss: 0.5236 - accuracy: 0.7920 - val_loss: 0.3020 - val_accuracy: 0.9039\n",
      "Epoch 36/50\n",
      "6184/6184 [==============================] - 3s 545us/sample - loss: 0.5318 - accuracy: 0.7988 - val_loss: 0.3326 - val_accuracy: 0.8836\n",
      "Epoch 37/50\n",
      "6184/6184 [==============================] - 3s 534us/sample - loss: 0.5406 - accuracy: 0.7883 - val_loss: 0.2849 - val_accuracy: 0.9122\n",
      "Epoch 38/50\n",
      "6184/6184 [==============================] - 5s 763us/sample - loss: 0.4854 - accuracy: 0.8134 - val_loss: 0.2988 - val_accuracy: 0.8941\n",
      "Epoch 39/50\n",
      "6184/6184 [==============================] - 4s 618us/sample - loss: 0.4909 - accuracy: 0.8081 - val_loss: 0.2739 - val_accuracy: 0.9129\n",
      "Epoch 40/50\n",
      "6184/6184 [==============================] - 4s 593us/sample - loss: 0.4794 - accuracy: 0.8161 - val_loss: 0.3031 - val_accuracy: 0.8941\n",
      "Epoch 41/50\n",
      "6184/6184 [==============================] - 4s 567us/sample - loss: 0.4913 - accuracy: 0.8084 - val_loss: 0.2508 - val_accuracy: 0.9317\n",
      "Epoch 42/50\n",
      "6184/6184 [==============================] - 4s 597us/sample - loss: 0.4697 - accuracy: 0.8157 - val_loss: 0.2449 - val_accuracy: 0.9152\n",
      "Epoch 43/50\n",
      "6184/6184 [==============================] - 4s 625us/sample - loss: 0.4595 - accuracy: 0.8197 - val_loss: 0.2490 - val_accuracy: 0.9114\n",
      "Epoch 44/50\n",
      "6184/6184 [==============================] - 4s 584us/sample - loss: 0.4673 - accuracy: 0.8250 - val_loss: 0.2390 - val_accuracy: 0.9279\n",
      "Epoch 45/50\n",
      "6184/6184 [==============================] - 4s 579us/sample - loss: 0.4521 - accuracy: 0.8244 - val_loss: 0.2298 - val_accuracy: 0.9272\n",
      "Epoch 46/50\n",
      "6184/6184 [==============================] - 4s 591us/sample - loss: 0.4430 - accuracy: 0.8266 - val_loss: 0.2285 - val_accuracy: 0.9242\n",
      "Epoch 47/50\n",
      "6184/6184 [==============================] - 4s 617us/sample - loss: 0.4322 - accuracy: 0.8373 - val_loss: 0.2285 - val_accuracy: 0.9204\n",
      "Epoch 48/50\n",
      "6184/6184 [==============================] - 3s 497us/sample - loss: 0.4369 - accuracy: 0.8299 - val_loss: 0.2090 - val_accuracy: 0.9339\n",
      "Epoch 49/50\n",
      "6184/6184 [==============================] - 5s 734us/sample - loss: 0.4300 - accuracy: 0.8423 - val_loss: 0.1874 - val_accuracy: 0.9535\n",
      "Epoch 50/50\n",
      "6184/6184 [==============================] - 3s 492us/sample - loss: 0.4299 - accuracy: 0.8341 - val_loss: 0.1844 - val_accuracy: 0.9520\n",
      "Train on 6190 samples, validate on 1334 samples\n",
      "Epoch 1/50\n",
      "6190/6190 [==============================] - 5s 823us/sample - loss: 1.9764 - accuracy: 0.3178 - val_loss: 2.2020 - val_accuracy: 0.3193\n",
      "Epoch 2/50\n",
      "6190/6190 [==============================] - 4s 608us/sample - loss: 1.5716 - accuracy: 0.3834 - val_loss: 1.1720 - val_accuracy: 0.4933\n",
      "Epoch 3/50\n",
      "6190/6190 [==============================] - 4s 593us/sample - loss: 1.3499 - accuracy: 0.4380 - val_loss: 0.9834 - val_accuracy: 0.5825\n",
      "Epoch 4/50\n",
      "6190/6190 [==============================] - 4s 596us/sample - loss: 1.2142 - accuracy: 0.4940 - val_loss: 0.9567 - val_accuracy: 0.6019\n",
      "Epoch 5/50\n",
      "6190/6190 [==============================] - 4s 589us/sample - loss: 1.1136 - accuracy: 0.5372 - val_loss: 0.9119 - val_accuracy: 0.6274\n",
      "Epoch 6/50\n",
      "6190/6190 [==============================] - 3s 507us/sample - loss: 1.0349 - accuracy: 0.5737 - val_loss: 0.8700 - val_accuracy: 0.6357\n",
      "Epoch 7/50\n",
      "6190/6190 [==============================] - 4s 588us/sample - loss: 0.9766 - accuracy: 0.5981 - val_loss: 0.8424 - val_accuracy: 0.6507\n",
      "Epoch 8/50\n",
      "6190/6190 [==============================] - 4s 685us/sample - loss: 0.9431 - accuracy: 0.6183 - val_loss: 0.8005 - val_accuracy: 0.6717\n",
      "Epoch 9/50\n",
      "6190/6190 [==============================] - 4s 605us/sample - loss: 0.8856 - accuracy: 0.6373 - val_loss: 0.8032 - val_accuracy: 0.6799\n",
      "Epoch 10/50\n",
      "6190/6190 [==============================] - 4s 616us/sample - loss: 0.8807 - accuracy: 0.6499 - val_loss: 0.8034 - val_accuracy: 0.6702\n",
      "Epoch 11/50\n",
      "6190/6190 [==============================] - 4s 570us/sample - loss: 0.8677 - accuracy: 0.6477 - val_loss: 0.7561 - val_accuracy: 0.6837\n",
      "Epoch 12/50\n",
      "6190/6190 [==============================] - 4s 601us/sample - loss: 0.8270 - accuracy: 0.6679 - val_loss: 0.6666 - val_accuracy: 0.7376\n",
      "Epoch 13/50\n",
      "6190/6190 [==============================] - 4s 617us/sample - loss: 0.7729 - accuracy: 0.6937 - val_loss: 0.6705 - val_accuracy: 0.7219\n",
      "Epoch 14/50\n",
      "6190/6190 [==============================] - 4s 600us/sample - loss: 0.7600 - accuracy: 0.6973 - val_loss: 0.6242 - val_accuracy: 0.7414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50\n",
      "6190/6190 [==============================] - 4s 573us/sample - loss: 0.7293 - accuracy: 0.7126 - val_loss: 0.5939 - val_accuracy: 0.7774\n",
      "Epoch 16/50\n",
      "6190/6190 [==============================] - 3s 562us/sample - loss: 0.7148 - accuracy: 0.7120 - val_loss: 0.5427 - val_accuracy: 0.7886\n",
      "Epoch 17/50\n",
      "6190/6190 [==============================] - 4s 615us/sample - loss: 0.6997 - accuracy: 0.7242 - val_loss: 0.5250 - val_accuracy: 0.8073\n",
      "Epoch 18/50\n",
      "6190/6190 [==============================] - 3s 521us/sample - loss: 0.6792 - accuracy: 0.7323 - val_loss: 0.5408 - val_accuracy: 0.7879\n",
      "Epoch 19/50\n",
      "6190/6190 [==============================] - 4s 630us/sample - loss: 0.6592 - accuracy: 0.7402 - val_loss: 0.4763 - val_accuracy: 0.8298\n",
      "Epoch 20/50\n",
      "6190/6190 [==============================] - 4s 576us/sample - loss: 0.6394 - accuracy: 0.7575 - val_loss: 0.4883 - val_accuracy: 0.8021\n",
      "Epoch 21/50\n",
      "6190/6190 [==============================] - 5s 773us/sample - loss: 0.6275 - accuracy: 0.7557 - val_loss: 0.4463 - val_accuracy: 0.8493\n",
      "Epoch 22/50\n",
      "6190/6190 [==============================] - 4s 606us/sample - loss: 0.5893 - accuracy: 0.7688 - val_loss: 0.4115 - val_accuracy: 0.8486\n",
      "Epoch 23/50\n",
      "6190/6190 [==============================] - 3s 563us/sample - loss: 0.6083 - accuracy: 0.7606 - val_loss: 0.4212 - val_accuracy: 0.8568\n",
      "Epoch 24/50\n",
      "6190/6190 [==============================] - 4s 587us/sample - loss: 0.5885 - accuracy: 0.7654 - val_loss: 0.4014 - val_accuracy: 0.8516\n",
      "Epoch 25/50\n",
      "6190/6190 [==============================] - 4s 619us/sample - loss: 0.5701 - accuracy: 0.7785 - val_loss: 0.3816 - val_accuracy: 0.8576\n",
      "Epoch 26/50\n",
      "6190/6190 [==============================] - 4s 590us/sample - loss: 0.5658 - accuracy: 0.7835 - val_loss: 0.4128 - val_accuracy: 0.8366\n",
      "Epoch 27/50\n",
      "6190/6190 [==============================] - 3s 503us/sample - loss: 0.5245 - accuracy: 0.8015 - val_loss: 0.3607 - val_accuracy: 0.8711\n",
      "Epoch 28/50\n",
      "6190/6190 [==============================] - 4s 650us/sample - loss: 0.5496 - accuracy: 0.7897 - val_loss: 0.3882 - val_accuracy: 0.8493\n",
      "Epoch 29/50\n",
      "6190/6190 [==============================] - 4s 670us/sample - loss: 0.5349 - accuracy: 0.7887 - val_loss: 0.3496 - val_accuracy: 0.8733\n",
      "Epoch 30/50\n",
      "6190/6190 [==============================] - 4s 603us/sample - loss: 0.5128 - accuracy: 0.8027 - val_loss: 0.3574 - val_accuracy: 0.8628\n",
      "Epoch 31/50\n",
      "6190/6190 [==============================] - 3s 536us/sample - loss: 0.5183 - accuracy: 0.8073 - val_loss: 0.3466 - val_accuracy: 0.8636\n",
      "Epoch 32/50\n",
      "6190/6190 [==============================] - 4s 621us/sample - loss: 0.4929 - accuracy: 0.8074 - val_loss: 0.3183 - val_accuracy: 0.8801\n",
      "Epoch 33/50\n",
      "6190/6190 [==============================] - 4s 601us/sample - loss: 0.4890 - accuracy: 0.8124 - val_loss: 0.3145 - val_accuracy: 0.8846\n",
      "Epoch 34/50\n",
      "6190/6190 [==============================] - 4s 588us/sample - loss: 0.4892 - accuracy: 0.8134 - val_loss: 0.2887 - val_accuracy: 0.8973\n",
      "Epoch 35/50\n",
      "6190/6190 [==============================] - 3s 536us/sample - loss: 0.4784 - accuracy: 0.8108 - val_loss: 0.2870 - val_accuracy: 0.9055\n",
      "Epoch 36/50\n",
      "6190/6190 [==============================] - 4s 613us/sample - loss: 0.4499 - accuracy: 0.8255 - val_loss: 0.2923 - val_accuracy: 0.8951\n",
      "Epoch 37/50\n",
      "6190/6190 [==============================] - 4s 585us/sample - loss: 0.4701 - accuracy: 0.8250 - val_loss: 0.2580 - val_accuracy: 0.9115\n",
      "Epoch 38/50\n",
      "6190/6190 [==============================] - 4s 580us/sample - loss: 0.4500 - accuracy: 0.8300 - val_loss: 0.2541 - val_accuracy: 0.9160\n",
      "Epoch 39/50\n",
      "6190/6190 [==============================] - 4s 606us/sample - loss: 0.4311 - accuracy: 0.8325 - val_loss: 0.2617 - val_accuracy: 0.9123\n",
      "Epoch 40/50\n",
      "6190/6190 [==============================] - 4s 606us/sample - loss: 0.4553 - accuracy: 0.8270 - val_loss: 0.2420 - val_accuracy: 0.9093\n",
      "Epoch 41/50\n",
      "6190/6190 [==============================] - 4s 580us/sample - loss: 0.4552 - accuracy: 0.8299 - val_loss: 0.2509 - val_accuracy: 0.9130\n",
      "Epoch 42/50\n",
      "6190/6190 [==============================] - 4s 583us/sample - loss: 0.4350 - accuracy: 0.8310 - val_loss: 0.2280 - val_accuracy: 0.9258\n",
      "Epoch 43/50\n",
      "6190/6190 [==============================] - 4s 600us/sample - loss: 0.4343 - accuracy: 0.8320 - val_loss: 0.2185 - val_accuracy: 0.9273\n",
      "Epoch 44/50\n",
      "6190/6190 [==============================] - 4s 683us/sample - loss: 0.4208 - accuracy: 0.8438 - val_loss: 0.2222 - val_accuracy: 0.9303\n",
      "Epoch 45/50\n",
      "6190/6190 [==============================] - 4s 620us/sample - loss: 0.4127 - accuracy: 0.8422 - val_loss: 0.2094 - val_accuracy: 0.9280\n",
      "Epoch 46/50\n",
      "6190/6190 [==============================] - 4s 579us/sample - loss: 0.3966 - accuracy: 0.8507 - val_loss: 0.1836 - val_accuracy: 0.9475\n",
      "Epoch 47/50\n",
      "6190/6190 [==============================] - 4s 610us/sample - loss: 0.3989 - accuracy: 0.8533 - val_loss: 0.1841 - val_accuracy: 0.9438\n",
      "Epoch 48/50\n",
      "6190/6190 [==============================] - 4s 647us/sample - loss: 0.4077 - accuracy: 0.8478 - val_loss: 0.1977 - val_accuracy: 0.9363\n",
      "Epoch 49/50\n",
      "6190/6190 [==============================] - 3s 515us/sample - loss: 0.3886 - accuracy: 0.8535 - val_loss: 0.1981 - val_accuracy: 0.9333\n",
      "Epoch 50/50\n",
      "6190/6190 [==============================] - 4s 577us/sample - loss: 0.3859 - accuracy: 0.8527 - val_loss: 0.1770 - val_accuracy: 0.9475\n",
      "Train on 6187 samples, validate on 1333 samples\n",
      "Epoch 1/50\n",
      "6187/6187 [==============================] - 4s 680us/sample - loss: 1.9589 - accuracy: 0.3267 - val_loss: 1.5792 - val_accuracy: 0.4426\n",
      "Epoch 2/50\n",
      "6187/6187 [==============================] - 4s 615us/sample - loss: 1.5471 - accuracy: 0.3955 - val_loss: 1.3437 - val_accuracy: 0.4576\n",
      "Epoch 3/50\n",
      "6187/6187 [==============================] - 4s 594us/sample - loss: 1.3374 - accuracy: 0.4477 - val_loss: 1.0245 - val_accuracy: 0.5679\n",
      "Epoch 4/50\n",
      "6187/6187 [==============================] - 4s 593us/sample - loss: 1.1822 - accuracy: 0.5065 - val_loss: 0.9253 - val_accuracy: 0.6107\n",
      "Epoch 5/50\n",
      "6187/6187 [==============================] - 4s 590us/sample - loss: 1.1074 - accuracy: 0.5373 - val_loss: 0.8731 - val_accuracy: 0.6527\n",
      "Epoch 6/50\n",
      "6187/6187 [==============================] - 4s 615us/sample - loss: 1.0217 - accuracy: 0.5738 - val_loss: 0.8604 - val_accuracy: 0.6632\n",
      "Epoch 7/50\n",
      "6187/6187 [==============================] - 4s 622us/sample - loss: 0.9847 - accuracy: 0.5959 - val_loss: 0.8079 - val_accuracy: 0.6722\n",
      "Epoch 8/50\n",
      "6187/6187 [==============================] - 4s 619us/sample - loss: 0.9376 - accuracy: 0.6068 - val_loss: 0.8269 - val_accuracy: 0.6744\n",
      "Epoch 9/50\n",
      "6187/6187 [==============================] - 4s 651us/sample - loss: 0.8856 - accuracy: 0.6386 - val_loss: 0.8144 - val_accuracy: 0.6542\n",
      "Epoch 10/50\n",
      "6187/6187 [==============================] - 4s 666us/sample - loss: 0.8669 - accuracy: 0.6496 - val_loss: 0.7526 - val_accuracy: 0.7082\n",
      "Epoch 11/50\n",
      "6187/6187 [==============================] - 4s 612us/sample - loss: 0.8410 - accuracy: 0.6570 - val_loss: 0.7039 - val_accuracy: 0.7239\n",
      "Epoch 12/50\n",
      "6187/6187 [==============================] - 4s 590us/sample - loss: 0.8150 - accuracy: 0.6766 - val_loss: 0.6345 - val_accuracy: 0.7689\n",
      "Epoch 13/50\n",
      "6187/6187 [==============================] - 3s 561us/sample - loss: 0.7826 - accuracy: 0.6921 - val_loss: 0.6232 - val_accuracy: 0.7742\n",
      "Epoch 14/50\n",
      "6187/6187 [==============================] - 4s 581us/sample - loss: 0.7623 - accuracy: 0.6965 - val_loss: 0.6164 - val_accuracy: 0.7607\n",
      "Epoch 15/50\n",
      "6187/6187 [==============================] - 5s 746us/sample - loss: 0.7408 - accuracy: 0.6995 - val_loss: 0.6236 - val_accuracy: 0.7614\n",
      "Epoch 16/50\n",
      "6187/6187 [==============================] - 4s 625us/sample - loss: 0.7163 - accuracy: 0.7102 - val_loss: 0.5923 - val_accuracy: 0.7727\n",
      "Epoch 17/50\n",
      "6187/6187 [==============================] - 4s 637us/sample - loss: 0.7037 - accuracy: 0.7220 - val_loss: 0.5516 - val_accuracy: 0.7907\n",
      "Epoch 18/50\n",
      "6187/6187 [==============================] - 4s 653us/sample - loss: 0.6841 - accuracy: 0.7254 - val_loss: 0.5595 - val_accuracy: 0.7779\n",
      "Epoch 19/50\n",
      "6187/6187 [==============================] - 4s 654us/sample - loss: 0.6709 - accuracy: 0.7315 - val_loss: 0.4978 - val_accuracy: 0.8162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50\n",
      "6187/6187 [==============================] - 4s 619us/sample - loss: 0.6634 - accuracy: 0.7340 - val_loss: 0.4832 - val_accuracy: 0.8312\n",
      "Epoch 21/50\n",
      "6187/6187 [==============================] - 3s 519us/sample - loss: 0.6472 - accuracy: 0.7378 - val_loss: 0.5156 - val_accuracy: 0.8080\n",
      "Epoch 22/50\n",
      "6187/6187 [==============================] - 3s 510us/sample - loss: 0.6406 - accuracy: 0.7399 - val_loss: 0.4960 - val_accuracy: 0.8170\n",
      "Epoch 23/50\n",
      "6187/6187 [==============================] - 4s 601us/sample - loss: 0.6413 - accuracy: 0.7438 - val_loss: 0.4576 - val_accuracy: 0.8335\n",
      "Epoch 24/50\n",
      "6187/6187 [==============================] - 4s 569us/sample - loss: 0.6130 - accuracy: 0.7564 - val_loss: 0.4513 - val_accuracy: 0.8290\n",
      "Epoch 25/50\n",
      "6187/6187 [==============================] - 4s 614us/sample - loss: 0.5915 - accuracy: 0.7710 - val_loss: 0.4115 - val_accuracy: 0.8582\n",
      "Epoch 26/50\n",
      "6187/6187 [==============================] - 4s 603us/sample - loss: 0.5784 - accuracy: 0.7690 - val_loss: 0.3896 - val_accuracy: 0.8665\n",
      "Epoch 27/50\n",
      "6187/6187 [==============================] - 4s 597us/sample - loss: 0.5565 - accuracy: 0.7820 - val_loss: 0.3794 - val_accuracy: 0.8770\n",
      "Epoch 28/50\n",
      "6187/6187 [==============================] - 4s 566us/sample - loss: 0.5563 - accuracy: 0.7803 - val_loss: 0.3626 - val_accuracy: 0.8725\n",
      "Epoch 29/50\n",
      "6187/6187 [==============================] - 4s 597us/sample - loss: 0.5579 - accuracy: 0.7821 - val_loss: 0.3767 - val_accuracy: 0.8545\n",
      "Epoch 30/50\n",
      "6187/6187 [==============================] - 4s 622us/sample - loss: 0.5508 - accuracy: 0.7849 - val_loss: 0.3516 - val_accuracy: 0.8710\n",
      "Epoch 31/50\n",
      "6187/6187 [==============================] - 4s 583us/sample - loss: 0.5438 - accuracy: 0.7907 - val_loss: 0.3396 - val_accuracy: 0.8875\n",
      "Epoch 32/50\n",
      "6187/6187 [==============================] - 3s 553us/sample - loss: 0.5240 - accuracy: 0.7912 - val_loss: 0.3232 - val_accuracy: 0.8950\n",
      "Epoch 33/50\n",
      "6187/6187 [==============================] - 4s 590us/sample - loss: 0.5059 - accuracy: 0.8048 - val_loss: 0.3092 - val_accuracy: 0.9025\n",
      "Epoch 34/50\n",
      "6187/6187 [==============================] - 4s 619us/sample - loss: 0.5189 - accuracy: 0.7994 - val_loss: 0.3071 - val_accuracy: 0.8927\n",
      "Epoch 35/50\n",
      "6187/6187 [==============================] - 3s 541us/sample - loss: 0.5146 - accuracy: 0.8025 - val_loss: 0.3050 - val_accuracy: 0.9017\n",
      "Epoch 36/50\n",
      "6187/6187 [==============================] - 3s 503us/sample - loss: 0.4779 - accuracy: 0.8174 - val_loss: 0.2757 - val_accuracy: 0.9122\n",
      "Epoch 37/50\n",
      "6187/6187 [==============================] - 4s 665us/sample - loss: 0.4790 - accuracy: 0.8138 - val_loss: 0.2629 - val_accuracy: 0.9175\n",
      "Epoch 38/50\n",
      "6187/6187 [==============================] - 3s 510us/sample - loss: 0.4759 - accuracy: 0.8190 - val_loss: 0.2692 - val_accuracy: 0.9160\n",
      "Epoch 39/50\n",
      "6187/6187 [==============================] - 4s 681us/sample - loss: 0.4696 - accuracy: 0.8169 - val_loss: 0.2473 - val_accuracy: 0.9190\n",
      "Epoch 40/50\n",
      "6187/6187 [==============================] - 4s 597us/sample - loss: 0.4779 - accuracy: 0.8157 - val_loss: 0.2542 - val_accuracy: 0.9257\n",
      "Epoch 41/50\n",
      "6187/6187 [==============================] - 4s 606us/sample - loss: 0.4513 - accuracy: 0.8314 - val_loss: 0.2487 - val_accuracy: 0.9175\n",
      "Epoch 42/50\n",
      "6187/6187 [==============================] - 4s 582us/sample - loss: 0.4435 - accuracy: 0.8293 - val_loss: 0.2498 - val_accuracy: 0.9212\n",
      "Epoch 43/50\n",
      "6187/6187 [==============================] - 4s 602us/sample - loss: 0.4564 - accuracy: 0.8256 - val_loss: 0.2659 - val_accuracy: 0.9115\n",
      "Epoch 44/50\n",
      "6187/6187 [==============================] - 4s 595us/sample - loss: 0.4504 - accuracy: 0.8287 - val_loss: 0.2514 - val_accuracy: 0.9145\n",
      "Epoch 45/50\n",
      "6187/6187 [==============================] - 4s 599us/sample - loss: 0.4356 - accuracy: 0.8335 - val_loss: 0.2193 - val_accuracy: 0.9280\n",
      "Epoch 46/50\n",
      "6187/6187 [==============================] - 4s 571us/sample - loss: 0.4302 - accuracy: 0.8366 - val_loss: 0.2134 - val_accuracy: 0.9295\n",
      "Epoch 47/50\n",
      "6187/6187 [==============================] - 4s 604us/sample - loss: 0.4269 - accuracy: 0.8359 - val_loss: 0.2415 - val_accuracy: 0.9145\n",
      "Epoch 48/50\n",
      "6187/6187 [==============================] - 3s 497us/sample - loss: 0.4062 - accuracy: 0.8431 - val_loss: 0.2201 - val_accuracy: 0.9310\n",
      "Epoch 49/50\n",
      "6187/6187 [==============================] - 4s 673us/sample - loss: 0.4113 - accuracy: 0.8435 - val_loss: 0.2054 - val_accuracy: 0.9280\n",
      "Epoch 50/50\n",
      "6187/6187 [==============================] - 3s 530us/sample - loss: 0.4152 - accuracy: 0.8380 - val_loss: 0.2033 - val_accuracy: 0.9302\n",
      "Train on 6184 samples, validate on 1332 samples\n",
      "Epoch 1/50\n",
      "6184/6184 [==============================] - 4s 700us/sample - loss: 1.9909 - accuracy: 0.3174 - val_loss: 1.6324 - val_accuracy: 0.4242\n",
      "Epoch 2/50\n",
      "6184/6184 [==============================] - 4s 587us/sample - loss: 1.5637 - accuracy: 0.3821 - val_loss: 1.3407 - val_accuracy: 0.4482\n",
      "Epoch 3/50\n",
      "6184/6184 [==============================] - 4s 632us/sample - loss: 1.3215 - accuracy: 0.4534 - val_loss: 1.0987 - val_accuracy: 0.5465\n",
      "Epoch 4/50\n",
      "6184/6184 [==============================] - 4s 633us/sample - loss: 1.1788 - accuracy: 0.5154 - val_loss: 0.9767 - val_accuracy: 0.5998\n",
      "Epoch 5/50\n",
      "6184/6184 [==============================] - 3s 560us/sample - loss: 1.1334 - accuracy: 0.5285 - val_loss: 0.9487 - val_accuracy: 0.6156\n",
      "Epoch 6/50\n",
      "6184/6184 [==============================] - 3s 524us/sample - loss: 1.0319 - accuracy: 0.5684 - val_loss: 0.8778 - val_accuracy: 0.6426\n",
      "Epoch 7/50\n",
      "6184/6184 [==============================] - 5s 763us/sample - loss: 0.9785 - accuracy: 0.6007 - val_loss: 0.8844 - val_accuracy: 0.6306\n",
      "Epoch 8/50\n",
      "6184/6184 [==============================] - 4s 626us/sample - loss: 0.9273 - accuracy: 0.6171 - val_loss: 0.8001 - val_accuracy: 0.6929\n",
      "Epoch 9/50\n",
      "6184/6184 [==============================] - 3s 486us/sample - loss: 0.8837 - accuracy: 0.6505 - val_loss: 0.7748 - val_accuracy: 0.6959\n",
      "Epoch 10/50\n",
      "6184/6184 [==============================] - 4s 656us/sample - loss: 0.8523 - accuracy: 0.6570 - val_loss: 0.7336 - val_accuracy: 0.7222\n",
      "Epoch 11/50\n",
      "6184/6184 [==============================] - 4s 693us/sample - loss: 0.8181 - accuracy: 0.6700 - val_loss: 0.7372 - val_accuracy: 0.6982\n",
      "Epoch 12/50\n",
      "6184/6184 [==============================] - 3s 564us/sample - loss: 0.8028 - accuracy: 0.6787 - val_loss: 0.6502 - val_accuracy: 0.7673\n",
      "Epoch 13/50\n",
      "6184/6184 [==============================] - 4s 582us/sample - loss: 0.7838 - accuracy: 0.6835 - val_loss: 0.6179 - val_accuracy: 0.7673\n",
      "Epoch 14/50\n",
      "6184/6184 [==============================] - 4s 610us/sample - loss: 0.7457 - accuracy: 0.7007 - val_loss: 0.6428 - val_accuracy: 0.7643\n",
      "Epoch 15/50\n",
      "6184/6184 [==============================] - 4s 600us/sample - loss: 0.7244 - accuracy: 0.7099 - val_loss: 0.5879 - val_accuracy: 0.7755\n",
      "Epoch 16/50\n",
      "6184/6184 [==============================] - 4s 605us/sample - loss: 0.7038 - accuracy: 0.7225 - val_loss: 0.5896 - val_accuracy: 0.7845\n",
      "Epoch 17/50\n",
      "6184/6184 [==============================] - 4s 597us/sample - loss: 0.6899 - accuracy: 0.7248 - val_loss: 0.5667 - val_accuracy: 0.7995\n",
      "Epoch 18/50\n",
      "6184/6184 [==============================] - 3s 551us/sample - loss: 0.6724 - accuracy: 0.7316 - val_loss: 0.5623 - val_accuracy: 0.7830\n",
      "Epoch 19/50\n",
      "6184/6184 [==============================] - 4s 670us/sample - loss: 0.6697 - accuracy: 0.7338 - val_loss: 0.5199 - val_accuracy: 0.8086\n",
      "Epoch 20/50\n",
      "6184/6184 [==============================] - 3s 543us/sample - loss: 0.6524 - accuracy: 0.7453 - val_loss: 0.5271 - val_accuracy: 0.8003\n",
      "Epoch 21/50\n",
      "6184/6184 [==============================] - 3s 505us/sample - loss: 0.6286 - accuracy: 0.7553 - val_loss: 0.5114 - val_accuracy: 0.8086\n",
      "Epoch 22/50\n",
      "6184/6184 [==============================] - 4s 722us/sample - loss: 0.6327 - accuracy: 0.7526 - val_loss: 0.5020 - val_accuracy: 0.8183\n",
      "Epoch 23/50\n",
      "6184/6184 [==============================] - 4s 614us/sample - loss: 0.6116 - accuracy: 0.7618 - val_loss: 0.4550 - val_accuracy: 0.8483\n",
      "Epoch 24/50\n",
      "6184/6184 [==============================] - 4s 599us/sample - loss: 0.6007 - accuracy: 0.7649 - val_loss: 0.4291 - val_accuracy: 0.8544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50\n",
      "6184/6184 [==============================] - 4s 586us/sample - loss: 0.5938 - accuracy: 0.7649 - val_loss: 0.4507 - val_accuracy: 0.8378\n",
      "Epoch 26/50\n",
      "6184/6184 [==============================] - 4s 597us/sample - loss: 0.5598 - accuracy: 0.7854 - val_loss: 0.4179 - val_accuracy: 0.8566\n",
      "Epoch 27/50\n",
      "6184/6184 [==============================] - 4s 606us/sample - loss: 0.5635 - accuracy: 0.7823 - val_loss: 0.4412 - val_accuracy: 0.8386\n",
      "Epoch 28/50\n",
      "6184/6184 [==============================] - 3s 558us/sample - loss: 0.5522 - accuracy: 0.7851 - val_loss: 0.4270 - val_accuracy: 0.8521\n",
      "Epoch 29/50\n",
      "6184/6184 [==============================] - 4s 569us/sample - loss: 0.5408 - accuracy: 0.7896 - val_loss: 0.4010 - val_accuracy: 0.8544\n",
      "Epoch 30/50\n",
      "6184/6184 [==============================] - 4s 631us/sample - loss: 0.5485 - accuracy: 0.7862 - val_loss: 0.4027 - val_accuracy: 0.8581\n",
      "Epoch 31/50\n",
      "6184/6184 [==============================] - 3s 515us/sample - loss: 0.5434 - accuracy: 0.7877 - val_loss: 0.3922 - val_accuracy: 0.8701\n",
      "Epoch 32/50\n",
      "6184/6184 [==============================] - 3s 537us/sample - loss: 0.5147 - accuracy: 0.8027 - val_loss: 0.3508 - val_accuracy: 0.8934\n",
      "Epoch 33/50\n",
      "6184/6184 [==============================] - 3s 566us/sample - loss: 0.4983 - accuracy: 0.8066 - val_loss: 0.3758 - val_accuracy: 0.8619\n",
      "Epoch 34/50\n",
      "6184/6184 [==============================] - 5s 760us/sample - loss: 0.5021 - accuracy: 0.8089 - val_loss: 0.3466 - val_accuracy: 0.8926\n",
      "Epoch 35/50\n",
      "6184/6184 [==============================] - 4s 614us/sample - loss: 0.5041 - accuracy: 0.8103 - val_loss: 0.3377 - val_accuracy: 0.8859\n",
      "Epoch 36/50\n",
      "6184/6184 [==============================] - 4s 568us/sample - loss: 0.4878 - accuracy: 0.8106 - val_loss: 0.3449 - val_accuracy: 0.8761\n",
      "Epoch 37/50\n",
      "6184/6184 [==============================] - 4s 591us/sample - loss: 0.4847 - accuracy: 0.8106 - val_loss: 0.2995 - val_accuracy: 0.8964\n",
      "Epoch 38/50\n",
      "6184/6184 [==============================] - 4s 616us/sample - loss: 0.4662 - accuracy: 0.8310 - val_loss: 0.2777 - val_accuracy: 0.9114\n",
      "Epoch 39/50\n",
      "6184/6184 [==============================] - 4s 586us/sample - loss: 0.4700 - accuracy: 0.8213 - val_loss: 0.2972 - val_accuracy: 0.8964\n",
      "Epoch 40/50\n",
      "6184/6184 [==============================] - 4s 576us/sample - loss: 0.4366 - accuracy: 0.8342 - val_loss: 0.2750 - val_accuracy: 0.9159\n",
      "Epoch 41/50\n",
      "6184/6184 [==============================] - 4s 593us/sample - loss: 0.4578 - accuracy: 0.8279 - val_loss: 0.2837 - val_accuracy: 0.9152\n",
      "Epoch 42/50\n",
      "6184/6184 [==============================] - 3s 494us/sample - loss: 0.4542 - accuracy: 0.8254 - val_loss: 0.2691 - val_accuracy: 0.9189\n",
      "Epoch 43/50\n",
      "6184/6184 [==============================] - 4s 702us/sample - loss: 0.4445 - accuracy: 0.8262 - val_loss: 0.2482 - val_accuracy: 0.9332\n",
      "Epoch 44/50\n",
      "6184/6184 [==============================] - 3s 546us/sample - loss: 0.4329 - accuracy: 0.8291 - val_loss: 0.2909 - val_accuracy: 0.8964\n",
      "Epoch 45/50\n",
      "6184/6184 [==============================] - 4s 728us/sample - loss: 0.4329 - accuracy: 0.8359 - val_loss: 0.2514 - val_accuracy: 0.9287\n",
      "Epoch 46/50\n",
      "6184/6184 [==============================] - 4s 608us/sample - loss: 0.4120 - accuracy: 0.8381 - val_loss: 0.2343 - val_accuracy: 0.9309\n",
      "Epoch 47/50\n",
      "6184/6184 [==============================] - 4s 596us/sample - loss: 0.4100 - accuracy: 0.8383 - val_loss: 0.2471 - val_accuracy: 0.9227\n",
      "Epoch 48/50\n",
      "6184/6184 [==============================] - 4s 576us/sample - loss: 0.4118 - accuracy: 0.8461 - val_loss: 0.2278 - val_accuracy: 0.9182\n",
      "Epoch 49/50\n",
      "6184/6184 [==============================] - 4s 601us/sample - loss: 0.4020 - accuracy: 0.8467 - val_loss: 0.2060 - val_accuracy: 0.9377\n",
      "Epoch 50/50\n",
      "6184/6184 [==============================] - 4s 582us/sample - loss: 0.3830 - accuracy: 0.8528 - val_loss: 0.2030 - val_accuracy: 0.9414\n",
      "Train on 6177 samples, validate on 1331 samples\n",
      "Epoch 1/50\n",
      "6177/6177 [==============================] - 4s 617us/sample - loss: 1.9946 - accuracy: 0.3238 - val_loss: 1.9947 - val_accuracy: 0.3689\n",
      "Epoch 2/50\n",
      "6177/6177 [==============================] - 4s 629us/sample - loss: 1.5590 - accuracy: 0.3827 - val_loss: 1.4429 - val_accuracy: 0.4463\n",
      "Epoch 3/50\n",
      "6177/6177 [==============================] - 4s 603us/sample - loss: 1.3998 - accuracy: 0.4254 - val_loss: 1.2391 - val_accuracy: 0.4748\n",
      "Epoch 4/50\n",
      "6177/6177 [==============================] - 4s 628us/sample - loss: 1.2612 - accuracy: 0.4612 - val_loss: 1.0700 - val_accuracy: 0.5687\n",
      "Epoch 5/50\n",
      "6177/6177 [==============================] - 4s 576us/sample - loss: 1.1755 - accuracy: 0.5020 - val_loss: 0.9830 - val_accuracy: 0.6011\n",
      "Epoch 6/50\n",
      "6177/6177 [==============================] - 4s 575us/sample - loss: 1.0989 - accuracy: 0.5347 - val_loss: 0.9148 - val_accuracy: 0.6311\n",
      "Epoch 7/50\n",
      "6177/6177 [==============================] - 4s 602us/sample - loss: 1.0555 - accuracy: 0.5577 - val_loss: 0.9100 - val_accuracy: 0.6326\n",
      "Epoch 8/50\n",
      "6177/6177 [==============================] - 4s 609us/sample - loss: 1.0082 - accuracy: 0.5752 - val_loss: 0.8699 - val_accuracy: 0.6589\n",
      "Epoch 9/50\n",
      "6177/6177 [==============================] - 4s 579us/sample - loss: 0.9770 - accuracy: 0.5915 - val_loss: 0.8369 - val_accuracy: 0.6717\n",
      "Epoch 10/50\n",
      "6177/6177 [==============================] - 4s 570us/sample - loss: 0.9381 - accuracy: 0.6170 - val_loss: 0.8174 - val_accuracy: 0.6762\n",
      "Epoch 11/50\n",
      "6177/6177 [==============================] - 4s 582us/sample - loss: 0.8966 - accuracy: 0.6272 - val_loss: 0.7556 - val_accuracy: 0.7145\n",
      "Epoch 12/50\n",
      "6177/6177 [==============================] - 3s 527us/sample - loss: 0.8762 - accuracy: 0.6401 - val_loss: 0.7262 - val_accuracy: 0.7265\n",
      "Epoch 13/50\n",
      "6177/6177 [==============================] - 3s 522us/sample - loss: 0.8393 - accuracy: 0.6573 - val_loss: 0.6909 - val_accuracy: 0.7453\n",
      "Epoch 14/50\n",
      "6177/6177 [==============================] - 4s 726us/sample - loss: 0.8056 - accuracy: 0.6757 - val_loss: 0.6537 - val_accuracy: 0.7641\n",
      "Epoch 15/50\n",
      "6177/6177 [==============================] - 4s 668us/sample - loss: 0.8016 - accuracy: 0.6780 - val_loss: 0.6047 - val_accuracy: 0.7746\n",
      "Epoch 16/50\n",
      "6177/6177 [==============================] - 4s 593us/sample - loss: 0.7662 - accuracy: 0.6947 - val_loss: 0.5804 - val_accuracy: 0.7896\n",
      "Epoch 17/50\n",
      "6177/6177 [==============================] - 4s 602us/sample - loss: 0.7297 - accuracy: 0.7130 - val_loss: 0.5763 - val_accuracy: 0.7799\n",
      "Epoch 18/50\n",
      "6177/6177 [==============================] - 4s 593us/sample - loss: 0.7168 - accuracy: 0.7157 - val_loss: 0.5531 - val_accuracy: 0.7964\n",
      "Epoch 19/50\n",
      "6177/6177 [==============================] - 4s 600us/sample - loss: 0.7256 - accuracy: 0.7097 - val_loss: 0.5465 - val_accuracy: 0.8009\n",
      "Epoch 20/50\n",
      "6177/6177 [==============================] - 3s 562us/sample - loss: 0.6909 - accuracy: 0.7243 - val_loss: 0.5144 - val_accuracy: 0.8234\n",
      "Epoch 21/50\n",
      "6177/6177 [==============================] - 3s 529us/sample - loss: 0.6527 - accuracy: 0.7434 - val_loss: 0.4991 - val_accuracy: 0.8114\n",
      "Epoch 22/50\n",
      "6177/6177 [==============================] - 4s 621us/sample - loss: 0.6676 - accuracy: 0.7332 - val_loss: 0.5106 - val_accuracy: 0.8039\n",
      "Epoch 23/50\n",
      "6177/6177 [==============================] - 4s 579us/sample - loss: 0.6486 - accuracy: 0.7483 - val_loss: 0.4454 - val_accuracy: 0.8467\n",
      "Epoch 24/50\n",
      "6177/6177 [==============================] - 4s 581us/sample - loss: 0.6346 - accuracy: 0.7475 - val_loss: 0.4846 - val_accuracy: 0.8197\n",
      "Epoch 25/50\n",
      "6177/6177 [==============================] - 4s 594us/sample - loss: 0.6146 - accuracy: 0.7593 - val_loss: 0.4540 - val_accuracy: 0.8295\n",
      "Epoch 26/50\n",
      "6177/6177 [==============================] - 4s 636us/sample - loss: 0.6178 - accuracy: 0.7606 - val_loss: 0.4688 - val_accuracy: 0.8257\n",
      "Epoch 27/50\n",
      "6177/6177 [==============================] - 4s 583us/sample - loss: 0.6059 - accuracy: 0.7588 - val_loss: 0.4001 - val_accuracy: 0.8685\n",
      "Epoch 28/50\n",
      "6177/6177 [==============================] - 3s 532us/sample - loss: 0.5965 - accuracy: 0.7636 - val_loss: 0.3794 - val_accuracy: 0.8798\n",
      "Epoch 29/50\n",
      "6177/6177 [==============================] - 3s 558us/sample - loss: 0.5679 - accuracy: 0.7790 - val_loss: 0.3714 - val_accuracy: 0.8685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50\n",
      "6177/6177 [==============================] - 4s 626us/sample - loss: 0.5736 - accuracy: 0.7772 - val_loss: 0.3705 - val_accuracy: 0.8715\n",
      "Epoch 31/50\n",
      "6177/6177 [==============================] - 4s 625us/sample - loss: 0.5751 - accuracy: 0.7774 - val_loss: 0.3694 - val_accuracy: 0.8775\n",
      "Epoch 32/50\n",
      "6177/6177 [==============================] - 4s 589us/sample - loss: 0.5700 - accuracy: 0.7717 - val_loss: 0.3682 - val_accuracy: 0.8588\n",
      "Epoch 33/50\n",
      "6177/6177 [==============================] - 4s 602us/sample - loss: 0.5404 - accuracy: 0.7900 - val_loss: 0.3586 - val_accuracy: 0.8678\n",
      "Epoch 34/50\n",
      "6177/6177 [==============================] - 4s 593us/sample - loss: 0.5365 - accuracy: 0.7936 - val_loss: 0.3307 - val_accuracy: 0.8911\n",
      "Epoch 35/50\n",
      "6177/6177 [==============================] - 4s 585us/sample - loss: 0.5373 - accuracy: 0.7944 - val_loss: 0.3200 - val_accuracy: 0.8941\n",
      "Epoch 36/50\n",
      "6177/6177 [==============================] - 4s 588us/sample - loss: 0.5163 - accuracy: 0.7988 - val_loss: 0.3186 - val_accuracy: 0.8971\n",
      "Epoch 37/50\n",
      "6177/6177 [==============================] - 4s 599us/sample - loss: 0.5245 - accuracy: 0.7976 - val_loss: 0.3261 - val_accuracy: 0.8843\n",
      "Epoch 38/50\n",
      "6177/6177 [==============================] - 4s 578us/sample - loss: 0.4895 - accuracy: 0.8159 - val_loss: 0.3010 - val_accuracy: 0.8986\n",
      "Epoch 39/50\n",
      "6177/6177 [==============================] - 4s 602us/sample - loss: 0.5070 - accuracy: 0.8017 - val_loss: 0.2950 - val_accuracy: 0.9076\n",
      "Epoch 40/50\n",
      "6177/6177 [==============================] - 4s 595us/sample - loss: 0.4916 - accuracy: 0.8088 - val_loss: 0.3004 - val_accuracy: 0.8986\n",
      "Epoch 41/50\n",
      "6177/6177 [==============================] - 3s 559us/sample - loss: 0.4977 - accuracy: 0.8064 - val_loss: 0.2791 - val_accuracy: 0.9144\n",
      "Epoch 42/50\n",
      "6177/6177 [==============================] - 3s 552us/sample - loss: 0.4872 - accuracy: 0.8140 - val_loss: 0.2993 - val_accuracy: 0.9046\n",
      "Epoch 43/50\n",
      "6177/6177 [==============================] - 3s 503us/sample - loss: 0.4756 - accuracy: 0.8167 - val_loss: 0.2503 - val_accuracy: 0.9196\n",
      "Epoch 44/50\n",
      "6177/6177 [==============================] - 5s 747us/sample - loss: 0.4640 - accuracy: 0.8164 - val_loss: 0.2397 - val_accuracy: 0.9354\n",
      "Epoch 45/50\n",
      "6177/6177 [==============================] - 4s 578us/sample - loss: 0.4360 - accuracy: 0.8326 - val_loss: 0.2474 - val_accuracy: 0.9361\n",
      "Epoch 46/50\n",
      "6177/6177 [==============================] - 4s 571us/sample - loss: 0.4455 - accuracy: 0.8313 - val_loss: 0.2462 - val_accuracy: 0.9241\n",
      "Epoch 47/50\n",
      "6177/6177 [==============================] - 4s 593us/sample - loss: 0.4305 - accuracy: 0.8347 - val_loss: 0.2330 - val_accuracy: 0.9331\n",
      "Epoch 48/50\n",
      "6177/6177 [==============================] - 4s 625us/sample - loss: 0.4442 - accuracy: 0.8273 - val_loss: 0.2234 - val_accuracy: 0.9361\n",
      "Epoch 49/50\n",
      "6177/6177 [==============================] - 4s 569us/sample - loss: 0.4248 - accuracy: 0.8378 - val_loss: 0.2027 - val_accuracy: 0.9421\n",
      "Epoch 50/50\n",
      "6177/6177 [==============================] - 4s 585us/sample - loss: 0.4267 - accuracy: 0.8391 - val_loss: 0.2061 - val_accuracy: 0.9391\n",
      "Train on 6197 samples, validate on 1335 samples\n",
      "Epoch 1/50\n",
      "6197/6197 [==============================] - 4s 675us/sample - loss: 1.9964 - accuracy: 0.3234 - val_loss: 1.4571 - val_accuracy: 0.4180\n",
      "Epoch 2/50\n",
      "6197/6197 [==============================] - 4s 601us/sample - loss: 1.6130 - accuracy: 0.3687 - val_loss: 1.2143 - val_accuracy: 0.4861\n",
      "Epoch 3/50\n",
      "6197/6197 [==============================] - 3s 483us/sample - loss: 1.4070 - accuracy: 0.4299 - val_loss: 0.9885 - val_accuracy: 0.6060\n",
      "Epoch 4/50\n",
      "6197/6197 [==============================] - 4s 636us/sample - loss: 1.2258 - accuracy: 0.4898 - val_loss: 0.9278 - val_accuracy: 0.6307\n",
      "Epoch 5/50\n",
      "6197/6197 [==============================] - 3s 509us/sample - loss: 1.1252 - accuracy: 0.5325 - val_loss: 0.9144 - val_accuracy: 0.6232\n",
      "Epoch 6/50\n",
      "6197/6197 [==============================] - 5s 738us/sample - loss: 1.0804 - accuracy: 0.5574 - val_loss: 0.8958 - val_accuracy: 0.6330\n",
      "Epoch 7/50\n",
      "6197/6197 [==============================] - 4s 576us/sample - loss: 1.0058 - accuracy: 0.5875 - val_loss: 0.8767 - val_accuracy: 0.6225\n",
      "Epoch 8/50\n",
      "6197/6197 [==============================] - 4s 575us/sample - loss: 0.9655 - accuracy: 0.6034 - val_loss: 0.8225 - val_accuracy: 0.6719\n",
      "Epoch 9/50\n",
      "6197/6197 [==============================] - 4s 627us/sample - loss: 0.9347 - accuracy: 0.6135 - val_loss: 0.7796 - val_accuracy: 0.6914\n",
      "Epoch 10/50\n",
      "6197/6197 [==============================] - 4s 625us/sample - loss: 0.8848 - accuracy: 0.6387 - val_loss: 0.7879 - val_accuracy: 0.6712\n",
      "Epoch 11/50\n",
      "6197/6197 [==============================] - 4s 566us/sample - loss: 0.8587 - accuracy: 0.6590 - val_loss: 0.7082 - val_accuracy: 0.7146\n",
      "Epoch 12/50\n",
      "6197/6197 [==============================] - 4s 584us/sample - loss: 0.8635 - accuracy: 0.6532 - val_loss: 0.7046 - val_accuracy: 0.7266\n",
      "Epoch 13/50\n",
      "6197/6197 [==============================] - 3s 509us/sample - loss: 0.8289 - accuracy: 0.6677 - val_loss: 0.6443 - val_accuracy: 0.7625\n",
      "Epoch 14/50\n",
      "6197/6197 [==============================] - 5s 735us/sample - loss: 0.8045 - accuracy: 0.6800 - val_loss: 0.6276 - val_accuracy: 0.7528\n",
      "Epoch 15/50\n",
      "6197/6197 [==============================] - 4s 575us/sample - loss: 0.7939 - accuracy: 0.6863 - val_loss: 0.6414 - val_accuracy: 0.7498\n",
      "Epoch 16/50\n",
      "6197/6197 [==============================] - 4s 583us/sample - loss: 0.7555 - accuracy: 0.7042 - val_loss: 0.6102 - val_accuracy: 0.7663\n",
      "Epoch 17/50\n",
      "6197/6197 [==============================] - 4s 602us/sample - loss: 0.7317 - accuracy: 0.7034 - val_loss: 0.5964 - val_accuracy: 0.7760\n",
      "Epoch 18/50\n",
      "6197/6197 [==============================] - 4s 600us/sample - loss: 0.7121 - accuracy: 0.7255 - val_loss: 0.5494 - val_accuracy: 0.7895\n",
      "Epoch 19/50\n",
      "6197/6197 [==============================] - 3s 515us/sample - loss: 0.6981 - accuracy: 0.7308 - val_loss: 0.5526 - val_accuracy: 0.7813\n",
      "Epoch 20/50\n",
      "6197/6197 [==============================] - 4s 598us/sample - loss: 0.6718 - accuracy: 0.7360 - val_loss: 0.4861 - val_accuracy: 0.8247\n",
      "Epoch 21/50\n",
      "6197/6197 [==============================] - 4s 721us/sample - loss: 0.6561 - accuracy: 0.7436 - val_loss: 0.4632 - val_accuracy: 0.8232\n",
      "Epoch 22/50\n",
      "6197/6197 [==============================] - 4s 657us/sample - loss: 0.6512 - accuracy: 0.7483 - val_loss: 0.4584 - val_accuracy: 0.8247\n",
      "Epoch 23/50\n",
      "6197/6197 [==============================] - 4s 615us/sample - loss: 0.6303 - accuracy: 0.7573 - val_loss: 0.4410 - val_accuracy: 0.8517\n",
      "Epoch 24/50\n",
      "6197/6197 [==============================] - 4s 621us/sample - loss: 0.6318 - accuracy: 0.7549 - val_loss: 0.4382 - val_accuracy: 0.8442\n",
      "Epoch 25/50\n",
      "6197/6197 [==============================] - 3s 556us/sample - loss: 0.6243 - accuracy: 0.7592 - val_loss: 0.4231 - val_accuracy: 0.8494\n",
      "Epoch 26/50\n",
      "6197/6197 [==============================] - 5s 730us/sample - loss: 0.5967 - accuracy: 0.7659 - val_loss: 0.3777 - val_accuracy: 0.8772\n",
      "Epoch 27/50\n",
      "6197/6197 [==============================] - 4s 586us/sample - loss: 0.5983 - accuracy: 0.7657 - val_loss: 0.3811 - val_accuracy: 0.8787\n",
      "Epoch 28/50\n",
      "6197/6197 [==============================] - 3s 521us/sample - loss: 0.5916 - accuracy: 0.7680 - val_loss: 0.4394 - val_accuracy: 0.8330\n",
      "Epoch 29/50\n",
      "6197/6197 [==============================] - 5s 741us/sample - loss: 0.5967 - accuracy: 0.7638 - val_loss: 0.3906 - val_accuracy: 0.8719\n",
      "Epoch 30/50\n",
      "6197/6197 [==============================] - 4s 624us/sample - loss: 0.5631 - accuracy: 0.7899 - val_loss: 0.3522 - val_accuracy: 0.8794\n",
      "Epoch 31/50\n",
      "6197/6197 [==============================] - 4s 592us/sample - loss: 0.5326 - accuracy: 0.7925 - val_loss: 0.3593 - val_accuracy: 0.8757\n",
      "Epoch 32/50\n",
      "6197/6197 [==============================] - 3s 558us/sample - loss: 0.5372 - accuracy: 0.7907 - val_loss: 0.3391 - val_accuracy: 0.8929\n",
      "Epoch 33/50\n",
      "6197/6197 [==============================] - 3s 486us/sample - loss: 0.5451 - accuracy: 0.7899 - val_loss: 0.3223 - val_accuracy: 0.8989\n",
      "Epoch 34/50\n",
      "6197/6197 [==============================] - 5s 734us/sample - loss: 0.5235 - accuracy: 0.7959 - val_loss: 0.3362 - val_accuracy: 0.8839\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50\n",
      "6197/6197 [==============================] - 3s 498us/sample - loss: 0.5215 - accuracy: 0.7972 - val_loss: 0.2880 - val_accuracy: 0.9131\n",
      "Epoch 36/50\n",
      "6197/6197 [==============================] - 5s 768us/sample - loss: 0.5071 - accuracy: 0.7985 - val_loss: 0.2958 - val_accuracy: 0.8989\n",
      "Epoch 37/50\n",
      "6197/6197 [==============================] - 4s 584us/sample - loss: 0.5025 - accuracy: 0.8099 - val_loss: 0.2910 - val_accuracy: 0.9019\n",
      "Epoch 38/50\n",
      "6197/6197 [==============================] - 4s 597us/sample - loss: 0.5110 - accuracy: 0.8109 - val_loss: 0.2739 - val_accuracy: 0.9146\n",
      "Epoch 39/50\n",
      "6197/6197 [==============================] - 4s 596us/sample - loss: 0.4727 - accuracy: 0.8165 - val_loss: 0.2716 - val_accuracy: 0.9221\n",
      "Epoch 40/50\n",
      "6197/6197 [==============================] - 4s 568us/sample - loss: 0.4648 - accuracy: 0.8172 - val_loss: 0.2434 - val_accuracy: 0.9348\n",
      "Epoch 41/50\n",
      "6197/6197 [==============================] - 3s 552us/sample - loss: 0.4573 - accuracy: 0.8278 - val_loss: 0.2509 - val_accuracy: 0.9243\n",
      "Epoch 42/50\n",
      "6197/6197 [==============================] - 4s 714us/sample - loss: 0.4526 - accuracy: 0.8185 - val_loss: 0.2350 - val_accuracy: 0.9416\n",
      "Epoch 43/50\n",
      "6197/6197 [==============================] - 3s 520us/sample - loss: 0.4521 - accuracy: 0.8270 - val_loss: 0.2378 - val_accuracy: 0.9378\n",
      "Epoch 44/50\n",
      "6197/6197 [==============================] - 4s 571us/sample - loss: 0.4563 - accuracy: 0.8223 - val_loss: 0.2169 - val_accuracy: 0.9431\n",
      "Epoch 45/50\n",
      "6197/6197 [==============================] - 5s 737us/sample - loss: 0.4559 - accuracy: 0.8256 - val_loss: 0.2167 - val_accuracy: 0.9431\n",
      "Epoch 46/50\n",
      "6197/6197 [==============================] - 4s 586us/sample - loss: 0.4438 - accuracy: 0.8309 - val_loss: 0.2331 - val_accuracy: 0.9423\n",
      "Epoch 47/50\n",
      "6197/6197 [==============================] - 4s 632us/sample - loss: 0.4416 - accuracy: 0.8275 - val_loss: 0.2067 - val_accuracy: 0.9453\n",
      "Epoch 48/50\n",
      "6197/6197 [==============================] - 4s 591us/sample - loss: 0.4334 - accuracy: 0.8383 - val_loss: 0.2250 - val_accuracy: 0.9386\n",
      "Epoch 49/50\n",
      "6197/6197 [==============================] - 4s 586us/sample - loss: 0.4253 - accuracy: 0.8343 - val_loss: 0.1964 - val_accuracy: 0.9521\n",
      "Epoch 50/50\n",
      "6197/6197 [==============================] - 4s 577us/sample - loss: 0.4191 - accuracy: 0.8393 - val_loss: 0.1844 - val_accuracy: 0.9573\n",
      "Train on 6200 samples, validate on 1336 samples\n",
      "Epoch 1/50\n",
      "6200/6200 [==============================] - 4s 595us/sample - loss: 2.0182 - accuracy: 0.3176 - val_loss: 1.5055 - val_accuracy: 0.4162\n",
      "Epoch 2/50\n",
      "6200/6200 [==============================] - 3s 498us/sample - loss: 1.6448 - accuracy: 0.3616 - val_loss: 1.4989 - val_accuracy: 0.4326\n",
      "Epoch 3/50\n",
      "6200/6200 [==============================] - 4s 650us/sample - loss: 1.3806 - accuracy: 0.4366 - val_loss: 1.0316 - val_accuracy: 0.5651\n",
      "Epoch 4/50\n",
      "6200/6200 [==============================] - 4s 595us/sample - loss: 1.2287 - accuracy: 0.4906 - val_loss: 0.9739 - val_accuracy: 0.5928\n",
      "Epoch 5/50\n",
      "6200/6200 [==============================] - 4s 574us/sample - loss: 1.1416 - accuracy: 0.5235 - val_loss: 0.9394 - val_accuracy: 0.6205\n",
      "Epoch 6/50\n",
      "6200/6200 [==============================] - 4s 575us/sample - loss: 1.1014 - accuracy: 0.5500 - val_loss: 0.8913 - val_accuracy: 0.6564\n",
      "Epoch 7/50\n",
      "6200/6200 [==============================] - 4s 594us/sample - loss: 1.0359 - accuracy: 0.5753 - val_loss: 0.8558 - val_accuracy: 0.6707\n",
      "Epoch 8/50\n",
      "6200/6200 [==============================] - 4s 575us/sample - loss: 0.9949 - accuracy: 0.5919 - val_loss: 0.8385 - val_accuracy: 0.6789\n",
      "Epoch 9/50\n",
      "6200/6200 [==============================] - 4s 580us/sample - loss: 0.9547 - accuracy: 0.6094 - val_loss: 0.7867 - val_accuracy: 0.7051\n",
      "Epoch 10/50\n",
      "6200/6200 [==============================] - 4s 578us/sample - loss: 0.9105 - accuracy: 0.6315 - val_loss: 0.8429 - val_accuracy: 0.6714\n",
      "Epoch 11/50\n",
      "6200/6200 [==============================] - 4s 591us/sample - loss: 0.9155 - accuracy: 0.6311 - val_loss: 0.7355 - val_accuracy: 0.7096\n",
      "Epoch 12/50\n",
      "6200/6200 [==============================] - 3s 557us/sample - loss: 0.8789 - accuracy: 0.6535 - val_loss: 0.7633 - val_accuracy: 0.6781\n",
      "Epoch 13/50\n",
      "6200/6200 [==============================] - 4s 586us/sample - loss: 0.8474 - accuracy: 0.6553 - val_loss: 0.7058 - val_accuracy: 0.7275\n",
      "Epoch 14/50\n",
      "6200/6200 [==============================] - 4s 604us/sample - loss: 0.8252 - accuracy: 0.6734 - val_loss: 0.6854 - val_accuracy: 0.7268\n",
      "Epoch 15/50\n",
      "6200/6200 [==============================] - 4s 576us/sample - loss: 0.8120 - accuracy: 0.6721 - val_loss: 0.6354 - val_accuracy: 0.7560\n",
      "Epoch 16/50\n",
      "6200/6200 [==============================] - 3s 512us/sample - loss: 0.7796 - accuracy: 0.6939 - val_loss: 0.5932 - val_accuracy: 0.7964\n",
      "Epoch 17/50\n",
      "6200/6200 [==============================] - 4s 580us/sample - loss: 0.7696 - accuracy: 0.7024 - val_loss: 0.5597 - val_accuracy: 0.8061\n",
      "Epoch 18/50\n",
      "6200/6200 [==============================] - 4s 574us/sample - loss: 0.7579 - accuracy: 0.6965 - val_loss: 0.5483 - val_accuracy: 0.8106\n",
      "Epoch 19/50\n",
      "6200/6200 [==============================] - 3s 520us/sample - loss: 0.7192 - accuracy: 0.7148 - val_loss: 0.5476 - val_accuracy: 0.7912\n",
      "Epoch 20/50\n",
      "6200/6200 [==============================] - 5s 762us/sample - loss: 0.7166 - accuracy: 0.7126 - val_loss: 0.5071 - val_accuracy: 0.8211\n",
      "Epoch 21/50\n",
      "6200/6200 [==============================] - 4s 613us/sample - loss: 0.6932 - accuracy: 0.7240 - val_loss: 0.4840 - val_accuracy: 0.8234\n",
      "Epoch 22/50\n",
      "6200/6200 [==============================] - 4s 619us/sample - loss: 0.6880 - accuracy: 0.7313 - val_loss: 0.4863 - val_accuracy: 0.8174\n",
      "Epoch 23/50\n",
      "6200/6200 [==============================] - 3s 563us/sample - loss: 0.6645 - accuracy: 0.7421 - val_loss: 0.4640 - val_accuracy: 0.8301\n",
      "Epoch 24/50\n",
      "6200/6200 [==============================] - 3s 485us/sample - loss: 0.6638 - accuracy: 0.7400 - val_loss: 0.4355 - val_accuracy: 0.8353\n",
      "Epoch 25/50\n",
      "6200/6200 [==============================] - 4s 702us/sample - loss: 0.6475 - accuracy: 0.7469 - val_loss: 0.4512 - val_accuracy: 0.8346\n",
      "Epoch 26/50\n",
      "6200/6200 [==============================] - 3s 542us/sample - loss: 0.6228 - accuracy: 0.7608 - val_loss: 0.4537 - val_accuracy: 0.8376\n",
      "Epoch 27/50\n",
      "6200/6200 [==============================] - 4s 589us/sample - loss: 0.6333 - accuracy: 0.7550 - val_loss: 0.3941 - val_accuracy: 0.8555\n",
      "Epoch 28/50\n",
      "6200/6200 [==============================] - 4s 618us/sample - loss: 0.6097 - accuracy: 0.7602 - val_loss: 0.4273 - val_accuracy: 0.8353\n",
      "Epoch 29/50\n",
      "6200/6200 [==============================] - 4s 598us/sample - loss: 0.5997 - accuracy: 0.7640 - val_loss: 0.3787 - val_accuracy: 0.8600\n",
      "Epoch 30/50\n",
      "6200/6200 [==============================] - 4s 577us/sample - loss: 0.5897 - accuracy: 0.7623 - val_loss: 0.3611 - val_accuracy: 0.8683\n",
      "Epoch 31/50\n",
      "6200/6200 [==============================] - 4s 596us/sample - loss: 0.5668 - accuracy: 0.7831 - val_loss: 0.3665 - val_accuracy: 0.8690\n",
      "Epoch 32/50\n",
      "6200/6200 [==============================] - 4s 579us/sample - loss: 0.5657 - accuracy: 0.7761 - val_loss: 0.3355 - val_accuracy: 0.8765\n",
      "Epoch 33/50\n",
      "6200/6200 [==============================] - 3s 563us/sample - loss: 0.5106 - accuracy: 0.8031 - val_loss: 0.3307 - val_accuracy: 0.8787\n",
      "Epoch 34/50\n",
      "6200/6200 [==============================] - 4s 637us/sample - loss: 0.5354 - accuracy: 0.7984 - val_loss: 0.3133 - val_accuracy: 0.8922\n",
      "Epoch 35/50\n",
      "6200/6200 [==============================] - 3s 548us/sample - loss: 0.5251 - accuracy: 0.7973 - val_loss: 0.3129 - val_accuracy: 0.8907\n",
      "Epoch 36/50\n",
      "6200/6200 [==============================] - 3s 556us/sample - loss: 0.5095 - accuracy: 0.8034 - val_loss: 0.2913 - val_accuracy: 0.9049\n",
      "Epoch 37/50\n",
      "6200/6200 [==============================] - 4s 702us/sample - loss: 0.4987 - accuracy: 0.8068 - val_loss: 0.2662 - val_accuracy: 0.9222\n",
      "Epoch 38/50\n",
      "6200/6200 [==============================] - 3s 544us/sample - loss: 0.4868 - accuracy: 0.8129 - val_loss: 0.2671 - val_accuracy: 0.9199\n",
      "Epoch 39/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6200/6200 [==============================] - 4s 686us/sample - loss: 0.5053 - accuracy: 0.8085 - val_loss: 0.2857 - val_accuracy: 0.9049\n",
      "Epoch 40/50\n",
      "6200/6200 [==============================] - 4s 578us/sample - loss: 0.5051 - accuracy: 0.8034 - val_loss: 0.2762 - val_accuracy: 0.9117\n",
      "Epoch 41/50\n",
      "6200/6200 [==============================] - 4s 581us/sample - loss: 0.4706 - accuracy: 0.8161 - val_loss: 0.2496 - val_accuracy: 0.9222\n",
      "Epoch 42/50\n",
      "6200/6200 [==============================] - 3s 550us/sample - loss: 0.4891 - accuracy: 0.8102 - val_loss: 0.2292 - val_accuracy: 0.9326\n",
      "Epoch 43/50\n",
      "6200/6200 [==============================] - 4s 594us/sample - loss: 0.4797 - accuracy: 0.8192 - val_loss: 0.2423 - val_accuracy: 0.9199\n",
      "Epoch 44/50\n",
      "6200/6200 [==============================] - 3s 561us/sample - loss: 0.4647 - accuracy: 0.8203 - val_loss: 0.2253 - val_accuracy: 0.9349\n",
      "Epoch 45/50\n",
      "6200/6200 [==============================] - 5s 729us/sample - loss: 0.4653 - accuracy: 0.8177 - val_loss: 0.2349 - val_accuracy: 0.9207\n",
      "Epoch 46/50\n",
      "6200/6200 [==============================] - 3s 501us/sample - loss: 0.4505 - accuracy: 0.8318 - val_loss: 0.2182 - val_accuracy: 0.9341\n",
      "Epoch 47/50\n",
      "6200/6200 [==============================] - 5s 728us/sample - loss: 0.4368 - accuracy: 0.8332 - val_loss: 0.1936 - val_accuracy: 0.9469\n",
      "Epoch 48/50\n",
      "6200/6200 [==============================] - 3s 494us/sample - loss: 0.4360 - accuracy: 0.8321 - val_loss: 0.1947 - val_accuracy: 0.9371\n",
      "Epoch 49/50\n",
      "6200/6200 [==============================] - 4s 716us/sample - loss: 0.4357 - accuracy: 0.8315 - val_loss: 0.1879 - val_accuracy: 0.9476\n",
      "Epoch 50/50\n",
      "6200/6200 [==============================] - 3s 497us/sample - loss: 0.4287 - accuracy: 0.8361 - val_loss: 0.1760 - val_accuracy: 0.9551\n"
     ]
    }
   ],
   "source": [
    "left_user_acc = []\n",
    "test_acc = []\n",
    "\n",
    "for i in range(0,9):\n",
    "    acc = train_by_subjects_random_sampling(i)\n",
    "    left_user_acc.append(acc[0])\n",
    "    test_acc.append(acc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1e9ca5e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqMAAAIlCAYAAADhdvGtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAMTQAADE0B0s6tTgAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3debwddX3/8dc7JCTEsBWCLAGCAloUQQRZ6gZFBWRTUNzArS1ILbagBZUqUhWxQBUrCG6A4E8LKAhSpZGiLC1IC8gexKYhUBaFAAGBLJ/fH+fc9HK5SW5Czv1ecl/Px2MeOTPzPTOfOecmed/vfGcmVYUkSZLUwpjWBUiSJGn0MoxKkiSpGcOoJEmSmjGMSpIkqRnDqCRJkpoxjEqSJKkZw6gkSZKaMYxKkp6XklSSXVvXIem5MYxKGrIklyf5XOs6lkaS9ZN8M8n/JnkqyZ1JPp1k5R7v9w3dsDR2wPKp3eWb9nL/i6hpapJ5SS4b7n33yHrAL1sXIem5MYxKWmElWRe4BtgUeDuwGfBx4APAj5KkYXnLXZLxS2hyEHAGsHWSjXtf0eCSjBkY0pdFVd1XVU8vj5oktWMYlbTcJNk1yXVJ/pBkepK/7LdufJKzktyd5PEk/5lkl37rL0xyyoDtbdvtyXthd/5FSS5KMifJvUn+KcnExZT0BWABsFtVXVlVM6vqAmAvYDfgPd3t9vVW7pvk2m59lyfZaEA9hyX5bZInkvwqyRue40dGkm2SXNnd58NJfpFkjaHsM8n7k8xK8u4kdwEPLmF3BwFnAhcABw5SyxuTXJPkyST39/8+kqyT5OwkD3U//6uSvLi77lk95klmJPmz7uu+z3f/JNcCT9IJxDsl+bcks5M8mOT/JVl7KWp6xmn67md5effnb0aSz/aF3nQcl+Se7rZ+m+TgJXxekoaBYVTScpHkJcAPgVOBlwGHA59JckC3yVhgOp0guBXwY+DCJOt0138f2D/JSv02+w7g8qq6v3ta/WfAncCrgH2A7YATF1HPGGA/4NSqerL/uqq6GZjW3X5/xwBHAq8GJgL/2G97HwQ+ChwKvBw4C7gkydTFfzJLdDZwFbAl8BrgnKXc59p0enr3B3Za1E6SvAYYD1xJ57M+aMD6LYCf0PlcXgnsDtzWr8kPgRfT+f5eCZxG5ztdGn8PHA1sQed7nETn52Xb7v42BPqHzSXV1L/+tYB/BS6h81m+H3g3cES3ydu78+8AXgJ8CLh/KeuX1AtV5eTk5DSkCbgc+Nwi1n0bOGHAsk8C0xazvduBg7qvXwA8Duzab/1/A3/WfX0QcN2A9+8EPAWsNMi2XwgUsO8i9v0V4Nbu66ndtu/ot/5dwO/6zf8W2HPANi4Fjl7E9t/Q3ebYAcv79rVpd/4x4LWL2MZi90kncBUwdQjf3TeAE7uvVwIeAHbqt/5M4OJFvHfn7ue8wVB/LoAZ/b67vmN+3xJq3AGY2/d9Lq6m7vrq+3kBPg2cN2D9u4HfdF8fQSfUZjj/zjg5OS15es5jdiSpa0tgyySH9Fs2Fri3bybJx+iEyinAysAqdHrDqKrHk/wEOACYluTVwAZ0euT6tr9Vkjn9tp/udjYAZg6oZ1nGg97U7/V9wFrdntpVgE2AHySpfm3GA7OWYT/9/RNwaZKf0enZ+0FV/S7JpCHu8+GqmrG4HSSZQKdn8I0AVTU/yXl0vouru81eDvy/RWzi5cCdVXXPUh3Zs10/oK4pwHHAnwCT6ZytGwusC9yzhJoG2hLYe8DPx0rAuG4v+fl0AultSf4FuKCqfvEcjkXScmIYlbS8TAJOotND2t88gCTvpdN79VfADXR6QX8EjOvX9gfA6UkOpRNK/7WqHuq3/V8Cg43z+99Blj0APAr8MZ0xkgO9FPjNgGVz+73uC4Ch02sLnZ62Wwa857FBtk133wCrAQ/1W756//VV9Ykk5wB70hnHeWySHfq9f0n7fGIR++9v3+5+/z3/d81WgEeT/HV1hjEsLrwvKdgvGKTNuEHaDaz1DDq/TPwFnYC9CZ3T7H3vXZpfKCbRGX5w7MAVVbUAmJFkMzqn+t8MXJTkzKr6q6XYh6QecMyopOXlRuAlVfWbAdOM7vodgMuq6syqupFOz+NGA7bxEzpB5I10xkD+YMD2XwrMGmQfcwdspy+A/Aj4cLdncKEkLwd2Bf55iMf2QF+9g+x7UeMO76ITaLcesHwb4JGqeqBfrTdX1Reraofuft66jPtclPcBX+vW0jdtRSfw7t1tcxOdoQWDuQnYLMn6i1j/IJ3eTACSTO4/vxg7ACdV1bSqup3O+NeB+11UTQPdCGwxyGe18BeOqnq8qs6rqj8H/ozOuFFJjRlGJS2tFybZesA0CfgHYM8kn0uyRZKXda/2PrT7vruAnZK8NsnL6IwHfMa/Qd0euh8Dx9MZ89m/R/Mc4Gk6p623S7Jpkr2SnLCYWj9B51TtvyR5TZKNkuwLXAT8FPjeUA64qorOlfl/n+QDSV6czpX+R6XfHQEGvOeR7jF+NZ27DGySZB86F/GcDJBklSQndz+TjZPsQSeg37Es+xxMkvXohPszuqF34UTns35ft+nxwJuSfD7JS5NsleQj3WP5N+BXwPlJ/qRby3u6F61Bp8f6bUl2SbIl8E06Y0yX5C7gwCSbJdmNzhjj/hZZ0yC+Brw4yTe67V6S5B1Jju5+Du/r/jz+cZLN6fQW3zGEGiX1WutBq05OTs+fic6FKjXI9Ibu+tcBVwB/AB4GfgHs0V23Cp3xf4/RGUf613Su7D5mwD727G7zR4Psf2PgXGA2ndP8NwJHLKHmDegMHbiPTpj9DfAZYOV+babS76Ki7rI3MOACJDqnk2/rbud/6Yxnfcli9j2RTqC6k84p6tvoBORx3fUr0zm1PItOePst8PEB21jkPulcwDRrCcf/ceDuRazblc4winW7828G/rNby33AV/u1Xaf7/T3S/Q6vAF7UXTce+Fb3e5kJvJPBL2DadMD+t+t+h0/SCbv7MeCCrCXUtPACpu78lnR+yZhDp9f3Wv7vArl9u/OPdev86eK+Oycnp+GbUtV/XLwkSZI0fDxNL0mSpGYMo5IkSWrGMCpJkqRmDKOSJElqxjAqSZKkZgyjkiRJauZ5/zjQ8ePH1+TJk1uXIUmSpEW45557nq6q8YOte96H0cmTJzNr1qzWZUiSJGkRkjy4qHWeppckSVIzhlFJkiQ187w/TS9JklY8CxYswEeWP38kYcyYZevjNIxKkqQR4+mnn2bmzJnMnTu3dSlaSuPGjWOjjTZi5ZVXXqr3GUYlSdKIMXPmTFZddVXWWmstkrQuR0NUVfz+979n5syZbLrppkv1XsOoJEkaERYsWMDcuXNZa621GDvWiPJ8s9Zaa/HQQw+xYMGCpTpl7wVMkiRpROgbI2qP6PNT3/e2tGN9DaOSJElqxj5wSZI0Yu11xIU92/ZFJ+4zpHZJeOyxx5g0adJi21144YUcddRRjB8/nu9+97ucf/75fPKTn1zqC3pGG3tGJUmSloOvf/3rHHvssdxwww1sueWWfPazn+Xpp59uUsv8+fOb7HdZGEYlSZKG6M477+Qtb3kL2223HVtttRWnnHIKAIcddhhXXHEFRx55JDvttBOHHHIIADvttBNbb701DzzwwDO2M2PGDNZee+2F83PmzFk45vIPf/gDBxxwAFtssQVbbbUVb3rTmxa2++53v8v222/PNttsw+tf/3puvvlmAM444wx22203DjroILbddluuvfbaZ+zvvvvuY+edd+ZVr3oVL3vZyzjssMMWju18+umn+fjHP86WW27JVlttxW677bbwfccff/zC5TvssANPPPHE8vooF/I0vSRJ0hDMnz+fd7/73Xz3u9/lpS99KU888QQ77LADO+ywAyeffDK//vWv+djHPsaee+4JwGmnncbVV1+9xNP7A/30pz/l4Ycf5tZbbwXgoYceAuCqq67i+9//Pr/85S8ZP348V1xxBe95z3u48cYbAbjyyiu5/vrr2WyzzZ61zTXWWIOLLrqISZMmMX/+fPbZZx/OP/989t9/f4477jjuuusurrvuOsaPH8+DD3YeI3/mmWdywQUXcNVVV7Haaqvx8MMPM378+GX+/Bal52E0ycnA3sDGwJZVdfMi2h0NfKA7+72q+rte1yZJkjRUd9xxB7fccgvvfOc7Fy577LHHuPXWW9lmm22W23622morbr/9dg499FBe//rXs8ceewCdMak33ngj22+//cK2Dz744MKhAK95zWsGDaLQuW3WkUceyZVXXklV8cADD7D11luz//77c/HFF3PiiScuDJqTJ08G4OKLL+bDH/4wq622GgBrrrnmcjvG/oajZ/Q84EvAlYtqkOR1wLuAVwDzgKuSXFlVPxuG+iRJkpaoqlh77bW54YYbnvO2xo4d+4xxnU8++eTC1y960Yu49dZbueyyy5g2bRp/+7d/yw033EBV8cEPfpBjjz120G0urgf2pJNO4ve//z3XXHMNEyZM4PDDD3/GPlvq+ZjRqvplVc1aQrMDgDOq6vGqegr4Np1wKkmSNCK85CUvYeLEiZx11lkLl/3mN79ZeBp9oFVXXZVHHnlk0HXrrrsu8+bN44477gB4xjZnzZpFEvbee29OOOEEqoq7776bvfbai7POOou7774b6PR2XnfddUOq/eGHH2bddddlwoQJ3H///Zx77rkL1+299958+ctf5qmnngJYeJp+77335tRTT+XRRx8FYPbs2T25MGqkjBndCPhFv/kZwP5tSpEkSXq2sWPHctFFF/E3f/M3nHDCCcyfP5/JkydzzjnnDNr+iCOOYJdddmGVVVbh0ksvZZ111nnGtk4++WR23313pkyZwu67775w3U033cRRRx1FVbFgwQIOPPBAXvGKVwDwhS98gX322Yf58+czd+5c3vKWt7DtttsusfbDDjuMt7/97Wy99dZssMEG7LrrrgvXHXnkkXzqU5/ila98JSuvvDLrr78+l1xyCQceeCD33nsvO+64I+PGjWPixIlMmzaN2bNns8ceeyyXHmKALO1d8pd5R8kMYM/BxowmuQg4q6rO7c6/BTiiqnYZpO3hwOF986uvvvoGs2fP7lndkiRpeMyfP5/p06ez+eabs9JKK7UuR0tpcd9fknuqaspg7xspt3aaCUztN79xd9mzVNVJVTWlb1raK9QkSZI0coyUMHou8L4kL0gyHvgg8P3GNUmSJKnHeh5Gk3wtySxgCjAtyW+6yy9Jsi1AVV0O/DNwE3AbcGlV/bTXtUmSJKmtnl/AVFV/CfzlIMv3GDB/LDD4vQokSZK0QhopV9NLkiQ9L9x59/BcOL3ZhmsMy35aGyljRiVJkjQK2TMqLaW9jrhwWPZz0Yn7DMt+JGkke8cPPtyzbf/zAacOqd0xxxzDJz/5SVZeeeVl3tfJJ32RQz5y+HPaxorKnlFJkqTF+OxnP7vw+e/L6p++fDxz5z63bayo7BmVtFTsGZY0mhxyyCEA7LTTTowZM4ZLL72UOXOe4rhjj+b2227m6aee5JWvejV/d+yXGDduHKecfAI/vuDchT2gp37zHE772j8C8M63vpmMGcN3zv4ha609eeE+5s2bx1+8/wBmP/wQTz75JH/8spfzueO/AnTGjB5//PGcffbZjBkzhlVWWYXLLruMiRMn8p3vfIevfOUrVBXjxo3jvPPOY+rUqcP6+SwPhlFJkqRF+PrXv85pp53G1VdfTd+Ddv7qr9/PdtvvyOe/1AmCnzryo5x95jd42/7v5lunf5WrrrudCRNW4Q9/eIIxGcOxx/0j3z/nDL7/o5/xghc8+2E9K620Eid+9RusueYfUVUc86kj+N5Z3+IVn/s7zjzzTC644AKuuuoqVlttNR5++GHGjx/P5Zdfzuc//3muuOIK1ltvPZ544olh/mSWH8OoJEnSUph26U+48fpf8e1vfA2Ap558kpXHjWPSqquy8dQX87GPHsxrXrszb/jTN7HuehsscXtVxRnfPIXLL7uU+fPm8dhjj7Ld9jsBcPHFF/PhD3+Y1VZbDYA111wTgJ/85CccdNBBrLfeegBMnDixF4c6LAyjkiRJS6Gq+No3zmGjjac+a925F/4r/3XdNVz7H1fx9n3exElf/cbCYLkoF11wLtf+x1Wcc+5PmDRpVc769mn86pqre1T9yOMFTJIkSYux6qqr8sgjjyyc/9M37s7pp3yZefPmAfDI7Nn8z4zfMmfOY/zuwQfYbvud+MuPfpxXbbc9t91yEwAvmLQqjz326KDbf+SRR1hjzT9i0qRVmTPnMX543vcWrtt777059dRTefTRzntnz57N/Pnz2WuvvTjrrLO47777AHjiiSeet6fq7RmVJElLpVcXMo5bKXx03w1Y6Z5HSMaMmJu+H3HEEeyyyy6sssoqXHrppXzyM1/ghOOOYZ/dXsuYMWMYO3YcH/vEMYwfP56/OuT9/OGJx0nCxpu8mLfu/04APvjnf8n73rkP4ydMeNYFTG/d7wB+fukl7L7LDrxw3fXYdrsduf++/wXgwAMP5N5772XHHXdk3LhxTJw4kWnTpvG6172Oo48+mje96U0kYeWVV+a8885j4403Zuutt+aSSy5h/fXXb/J5La1UVesanpMpU6bUrFmzWpehUWS0X00+2o9fUu/D6HpTNhlRYXQgn8A0uPnz5zN9+nQ233xzVlpppWesS3JPVU0Z7H32jEqSloq/kEhanhwzKkmSpGbsGdVSsUdEkiQtT/aMSpKkkaO6k563kixVe8OoJEkaEebOL+bOLxYsmNe6FC2DuXPnkmSpw6in6SVJ0ohxw12Psfpqv2f1Nddh/vz5rcsZVNWCYdnPSD3+wVQV999/P2ussYZhVJIkPX9dfdtjbLD2eNZ7/AnmPzEyH3H5wMPDc3P5+Y+PzONflAkTJrDOOuss9fsMo5IkacSYO7/43uUPMnYMnPfFPVuXM6hPfeInw7Kfc497y7DsZ3lIwpgxyzb60zAqSZJGnHkLeNaN00eKufOH5wqrkXr8y5sXMEmSJKkZw6gkSZKaMYxKkiSpGceMLiWfQCRJkrT82DMqSZKkZgyjkiRJasYwKkmSpGYcMypJS2k4xo47blzSaGHPqCRJkpoxjEqSJKkZw6gkSZKaMYxKkiSpGcOoJEmSmjGMSpIkqRnDqCRJkpoxjEqSJKkZw6gkSZKaMYxKkiSpGcOoJEmSmvHZ9JIkLaW9jriw5/u46MR9er4PaSSwZ1SSJEnNGEYlSZLUjGFUkiRJzRhGJUmS1IxhVJIkSc0YRiVJktSMYVSSJEnNGEYlSZLUjGFUkiRJzRhGJUmS1IxhVJIkSc0YRiVJktSMYVSSJEnNGEYlSZLUjGFUkiRJzRhGJUmS1IxhVJIkSc0YRiVJktSMYVSSJEnNGEYlSZLUjGFUkiRJzRhGJUmS1IxhVJIkSc0YRiVJktSMYVSSJEnNGEYlSZLUjGFUkiRJzRhGJUmS1IxhVJIkSc0YRiVJktSMYVSSJEnNGEYlSZLUjGFUkiRJzRhGJUmS1IxhVJIkSc0YRiVJktSMYVSSJEnNGEYlSZLUjGFUkiRJzRhGJUmS1IxhVJIkSc0YRiVJktSMYVSSJEnNGEYlSZLUTM/DaJLNklydZHqSa5NsMUibCUnOSHJTkpuT/DjJ2r2uTZIkSW0NR8/oacDpVbU58CXgW4O0ORiYBLyiql4O3A/87TDUJkmSpIZ6GkaTrANsA5zdXXQ+sEmSqYM0nwiMSzKWTjCd1cvaJEmS1F6ve0Y3BO6tqnkAVVXATGCjAe1OAx4FHqDTK7o68E89rk2SJEmNDcdp+hown0Ha7Nptty6wHjAb+PRgG0tyeJJZfdOcOXOWa7GSJEkaPr0Oo3cDU7qn3kkSOr2lMwe0OwT4UVU9WVVPA+cAOw+2wao6qaqm9E2TJk3qYfmSJEnqpZ6G0ap6ALgeeG930X7AjKqaMaDpb4E3pwvYE7i5l7VJkiSpveE4TX8wcHCS6cBRwIcAklySZNtum2PojBO9hU4IXRv4u2GoTZIkSQ2N7fUOquoOYMdBlu/R7/VDwP69rkWSJEkji09gkiRJUjOGUUmSJDVjGJUkSVIzhlFJkiQ1YxiVJElSM4ZRSZIkNWMYlSRJUjOGUUmSJDVjGJUkSVIzhlFJkiQ1YxiVJElSM4ZRSZIkNWMYlSRJUjOGUUmSJDVjGJUkSVIzhlFJkiQ1YxiVJElSM4ZRSZIkNWMYlSRJUjOGUUmSJDUztnUBkiQtyTt+8OHltq1/PuDU5bYtSc+dPaOSJElqxjAqSZKkZgyjkiRJasYwKkmSpGYMo5IkSWrGMCpJkqRmDKOSJElqxjAqSZKkZrzp/fOAN3uWJI12/l+44rJnVJIkSc0YRiVJktSMYVSSJEnNGEYlSZLUjGFUkiRJzRhGJUmS1IxhVJIkSc14n1FJkp4HvM+mVlT2jEqSJKkZw6gkSZKa8TS99Dww2k/PLc/jh+fnZyBJKyp7RiVJktSMPaMa8ewVkyRpxWUYlaTngdE+VEPSisswKkmSNMKtyGcJHTMqSZKkZgyjkiRJasYwKkmSpGYMo5IkSWrGMCpJkqRmDKOSJElqxjAqSZKkZgyjkiRJasYwKkmSpGYMo5IkSWrGMCpJkqRmDKOSJElqxjAqSZKkZgyjkiRJasYwKkmSpGYMo5IkSWrGMCpJkqRmDKOSJElqxjAqSZKkZgyjkiRJasYwKkmSpGYMo5IkSWrGMCpJkqRmDKOSJElqxjAqSZKkZgyjkiRJasYwKkmSpGYMo5IkSWrGMCpJkqRmDKOSJElqxjAqSZKkZgyjkiRJasYwKkmSpGYMo5IkSWrGMCpJkqRmDKOSJElqxjAqSZKkZgyjkiRJasYwKkmSpGZ6HkaTbJbk6iTTk1ybZItFtHt9kl8luSXJ7Ul27HVtkiRJamvsMOzjNOD0qjojyf7At4BnBM0k6wNnArtX1W1JJgAThqE2SZIkNdTTntEk6wDbAGd3F50PbJJk6oCmhwJnV9VtAFX1ZFXN7mVtkiRJaq/Xp+k3BO6tqnkAVVXATGCjAe22AFZJMi3JDUm+mmRij2uTJElSY8NxAVMNmM8gbcYBbwDeDmwLrA4cM9jGkhyeZFbfNGfOnOVYqiRJkoZTr8Po3cCUJGMBkoROb+nMAe3+B/hJVT3c7UX9PvDqwTZYVSdV1ZS+adKkST0sX5IkSb3U0zBaVQ8A1wPv7S7aD5hRVTMGNP0esHOS8d353YAbe1mbJEmS2huO0/QHAwcnmQ4cBXwIIMklSbYFqKqrgYuAG5LcBEwGPj0MtUmSJKmhnt/aqaruYMCtnLrL9xgw/yXgS72uR5IkSSOHT2CSJElSM4ZRSZIkNWMYlSRJUjOGUUmSJDVjGJUkSVIzhlFJkiQ1YxiVJElSM4ZRSZIkNWMYlSRJUjNDCqNJjkuyYa+LkSRJ0uiyND2j1yb5UZI/7Vk1kiRJGlWGFEar6hPAxsAFwBeS3Jrk0CQv6Gl1kiRJWqENuWe0qp4GzgG+DEwCDgGmJ3lvj2qTJEnSCm6oY0Y3SPL3wG+BPYG3V9UrgB2AL/SwPkmSJK3Axg6x3XXAN4EdqurevoVVdXeS7/SkMkmSJK3whhpGp1bVU4OtqKrPLMd6JEmSNIoMdczo15Ks1TeTZO0kp/WoJkmSJI0SQw2jr6qq3/fNVNXvgO16U5IkSZJGi6GG0ZX6zyQJMH75lyNJkqTRZKhh9JokX+leVT+Fzu2d/r2HdUmSJGkUGGoYPQJYFbge+E9gIvA3vSpKkiRJo8OQrqavqkeBD/a4FkmSJI0yQ721E0m2AbYGJvQtq6pTelGUJEmSRochhdEkRwIHABsBvwDeCPwcMIxKkiRpmQ11zOiBwE7ArKraj85tnZ7uWVWSJEkaFYYaRp+sqieBMUlSVXcAU3tXliRJkkaDoY4ZfSLJOOAG4Pgks+hcUS9JkiQts6H2jB4KrEznFk9rAq+jc+pekiRJWmZL7BlNshJwYFUdCTwO/HnPq5IkSdKosMSe0aqaD7x6GGqRJEnSKDPU0/QXJTkyyTpJJvZNPa1MkiRJK7yhXsB0QvfP44AC0v1zpV4UJUmSpNFhqI8DHWoPqiRJkjRkhkxJkiQ1M9THgS6gc1r+GarK0/SSJElaZkMdM7pqv9erAAfRue+oJEmStMyGdJq+qh7vN/2uqk4CdutxbZIkSVrBLdOY0SSbARsu51okSZI0ygx1zOiD/N+Y0ZW67zusV0VJkiRpdBjqmNFt+72eB9zXfTKTJEmStMyGGkYLeKCqngRIMiHJ+lV1d+9KkyRJ0opuqGNGzxswn0GWSZIkSUtlqGF05b5eUYCq+gMwvjclSZIkabQYahitJOv0zSR5IZ3eUUmSJGmZDXXM6MnAlUnO6s4fBHyuNyVJkiRptBhSGK2q7yT5b2CP7qIPVdUVvStLkiRJo8FQ7zM6AfhFVV3enR+TZEL/caSSJEnS0hrqmNHLgNX6za8KTFv+5UiSJGk0GWoYnVhVj/TNdF+/oDclSZIkabQYahgdk2Rh+EyyKjCuNyVJkiRptBjq1fTnAJcmObU7/2HgzN6UJEmSpNFiqFfTH5/kPmBvOo8GPQV4vJeFSZIkacU31J5RqurMJNcAHwROBO4BLuhVYZIkSVrxLTGMJpkIvAP4EPBiYBXgNVV1S49rkyRJ0gpusRcwJTkduBvYF/gHYCNgtkFUkiRJy8OSrqZ/F3ATcBpwUVXNozNmVJIkSXrOlhRG1wPOBj4NzEzyebylkyRJkpaTxYbRqppTVd+sqh2B3YAJwMpJrk5y6LBUKEmSpBXWUG96T1XdUlVHABsAJwF79qwqSZIkjQpDDqN9qmpeVZ1XVXv0oiBJkiSNHksdRiVJkqTlxTAqSZKkZgyjkiRJasYwKkmSpGYMo5IkSWrGMCpJkqRmDKOSJElqxjAqSZKkZgyjkiRJasYwKkmSpGYMo5IkSWrGMCpJkqRmDKOSJElqxjAqSZKkZgyjkiRJasYwKkmSpGYMo5IkSWrGMCpJkqRmDKOSJElqxjAqSZKkZgyjkiRJasYwKkmSpGYMo5IkSWrGMCpJkqRmeh5Gk2yW5PIms60AAA85SURBVOok05Ncm2SLxbSdnOT+JOf1ui5JkiS1Nxw9o6cBp1fV5sCXgG8tpu0pwCXDUJMkSZJGgJ6G0STrANsAZ3cXnQ9skmTqIG3fA9wP/KKXNUmSJGnk6HXP6IbAvVU1D6CqCpgJbNS/UZL1gcOBo3pcjyRJkkaQ4ThNXwPmM0ibbwB/W1VzlrSxJIcnmdU3zZmzxLdIkiRphBrb4+3fDUxJMraq5iUJnd7SmQPa7Qh8q7OaScAqSX5WVW8euMGqOgk4qW9+ypQpA8OuJEmSnid62jNaVQ8A1wPv7S7aD5hRVTMGtPujqppaVVOBjwH/MlgQlSRJ0oplOE7THwwcnGQ6nTGhHwJIckmSbYdh/5IkSRqhen2anqq6g85p+IHL91hE+zOAM3pblSRJkkYCn8AkSZKkZgyjkiRJasYwKkmSpGYMo5IkSWrGMCpJkqRmDKOSJElqxjAqSZKkZgyjkiRJasYwKkmSpGYMo5IkSWrGMCpJkqRmDKOSJElqxjAqSZKkZgyjkiRJasYwKkmSpGYMo5IkSWrGMCpJkqRmDKOSJElqxjAqSZKkZgyjkiRJasYwKkmSpGYMo5IkSWrGMCpJkqRmDKOSJElqxjAqSZKkZgyjkiRJasYwKkmSpGYMo5IkSWrGMCpJkqRmDKOSJElqxjAqSZKkZgyjkiRJasYwKkmSpGYMo5IkSWrGMCpJkqRmDKOSJElqxjAqSZKkZgyjkiRJasYwKkmSpGYMo5IkSWrGMCpJkqRmDKOSJElqxjAqSZKkZgyjkiRJasYwKkmSpGYMo5IkSWrGMCpJkqRmDKOSJElqxjAqSZKkZgyjkiRJasYwKkmSpGYMo5IkSWrGMCpJkqRmDKOSJElqxjAqSZKkZgyjkiRJasYwKkmSpGYMo5IkSWrGMCpJkqRmDKOSJElqxjAqSZKkZgyjkiRJasYwKkmSpGYMo5IkSWrGMCpJkqRmDKOSJElqxjAqSZKkZgyjkiRJasYwKkmSpGYMo5IkSWrGMCpJkqRmDKOSJElqxjAqSZKkZgyjkiRJasYwKkmSpGYMo5IkSWrGMCpJkqRmDKOSJElqxjAqSZKkZgyjkiRJasYwKkmSpGYMo5IkSWrGMCpJkqRmDKOSJElqpudhNMlmSa5OMj3JtUm2GKTNAUmuT3JzkpuS/FWv65IkSVJ7w9EzehpwelVtDnwJ+NYgbWYBu1fVy4HXAB9N8ifDUJskSZIa6mkYTbIOsA1wdnfR+cAmSab2b1dVV1XVfd3XjwC3A5v0sjZJkiS11+ue0Q2Be6tqHkBVFTAT2GhRb+iext8RuKzHtUmSJKmx4ThNXwPms6iGSaYAFwKHVNW9i2hzeJJZfdOcOXOWY6mSJEkaTr0Oo3cDU5KMBUgSOr2lMwc2TLI+MA34XFWdu6gNVtVJVTWlb5o0aVKPSpckSVKv9TSMVtUDwPXAe7uL9gNmVNWM/u2SrAf8HDi+qs7sZU2SJEkaOYbjNP3BwMFJpgNHAR8CSHJJkm27bY6lM470o0lu6E4fGIbaJEmS1NDYXu+gqu6gc0HSwOV79Hv958Cf97oWSZIkjSw+gUmSJEnNGEYlSZLUjGFUkiRJzRhGJUmS1IxhVJIkSc0YRiVJktSMYVSSJEnNGEYlSZLUjGFUkiRJzRhGJUmS1IxhVJIkSc0YRiVJktSMYVSSJEnNGEYlSZLUjGFUkiRJzRhGJUmS1IxhVJIkSc0YRiVJktSMYVSSJEnNGEYlSZLUjGFUkiRJzRhGJUmS1IxhVJIkSc0YRiVJktSMYVSSJEnNGEYlSZLUjGFUkiRJzRhGJUmS1IxhVJIkSc0YRiVJktSMYVSSJEnNGEYlSZLUjGFUkiRJzRhGJUmS1IxhVJIkSc0YRiVJktSMYVSSJEnNGEYlSZLUjGFUkiRJzRhGJUmS1IxhVJIkSc0YRiVJktSMYVSSJEnNGEYlSZLUjGFUkiRJzRhGJUmS1IxhVJIkSc0YRiVJktSMYVSSJEnNGEYlSZLUjGFUkiRJzRhGJUmS1IxhVJIkSc0YRiVJktSMYVSSJEnNGEYlSZLUjGFUkiRJzRhGJUmS1IxhVJIkSc0YRiVJktSMYVSSJEnNGEYlSZLUjGFUkiRJzRhGJUmS1IxhVJIkSc0YRiVJktSMYVSSJEnNGEYlSZLUjGFUkiRJzRhGJUmS1IxhVJIkSc0YRiVJktSMYVSSJEnNGEYlSZLUjGFUkiRJzRhGJUmS1IxhVJIkSc0YRiVJktSMYVSSJEnNGEYlSZLUjGFUkiRJzRhGJUmS1IxhVJIkSc0YRiVJktRMz8Noks2SXJ1kepJrk2yxiHZHJ7mrO/19r+uSJElSe8PRM3oacHpVbQ58CfjWwAZJXge8C3gFsAWwe5I3D0NtkiRJaqinYTTJOsA2wNndRecDmySZOqDpAcAZVfV4VT0FfJtOOJUkSdIKrNc9oxsC91bVPICqKmAmsNGAdhsB/9NvfsYgbSRJkrSCSScf9mjjyauAs6rqZf2W/Qo4oqp+2W/ZRd1253bn39Jts8sg2zwcOLzfonWB+3p0CC1NAua0LqKh0X784Gfg8Y/u4wc/g9F+/OBnsCId/+SqGj/YirE93vHdwJQkY6tqXpLQ6S2dOaDdTGBqv/mNB2kDQFWdBJzUg1pHlCSzqmpK6zpaGe3HD34GHv/oPn7wMxjtxw9+BqPl+Ht6mr6qHgCuB97bXbQfMKOqZgxoei7wviQvSDIe+CDw/V7WJkmSpPaG42r6g4GDk0wHjgI+BJDkkiTbAlTV5cA/AzcBtwGXVtVPh6E2SZIkNdTr0/RU1R3AjoMs32PA/LHAsb2u53lkhR+KsASj/fjBz8Dj12j/DEb78YOfwag4/p5ewCRJkiQtjo8DlSRJUjOGUUmSJDVjGB1hkmyW5Ook05Ncm2SL1jUNpyQnJ5mRpJK8vHU9wy3JhCQXdL//G5L8dJAnlq3Qklya5Nfd478iydata2ohyWdG8d+DGUlu7/4M3JDkgNY1Dbck45P8U5I7k9yS5Owlv2vFkGSNft/9Dd1/D+cl+aPWtQ2XJG9O8p9Jrk9yc5L3ta6pl3p+AZOW2mnA6VV1RpL9gW8xyAVgK7DzgC8BV7YupKHTgX+pqkryke78mxrXNJzeUVWzAZLsS+fxwNu0LWl4JdkG2IFF3G95lNi/qm5uXURDXwQWAJt3/y1Yr3VBw6X793/hL6FJPga8vqoealfV8Onek/17wM5V9etuh8TtSX5YVY81La5H7BkdQZKsQ+c/3b7fgM8HNhlNPWNV9cuqmtW6jlaq6smquqT+78rC/wBe1LKm4dYXRLtWp/Mf8qjRvdfy14BDAa8wHYWSvAD4APDJvn8Lqup/21bV1AfodMyMNmt0/1wN+D3wVMNaesqe0ZFlQ+DeqpoH0P1teCawETCjZWFq5jDgotZFDLckZwE7d2d3a1lLA8cCZ1fVf3c6SEatc5KMAa4BPlFVD7YuaBi9mE74ODrJrsAfgGOq6udtyxp+SXYE1gIubl3LcOn+3/8O4IdJHgfWBN5WVU83Lq1n7BkdeQb2hIzq/41GsySfBDYDPtW6luFWVQdV1YbA0cA/tK5nuHT/490OOKV1LY29rqq2onOm6PfAmY3rGW7j6JwRubWqtgU+Anw/yeS2ZTXxQeCsvk6a0SDJWOATwD5VtTHwp8CZK/KYWcPoyHI3MKX7g9g3bmRDRve4sVGpO0bqbcDuVfVE63paqaozgZ2TrNW6lmHyeuClwH8nmQFMAX6WZPemVQ2zqprZ/XMu8GXgtW0rGnb/Q2d4yjkAVXUj8N/Ay1oWNdy6wxUOoDNufDTZGli/qq4CqKpfAfcCWzWtqocMoyNIVT0AXA+8t7toP2BGVc1oVpSGXZLDgXcBbxwwfnKFl2S1JOv3m38rnZ6xUXHhQlV9sarWr6qpVTUVmAW8uar+pXFpwybJC5Ks0W/Ru+j8uzhqVNXvgJ8DbwZIsjGwCXBHy7oaeDvw66q6vXUhw6yvY+olAEk2pTN0Y3rTqnrIMaMjz8HAGd1TtI8CK/TtHAZK8jVgH2BdYFqSOVW1aeOyhk2SKcCJwG+Bf+uOGXyqqrZvWtjwWR04P8kqdHqGHgT27HdBl1Z8L6TzM7ASnWFKvwUOaltSE4cA305yPDAf+ItReBHThxiFFy5V1f1JDgbOS7KAzt+DQ6vqnsal9YyPA5UkSVIznqaXJElSM4ZRSZIkNWMYlSRJUjOGUUmSJDVjGJUkSVIzhlFJWoIkb0vyn0luSHJbkp93H1W5pPddnmTPRaz7ZpJlvpl7kn2TvHox689I8pHu6/cnmZ3k+m79Nyb5TPcWWpLUlPcZlaTFSLIu8HVgu6r6n+6ybXj2o3uXSlX92XMsbV/gOuDaIbafVlX7A3QfK3k68ANg7+dYhyQ9J/aMStLirQfMo/MkKACq6r/6bsSfZEaSl/etS3Jdkjf0e/+u3R7SO5P8Q/cxv8/oNU2yapJvJLk2ya+TfD3JuO66DZKc113+6yR/n2QPOiHyqG5v7VIF26p6kM4zv/80yah6xKSkkccwKkmLdyPw78DMJD9K8vEkGyzF+7cA3kjnudI703nE4UAnAr+sqld3240FPtJddzZwTVW9oqpeAZxcVZcAPwa+WFVbV9U3l/agquph4DeMsuedSxp5DKOStBhVtaCq9gN2An4K/AlwS/d50UNxZlXNraon6ATLXQdpsy/w8SQ30HkO+2uBzZJM6u73H/vV8+CyH82zZDluS5KWiWNGJWkIqup24HbgtCQ/pXOa/CQ6p/BX6td0wpI2NciyAPtW1W+fsbATRnsiyZrApsDNvdqHJA2FPaOStBjdMZt/0m9+TWAT4K7uoruA7bvrXg28ZMAmDkwytnvl+ruBaYPs5sd0xn+O7dtHkk2rag5wJfA3/fY/ufvyUWD1ZTymycC36VzUdOuybEOSlhfDqCQt3ljg00mmd0+jX0Hn1PuF3fWfAj6a5BrgA8AtA97/X3QC6K+BXwDn9VvX10v613R6WG9I8utu+6nddQcCOyS5JcmN/N9Y0u8C716KC5h27d7a6fbu9m8EDhjC+ySpp9K9IFSSNIyS3AJ8qKr+o3UtktSSPaOSNMyS3AHcydDvESpJKyx7RiVJktSMPaOSJElqxjAqSZKkZgyjkiRJasYwKkmSpGYMo5IkSWrGMCpJkqRmDKOSJElq5v8D41MktKL72mUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 800x640 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10,8), dpi=80)\n",
    "\n",
    "#plt.style.use('seaborn-deep')\n",
    "\n",
    "nums = np.arange(9)\n",
    "\n",
    "ax.bar(nums-0.2,left_user_acc,0.4, label='left user acc.')\n",
    "ax.bar(nums+0.2,test_acc,0.3, label='test acc.')\n",
    "ax.set_xticks(nums)\n",
    "\n",
    "ax.set_xlabel('Subject ID')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Leave One User Accuracies')\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "cac696ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left user acc.  [0.94, 0.96, 0.985, 0.98, 0.93085104, 0.96428573, 0.905, 0.97, 0.9893617]\n",
      "test acc. [0.7268623, 0.6975169, 0.7014673, 0.7014673, 0.6958239, 0.74492097, 0.70936793, 0.7268623, 0.6930023]\n"
     ]
    }
   ],
   "source": [
    "print('left user acc. ', left_user_acc)\n",
    "print('test acc.', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff80da0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
