{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbdc3434",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten,Dropout\n",
    "from tensorflow.keras.layers import Conv1D,Conv2D,BatchNormalization,MaxPooling1D,MaxPooling2D,Reshape, Dense, Embedding, LSTM,GRU, Bidirectional, TimeDistributed\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import optimizers\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "026bc9ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d0da37e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training/Valid data shape: (2115, 22, 1000)\n",
      "Test data shape: (443, 22, 1000)\n",
      "Training/Valid target shape: (2115,)\n",
      "Test target shape: (443,)\n",
      "Person train/valid shape: (2115, 1)\n",
      "Person test shape: (443, 1)\n"
     ]
    }
   ],
   "source": [
    "X_test = np.load(\"X_test.npy\")\n",
    "y_test = np.load(\"y_test.npy\")\n",
    "person_train_valid = np.load(\"person_train_valid.npy\")\n",
    "X_train_valid = np.load(\"X_train_valid.npy\")\n",
    "y_train_valid = np.load(\"y_train_valid.npy\")\n",
    "person_test = np.load(\"person_test.npy\")\n",
    "\n",
    "## Printing the shapes of the numpy arrays\n",
    "\n",
    "print ('Training/Valid data shape: {}'.format(X_train_valid.shape))\n",
    "print ('Test data shape: {}'.format(X_test.shape))\n",
    "print ('Training/Valid target shape: {}'.format(y_train_valid.shape))\n",
    "print ('Test target shape: {}'.format(y_test.shape))\n",
    "print ('Person train/valid shape: {}'.format(person_train_valid.shape))\n",
    "print ('Person test shape: {}'.format(person_test.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5143147c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a8965f4bc8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Adjusting the labels to {0,1,2,3}\n",
    "\n",
    "# Cue onset left - 0\n",
    "# Cue onset right - 1\n",
    "# Cue onset foot - 2\n",
    "# Cue onset tongue - 3\n",
    "\n",
    "y_train_valid -= 769\n",
    "y_test -= 769\n",
    "## Visualizing the data\n",
    "\n",
    "ch_data = X_train_valid[:,8,:]\n",
    "\n",
    "\n",
    "class_0_ind = np.where(y_train_valid == 0)\n",
    "ch_data_class_0 = ch_data[class_0_ind]\n",
    "avg_ch_data_class_0 = np.mean(ch_data_class_0,axis=0)\n",
    "\n",
    "\n",
    "class_1_ind = np.where(y_train_valid == 1)\n",
    "ch_data_class_1 = ch_data[class_1_ind]\n",
    "avg_ch_data_class_1 = np.mean(ch_data_class_1,axis=0)\n",
    "\n",
    "class_2_ind = np.where(y_train_valid == 2)\n",
    "ch_data_class_2 = ch_data[class_2_ind]\n",
    "avg_ch_data_class_2 = np.mean(ch_data_class_2,axis=0)\n",
    "\n",
    "class_3_ind = np.where(y_train_valid == 3)\n",
    "ch_data_class_3 = ch_data[class_3_ind]\n",
    "avg_ch_data_class_3 = np.mean(ch_data_class_3,axis=0)\n",
    "\n",
    "\n",
    "plt.plot(np.arange(1000),avg_ch_data_class_0)\n",
    "plt.plot(np.arange(1000),avg_ch_data_class_1)\n",
    "plt.plot(np.arange(1000),avg_ch_data_class_2)\n",
    "plt.plot(np.arange(1000),avg_ch_data_class_3)\n",
    "plt.axvline(x=500, label='line at t=500',c='cyan')\n",
    "\n",
    "plt.legend([\"Cue Onset left\", \"Cue Onset right\", \"Cue onset foot\", \"Cue onset tongue\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aeede2fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X after trimming: (2115, 22, 500)\n",
      "Shape of X after maxpooling: (2115, 22, 250)\n",
      "Shape of X after averaging+noise and concatenating: (4230, 22, 250)\n",
      "Shape of X after subsampling and concatenating: (8460, 22, 250)\n"
     ]
    }
   ],
   "source": [
    "def data_prep(X,y,sub_sample,average,noise):\n",
    "    \n",
    "    total_X = None\n",
    "    total_y = None\n",
    "    \n",
    "    # Trimming the data (sample,22,1000) -> (sample,22,500)\n",
    "    X = X[:,:,0:500]\n",
    "    print('Shape of X after trimming:',X.shape)\n",
    "    \n",
    "    # Maxpooling the data (sample,22,1000) -> (sample,22,500/sub_sample)\n",
    "    X_max = np.max(X.reshape(X.shape[0], X.shape[1], -1, sub_sample), axis=3)\n",
    "    \n",
    "    \n",
    "    total_X = X_max\n",
    "    total_y = y\n",
    "    print('Shape of X after maxpooling:',total_X.shape)\n",
    "    \n",
    "    # Averaging + noise \n",
    "    X_average = np.mean(X.reshape(X.shape[0], X.shape[1], -1, average),axis=3)\n",
    "    X_average = X_average + np.random.normal(0.0, 0.5, X_average.shape)\n",
    "    \n",
    "    total_X = np.vstack((total_X, X_average))\n",
    "    total_y = np.hstack((total_y, y))\n",
    "    print('Shape of X after averaging+noise and concatenating:',total_X.shape)\n",
    "    \n",
    "    # Subsampling\n",
    "    \n",
    "    for i in range(sub_sample):\n",
    "        \n",
    "        X_subsample = X[:, :, i::sub_sample] + \\\n",
    "                            (np.random.normal(0.0, 0.5, X[:, :,i::sub_sample].shape) if noise else 0.0)\n",
    "            \n",
    "        total_X = np.vstack((total_X, X_subsample))\n",
    "        total_y = np.hstack((total_y, y))\n",
    "        \n",
    "    \n",
    "    print('Shape of X after subsampling and concatenating:',total_X.shape)\n",
    "    return total_X,total_y\n",
    "\n",
    "\n",
    "X_train_valid_prep,y_train_valid_prep = data_prep(X_train_valid,y_train_valid,2,2,True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b6dbaad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X after trimming: (2115, 22, 500)\n",
      "Shape of X after maxpooling: (2115, 22, 250)\n",
      "Shape of X after averaging+noise and concatenating: (4230, 22, 250)\n",
      "Shape of X after subsampling and concatenating: (8460, 22, 250)\n",
      "Shape of X after trimming: (443, 22, 500)\n",
      "Shape of X after maxpooling: (443, 22, 250)\n",
      "Shape of X after averaging+noise and concatenating: (886, 22, 250)\n",
      "Shape of X after subsampling and concatenating: (1772, 22, 250)\n",
      "(8460, 22, 250)\n",
      "(8460,)\n",
      "(1772, 22, 250)\n",
      "(1772,)\n",
      "Shape of training set: (6960, 22, 250)\n",
      "Shape of validation set: (1500, 22, 250)\n",
      "Shape of training labels: (6960,)\n",
      "Shape of validation labels: (1500,)\n",
      "Shape of training labels after categorical conversion: (6960, 4)\n",
      "Shape of validation labels after categorical conversion: (1500, 4)\n",
      "Shape of test labels after categorical conversion: (1772, 4)\n",
      "Shape of training set after adding width info: (6960, 22, 250, 1)\n",
      "Shape of validation set after adding width info: (1500, 22, 250, 1)\n",
      "Shape of test set after adding width info: (1772, 22, 250, 1)\n",
      "Shape of training set after dimension reshaping: (6960, 250, 1, 22)\n",
      "Shape of validation set after dimension reshaping: (1500, 250, 1, 22)\n",
      "Shape of test set after dimension reshaping: (1772, 250, 1, 22)\n"
     ]
    }
   ],
   "source": [
    "## Preprocessing the dataset\n",
    "\n",
    "X_train_valid_prep,y_train_valid_prep = data_prep(X_train_valid,y_train_valid,2,2,True)\n",
    "X_test_prep,y_test_prep = data_prep(X_test,y_test,2,2,True)\n",
    "\n",
    "print(X_train_valid_prep.shape)\n",
    "print(y_train_valid_prep.shape)\n",
    "print(X_test_prep.shape)\n",
    "print(y_test_prep.shape)\n",
    "\n",
    "\n",
    "\n",
    "## Random splitting and reshaping the data\n",
    "\n",
    "# First generating the training and validation indices using random splitting\n",
    "ind_valid = np.random.choice(8460, 1500, replace=False)\n",
    "ind_train = np.array(list(set(range(8460)).difference(set(ind_valid))))\n",
    "\n",
    "# Creating the training and validation sets using the generated indices\n",
    "(x_train, x_valid) = X_train_valid_prep[ind_train], X_train_valid_prep[ind_valid] \n",
    "(y_train, y_valid) = y_train_valid_prep[ind_train], y_train_valid_prep[ind_valid]\n",
    "print('Shape of training set:',x_train.shape)\n",
    "print('Shape of validation set:',x_valid.shape)\n",
    "print('Shape of training labels:',y_train.shape)\n",
    "print('Shape of validation labels:',y_valid.shape)\n",
    "\n",
    "\n",
    "# Converting the labels to categorical variables for multiclass classification\n",
    "y_train = to_categorical(y_train, 4)\n",
    "y_valid = to_categorical(y_valid, 4)\n",
    "y_test = to_categorical(y_test_prep, 4)\n",
    "print('Shape of training labels after categorical conversion:',y_train.shape)\n",
    "print('Shape of validation labels after categorical conversion:',y_valid.shape)\n",
    "print('Shape of test labels after categorical conversion:',y_test.shape)\n",
    "\n",
    "# Adding width of the segment to be 1\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
    "x_valid = x_valid.reshape(x_valid.shape[0], x_valid.shape[1], x_train.shape[2], 1)\n",
    "x_test = X_test_prep.reshape(X_test_prep.shape[0], X_test_prep.shape[1], X_test_prep.shape[2], 1)\n",
    "print('Shape of training set after adding width info:',x_train.shape)\n",
    "print('Shape of validation set after adding width info:',x_valid.shape)\n",
    "print('Shape of test set after adding width info:',x_test.shape)\n",
    "\n",
    "\n",
    "# Reshaping the training and validation dataset\n",
    "x_train = np.swapaxes(x_train, 1,3)\n",
    "x_train = np.swapaxes(x_train, 1,2)\n",
    "x_valid = np.swapaxes(x_valid, 1,3)\n",
    "x_valid = np.swapaxes(x_valid, 1,2)\n",
    "x_test = np.swapaxes(x_test, 1,3)\n",
    "x_test = np.swapaxes(x_test, 1,2)\n",
    "print('Shape of training set after dimension reshaping:',x_train.shape)\n",
    "print('Shape of validation set after dimension reshaping:',x_valid.shape)\n",
    "print('Shape of test set after dimension reshaping:',x_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92cbf6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model(time_period=1000):   \n",
    "    time_period = min(time_period, 250)\n",
    "    \n",
    "    # Building the CNN model using sequential class\n",
    "    basic_cnn_model = Sequential()\n",
    "    \n",
    "    # Conv. block 1\n",
    "    basic_cnn_model.add(Conv2D(filters=100, kernel_size=(10,1), padding='same', activation='elu', input_shape=(time_period,1,22)))\n",
    "    basic_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same')) # Read the keras documentation\n",
    "    basic_cnn_model.add(BatchNormalization())\n",
    "    basic_cnn_model.add(Dropout(0.5))\n",
    "\n",
    "    # Conv. block 2\n",
    "    basic_cnn_model.add(Conv2D(filters=100, kernel_size=(10,1), padding='same', activation='elu'))\n",
    "    basic_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "    basic_cnn_model.add(BatchNormalization())\n",
    "    basic_cnn_model.add(Dropout(0.5))\n",
    "\n",
    "    # Conv. block 3\n",
    "    basic_cnn_model.add(Conv2D(filters=100, kernel_size=(10,1), padding='same', activation='elu'))\n",
    "    basic_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "    basic_cnn_model.add(BatchNormalization())\n",
    "    basic_cnn_model.add(Dropout(0.5))\n",
    "\n",
    "    # Conv. block 4\n",
    "    basic_cnn_model.add(Conv2D(filters=100, kernel_size=(10,1), padding='same', activation='elu'))\n",
    "    basic_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "    basic_cnn_model.add(BatchNormalization())\n",
    "    basic_cnn_model.add(Dropout(0.5))\n",
    "\n",
    "    # Output layer with Softmax activation\n",
    "    basic_cnn_model.add(Flatten()) # Flattens the input\n",
    "    basic_cnn_model.add(Dense(4, activation='softmax')) # Output FC layer with softmax activation\n",
    "    \n",
    "    cnn_optimizer = optimizers.Adam(learning_rate)\n",
    "    \n",
    "    basic_cnn_model.compile(loss='categorical_crossentropy',\n",
    "                     optimizer=cnn_optimizer,\n",
    "                     metrics=['accuracy'])\n",
    "\n",
    "    # Printing the model summary\n",
    "    basic_cnn_model.summary()\n",
    "    \n",
    "    return basic_cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f58323b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "learning_rate = 1.5e-3\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21bd7c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_data(time_period=1000):\n",
    "    # different period of time\n",
    "    x_train_time = x_train[:,:time_period,:,:]\n",
    "    y_train_time = y_train\n",
    "    x_valid_time = x_valid[:,:time_period,:,:]\n",
    "    y_valid_time = y_valid\n",
    "    x_test_time = x_test[:,:time_period,:,:]\n",
    "    y_test_time = y_test\n",
    "    \n",
    "    \n",
    "    model = cnn_model(time_period)\n",
    "\n",
    "    # Training and validating the model\n",
    "    cnn_model_results = model.fit(x_train_time,\n",
    "                 y_train_time,\n",
    "                 batch_size=200,\n",
    "                 epochs=epochs,\n",
    "                 validation_data=(x_valid_time, y_valid_time), verbose=True)\n",
    "    \n",
    "    train_score = model.evaluate(x_train_time, y_train_time)\n",
    "    \n",
    "    test_score = model.evaluate(x_test_time, y_test_time)\n",
    "\n",
    "    print('train {:s}: {:.3f}%'.format(model.metrics_names[1], train_score[1]*100))\n",
    "    print('test {:s}: {:.3f}%'.format(model.metrics_names[1], test_score[1]*100))\n",
    "    #print(model.summary())\n",
    "    \n",
    "    return train_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c18773e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================25===================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 25, 1, 100)        22100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 9, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 9, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 9, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 9, 1, 100)         100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 3, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 3, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 3, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 3, 1, 100)         100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 1, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 1, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 1, 1, 100)         100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 1, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 1, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 404       \n",
      "=================================================================\n",
      "Total params: 324,404\n",
      "Trainable params: 323,604\n",
      "Non-trainable params: 800\n",
      "_________________________________________________________________\n",
      "Train on 6960 samples, validate on 1500 samples\n",
      "Epoch 1/50\n",
      "6960/6960 [==============================] - 24s 3ms/sample - loss: 2.0586 - accuracy: 0.2749 - val_loss: 1.4905 - val_accuracy: 0.2913\n",
      "Epoch 2/50\n",
      "6960/6960 [==============================] - 4s 643us/sample - loss: 1.7701 - accuracy: 0.2784 - val_loss: 1.5605 - val_accuracy: 0.2813\n",
      "Epoch 3/50\n",
      "6960/6960 [==============================] - 3s 489us/sample - loss: 1.6429 - accuracy: 0.2799 - val_loss: 1.4652 - val_accuracy: 0.2947\n",
      "Epoch 4/50\n",
      "6960/6960 [==============================] - 4s 608us/sample - loss: 1.5284 - accuracy: 0.3000 - val_loss: 1.3417 - val_accuracy: 0.3380\n",
      "Epoch 5/50\n",
      "6960/6960 [==============================] - 3s 436us/sample - loss: 1.4708 - accuracy: 0.3134 - val_loss: 1.3199 - val_accuracy: 0.3593\n",
      "Epoch 6/50\n",
      "6960/6960 [==============================] - 4s 618us/sample - loss: 1.4069 - accuracy: 0.3329 - val_loss: 1.2952 - val_accuracy: 0.3813\n",
      "Epoch 7/50\n",
      "6960/6960 [==============================] - 3s 405us/sample - loss: 1.3687 - accuracy: 0.3543 - val_loss: 1.2859 - val_accuracy: 0.3880\n",
      "Epoch 8/50\n",
      "6960/6960 [==============================] - 4s 639us/sample - loss: 1.3313 - accuracy: 0.3711 - val_loss: 1.2669 - val_accuracy: 0.4093\n",
      "Epoch 9/50\n",
      "6960/6960 [==============================] - 3s 412us/sample - loss: 1.3041 - accuracy: 0.3841 - val_loss: 1.2523 - val_accuracy: 0.4300\n",
      "Epoch 10/50\n",
      "6960/6960 [==============================] - 3s 472us/sample - loss: 1.2817 - accuracy: 0.4040 - val_loss: 1.2376 - val_accuracy: 0.4247\n",
      "Epoch 11/50\n",
      "6960/6960 [==============================] - 3s 410us/sample - loss: 1.2602 - accuracy: 0.4213 - val_loss: 1.2344 - val_accuracy: 0.4300\n",
      "Epoch 12/50\n",
      "6960/6960 [==============================] - 5s 657us/sample - loss: 1.2449 - accuracy: 0.4284 - val_loss: 1.2158 - val_accuracy: 0.4507\n",
      "Epoch 13/50\n",
      "6960/6960 [==============================] - 3s 496us/sample - loss: 1.2220 - accuracy: 0.4417 - val_loss: 1.1998 - val_accuracy: 0.4467\n",
      "Epoch 14/50\n",
      "6960/6960 [==============================] - 3s 428us/sample - loss: 1.2145 - accuracy: 0.4513 - val_loss: 1.1723 - val_accuracy: 0.4740\n",
      "Epoch 15/50\n",
      "6960/6960 [==============================] - 3s 474us/sample - loss: 1.1990 - accuracy: 0.4614 - val_loss: 1.1549 - val_accuracy: 0.4973\n",
      "Epoch 16/50\n",
      "6960/6960 [==============================] - 2s 330us/sample - loss: 1.1818 - accuracy: 0.4675 - val_loss: 1.1364 - val_accuracy: 0.5020\n",
      "Epoch 17/50\n",
      "6960/6960 [==============================] - 3s 475us/sample - loss: 1.1717 - accuracy: 0.4739 - val_loss: 1.1215 - val_accuracy: 0.5093\n",
      "Epoch 18/50\n",
      "6960/6960 [==============================] - 2s 302us/sample - loss: 1.1510 - accuracy: 0.4917 - val_loss: 1.1054 - val_accuracy: 0.5267\n",
      "Epoch 19/50\n",
      "6960/6960 [==============================] - 2s 228us/sample - loss: 1.1452 - accuracy: 0.5014 - val_loss: 1.1130 - val_accuracy: 0.5147\n",
      "Epoch 20/50\n",
      "6960/6960 [==============================] - 2s 241us/sample - loss: 1.1265 - accuracy: 0.5112 - val_loss: 1.0813 - val_accuracy: 0.5480\n",
      "Epoch 21/50\n",
      "6960/6960 [==============================] - 3s 491us/sample - loss: 1.1035 - accuracy: 0.5266 - val_loss: 1.0489 - val_accuracy: 0.5513\n",
      "Epoch 22/50\n",
      "6960/6960 [==============================] - 2s 273us/sample - loss: 1.0932 - accuracy: 0.5297 - val_loss: 1.0316 - val_accuracy: 0.5653\n",
      "Epoch 23/50\n",
      "6960/6960 [==============================] - 2s 323us/sample - loss: 1.0749 - accuracy: 0.5338 - val_loss: 1.0096 - val_accuracy: 0.5767\n",
      "Epoch 24/50\n",
      "6960/6960 [==============================] - 4s 569us/sample - loss: 1.0685 - accuracy: 0.5398 - val_loss: 1.0074 - val_accuracy: 0.5787\n",
      "Epoch 25/50\n",
      "6960/6960 [==============================] - 2s 316us/sample - loss: 1.0471 - accuracy: 0.5533 - val_loss: 0.9916 - val_accuracy: 0.5927\n",
      "Epoch 26/50\n",
      "6960/6960 [==============================] - 3s 393us/sample - loss: 1.0317 - accuracy: 0.5645 - val_loss: 0.9641 - val_accuracy: 0.5980\n",
      "Epoch 27/50\n",
      "6960/6960 [==============================] - 3s 483us/sample - loss: 1.0290 - accuracy: 0.5608 - val_loss: 1.0213 - val_accuracy: 0.5733\n",
      "Epoch 28/50\n",
      "6960/6960 [==============================] - 3s 392us/sample - loss: 0.9966 - accuracy: 0.5907 - val_loss: 0.8995 - val_accuracy: 0.6513\n",
      "Epoch 29/50\n",
      "6960/6960 [==============================] - 4s 614us/sample - loss: 0.9668 - accuracy: 0.5950 - val_loss: 0.9071 - val_accuracy: 0.6333\n",
      "Epoch 30/50\n",
      "6960/6960 [==============================] - 3s 397us/sample - loss: 0.9810 - accuracy: 0.5869 - val_loss: 0.8874 - val_accuracy: 0.6500\n",
      "Epoch 31/50\n",
      "6960/6960 [==============================] - 4s 635us/sample - loss: 0.9588 - accuracy: 0.6013 - val_loss: 0.8604 - val_accuracy: 0.6467\n",
      "Epoch 32/50\n",
      "6960/6960 [==============================] - 3s 387us/sample - loss: 0.9295 - accuracy: 0.6142 - val_loss: 0.8503 - val_accuracy: 0.6627\n",
      "Epoch 33/50\n",
      "6960/6960 [==============================] - 3s 474us/sample - loss: 0.9263 - accuracy: 0.6154 - val_loss: 0.8348 - val_accuracy: 0.6727\n",
      "Epoch 34/50\n",
      "6960/6960 [==============================] - 3s 490us/sample - loss: 0.9179 - accuracy: 0.6198 - val_loss: 0.7985 - val_accuracy: 0.6940\n",
      "Epoch 35/50\n",
      "6960/6960 [==============================] - 4s 536us/sample - loss: 0.9014 - accuracy: 0.6328 - val_loss: 0.8035 - val_accuracy: 0.6813\n",
      "Epoch 36/50\n",
      "6960/6960 [==============================] - 3s 393us/sample - loss: 0.8902 - accuracy: 0.6349 - val_loss: 0.7832 - val_accuracy: 0.6940\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6960/6960 [==============================] - 3s 453us/sample - loss: 0.8730 - accuracy: 0.6353 - val_loss: 0.7732 - val_accuracy: 0.6880\n",
      "Epoch 38/50\n",
      "6960/6960 [==============================] - 3s 394us/sample - loss: 0.8658 - accuracy: 0.6407 - val_loss: 0.7456 - val_accuracy: 0.7140\n",
      "Epoch 39/50\n",
      "6960/6960 [==============================] - 6s 818us/sample - loss: 0.9788 - accuracy: 0.5911 - val_loss: 0.8634 - val_accuracy: 0.6353\n",
      "Epoch 20/50\n",
      "6960/6960 [==============================] - 6s 809us/sample - loss: 0.9493 - accuracy: 0.6122 - val_loss: 0.9287 - val_accuracy: 0.6073\n",
      "Epoch 21/50\n",
      "6960/6960 [==============================] - 5s 717us/sample - loss: 0.9490 - accuracy: 0.6063 - val_loss: 0.7850 - val_accuracy: 0.6820\n",
      "Epoch 22/50\n",
      "6960/6960 [==============================] - 6s 849us/sample - loss: 0.9114 - accuracy: 0.6240 - val_loss: 0.7630 - val_accuracy: 0.6873\n",
      "Epoch 23/50\n",
      "6960/6960 [==============================] - 5s 730us/sample - loss: 0.8851 - accuracy: 0.6362 - val_loss: 0.7308 - val_accuracy: 0.6987\n",
      "Epoch 24/50\n",
      "6960/6960 [==============================] - 5s 787us/sample - loss: 0.8580 - accuracy: 0.6467 - val_loss: 0.6862 - val_accuracy: 0.7240\n",
      "Epoch 25/50\n",
      "6960/6960 [==============================] - 5s 709us/sample - loss: 0.8409 - accuracy: 0.6575 - val_loss: 0.6852 - val_accuracy: 0.7227\n",
      "Epoch 26/50\n",
      "6960/6960 [==============================] - 5s 729us/sample - loss: 0.8176 - accuracy: 0.6691 - val_loss: 0.6862 - val_accuracy: 0.7260\n",
      "Epoch 27/50\n",
      "6960/6960 [==============================] - 6s 903us/sample - loss: 0.7941 - accuracy: 0.6757 - val_loss: 0.7206 - val_accuracy: 0.7180\n",
      "Epoch 28/50\n",
      "6960/6960 [==============================] - 6s 843us/sample - loss: 0.7890 - accuracy: 0.6858 - val_loss: 0.6126 - val_accuracy: 0.7500\n",
      "Epoch 29/50\n",
      "6960/6960 [==============================] - 3s 491us/sample - loss: 0.7541 - accuracy: 0.6909 - val_loss: 0.5879 - val_accuracy: 0.7773\n",
      "Epoch 30/50\n",
      "6960/6960 [==============================] - 3s 455us/sample - loss: 0.7429 - accuracy: 0.7047 - val_loss: 0.5428 - val_accuracy: 0.7933\n",
      "Epoch 31/50\n",
      "6960/6960 [==============================] - 5s 715us/sample - loss: 0.7109 - accuracy: 0.7213 - val_loss: 0.5351 - val_accuracy: 0.7967\n",
      "Epoch 32/50\n",
      "6960/6960 [==============================] - 3s 482us/sample - loss: 0.7135 - accuracy: 0.7221 - val_loss: 0.5332 - val_accuracy: 0.8033\n",
      "Epoch 33/50\n",
      "6960/6960 [==============================] - 5s 694us/sample - loss: 0.7043 - accuracy: 0.7167 - val_loss: 0.4984 - val_accuracy: 0.8120\n",
      "Epoch 34/50\n",
      "6960/6960 [==============================] - 4s 520us/sample - loss: 0.6655 - accuracy: 0.7412 - val_loss: 0.4676 - val_accuracy: 0.8333\n",
      "Epoch 35/50\n",
      "6960/6960 [==============================] - 6s 850us/sample - loss: 0.6530 - accuracy: 0.7420 - val_loss: 0.4747 - val_accuracy: 0.8160\n",
      "Epoch 36/50\n",
      "6960/6960 [==============================] - 6s 829us/sample - loss: 0.6425 - accuracy: 0.7468 - val_loss: 0.4274 - val_accuracy: 0.8467\n",
      "Epoch 37/50\n",
      "6960/6960 [==============================] - 6s 895us/sample - loss: 0.6272 - accuracy: 0.7568 - val_loss: 0.4168 - val_accuracy: 0.8567\n",
      "Epoch 38/50\n",
      "6960/6960 [==============================] - 5s 719us/sample - loss: 0.6146 - accuracy: 0.7609 - val_loss: 0.4032 - val_accuracy: 0.8560\n",
      "Epoch 39/50\n",
      "6960/6960 [==============================] - 5s 730us/sample - loss: 0.6010 - accuracy: 0.7648 - val_loss: 0.4003 - val_accuracy: 0.8533\n",
      "Epoch 40/50\n",
      "6960/6960 [==============================] - 6s 890us/sample - loss: 0.5778 - accuracy: 0.7726 - val_loss: 0.3740 - val_accuracy: 0.8673\n",
      "Epoch 41/50\n",
      "6960/6960 [==============================] - 5s 774us/sample - loss: 0.5685 - accuracy: 0.7770 - val_loss: 0.3444 - val_accuracy: 0.8780\n",
      "Epoch 42/50\n",
      "6960/6960 [==============================] - 5s 714us/sample - loss: 0.5701 - accuracy: 0.7846 - val_loss: 0.3480 - val_accuracy: 0.8800\n",
      "Epoch 43/50\n",
      "6960/6960 [==============================] - 6s 905us/sample - loss: 0.5606 - accuracy: 0.7842 - val_loss: 0.3433 - val_accuracy: 0.8807\n",
      "Epoch 44/50\n",
      "6960/6960 [==============================] - 5s 677us/sample - loss: 0.5309 - accuracy: 0.7948 - val_loss: 0.3069 - val_accuracy: 0.8900\n",
      "Epoch 45/50\n",
      "6960/6960 [==============================] - 6s 902us/sample - loss: 0.5446 - accuracy: 0.7950 - val_loss: 0.2986 - val_accuracy: 0.9013\n",
      "Epoch 46/50\n",
      "6960/6960 [==============================] - 6s 873us/sample - loss: 0.5233 - accuracy: 0.7968 - val_loss: 0.3089 - val_accuracy: 0.9007\n",
      "Epoch 47/50\n",
      "6960/6960 [==============================] - 5s 721us/sample - loss: 0.5251 - accuracy: 0.7941 - val_loss: 0.2666 - val_accuracy: 0.9147\n",
      "Epoch 48/50\n",
      "6960/6960 [==============================] - 5s 713us/sample - loss: 0.5148 - accuracy: 0.8049 - val_loss: 0.2674 - val_accuracy: 0.9020\n",
      "Epoch 49/50\n",
      "6960/6960 [==============================] - 5s 747us/sample - loss: 0.5108 - accuracy: 0.8023 - val_loss: 0.2539 - val_accuracy: 0.9160\n",
      "Epoch 50/50\n",
      "6960/6960 [==============================] - 6s 823us/sample - loss: 0.4903 - accuracy: 0.8083 - val_loss: 0.2494 - val_accuracy: 0.9213\n",
      "6960/6960 [==============================] - 3s 410us/sample - loss: 0.1092 - accuracy: 0.9802\n",
      "1772/1772 [==============================] - 1s 349us/sample - loss: 1.3354 - accuracy: 0.5372\n",
      "train accuracy: 98.017%\n",
      "test accuracy: 53.725%\n",
      "=================75===================\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 75, 1, 100)        22100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 25, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 25, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 25, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 25, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 9, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 9, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 9, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 9, 1, 100)         100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 3, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 3, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 3, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 3, 1, 100)         100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 1, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 1, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 1, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 404       \n",
      "=================================================================\n",
      "Total params: 324,404\n",
      "Trainable params: 323,604\n",
      "Non-trainable params: 800\n",
      "_________________________________________________________________\n",
      "Train on 6960 samples, validate on 1500 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 1.9422 - accuracy: 0.2843 - val_loss: 2.3640 - val_accuracy: 0.2793\n",
      "Epoch 2/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 1.6693 - accuracy: 0.2978 - val_loss: 1.6525 - val_accuracy: 0.2993\n",
      "Epoch 3/50\n",
      "6960/6960 [==============================] - 9s 1ms/sample - loss: 1.5351 - accuracy: 0.3083 - val_loss: 1.3555 - val_accuracy: 0.3913\n",
      "Epoch 4/50\n",
      "6960/6960 [==============================] - 7s 1ms/sample - loss: 1.4487 - accuracy: 0.3270 - val_loss: 1.3029 - val_accuracy: 0.3813\n",
      "Epoch 5/50\n",
      "6960/6960 [==============================] - 9s 1ms/sample - loss: 1.3774 - accuracy: 0.3527 - val_loss: 1.2384 - val_accuracy: 0.4347\n",
      "Epoch 6/50\n",
      "6960/6960 [==============================] - 7s 976us/sample - loss: 1.3243 - accuracy: 0.3918 - val_loss: 1.2244 - val_accuracy: 0.4507\n",
      "Epoch 7/50\n",
      "6960/6960 [==============================] - 9s 1ms/sample - loss: 1.2775 - accuracy: 0.4218 - val_loss: 1.1793 - val_accuracy: 0.4873\n",
      "Epoch 8/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 1.2391 - accuracy: 0.4486 - val_loss: 1.1529 - val_accuracy: 0.5047\n",
      "Epoch 9/50\n",
      "6960/6960 [==============================] - 7s 1ms/sample - loss: 1.2012 - accuracy: 0.4688 - val_loss: 1.1344 - val_accuracy: 0.5147\n",
      "Epoch 10/50\n",
      "6960/6960 [==============================] - 9s 1ms/sample - loss: 1.1679 - accuracy: 0.4845 - val_loss: 1.0656 - val_accuracy: 0.5553\n",
      "Epoch 11/50\n",
      "6960/6960 [==============================] - 7s 1ms/sample - loss: 1.1428 - accuracy: 0.5034 - val_loss: 1.0461 - val_accuracy: 0.5647\n",
      "Epoch 12/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 1.1149 - accuracy: 0.5205 - val_loss: 1.0184 - val_accuracy: 0.5720\n",
      "Epoch 13/50\n",
      "6960/6960 [==============================] - 7s 990us/sample - loss: 1.0865 - accuracy: 0.5411 - val_loss: 1.0205 - val_accuracy: 0.5780\n",
      "Epoch 14/50\n",
      "6960/6960 [==============================] - 6s 902us/sample - loss: 0.7990 - accuracy: 0.6759 - val_loss: 0.5638 - val_accuracy: 0.7987\n",
      "Epoch 25/50\n",
      "6960/6960 [==============================] - 6s 852us/sample - loss: 0.7731 - accuracy: 0.6874 - val_loss: 0.6208 - val_accuracy: 0.7580\n",
      "Epoch 26/50\n",
      "6960/6960 [==============================] - 6s 898us/sample - loss: 0.7511 - accuracy: 0.6993 - val_loss: 0.5237 - val_accuracy: 0.8067\n",
      "Epoch 27/50\n",
      "6960/6960 [==============================] - 6s 832us/sample - loss: 0.7340 - accuracy: 0.7126 - val_loss: 0.4898 - val_accuracy: 0.8240\n",
      "Epoch 28/50\n",
      "6960/6960 [==============================] - 7s 1ms/sample - loss: 0.6971 - accuracy: 0.7305 - val_loss: 0.4987 - val_accuracy: 0.8173\n",
      "Epoch 29/50\n",
      "6960/6960 [==============================] - 6s 802us/sample - loss: 0.6857 - accuracy: 0.7292 - val_loss: 0.4463 - val_accuracy: 0.8453\n",
      "Epoch 30/50\n",
      "6960/6960 [==============================] - 7s 985us/sample - loss: 0.6550 - accuracy: 0.7388 - val_loss: 0.4167 - val_accuracy: 0.8473\n",
      "Epoch 31/50\n",
      "6960/6960 [==============================] - 7s 985us/sample - loss: 0.6466 - accuracy: 0.7454 - val_loss: 0.4515 - val_accuracy: 0.8460\n",
      "Epoch 32/50\n",
      "6960/6960 [==============================] - 7s 968us/sample - loss: 0.6378 - accuracy: 0.7520 - val_loss: 0.4013 - val_accuracy: 0.8580\n",
      "Epoch 33/50\n",
      "6960/6960 [==============================] - 7s 938us/sample - loss: 0.6038 - accuracy: 0.7682 - val_loss: 0.3494 - val_accuracy: 0.8847\n",
      "Epoch 34/50\n",
      "6960/6960 [==============================] - 4s 562us/sample - loss: 0.6000 - accuracy: 0.7700 - val_loss: 0.3545 - val_accuracy: 0.8820\n",
      "Epoch 35/50\n",
      "6960/6960 [==============================] - 5s 684us/sample - loss: 0.5814 - accuracy: 0.7780 - val_loss: 0.3163 - val_accuracy: 0.8933\n",
      "Epoch 36/50\n",
      "6960/6960 [==============================] - 4s 617us/sample - loss: 0.5646 - accuracy: 0.7812 - val_loss: 0.3190 - val_accuracy: 0.8907\n",
      "Epoch 37/50\n",
      "6960/6960 [==============================] - 5s 782us/sample - loss: 0.5291 - accuracy: 0.7981 - val_loss: 0.2953 - val_accuracy: 0.9053\n",
      "Epoch 38/50\n",
      "6960/6960 [==============================] - 7s 999us/sample - loss: 0.5455 - accuracy: 0.7917 - val_loss: 0.3207 - val_accuracy: 0.8940\n",
      "Epoch 39/50\n",
      "6960/6960 [==============================] - 7s 1ms/sample - loss: 0.5288 - accuracy: 0.7960 - val_loss: 0.2649 - val_accuracy: 0.9127\n",
      "Epoch 40/50\n",
      "6960/6960 [==============================] - 6s 822us/sample - loss: 0.5092 - accuracy: 0.8030 - val_loss: 0.2791 - val_accuracy: 0.9120\n",
      "Epoch 41/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 0.4998 - accuracy: 0.8164 - val_loss: 0.2394 - val_accuracy: 0.9300\n",
      "Epoch 42/50\n",
      "6960/6960 [==============================] - 6s 880us/sample - loss: 0.4748 - accuracy: 0.8188 - val_loss: 0.2554 - val_accuracy: 0.9207\n",
      "Epoch 43/50\n",
      "6960/6960 [==============================] - 7s 979us/sample - loss: 0.4697 - accuracy: 0.8200 - val_loss: 0.2437 - val_accuracy: 0.9133\n",
      "Epoch 44/50\n",
      "6960/6960 [==============================] - 7s 961us/sample - loss: 0.4711 - accuracy: 0.8171 - val_loss: 0.2025 - val_accuracy: 0.9440\n",
      "Epoch 45/50\n",
      "6960/6960 [==============================] - 6s 883us/sample - loss: 0.4573 - accuracy: 0.8261 - val_loss: 0.2057 - val_accuracy: 0.9420\n",
      "Epoch 46/50\n",
      "6960/6960 [==============================] - 6s 867us/sample - loss: 0.4520 - accuracy: 0.8283 - val_loss: 0.2007 - val_accuracy: 0.9367\n",
      "Epoch 47/50\n",
      "6960/6960 [==============================] - 7s 935us/sample - loss: 0.4445 - accuracy: 0.8355 - val_loss: 0.1876 - val_accuracy: 0.9440\n",
      "Epoch 48/50\n",
      "6960/6960 [==============================] - 6s 819us/sample - loss: 0.4208 - accuracy: 0.8445 - val_loss: 0.1691 - val_accuracy: 0.9487\n",
      "Epoch 49/50\n",
      "6960/6960 [==============================] - 7s 955us/sample - loss: 0.4175 - accuracy: 0.8379 - val_loss: 0.1775 - val_accuracy: 0.9413\n",
      "Epoch 50/50\n",
      "6960/6960 [==============================] - 7s 964us/sample - loss: 0.4145 - accuracy: 0.8448 - val_loss: 0.1818 - val_accuracy: 0.9440\n",
      "6960/6960 [==============================] - 3s 396us/sample - loss: 0.0720 - accuracy: 0.9882\n",
      "1772/1772 [==============================] - 1s 412us/sample - loss: 1.3417 - accuracy: 0.5847\n",
      "train accuracy: 98.822%\n",
      "test accuracy: 58.465%\n",
      "=================100===================\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 100, 1, 100)       22100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 34, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 34, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 34, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 34, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 12, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 12, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 12, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 12, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 4, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 4, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 4, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 4, 1, 100)         100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 2, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 2, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 2, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 804       \n",
      "=================================================================\n",
      "Total params: 324,804\n",
      "Trainable params: 324,004\n",
      "Non-trainable params: 800\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6960 samples, validate on 1500 samples\n",
      "Epoch 1/50\n",
      "6960/6960 [==============================] - 13s 2ms/sample - loss: 2.0753 - accuracy: 0.2746 - val_loss: 3.3851 - val_accuracy: 0.2793\n",
      "Epoch 2/50\n",
      "6960/6960 [==============================] - 9s 1ms/sample - loss: 1.6628 - accuracy: 0.3162 - val_loss: 1.9337 - val_accuracy: 0.3020\n",
      "Epoch 3/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 1.5048 - accuracy: 0.3379 - val_loss: 1.2674 - val_accuracy: 0.4267\n",
      "Epoch 4/50\n",
      "6960/6960 [==============================] - 7s 1ms/sample - loss: 1.3722 - accuracy: 0.3839 - val_loss: 1.1845 - val_accuracy: 0.4587\n",
      "Epoch 5/50\n",
      "6960/6960 [==============================] - 9s 1ms/sample - loss: 1.2876 - accuracy: 0.4260 - val_loss: 1.0961 - val_accuracy: 0.5220\n",
      "Epoch 6/50\n",
      "6960/6960 [==============================] - 9s 1ms/sample - loss: 1.2231 - accuracy: 0.4520 - val_loss: 1.0564 - val_accuracy: 0.5407\n",
      "Epoch 7/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 1.1665 - accuracy: 0.4971 - val_loss: 1.0070 - val_accuracy: 0.5827\n",
      "Epoch 8/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 1.1268 - accuracy: 0.5109 - val_loss: 0.9824 - val_accuracy: 0.5827\n",
      "Epoch 9/50\n",
      "6960/6960 [==============================] - 7s 1ms/sample - loss: 1.0894 - accuracy: 0.5325 - val_loss: 0.9712 - val_accuracy: 0.5927\n",
      "Epoch 10/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 1.0543 - accuracy: 0.5476 - val_loss: 0.9239 - val_accuracy: 0.6113\n",
      "Epoch 11/50\n",
      "6960/6960 [==============================] - 9s 1ms/sample - loss: 1.0203 - accuracy: 0.5704 - val_loss: 0.8854 - val_accuracy: 0.6433\n",
      "Epoch 12/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 0.9924 - accuracy: 0.5812 - val_loss: 0.9259 - val_accuracy: 0.6247\n",
      "Epoch 13/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 0.9587 - accuracy: 0.5977 - val_loss: 0.8413 - val_accuracy: 0.6627\n",
      "Epoch 14/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 0.9192 - accuracy: 0.6165 - val_loss: 0.7903 - val_accuracy: 0.6873\n",
      "Epoch 15/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 0.8906 - accuracy: 0.6346 - val_loss: 0.7277 - val_accuracy: 0.7227\n",
      "Epoch 16/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 0.8538 - accuracy: 0.6493 - val_loss: 0.6749 - val_accuracy: 0.7287\n",
      "Epoch 17/50\n",
      "6960/6960 [==============================] - 9s 1ms/sample - loss: 0.8425 - accuracy: 0.6579 - val_loss: 0.6392 - val_accuracy: 0.7607\n",
      "Epoch 18/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 0.8055 - accuracy: 0.6710 - val_loss: 0.6316 - val_accuracy: 0.7627\n",
      "Epoch 19/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 0.7812 - accuracy: 0.6810 - val_loss: 0.5903 - val_accuracy: 0.7820\n",
      "Epoch 20/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 0.7419 - accuracy: 0.7029 - val_loss: 0.6206 - val_accuracy: 0.7560\n",
      "Epoch 21/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 0.7108 - accuracy: 0.7195 - val_loss: 0.5155 - val_accuracy: 0.8013\n",
      "Epoch 22/50\n",
      "6960/6960 [==============================] - 10s 1ms/sample - loss: 0.6964 - accuracy: 0.7243 - val_loss: 0.4913 - val_accuracy: 0.8100\n",
      "Epoch 23/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 0.6576 - accuracy: 0.7425 - val_loss: 0.4454 - val_accuracy: 0.8387\n",
      "Epoch 24/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 0.6530 - accuracy: 0.7428 - val_loss: 0.4296 - val_accuracy: 0.8400\n",
      "Epoch 25/50\n",
      "6960/6960 [==============================] - 7s 1ms/sample - loss: 0.6239 - accuracy: 0.7539 - val_loss: 0.3939 - val_accuracy: 0.8660\n",
      "Epoch 26/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 0.6030 - accuracy: 0.7644 - val_loss: 0.3994 - val_accuracy: 0.8573\n",
      "Epoch 27/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 0.5873 - accuracy: 0.7672 - val_loss: 0.3719 - val_accuracy: 0.8793\n",
      "Epoch 28/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 0.5422 - accuracy: 0.7810 - val_loss: 0.3383 - val_accuracy: 0.8740\n",
      "Epoch 29/50\n",
      "6960/6960 [==============================] - 7s 1ms/sample - loss: 0.5353 - accuracy: 0.7846 - val_loss: 0.3222 - val_accuracy: 0.8880\n",
      "Epoch 30/50\n",
      "6960/6960 [==============================] - 9s 1ms/sample - loss: 0.5138 - accuracy: 0.8011 - val_loss: 0.2918 - val_accuracy: 0.9000\n",
      "Epoch 31/50\n",
      "6960/6960 [==============================] - 7s 1ms/sample - loss: 0.5185 - accuracy: 0.7967 - val_loss: 0.2834 - val_accuracy: 0.8920\n",
      "Epoch 32/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 0.4950 - accuracy: 0.8096 - val_loss: 0.2713 - val_accuracy: 0.9187\n",
      "Epoch 33/50\n",
      "6960/6960 [==============================] - 9s 1ms/sample - loss: 0.4708 - accuracy: 0.8193 - val_loss: 0.2430 - val_accuracy: 0.9240\n",
      "Epoch 34/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 0.4580 - accuracy: 0.8257 - val_loss: 0.2457 - val_accuracy: 0.9153\n",
      "Epoch 35/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 0.4334 - accuracy: 0.8341 - val_loss: 0.2352 - val_accuracy: 0.9167\n",
      "Epoch 36/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 0.4352 - accuracy: 0.8351 - val_loss: 0.1927 - val_accuracy: 0.9413\n",
      "Epoch 37/50\n",
      "6960/6960 [==============================] - 7s 982us/sample - loss: 0.4305 - accuracy: 0.8362 - val_loss: 0.1847 - val_accuracy: 0.9467\n",
      "Epoch 38/50\n",
      "6960/6960 [==============================] - 5s 677us/sample - loss: 0.4081 - accuracy: 0.8447 - val_loss: 0.2162 - val_accuracy: 0.9320\n",
      "Epoch 39/50\n",
      "6960/6960 [==============================] - 5s 741us/sample - loss: 0.4263 - accuracy: 0.8375 - val_loss: 0.1784 - val_accuracy: 0.9487\n",
      "Epoch 40/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 0.4254 - accuracy: 0.8356 - val_loss: 0.1837 - val_accuracy: 0.9453\n",
      "Epoch 41/50\n",
      "6960/6960 [==============================] - 7s 1ms/sample - loss: 0.3826 - accuracy: 0.8552 - val_loss: 0.1427 - val_accuracy: 0.9600\n",
      "Epoch 42/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 0.3701 - accuracy: 0.8578 - val_loss: 0.1376 - val_accuracy: 0.9633\n",
      "Epoch 43/50\n",
      "6960/6960 [==============================] - 7s 1ms/sample - loss: 0.3644 - accuracy: 0.8641 - val_loss: 0.1358 - val_accuracy: 0.9560\n",
      "Epoch 44/50\n",
      "6960/6960 [==============================] - 9s 1ms/sample - loss: 0.3590 - accuracy: 0.8645 - val_loss: 0.1293 - val_accuracy: 0.9667\n",
      "Epoch 45/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 0.3410 - accuracy: 0.8718 - val_loss: 0.1058 - val_accuracy: 0.9747\n",
      "Epoch 46/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 0.3395 - accuracy: 0.8749 - val_loss: 0.1102 - val_accuracy: 0.9693\n",
      "Epoch 47/50\n",
      "6960/6960 [==============================] - 9s 1ms/sample - loss: 0.3446 - accuracy: 0.8716 - val_loss: 0.1030 - val_accuracy: 0.9713\n",
      "Epoch 48/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 0.3314 - accuracy: 0.8764 - val_loss: 0.0867 - val_accuracy: 0.9813\n",
      "Epoch 49/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 0.3254 - accuracy: 0.8773 - val_loss: 0.1100 - val_accuracy: 0.9687\n",
      "Epoch 50/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 0.3256 - accuracy: 0.8792 - val_loss: 0.0946 - val_accuracy: 0.9753\n",
      "6960/6960 [==============================] - 4s 534us/sample - loss: 0.0343 - accuracy: 0.9961\n",
      "1772/1772 [==============================] - 1s 826us/sample - loss: 1.1226 - accuracy: 0.6569\n",
      "train accuracy: 99.612%\n",
      "test accuracy: 65.688%\n",
      "=================125===================\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 125, 1, 100)       22100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 42, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 42, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 42, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 42, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 14, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 14, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 14, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 14, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 5, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 5, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 5, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 5, 1, 100)         100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 2, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 2, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 2, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4)                 804       \n",
      "=================================================================\n",
      "Total params: 324,804\n",
      "Trainable params: 324,004\n",
      "Non-trainable params: 800\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6960 samples, validate on 1500 samples\n",
      "Epoch 1/50\n",
      "6960/6960 [==============================] - 17s 2ms/sample - loss: 1.9958 - accuracy: 0.2954 - val_loss: 5.9017 - val_accuracy: 0.2740\n",
      "Epoch 2/50\n",
      "6960/6960 [==============================] - 10s 1ms/sample - loss: 1.6258 - accuracy: 0.3142 - val_loss: 1.4589 - val_accuracy: 0.3867\n",
      "Epoch 3/50\n",
      "6960/6960 [==============================] - 10s 1ms/sample - loss: 1.4331 - accuracy: 0.3700 - val_loss: 1.2182 - val_accuracy: 0.4660\n",
      "Epoch 4/50\n",
      "6960/6960 [==============================] - 10s 1ms/sample - loss: 1.2961 - accuracy: 0.4309 - val_loss: 1.1423 - val_accuracy: 0.4880\n",
      "Epoch 5/50\n",
      "6960/6960 [==============================] - 9s 1ms/sample - loss: 1.2255 - accuracy: 0.4678 - val_loss: 1.0317 - val_accuracy: 0.5720\n",
      "Epoch 6/50\n",
      "6960/6960 [==============================] - 9s 1ms/sample - loss: 1.1476 - accuracy: 0.5072 - val_loss: 1.0352 - val_accuracy: 0.5600\n",
      "Epoch 7/50\n",
      "6960/6960 [==============================] - 10s 1ms/sample - loss: 1.0998 - accuracy: 0.5243 - val_loss: 0.9734 - val_accuracy: 0.6040\n",
      "Epoch 8/50\n",
      "6960/6960 [==============================] - 11s 2ms/sample - loss: 1.0390 - accuracy: 0.5704 - val_loss: 0.9788 - val_accuracy: 0.6040\n",
      "Epoch 9/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 1.0089 - accuracy: 0.5841 - val_loss: 0.9135 - val_accuracy: 0.6320\n",
      "Epoch 10/50\n",
      "6960/6960 [==============================] - 11s 2ms/sample - loss: 0.9674 - accuracy: 0.6011 - val_loss: 0.8239 - val_accuracy: 0.6780\n",
      "Epoch 11/50\n",
      "6960/6960 [==============================] - 10s 1ms/sample - loss: 0.9283 - accuracy: 0.6228 - val_loss: 0.8168 - val_accuracy: 0.6740\n",
      "Epoch 12/50\n",
      "6960/6960 [==============================] - 10s 1ms/sample - loss: 0.8862 - accuracy: 0.6391 - val_loss: 0.7749 - val_accuracy: 0.7013\n",
      "Epoch 13/50\n",
      "6960/6960 [==============================] - 10s 1ms/sample - loss: 0.8430 - accuracy: 0.6605 - val_loss: 0.7240 - val_accuracy: 0.7107\n",
      "Epoch 14/50\n",
      "6960/6960 [==============================] - 10s 1ms/sample - loss: 0.8229 - accuracy: 0.6678 - val_loss: 0.6482 - val_accuracy: 0.7447\n",
      "Epoch 15/50\n",
      "6960/6960 [==============================] - 10s 1ms/sample - loss: 0.7726 - accuracy: 0.6881 - val_loss: 0.6310 - val_accuracy: 0.7433\n",
      "Epoch 16/50\n",
      "6960/6960 [==============================] - 10s 1ms/sample - loss: 0.7645 - accuracy: 0.6918 - val_loss: 0.5868 - val_accuracy: 0.7760\n",
      "Epoch 17/50\n",
      "6960/6960 [==============================] - 10s 1ms/sample - loss: 0.7199 - accuracy: 0.7157 - val_loss: 0.5694 - val_accuracy: 0.7900\n",
      "Epoch 18/50\n",
      "6960/6960 [==============================] - 10s 1ms/sample - loss: 0.7020 - accuracy: 0.7201 - val_loss: 0.5206 - val_accuracy: 0.7953\n",
      "Epoch 19/50\n",
      "6960/6960 [==============================] - 10s 1ms/sample - loss: 0.6649 - accuracy: 0.7388 - val_loss: 0.4583 - val_accuracy: 0.8413\n",
      "Epoch 20/50\n",
      "6960/6960 [==============================] - 10s 1ms/sample - loss: 0.6407 - accuracy: 0.7501 - val_loss: 0.4453 - val_accuracy: 0.8293\n",
      "Epoch 21/50\n",
      "6960/6960 [==============================] - 9s 1ms/sample - loss: 0.6152 - accuracy: 0.7593 - val_loss: 0.4506 - val_accuracy: 0.8307\n",
      "Epoch 22/50\n",
      "6960/6960 [==============================] - 10s 1ms/sample - loss: 0.6097 - accuracy: 0.7611 - val_loss: 0.4226 - val_accuracy: 0.8407\n",
      "Epoch 23/50\n",
      "6960/6960 [==============================] - 10s 1ms/sample - loss: 0.5725 - accuracy: 0.7757 - val_loss: 0.3753 - val_accuracy: 0.8667\n",
      "Epoch 24/50\n",
      "6960/6960 [==============================] - 10s 1ms/sample - loss: 0.5515 - accuracy: 0.7842 - val_loss: 0.3338 - val_accuracy: 0.8847\n",
      "Epoch 25/50\n",
      "6960/6960 [==============================] - 11s 2ms/sample - loss: 0.5091 - accuracy: 0.8045 - val_loss: 0.3157 - val_accuracy: 0.8893\n",
      "Epoch 26/50\n",
      "6960/6960 [==============================] - 9s 1ms/sample - loss: 0.5250 - accuracy: 0.7971 - val_loss: 0.2845 - val_accuracy: 0.9080\n",
      "Epoch 27/50\n",
      "6960/6960 [==============================] - 11s 2ms/sample - loss: 0.4867 - accuracy: 0.8170 - val_loss: 0.2727 - val_accuracy: 0.9093\n",
      "Epoch 28/50\n",
      "6960/6960 [==============================] - 10s 1ms/sample - loss: 0.4711 - accuracy: 0.8180 - val_loss: 0.2504 - val_accuracy: 0.9160\n",
      "Epoch 29/50\n",
      "6960/6960 [==============================] - 11s 2ms/sample - loss: 0.4794 - accuracy: 0.8165 - val_loss: 0.2853 - val_accuracy: 0.9013\n",
      "Epoch 30/50\n",
      "6960/6960 [==============================] - 9s 1ms/sample - loss: 0.4368 - accuracy: 0.8352 - val_loss: 0.2299 - val_accuracy: 0.9273\n",
      "Epoch 31/50\n",
      "6960/6960 [==============================] - 11s 2ms/sample - loss: 0.4361 - accuracy: 0.8333 - val_loss: 0.1983 - val_accuracy: 0.9407\n",
      "Epoch 32/50\n",
      "6960/6960 [==============================] - 11s 2ms/sample - loss: 0.4153 - accuracy: 0.8391 - val_loss: 0.2102 - val_accuracy: 0.9273\n",
      "Epoch 33/50\n",
      "6960/6960 [==============================] - 10s 1ms/sample - loss: 0.4008 - accuracy: 0.8457 - val_loss: 0.1793 - val_accuracy: 0.9547\n",
      "Epoch 34/50\n",
      "6960/6960 [==============================] - 10s 1ms/sample - loss: 0.3815 - accuracy: 0.8545 - val_loss: 0.1667 - val_accuracy: 0.9533\n",
      "Epoch 35/50\n",
      "6960/6960 [==============================] - 10s 1ms/sample - loss: 0.3715 - accuracy: 0.8625 - val_loss: 0.1482 - val_accuracy: 0.9547\n",
      "Epoch 36/50\n",
      "6960/6960 [==============================] - 10s 1ms/sample - loss: 0.3584 - accuracy: 0.8654 - val_loss: 0.1325 - val_accuracy: 0.9700\n",
      "Epoch 37/50\n",
      "6960/6960 [==============================] - 9s 1ms/sample - loss: 0.3558 - accuracy: 0.8628 - val_loss: 0.1300 - val_accuracy: 0.9667\n",
      "Epoch 38/50\n",
      "6960/6960 [==============================] - 10s 2ms/sample - loss: 0.3672 - accuracy: 0.8592 - val_loss: 0.1416 - val_accuracy: 0.9600\n",
      "Epoch 39/50\n",
      "6960/6960 [==============================] - 9s 1ms/sample - loss: 0.3439 - accuracy: 0.8671 - val_loss: 0.1190 - val_accuracy: 0.9687\n",
      "Epoch 40/50\n",
      "6960/6960 [==============================] - 7s 970us/sample - loss: 0.3160 - accuracy: 0.8799 - val_loss: 0.1141 - val_accuracy: 0.9693\n",
      "Epoch 41/50\n",
      "6960/6960 [==============================] - 6s 898us/sample - loss: 0.3093 - accuracy: 0.8832 - val_loss: 0.1107 - val_accuracy: 0.9753\n",
      "Epoch 42/50\n",
      "6960/6960 [==============================] - 9s 1ms/sample - loss: 0.3240 - accuracy: 0.8783 - val_loss: 0.0891 - val_accuracy: 0.9800\n",
      "Epoch 43/50\n",
      "6960/6960 [==============================] - 10s 1ms/sample - loss: 0.3036 - accuracy: 0.8852 - val_loss: 0.0854 - val_accuracy: 0.9827\n",
      "Epoch 44/50\n",
      "6960/6960 [==============================] - 10s 1ms/sample - loss: 0.2963 - accuracy: 0.8895 - val_loss: 0.0908 - val_accuracy: 0.9773\n",
      "Epoch 45/50\n",
      "6960/6960 [==============================] - 9s 1ms/sample - loss: 0.2820 - accuracy: 0.8957 - val_loss: 0.0940 - val_accuracy: 0.9747\n",
      "Epoch 46/50\n",
      "6960/6960 [==============================] - 10s 1ms/sample - loss: 0.3056 - accuracy: 0.8856 - val_loss: 0.1089 - val_accuracy: 0.9660\n",
      "Epoch 47/50\n",
      "6960/6960 [==============================] - 10s 1ms/sample - loss: 0.2834 - accuracy: 0.8932 - val_loss: 0.0733 - val_accuracy: 0.9820\n",
      "Epoch 48/50\n",
      "6960/6960 [==============================] - 10s 1ms/sample - loss: 0.2783 - accuracy: 0.8968 - val_loss: 0.0737 - val_accuracy: 0.9847\n",
      "Epoch 49/50\n",
      "6960/6960 [==============================] - 11s 2ms/sample - loss: 0.2594 - accuracy: 0.9046 - val_loss: 0.0705 - val_accuracy: 0.9840\n",
      "Epoch 50/50\n",
      "6960/6960 [==============================] - 10s 1ms/sample - loss: 0.2608 - accuracy: 0.9032 - val_loss: 0.0605 - val_accuracy: 0.9880\n",
      "6960/6960 [==============================] - 4s 588us/sample - loss: 0.0199 - accuracy: 0.9990\n",
      "1772/1772 [==============================] - 1s 512us/sample - loss: 0.9868 - accuracy: 0.7003\n",
      "train accuracy: 99.899%\n",
      "test accuracy: 70.034%\n",
      "=================150===================\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_20 (Conv2D)           (None, 150, 1, 100)       22100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 50, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 50, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 50, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 50, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 17, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 17, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 17, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 17, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 6, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 6, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 6, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 6, 1, 100)         100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 2, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 2, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 2, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4)                 804       \n",
      "=================================================================\n",
      "Total params: 324,804\n",
      "Trainable params: 324,004\n",
      "Non-trainable params: 800\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6960 samples, validate on 1500 samples\n",
      "Epoch 1/50\n",
      "6960/6960 [==============================] - 18s 3ms/sample - loss: 2.0133 - accuracy: 0.2889 - val_loss: 2.4351 - val_accuracy: 0.3453\n",
      "Epoch 2/50\n",
      "6960/6960 [==============================] - 11s 2ms/sample - loss: 1.6188 - accuracy: 0.3302 - val_loss: 1.6090 - val_accuracy: 0.3827\n",
      "Epoch 3/50\n",
      "6960/6960 [==============================] - 12s 2ms/sample - loss: 1.4229 - accuracy: 0.3789 - val_loss: 1.2305 - val_accuracy: 0.4687\n",
      "Epoch 4/50\n",
      "6960/6960 [==============================] - 12s 2ms/sample - loss: 1.2988 - accuracy: 0.4269 - val_loss: 1.1124 - val_accuracy: 0.5227\n",
      "Epoch 5/50\n",
      "6960/6960 [==============================] - 12s 2ms/sample - loss: 1.1920 - accuracy: 0.4802 - val_loss: 1.0322 - val_accuracy: 0.5473\n",
      "Epoch 6/50\n",
      "6960/6960 [==============================] - 11s 2ms/sample - loss: 1.1269 - accuracy: 0.5193 - val_loss: 0.9781 - val_accuracy: 0.5833\n",
      "Epoch 7/50\n",
      "6960/6960 [==============================] - 12s 2ms/sample - loss: 1.0690 - accuracy: 0.5441 - val_loss: 0.9281 - val_accuracy: 0.6127\n",
      "Epoch 8/50\n",
      "6960/6960 [==============================] - 11s 2ms/sample - loss: 1.0157 - accuracy: 0.5690 - val_loss: 0.9009 - val_accuracy: 0.6213\n",
      "Epoch 9/50\n",
      "6960/6960 [==============================] - 12s 2ms/sample - loss: 0.9597 - accuracy: 0.5991 - val_loss: 0.8855 - val_accuracy: 0.6433\n",
      "Epoch 10/50\n",
      "6960/6960 [==============================] - 12s 2ms/sample - loss: 0.9316 - accuracy: 0.6187 - val_loss: 0.8142 - val_accuracy: 0.6733\n",
      "Epoch 11/50\n",
      "6960/6960 [==============================] - 11s 2ms/sample - loss: 0.8772 - accuracy: 0.6417 - val_loss: 0.7593 - val_accuracy: 0.7027\n",
      "Epoch 12/50\n",
      "6960/6960 [==============================] - 11s 2ms/sample - loss: 0.8488 - accuracy: 0.6516 - val_loss: 0.7220 - val_accuracy: 0.7073\n",
      "Epoch 13/50\n",
      "6960/6960 [==============================] - 13s 2ms/sample - loss: 0.8212 - accuracy: 0.6705 - val_loss: 0.7327 - val_accuracy: 0.7127\n",
      "Epoch 14/50\n",
      "6960/6960 [==============================] - 11s 2ms/sample - loss: 0.7831 - accuracy: 0.6878 - val_loss: 0.6491 - val_accuracy: 0.7420\n",
      "Epoch 15/50\n",
      "6960/6960 [==============================] - 11s 2ms/sample - loss: 0.7393 - accuracy: 0.6999 - val_loss: 0.6193 - val_accuracy: 0.7573\n",
      "Epoch 16/50\n",
      "6960/6960 [==============================] - 13s 2ms/sample - loss: 0.7340 - accuracy: 0.7085 - val_loss: 0.5704 - val_accuracy: 0.7840\n",
      "Epoch 17/50\n",
      "6960/6960 [==============================] - 12s 2ms/sample - loss: 0.6878 - accuracy: 0.7284 - val_loss: 0.5434 - val_accuracy: 0.8053\n",
      "Epoch 18/50\n",
      "6960/6960 [==============================] - 12s 2ms/sample - loss: 0.6594 - accuracy: 0.7418 - val_loss: 0.5152 - val_accuracy: 0.8087\n",
      "Epoch 19/50\n",
      "6960/6960 [==============================] - 12s 2ms/sample - loss: 0.6302 - accuracy: 0.7524 - val_loss: 0.4864 - val_accuracy: 0.8207\n",
      "Epoch 20/50\n",
      "6960/6960 [==============================] - 13s 2ms/sample - loss: 0.6112 - accuracy: 0.7611 - val_loss: 0.4762 - val_accuracy: 0.8307\n",
      "Epoch 21/50\n",
      "6960/6960 [==============================] - 10s 1ms/sample - loss: 0.6029 - accuracy: 0.7648 - val_loss: 0.4100 - val_accuracy: 0.8587\n",
      "Epoch 22/50\n",
      "6960/6960 [==============================] - 13s 2ms/sample - loss: 0.5736 - accuracy: 0.7777 - val_loss: 0.3901 - val_accuracy: 0.8680\n",
      "Epoch 23/50\n",
      "6960/6960 [==============================] - 12s 2ms/sample - loss: 0.5526 - accuracy: 0.7848 - val_loss: 0.3791 - val_accuracy: 0.8620\n",
      "Epoch 24/50\n",
      "6960/6960 [==============================] - 11s 2ms/sample - loss: 0.5291 - accuracy: 0.7967 - val_loss: 0.3399 - val_accuracy: 0.8913\n",
      "Epoch 25/50\n",
      "6960/6960 [==============================] - 14s 2ms/sample - loss: 0.5186 - accuracy: 0.8019 - val_loss: 0.3504 - val_accuracy: 0.8647\n",
      "Epoch 26/50\n",
      "6960/6960 [==============================] - 10s 1ms/sample - loss: 0.5127 - accuracy: 0.7994 - val_loss: 0.2793 - val_accuracy: 0.9160\n",
      "Epoch 27/50\n",
      "6960/6960 [==============================] - 13s 2ms/sample - loss: 0.4917 - accuracy: 0.8106 - val_loss: 0.2664 - val_accuracy: 0.9180\n",
      "Epoch 28/50\n",
      "6960/6960 [==============================] - 13s 2ms/sample - loss: 0.4682 - accuracy: 0.8218 - val_loss: 0.2839 - val_accuracy: 0.8993\n",
      "Epoch 29/50\n",
      "6960/6960 [==============================] - 12s 2ms/sample - loss: 0.4304 - accuracy: 0.8375 - val_loss: 0.2042 - val_accuracy: 0.9400\n",
      "Epoch 30/50\n",
      "6960/6960 [==============================] - 12s 2ms/sample - loss: 0.4228 - accuracy: 0.8374 - val_loss: 0.2178 - val_accuracy: 0.9327\n",
      "Epoch 31/50\n",
      "6960/6960 [==============================] - 12s 2ms/sample - loss: 0.4175 - accuracy: 0.8431 - val_loss: 0.2081 - val_accuracy: 0.9280\n",
      "Epoch 32/50\n",
      "6960/6960 [==============================] - 11s 2ms/sample - loss: 0.4016 - accuracy: 0.8455 - val_loss: 0.1706 - val_accuracy: 0.9527\n",
      "Epoch 33/50\n",
      "6960/6960 [==============================] - 11s 2ms/sample - loss: 0.3803 - accuracy: 0.8549 - val_loss: 0.1830 - val_accuracy: 0.9407\n",
      "Epoch 34/50\n",
      "6960/6960 [==============================] - 12s 2ms/sample - loss: 0.3505 - accuracy: 0.8667 - val_loss: 0.1525 - val_accuracy: 0.9627\n",
      "Epoch 35/50\n",
      "6960/6960 [==============================] - 13s 2ms/sample - loss: 0.3494 - accuracy: 0.8678 - val_loss: 0.1259 - val_accuracy: 0.9687\n",
      "Epoch 36/50\n",
      "6960/6960 [==============================] - 12s 2ms/sample - loss: 0.3531 - accuracy: 0.8688 - val_loss: 0.1300 - val_accuracy: 0.9647\n",
      "Epoch 37/50\n",
      "6960/6960 [==============================] - 12s 2ms/sample - loss: 0.3543 - accuracy: 0.8648 - val_loss: 0.1249 - val_accuracy: 0.9693\n",
      "Epoch 38/50\n",
      "6960/6960 [==============================] - 11s 2ms/sample - loss: 0.3259 - accuracy: 0.8793 - val_loss: 0.1140 - val_accuracy: 0.9713\n",
      "Epoch 39/50\n",
      "6960/6960 [==============================] - 12s 2ms/sample - loss: 0.3074 - accuracy: 0.8852 - val_loss: 0.1206 - val_accuracy: 0.9667\n",
      "Epoch 40/50\n",
      "6960/6960 [==============================] - 13s 2ms/sample - loss: 0.3126 - accuracy: 0.8848 - val_loss: 0.0859 - val_accuracy: 0.9833\n",
      "Epoch 41/50\n",
      "6960/6960 [==============================] - 9s 1ms/sample - loss: 0.3102 - accuracy: 0.8846 - val_loss: 0.0971 - val_accuracy: 0.9773\n",
      "Epoch 42/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 0.2850 - accuracy: 0.8945 - val_loss: 0.0779 - val_accuracy: 0.9833\n",
      "Epoch 43/50\n",
      "6960/6960 [==============================] - 13s 2ms/sample - loss: 0.2728 - accuracy: 0.8973 - val_loss: 0.0783 - val_accuracy: 0.9787\n",
      "Epoch 44/50\n",
      "6960/6960 [==============================] - 12s 2ms/sample - loss: 0.2666 - accuracy: 0.9006 - val_loss: 0.0739 - val_accuracy: 0.9833\n",
      "Epoch 45/50\n",
      "6960/6960 [==============================] - 12s 2ms/sample - loss: 0.2610 - accuracy: 0.9026 - val_loss: 0.0776 - val_accuracy: 0.9807\n",
      "Epoch 46/50\n",
      "6960/6960 [==============================] - 12s 2ms/sample - loss: 0.2750 - accuracy: 0.8978 - val_loss: 0.0572 - val_accuracy: 0.9907\n",
      "Epoch 47/50\n",
      "6960/6960 [==============================] - 13s 2ms/sample - loss: 0.2648 - accuracy: 0.8997 - val_loss: 0.0671 - val_accuracy: 0.9813\n",
      "Epoch 48/50\n",
      "6960/6960 [==============================] - 12s 2ms/sample - loss: 0.2534 - accuracy: 0.9039 - val_loss: 0.0490 - val_accuracy: 0.9887\n",
      "Epoch 49/50\n",
      "6960/6960 [==============================] - 12s 2ms/sample - loss: 0.2518 - accuracy: 0.9073 - val_loss: 0.0512 - val_accuracy: 0.9893\n",
      "Epoch 50/50\n",
      "6960/6960 [==============================] - 12s 2ms/sample - loss: 0.2364 - accuracy: 0.9167 - val_loss: 0.0453 - val_accuracy: 0.9900\n",
      "6960/6960 [==============================] - 4s 621us/sample - loss: 0.0148 - accuracy: 0.9993\n",
      "1772/1772 [==============================] - 2s 1ms/sample - loss: 1.0558 - accuracy: 0.7026\n",
      "train accuracy: 99.928%\n",
      "test accuracy: 70.260%\n",
      "=================175===================\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_24 (Conv2D)           (None, 175, 1, 100)       22100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 59, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 59, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 59, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 59, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 20, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 20, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 20, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 20, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 7, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 7, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 7, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 7, 1, 100)         100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 3, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 3, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 3, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 4)                 1204      \n",
      "=================================================================\n",
      "Total params: 325,204\n",
      "Trainable params: 324,404\n",
      "Non-trainable params: 800\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6960 samples, validate on 1500 samples\n",
      "Epoch 1/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 2.0506 - accuracy: 0.2950 - val_loss: 3.1706 - val_accuracy: 0.3353\n",
      "Epoch 2/50\n",
      "6960/6960 [==============================] - 13s 2ms/sample - loss: 1.5966 - accuracy: 0.3565 - val_loss: 1.8746 - val_accuracy: 0.3987\n",
      "Epoch 3/50\n",
      "6960/6960 [==============================] - 14s 2ms/sample - loss: 1.3928 - accuracy: 0.4144 - val_loss: 1.1523 - val_accuracy: 0.4980\n",
      "Epoch 4/50\n",
      "6960/6960 [==============================] - 13s 2ms/sample - loss: 1.2718 - accuracy: 0.4483 - val_loss: 1.1050 - val_accuracy: 0.5353\n",
      "Epoch 5/50\n",
      "6960/6960 [==============================] - 15s 2ms/sample - loss: 1.1397 - accuracy: 0.5134 - val_loss: 1.0140 - val_accuracy: 0.5700\n",
      "Epoch 6/50\n",
      "6960/6960 [==============================] - 13s 2ms/sample - loss: 1.0613 - accuracy: 0.5522 - val_loss: 0.9750 - val_accuracy: 0.5640\n",
      "Epoch 7/50\n",
      "6960/6960 [==============================] - 14s 2ms/sample - loss: 1.0089 - accuracy: 0.5769 - val_loss: 0.8994 - val_accuracy: 0.6200\n",
      "Epoch 8/50\n",
      "6960/6960 [==============================] - 14s 2ms/sample - loss: 0.9533 - accuracy: 0.6040 - val_loss: 0.8381 - val_accuracy: 0.6513\n",
      "Epoch 9/50\n",
      "6960/6960 [==============================] - 15s 2ms/sample - loss: 0.9126 - accuracy: 0.6254 - val_loss: 0.8390 - val_accuracy: 0.6547\n",
      "Epoch 10/50\n",
      "6960/6960 [==============================] - 15s 2ms/sample - loss: 0.8787 - accuracy: 0.6398 - val_loss: 0.7485 - val_accuracy: 0.7060\n",
      "Epoch 11/50\n",
      "6960/6960 [==============================] - 14s 2ms/sample - loss: 0.8219 - accuracy: 0.6647 - val_loss: 0.7124 - val_accuracy: 0.7120\n",
      "Epoch 12/50\n",
      "6960/6960 [==============================] - 14s 2ms/sample - loss: 0.7949 - accuracy: 0.6813 - val_loss: 0.6727 - val_accuracy: 0.7327\n",
      "Epoch 13/50\n",
      "6960/6960 [==============================] - 13s 2ms/sample - loss: 0.7432 - accuracy: 0.7056 - val_loss: 0.6345 - val_accuracy: 0.7553\n",
      "Epoch 14/50\n",
      "6960/6960 [==============================] - 14s 2ms/sample - loss: 0.7274 - accuracy: 0.7111 - val_loss: 0.6212 - val_accuracy: 0.7580\n",
      "Epoch 15/50\n",
      "6960/6960 [==============================] - 14s 2ms/sample - loss: 0.6747 - accuracy: 0.7384 - val_loss: 0.5808 - val_accuracy: 0.7607\n",
      "Epoch 16/50\n",
      "6960/6960 [==============================] - 13s 2ms/sample - loss: 0.6774 - accuracy: 0.7283 - val_loss: 0.4975 - val_accuracy: 0.8133\n",
      "Epoch 17/50\n",
      "6960/6960 [==============================] - 15s 2ms/sample - loss: 0.6301 - accuracy: 0.7565 - val_loss: 0.4593 - val_accuracy: 0.8320\n",
      "Epoch 18/50\n",
      "6960/6960 [==============================] - 14s 2ms/sample - loss: 0.6044 - accuracy: 0.7614 - val_loss: 0.4399 - val_accuracy: 0.8440\n",
      "Epoch 19/50\n",
      "6960/6960 [==============================] - 13s 2ms/sample - loss: 0.5811 - accuracy: 0.7733 - val_loss: 0.3876 - val_accuracy: 0.8733\n",
      "Epoch 20/50\n",
      "6960/6960 [==============================] - 13s 2ms/sample - loss: 0.5489 - accuracy: 0.7907 - val_loss: 0.3544 - val_accuracy: 0.8827\n",
      "Epoch 21/50\n",
      "6960/6960 [==============================] - 13s 2ms/sample - loss: 0.5343 - accuracy: 0.7927 - val_loss: 0.3360 - val_accuracy: 0.8933\n",
      "Epoch 22/50\n",
      "6960/6960 [==============================] - 15s 2ms/sample - loss: 0.5187 - accuracy: 0.7970 - val_loss: 0.3111 - val_accuracy: 0.8967\n",
      "Epoch 23/50\n",
      "6960/6960 [==============================] - 13s 2ms/sample - loss: 0.5032 - accuracy: 0.8103 - val_loss: 0.3186 - val_accuracy: 0.8980\n",
      "Epoch 24/50\n",
      "6960/6960 [==============================] - 14s 2ms/sample - loss: 0.4782 - accuracy: 0.8125 - val_loss: 0.2611 - val_accuracy: 0.9227\n",
      "Epoch 25/50\n",
      "6960/6960 [==============================] - 13s 2ms/sample - loss: 0.4337 - accuracy: 0.8319 - val_loss: 0.2541 - val_accuracy: 0.9173\n",
      "Epoch 26/50\n",
      "6960/6960 [==============================] - 14s 2ms/sample - loss: 0.4289 - accuracy: 0.8371 - val_loss: 0.2306 - val_accuracy: 0.9327\n",
      "Epoch 27/50\n",
      "6960/6960 [==============================] - 13s 2ms/sample - loss: 0.4260 - accuracy: 0.8381 - val_loss: 0.2213 - val_accuracy: 0.9267\n",
      "Epoch 28/50\n",
      "6960/6960 [==============================] - 15s 2ms/sample - loss: 0.3992 - accuracy: 0.8510 - val_loss: 0.2117 - val_accuracy: 0.9280\n",
      "Epoch 29/50\n",
      "6960/6960 [==============================] - 14s 2ms/sample - loss: 0.3903 - accuracy: 0.8550 - val_loss: 0.1732 - val_accuracy: 0.9500\n",
      "Epoch 30/50\n",
      "6960/6960 [==============================] - 13s 2ms/sample - loss: 0.3674 - accuracy: 0.8626 - val_loss: 0.1735 - val_accuracy: 0.9467\n",
      "Epoch 31/50\n",
      "6960/6960 [==============================] - 13s 2ms/sample - loss: 0.3592 - accuracy: 0.8626 - val_loss: 0.1378 - val_accuracy: 0.9700\n",
      "Epoch 32/50\n",
      "6960/6960 [==============================] - 13s 2ms/sample - loss: 0.3537 - accuracy: 0.8624 - val_loss: 0.1294 - val_accuracy: 0.9700\n",
      "Epoch 33/50\n",
      "6960/6960 [==============================] - 13s 2ms/sample - loss: 0.3303 - accuracy: 0.8749 - val_loss: 0.1501 - val_accuracy: 0.9567\n",
      "Epoch 34/50\n",
      "6960/6960 [==============================] - 13s 2ms/sample - loss: 0.3382 - accuracy: 0.8714 - val_loss: 0.1079 - val_accuracy: 0.9773\n",
      "Epoch 35/50\n",
      "6960/6960 [==============================] - 14s 2ms/sample - loss: 0.3056 - accuracy: 0.8835 - val_loss: 0.1095 - val_accuracy: 0.9713\n",
      "Epoch 36/50\n",
      "6960/6960 [==============================] - 14s 2ms/sample - loss: 0.3147 - accuracy: 0.8774 - val_loss: 0.0876 - val_accuracy: 0.9787\n",
      "Epoch 37/50\n",
      "6960/6960 [==============================] - 13s 2ms/sample - loss: 0.3140 - accuracy: 0.8796 - val_loss: 0.1092 - val_accuracy: 0.9700\n",
      "Epoch 38/50\n",
      "6960/6960 [==============================] - 14s 2ms/sample - loss: 0.2994 - accuracy: 0.8914 - val_loss: 0.0998 - val_accuracy: 0.9747\n",
      "Epoch 39/50\n",
      "6960/6960 [==============================] - 13s 2ms/sample - loss: 0.2905 - accuracy: 0.8895 - val_loss: 0.0959 - val_accuracy: 0.9733\n",
      "Epoch 40/50\n",
      "6960/6960 [==============================] - 15s 2ms/sample - loss: 0.2854 - accuracy: 0.8932 - val_loss: 0.0792 - val_accuracy: 0.9813\n",
      "Epoch 41/50\n",
      "6960/6960 [==============================] - 14s 2ms/sample - loss: 0.2710 - accuracy: 0.8999 - val_loss: 0.0655 - val_accuracy: 0.9880\n",
      "Epoch 42/50\n",
      "6960/6960 [==============================] - 12s 2ms/sample - loss: 0.2638 - accuracy: 0.9004 - val_loss: 0.0613 - val_accuracy: 0.9913\n",
      "Epoch 43/50\n",
      "6960/6960 [==============================] - 10s 1ms/sample - loss: 0.2574 - accuracy: 0.9055 - val_loss: 0.0545 - val_accuracy: 0.9893\n",
      "Epoch 44/50\n",
      "6960/6960 [==============================] - 12s 2ms/sample - loss: 0.2308 - accuracy: 0.9164 - val_loss: 0.0636 - val_accuracy: 0.9847\n",
      "Epoch 45/50\n",
      "6960/6960 [==============================] - 14s 2ms/sample - loss: 0.2456 - accuracy: 0.9070 - val_loss: 0.0514 - val_accuracy: 0.9900\n",
      "Epoch 46/50\n",
      "6960/6960 [==============================] - 13s 2ms/sample - loss: 0.2381 - accuracy: 0.9102 - val_loss: 0.0519 - val_accuracy: 0.9900\n",
      "Epoch 47/50\n",
      "6960/6960 [==============================] - 14s 2ms/sample - loss: 0.2299 - accuracy: 0.9135 - val_loss: 0.0426 - val_accuracy: 0.9920\n",
      "Epoch 48/50\n",
      "6960/6960 [==============================] - 14s 2ms/sample - loss: 0.2216 - accuracy: 0.9157 - val_loss: 0.0375 - val_accuracy: 0.9940\n",
      "Epoch 49/50\n",
      "6960/6960 [==============================] - 15s 2ms/sample - loss: 0.2113 - accuracy: 0.9216 - val_loss: 0.0508 - val_accuracy: 0.9867\n",
      "Epoch 50/50\n",
      "6960/6960 [==============================] - 14s 2ms/sample - loss: 0.1976 - accuracy: 0.9287 - val_loss: 0.0580 - val_accuracy: 0.9833\n",
      "6960/6960 [==============================] - 5s 751us/sample - loss: 0.0175 - accuracy: 0.9976\n",
      "1772/1772 [==============================] - 1s 664us/sample - loss: 1.1680 - accuracy: 0.6845\n",
      "train accuracy: 99.756%\n",
      "test accuracy: 68.454%\n",
      "=================200===================\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_28 (Conv2D)           (None, 200, 1, 100)       22100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 67, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 67, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 67, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 67, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 23, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 23, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 23, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 23, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling (None, 8, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 8, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 8, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 8, 1, 100)         100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling (None, 3, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 3, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 3, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 4)                 1204      \n",
      "=================================================================\n",
      "Total params: 325,204\n",
      "Trainable params: 324,404\n",
      "Non-trainable params: 800\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6960 samples, validate on 1500 samples\n",
      "Epoch 1/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 2.0226 - accuracy: 0.3152 - val_loss: 3.6738 - val_accuracy: 0.2773\n",
      "Epoch 2/50\n",
      "6960/6960 [==============================] - 15s 2ms/sample - loss: 1.6070 - accuracy: 0.3494 - val_loss: 1.9351 - val_accuracy: 0.3747\n",
      "Epoch 3/50\n",
      "6960/6960 [==============================] - 16s 2ms/sample - loss: 1.3709 - accuracy: 0.4162 - val_loss: 1.2376 - val_accuracy: 0.5173\n",
      "Epoch 4/50\n",
      "6960/6960 [==============================] - 15s 2ms/sample - loss: 1.2321 - accuracy: 0.4770 - val_loss: 1.0553 - val_accuracy: 0.5587\n",
      "Epoch 5/50\n",
      "6960/6960 [==============================] - 16s 2ms/sample - loss: 1.1581 - accuracy: 0.5096 - val_loss: 1.0305 - val_accuracy: 0.5533\n",
      "Epoch 6/50\n",
      "6960/6960 [==============================] - 15s 2ms/sample - loss: 1.0784 - accuracy: 0.5455 - val_loss: 0.9438 - val_accuracy: 0.5967\n",
      "Epoch 7/50\n",
      "6960/6960 [==============================] - 16s 2ms/sample - loss: 1.0145 - accuracy: 0.5733 - val_loss: 0.8730 - val_accuracy: 0.6593\n",
      "Epoch 8/50\n",
      "6960/6960 [==============================] - 16s 2ms/sample - loss: 0.9474 - accuracy: 0.6080 - val_loss: 0.8314 - val_accuracy: 0.6647\n",
      "Epoch 9/50\n",
      "6960/6960 [==============================] - 15s 2ms/sample - loss: 0.8892 - accuracy: 0.6385 - val_loss: 0.7862 - val_accuracy: 0.7027\n",
      "Epoch 10/50\n",
      "6960/6960 [==============================] - 16s 2ms/sample - loss: 0.8477 - accuracy: 0.6511 - val_loss: 0.7552 - val_accuracy: 0.7073\n",
      "Epoch 11/50\n",
      "6960/6960 [==============================] - 16s 2ms/sample - loss: 0.8044 - accuracy: 0.6766 - val_loss: 0.6761 - val_accuracy: 0.7400\n",
      "Epoch 12/50\n",
      "6960/6960 [==============================] - 16s 2ms/sample - loss: 0.7675 - accuracy: 0.6947 - val_loss: 0.6691 - val_accuracy: 0.7353\n",
      "Epoch 13/50\n",
      "6960/6960 [==============================] - 15s 2ms/sample - loss: 0.7382 - accuracy: 0.7037 - val_loss: 0.6645 - val_accuracy: 0.7247\n",
      "Epoch 14/50\n",
      "6960/6960 [==============================] - 15s 2ms/sample - loss: 0.7071 - accuracy: 0.7273 - val_loss: 0.5901 - val_accuracy: 0.7800\n",
      "Epoch 15/50\n",
      "6960/6960 [==============================] - 15s 2ms/sample - loss: 0.6749 - accuracy: 0.7381 - val_loss: 0.5637 - val_accuracy: 0.7700\n",
      "Epoch 16/50\n",
      "6960/6960 [==============================] - 16s 2ms/sample - loss: 0.6564 - accuracy: 0.7437 - val_loss: 0.4997 - val_accuracy: 0.8233\n",
      "Epoch 17/50\n",
      "6960/6960 [==============================] - 14s 2ms/sample - loss: 0.6072 - accuracy: 0.7642 - val_loss: 0.4812 - val_accuracy: 0.8120\n",
      "Epoch 18/50\n",
      "6960/6960 [==============================] - 16s 2ms/sample - loss: 0.5791 - accuracy: 0.7747 - val_loss: 0.4851 - val_accuracy: 0.8247\n",
      "Epoch 19/50\n",
      "6960/6960 [==============================] - 14s 2ms/sample - loss: 0.5783 - accuracy: 0.7750 - val_loss: 0.3947 - val_accuracy: 0.8627\n",
      "Epoch 20/50\n",
      "6960/6960 [==============================] - 15s 2ms/sample - loss: 0.5375 - accuracy: 0.7918 - val_loss: 0.3803 - val_accuracy: 0.8787\n",
      "Epoch 21/50\n",
      "6960/6960 [==============================] - 17s 2ms/sample - loss: 0.5162 - accuracy: 0.7987 - val_loss: 0.3597 - val_accuracy: 0.8720\n",
      "Epoch 22/50\n",
      "6960/6960 [==============================] - 15s 2ms/sample - loss: 0.5257 - accuracy: 0.7966 - val_loss: 0.3400 - val_accuracy: 0.8887\n",
      "Epoch 23/50\n",
      "6960/6960 [==============================] - 17s 2ms/sample - loss: 0.4854 - accuracy: 0.8155 - val_loss: 0.2856 - val_accuracy: 0.9247\n",
      "Epoch 24/50\n",
      "6960/6960 [==============================] - 16s 2ms/sample - loss: 0.4537 - accuracy: 0.8293 - val_loss: 0.2707 - val_accuracy: 0.9193\n",
      "Epoch 25/50\n",
      "6960/6960 [==============================] - 15s 2ms/sample - loss: 0.4392 - accuracy: 0.8353 - val_loss: 0.2351 - val_accuracy: 0.9320\n",
      "Epoch 26/50\n",
      "6960/6960 [==============================] - 16s 2ms/sample - loss: 0.4195 - accuracy: 0.8437 - val_loss: 0.2260 - val_accuracy: 0.9387\n",
      "Epoch 27/50\n",
      "6960/6960 [==============================] - 15s 2ms/sample - loss: 0.3973 - accuracy: 0.8466 - val_loss: 0.2128 - val_accuracy: 0.9447\n",
      "Epoch 28/50\n",
      "6960/6960 [==============================] - 15s 2ms/sample - loss: 0.3805 - accuracy: 0.8593 - val_loss: 0.2017 - val_accuracy: 0.9440\n",
      "Epoch 29/50\n",
      "6960/6960 [==============================] - 15s 2ms/sample - loss: 0.3739 - accuracy: 0.8580 - val_loss: 0.1835 - val_accuracy: 0.9500\n",
      "Epoch 30/50\n",
      "6960/6960 [==============================] - 15s 2ms/sample - loss: 0.3577 - accuracy: 0.8664 - val_loss: 0.1637 - val_accuracy: 0.9527\n",
      "Epoch 31/50\n",
      "6960/6960 [==============================] - 15s 2ms/sample - loss: 0.3539 - accuracy: 0.8677 - val_loss: 0.1526 - val_accuracy: 0.9573\n",
      "Epoch 32/50\n",
      "6960/6960 [==============================] - 15s 2ms/sample - loss: 0.3273 - accuracy: 0.8769 - val_loss: 0.1488 - val_accuracy: 0.9613\n",
      "Epoch 33/50\n",
      "6960/6960 [==============================] - 18s 3ms/sample - loss: 0.3136 - accuracy: 0.8856 - val_loss: 0.1798 - val_accuracy: 0.9387\n",
      "Epoch 34/50\n",
      "6960/6960 [==============================] - 16s 2ms/sample - loss: 0.3173 - accuracy: 0.8812 - val_loss: 0.1207 - val_accuracy: 0.9727\n",
      "Epoch 35/50\n",
      "6960/6960 [==============================] - 16s 2ms/sample - loss: 0.2931 - accuracy: 0.8882 - val_loss: 0.0954 - val_accuracy: 0.9760\n",
      "Epoch 36/50\n",
      "6960/6960 [==============================] - 14s 2ms/sample - loss: 0.2990 - accuracy: 0.8875 - val_loss: 0.0844 - val_accuracy: 0.9800\n",
      "Epoch 37/50\n",
      "6960/6960 [==============================] - 18s 3ms/sample - loss: 0.2761 - accuracy: 0.8974 - val_loss: 0.1111 - val_accuracy: 0.9713\n",
      "Epoch 38/50\n",
      "6960/6960 [==============================] - 15s 2ms/sample - loss: 0.2700 - accuracy: 0.8997 - val_loss: 0.0853 - val_accuracy: 0.9833\n",
      "Epoch 39/50\n",
      "6960/6960 [==============================] - 14s 2ms/sample - loss: 0.2599 - accuracy: 0.9052 - val_loss: 0.0702 - val_accuracy: 0.9853\n",
      "Epoch 40/50\n",
      "6960/6960 [==============================] - 14s 2ms/sample - loss: 0.2623 - accuracy: 0.9033 - val_loss: 0.0703 - val_accuracy: 0.9813\n",
      "Epoch 41/50\n",
      "6960/6960 [==============================] - 18s 3ms/sample - loss: 0.2507 - accuracy: 0.9053 - val_loss: 0.0710 - val_accuracy: 0.9867\n",
      "Epoch 42/50\n",
      "6960/6960 [==============================] - 15s 2ms/sample - loss: 0.2604 - accuracy: 0.9022 - val_loss: 0.0635 - val_accuracy: 0.9853\n",
      "Epoch 43/50\n",
      "6960/6960 [==============================] - 10s 1ms/sample - loss: 0.2260 - accuracy: 0.9138 - val_loss: 0.0497 - val_accuracy: 0.9913\n",
      "Epoch 44/50\n",
      "6960/6960 [==============================] - 13s 2ms/sample - loss: 0.2454 - accuracy: 0.9086 - val_loss: 0.0595 - val_accuracy: 0.9827\n",
      "Epoch 45/50\n",
      "6960/6960 [==============================] - 16s 2ms/sample - loss: 0.2259 - accuracy: 0.9158 - val_loss: 0.0441 - val_accuracy: 0.9920\n",
      "Epoch 46/50\n",
      "6960/6960 [==============================] - 16s 2ms/sample - loss: 0.2089 - accuracy: 0.9233 - val_loss: 0.0503 - val_accuracy: 0.9867\n",
      "Epoch 47/50\n",
      "6960/6960 [==============================] - 15s 2ms/sample - loss: 0.2216 - accuracy: 0.9171 - val_loss: 0.0407 - val_accuracy: 0.9900\n",
      "Epoch 48/50\n",
      "6960/6960 [==============================] - 16s 2ms/sample - loss: 0.2062 - accuracy: 0.9233 - val_loss: 0.0406 - val_accuracy: 0.9913\n",
      "Epoch 49/50\n",
      "6960/6960 [==============================] - 15s 2ms/sample - loss: 0.2008 - accuracy: 0.9230 - val_loss: 0.0388 - val_accuracy: 0.9927\n",
      "Epoch 50/50\n",
      "6960/6960 [==============================] - 16s 2ms/sample - loss: 0.2055 - accuracy: 0.9267 - val_loss: 0.0298 - val_accuracy: 0.9940\n",
      "6960/6960 [==============================] - 6s 867us/sample - loss: 0.0081 - accuracy: 0.9994\n",
      "1772/1772 [==============================] - 1s 622us/sample - loss: 1.0873 - accuracy: 0.6981\n",
      "train accuracy: 99.943%\n",
      "test accuracy: 69.808%\n",
      "=================225===================\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_32 (Conv2D)           (None, 225, 1, 100)       22100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_32 (MaxPooling (None, 75, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 75, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 75, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 75, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_33 (MaxPooling (None, 25, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 25, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 25, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 25, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_34 (MaxPooling (None, 9, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 9, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 9, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 9, 1, 100)         100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_35 (MaxPooling (None, 3, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 3, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 3, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 4)                 1204      \n",
      "=================================================================\n",
      "Total params: 325,204\n",
      "Trainable params: 324,404\n",
      "Non-trainable params: 800\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6960 samples, validate on 1500 samples\n",
      "Epoch 1/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 2.0096 - accuracy: 0.3112 - val_loss: 3.9235 - val_accuracy: 0.3153\n",
      "Epoch 2/50\n",
      "6960/6960 [==============================] - 17s 2ms/sample - loss: 1.5486 - accuracy: 0.3816 - val_loss: 2.0927 - val_accuracy: 0.4000\n",
      "Epoch 3/50\n",
      "6960/6960 [==============================] - 16s 2ms/sample - loss: 1.3244 - accuracy: 0.4443 - val_loss: 1.4366 - val_accuracy: 0.4780\n",
      "Epoch 4/50\n",
      "6960/6960 [==============================] - 17s 2ms/sample - loss: 1.2038 - accuracy: 0.4951 - val_loss: 1.0895 - val_accuracy: 0.5307\n",
      "Epoch 5/50\n",
      "6960/6960 [==============================] - 17s 2ms/sample - loss: 1.1196 - accuracy: 0.5318 - val_loss: 1.0016 - val_accuracy: 0.5647\n",
      "Epoch 6/50\n",
      "6960/6960 [==============================] - 17s 2ms/sample - loss: 1.0413 - accuracy: 0.5705 - val_loss: 0.8947 - val_accuracy: 0.6400\n",
      "Epoch 7/50\n",
      "6960/6960 [==============================] - 17s 3ms/sample - loss: 0.9664 - accuracy: 0.6052 - val_loss: 0.8283 - val_accuracy: 0.6673\n",
      "Epoch 8/50\n",
      "6960/6960 [==============================] - 17s 2ms/sample - loss: 0.9173 - accuracy: 0.6200 - val_loss: 0.7864 - val_accuracy: 0.7007\n",
      "Epoch 9/50\n",
      "6960/6960 [==============================] - 17s 3ms/sample - loss: 0.8743 - accuracy: 0.6455 - val_loss: 0.8099 - val_accuracy: 0.6693\n",
      "Epoch 10/50\n",
      "6960/6960 [==============================] - 17s 2ms/sample - loss: 0.8033 - accuracy: 0.6809 - val_loss: 0.6849 - val_accuracy: 0.7520\n",
      "Epoch 11/50\n",
      "6960/6960 [==============================] - 17s 2ms/sample - loss: 0.7844 - accuracy: 0.6845 - val_loss: 0.6512 - val_accuracy: 0.7647\n",
      "Epoch 12/50\n",
      "6960/6960 [==============================] - 17s 2ms/sample - loss: 0.7380 - accuracy: 0.7060 - val_loss: 0.6064 - val_accuracy: 0.7747\n",
      "Epoch 13/50\n",
      "6960/6960 [==============================] - 15s 2ms/sample - loss: 0.7031 - accuracy: 0.7210 - val_loss: 0.5886 - val_accuracy: 0.7833\n",
      "Epoch 14/50\n",
      "6960/6960 [==============================] - 17s 2ms/sample - loss: 0.6747 - accuracy: 0.7384 - val_loss: 0.5647 - val_accuracy: 0.7860\n",
      "Epoch 15/50\n",
      "6960/6960 [==============================] - 17s 2ms/sample - loss: 0.6303 - accuracy: 0.7573 - val_loss: 0.4650 - val_accuracy: 0.8413\n",
      "Epoch 16/50\n",
      "6960/6960 [==============================] - 17s 2ms/sample - loss: 0.6218 - accuracy: 0.7569 - val_loss: 0.4513 - val_accuracy: 0.8367\n",
      "Epoch 17/50\n",
      "6960/6960 [==============================] - 18s 3ms/sample - loss: 0.5798 - accuracy: 0.7764 - val_loss: 0.4348 - val_accuracy: 0.8400\n",
      "Epoch 18/50\n",
      "6960/6960 [==============================] - 17s 2ms/sample - loss: 0.5617 - accuracy: 0.7868 - val_loss: 0.3833 - val_accuracy: 0.8620\n",
      "Epoch 19/50\n",
      "6960/6960 [==============================] - 17s 2ms/sample - loss: 0.5342 - accuracy: 0.7931 - val_loss: 0.3552 - val_accuracy: 0.8800\n",
      "Epoch 20/50\n",
      "6960/6960 [==============================] - 17s 2ms/sample - loss: 0.5259 - accuracy: 0.8000 - val_loss: 0.3423 - val_accuracy: 0.8893\n",
      "Epoch 21/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.4984 - accuracy: 0.8065 - val_loss: 0.3920 - val_accuracy: 0.8507\n",
      "Epoch 22/50\n",
      "6960/6960 [==============================] - 17s 3ms/sample - loss: 0.4748 - accuracy: 0.8190 - val_loss: 0.2959 - val_accuracy: 0.9093\n",
      "Epoch 23/50\n",
      "6960/6960 [==============================] - 17s 2ms/sample - loss: 0.4372 - accuracy: 0.8386 - val_loss: 0.2580 - val_accuracy: 0.9213\n",
      "Epoch 24/50\n",
      "6960/6960 [==============================] - 15s 2ms/sample - loss: 0.4396 - accuracy: 0.8330 - val_loss: 0.3005 - val_accuracy: 0.9000\n",
      "Epoch 25/50\n",
      "6960/6960 [==============================] - 17s 2ms/sample - loss: 0.4103 - accuracy: 0.8424 - val_loss: 0.2134 - val_accuracy: 0.9440\n",
      "Epoch 26/50\n",
      "6960/6960 [==============================] - 17s 3ms/sample - loss: 0.4034 - accuracy: 0.8440 - val_loss: 0.2349 - val_accuracy: 0.9307\n",
      "Epoch 27/50\n",
      "6960/6960 [==============================] - 18s 3ms/sample - loss: 0.3801 - accuracy: 0.8565 - val_loss: 0.1920 - val_accuracy: 0.9413\n",
      "Epoch 28/50\n",
      "6960/6960 [==============================] - 16s 2ms/sample - loss: 0.3725 - accuracy: 0.8555 - val_loss: 0.1993 - val_accuracy: 0.9393\n",
      "Epoch 29/50\n",
      "6960/6960 [==============================] - 18s 3ms/sample - loss: 0.3612 - accuracy: 0.8657 - val_loss: 0.1919 - val_accuracy: 0.9473\n",
      "Epoch 30/50\n",
      "6960/6960 [==============================] - 17s 2ms/sample - loss: 0.3600 - accuracy: 0.8628 - val_loss: 0.1544 - val_accuracy: 0.9620\n",
      "Epoch 31/50\n",
      "6960/6960 [==============================] - 17s 2ms/sample - loss: 0.3246 - accuracy: 0.8799 - val_loss: 0.1753 - val_accuracy: 0.9467\n",
      "Epoch 32/50\n",
      "6960/6960 [==============================] - 15s 2ms/sample - loss: 0.3249 - accuracy: 0.8763 - val_loss: 0.1474 - val_accuracy: 0.9587\n",
      "Epoch 33/50\n",
      "6960/6960 [==============================] - 16s 2ms/sample - loss: 0.3010 - accuracy: 0.8876 - val_loss: 0.1367 - val_accuracy: 0.9560\n",
      "Epoch 34/50\n",
      "6960/6960 [==============================] - 16s 2ms/sample - loss: 0.2896 - accuracy: 0.8922 - val_loss: 0.1266 - val_accuracy: 0.9680\n",
      "Epoch 35/50\n",
      "6960/6960 [==============================] - 17s 2ms/sample - loss: 0.2898 - accuracy: 0.8842 - val_loss: 0.1436 - val_accuracy: 0.9573\n",
      "Epoch 36/50\n",
      "6960/6960 [==============================] - 18s 3ms/sample - loss: 0.2706 - accuracy: 0.8983 - val_loss: 0.0853 - val_accuracy: 0.9807\n",
      "Epoch 37/50\n",
      "6960/6960 [==============================] - 16s 2ms/sample - loss: 0.2629 - accuracy: 0.9000 - val_loss: 0.1060 - val_accuracy: 0.9700\n",
      "Epoch 38/50\n",
      "6960/6960 [==============================] - 17s 2ms/sample - loss: 0.2506 - accuracy: 0.9050 - val_loss: 0.0961 - val_accuracy: 0.9740\n",
      "Epoch 39/50\n",
      "6960/6960 [==============================] - 18s 3ms/sample - loss: 0.2463 - accuracy: 0.9066 - val_loss: 0.0746 - val_accuracy: 0.9827\n",
      "Epoch 40/50\n",
      "6960/6960 [==============================] - 16s 2ms/sample - loss: 0.2518 - accuracy: 0.9091 - val_loss: 0.0768 - val_accuracy: 0.9800\n",
      "Epoch 41/50\n",
      "6960/6960 [==============================] - 16s 2ms/sample - loss: 0.2500 - accuracy: 0.9103 - val_loss: 0.0612 - val_accuracy: 0.9880\n",
      "Epoch 42/50\n",
      "6960/6960 [==============================] - 16s 2ms/sample - loss: 0.2369 - accuracy: 0.9099 - val_loss: 0.1056 - val_accuracy: 0.9680\n",
      "Epoch 43/50\n",
      "6960/6960 [==============================] - 16s 2ms/sample - loss: 0.2391 - accuracy: 0.9125 - val_loss: 0.0650 - val_accuracy: 0.9873\n",
      "Epoch 44/50\n",
      "6960/6960 [==============================] - 11s 2ms/sample - loss: 0.2258 - accuracy: 0.9154 - val_loss: 0.0614 - val_accuracy: 0.9873\n",
      "Epoch 45/50\n",
      "6960/6960 [==============================] - 18s 3ms/sample - loss: 0.2071 - accuracy: 0.9214 - val_loss: 0.0590 - val_accuracy: 0.9873\n",
      "Epoch 46/50\n",
      "6960/6960 [==============================] - 15s 2ms/sample - loss: 0.2117 - accuracy: 0.9233 - val_loss: 0.0474 - val_accuracy: 0.9887\n",
      "Epoch 47/50\n",
      "6960/6960 [==============================] - 18s 3ms/sample - loss: 0.2158 - accuracy: 0.9195 - val_loss: 0.0411 - val_accuracy: 0.9920\n",
      "Epoch 48/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.2183 - accuracy: 0.9191 - val_loss: 0.0715 - val_accuracy: 0.9767\n",
      "Epoch 49/50\n",
      "6960/6960 [==============================] - 17s 3ms/sample - loss: 0.2200 - accuracy: 0.9181 - val_loss: 0.0422 - val_accuracy: 0.9907\n",
      "Epoch 50/50\n",
      "6960/6960 [==============================] - 17s 2ms/sample - loss: 0.2027 - accuracy: 0.9241 - val_loss: 0.0588 - val_accuracy: 0.9853\n",
      "6960/6960 [==============================] - 6s 913us/sample - loss: 0.0197 - accuracy: 0.9974\n",
      "1772/1772 [==============================] - 1s 682us/sample - loss: 1.1064 - accuracy: 0.6834\n",
      "train accuracy: 99.741%\n",
      "test accuracy: 68.341%\n",
      "=================250===================\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_36 (Conv2D)           (None, 250, 1, 100)       22100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_36 (MaxPooling (None, 84, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 84, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 84, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 84, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_37 (MaxPooling (None, 28, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 28, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 28, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 28, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_38 (MaxPooling (None, 10, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 10, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 10, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 10, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_39 (MaxPooling (None, 4, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (None, 4, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 4, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 4)                 1604      \n",
      "=================================================================\n",
      "Total params: 325,604\n",
      "Trainable params: 324,804\n",
      "Non-trainable params: 800\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6960 samples, validate on 1500 samples\n",
      "Epoch 1/50\n",
      "6960/6960 [==============================] - 24s 3ms/sample - loss: 1.9531 - accuracy: 0.3336 - val_loss: 2.6227 - val_accuracy: 0.3620\n",
      "Epoch 2/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 1.5830 - accuracy: 0.3639 - val_loss: 1.8801 - val_accuracy: 0.3953\n",
      "Epoch 3/50\n",
      "6960/6960 [==============================] - 18s 3ms/sample - loss: 1.3404 - accuracy: 0.4292 - val_loss: 1.2260 - val_accuracy: 0.5120\n",
      "Epoch 4/50\n",
      "6960/6960 [==============================] - 18s 3ms/sample - loss: 1.2314 - accuracy: 0.4747 - val_loss: 1.0448 - val_accuracy: 0.5647\n",
      "Epoch 5/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 1.1167 - accuracy: 0.5302 - val_loss: 0.9851 - val_accuracy: 0.5747\n",
      "Epoch 6/50\n",
      "6960/6960 [==============================] - 21s 3ms/sample - loss: 1.0527 - accuracy: 0.5572 - val_loss: 0.9828 - val_accuracy: 0.5853\n",
      "Epoch 7/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 0.9790 - accuracy: 0.5937 - val_loss: 0.8669 - val_accuracy: 0.6500\n",
      "Epoch 8/50\n",
      "6960/6960 [==============================] - 17s 3ms/sample - loss: 0.9315 - accuracy: 0.6184 - val_loss: 0.8416 - val_accuracy: 0.6640\n",
      "Epoch 9/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.8802 - accuracy: 0.6507 - val_loss: 0.7580 - val_accuracy: 0.6987\n",
      "Epoch 10/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.8300 - accuracy: 0.6691 - val_loss: 0.7205 - val_accuracy: 0.7267\n",
      "Epoch 11/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.7868 - accuracy: 0.6815 - val_loss: 0.6579 - val_accuracy: 0.7527\n",
      "Epoch 12/50\n",
      "6960/6960 [==============================] - 18s 3ms/sample - loss: 0.7464 - accuracy: 0.7034 - val_loss: 0.5821 - val_accuracy: 0.7927\n",
      "Epoch 13/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.7092 - accuracy: 0.7243 - val_loss: 0.5595 - val_accuracy: 0.8000\n",
      "Epoch 14/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 0.6703 - accuracy: 0.7378 - val_loss: 0.5363 - val_accuracy: 0.7980\n",
      "Epoch 15/50\n",
      "6960/6960 [==============================] - 17s 2ms/sample - loss: 0.6543 - accuracy: 0.7466 - val_loss: 0.5849 - val_accuracy: 0.7747\n",
      "Epoch 16/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.6183 - accuracy: 0.7562 - val_loss: 0.4478 - val_accuracy: 0.8353\n",
      "Epoch 17/50\n",
      "6960/6960 [==============================] - 18s 3ms/sample - loss: 0.5790 - accuracy: 0.7754 - val_loss: 0.4008 - val_accuracy: 0.8580\n",
      "Epoch 18/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.5376 - accuracy: 0.7918 - val_loss: 0.3627 - val_accuracy: 0.8767\n",
      "Epoch 19/50\n",
      "6960/6960 [==============================] - 18s 3ms/sample - loss: 0.5372 - accuracy: 0.7904 - val_loss: 0.3833 - val_accuracy: 0.8607\n",
      "Epoch 20/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 0.5094 - accuracy: 0.8043 - val_loss: 0.3009 - val_accuracy: 0.9013\n",
      "Epoch 21/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.4885 - accuracy: 0.8141 - val_loss: 0.2744 - val_accuracy: 0.9220\n",
      "Epoch 22/50\n",
      "6960/6960 [==============================] - 18s 3ms/sample - loss: 0.4741 - accuracy: 0.8177 - val_loss: 0.2426 - val_accuracy: 0.9360\n",
      "Epoch 23/50\n",
      "6960/6960 [==============================] - 18s 3ms/sample - loss: 0.4355 - accuracy: 0.8358 - val_loss: 0.2364 - val_accuracy: 0.9287\n",
      "Epoch 24/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.4137 - accuracy: 0.8386 - val_loss: 0.2399 - val_accuracy: 0.9220\n",
      "Epoch 25/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 0.3966 - accuracy: 0.8491 - val_loss: 0.2223 - val_accuracy: 0.9287\n",
      "Epoch 26/50\n",
      "6960/6960 [==============================] - 18s 3ms/sample - loss: 0.3886 - accuracy: 0.8500 - val_loss: 0.1854 - val_accuracy: 0.9473\n",
      "Epoch 27/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.3680 - accuracy: 0.8576 - val_loss: 0.1796 - val_accuracy: 0.9467\n",
      "Epoch 28/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 0.3381 - accuracy: 0.8770 - val_loss: 0.1569 - val_accuracy: 0.9547\n",
      "Epoch 29/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.3253 - accuracy: 0.8773 - val_loss: 0.2098 - val_accuracy: 0.9273\n",
      "Epoch 30/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.3328 - accuracy: 0.8744 - val_loss: 0.1433 - val_accuracy: 0.9567\n",
      "Epoch 31/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.3154 - accuracy: 0.8841 - val_loss: 0.1062 - val_accuracy: 0.9780\n",
      "Epoch 32/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.2999 - accuracy: 0.8868 - val_loss: 0.1398 - val_accuracy: 0.9553\n",
      "Epoch 33/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.3042 - accuracy: 0.8879 - val_loss: 0.0996 - val_accuracy: 0.9753\n",
      "Epoch 34/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.2761 - accuracy: 0.8990 - val_loss: 0.1272 - val_accuracy: 0.9600\n",
      "Epoch 35/50\n",
      "6960/6960 [==============================] - 18s 3ms/sample - loss: 0.2938 - accuracy: 0.8937 - val_loss: 0.0729 - val_accuracy: 0.9833\n",
      "Epoch 36/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 0.2564 - accuracy: 0.9069 - val_loss: 0.0724 - val_accuracy: 0.9853\n",
      "Epoch 37/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.2484 - accuracy: 0.9050 - val_loss: 0.0712 - val_accuracy: 0.9847\n",
      "Epoch 38/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.2609 - accuracy: 0.9000 - val_loss: 0.0716 - val_accuracy: 0.9840\n",
      "Epoch 39/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.2469 - accuracy: 0.9089 - val_loss: 0.0707 - val_accuracy: 0.9833\n",
      "Epoch 40/50\n",
      "6960/6960 [==============================] - 18s 3ms/sample - loss: 0.2345 - accuracy: 0.9151 - val_loss: 0.0531 - val_accuracy: 0.9920\n",
      "Epoch 41/50\n",
      "6960/6960 [==============================] - 18s 3ms/sample - loss: 0.2180 - accuracy: 0.9191 - val_loss: 0.0453 - val_accuracy: 0.9913\n",
      "Epoch 42/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 0.2204 - accuracy: 0.9154 - val_loss: 0.0503 - val_accuracy: 0.9880\n",
      "Epoch 43/50\n",
      "6960/6960 [==============================] - 18s 3ms/sample - loss: 0.2242 - accuracy: 0.9154 - val_loss: 0.0450 - val_accuracy: 0.9920\n",
      "Epoch 44/50\n",
      "6960/6960 [==============================] - 15s 2ms/sample - loss: 0.2118 - accuracy: 0.9216 - val_loss: 0.0495 - val_accuracy: 0.9873\n",
      "Epoch 45/50\n",
      "6960/6960 [==============================] - 11s 2ms/sample - loss: 0.2169 - accuracy: 0.9165 - val_loss: 0.0484 - val_accuracy: 0.9873\n",
      "Epoch 46/50\n",
      "6960/6960 [==============================] - 10s 1ms/sample - loss: 0.2107 - accuracy: 0.9188 - val_loss: 0.0358 - val_accuracy: 0.9927\n",
      "Epoch 47/50\n",
      "6960/6960 [==============================] - 13s 2ms/sample - loss: 0.1871 - accuracy: 0.9349 - val_loss: 0.0313 - val_accuracy: 0.9933\n",
      "Epoch 48/50\n",
      "6960/6960 [==============================] - 14s 2ms/sample - loss: 0.1837 - accuracy: 0.9339 - val_loss: 0.0256 - val_accuracy: 0.9967\n",
      "Epoch 49/50\n",
      "6960/6960 [==============================] - 16s 2ms/sample - loss: 0.1858 - accuracy: 0.9328 - val_loss: 0.0258 - val_accuracy: 0.9947\n",
      "Epoch 50/50\n",
      "6960/6960 [==============================] - 15s 2ms/sample - loss: 0.1866 - accuracy: 0.9352 - val_loss: 0.0276 - val_accuracy: 0.9967\n",
      "6960/6960 [==============================] - 4s 538us/sample - loss: 0.0070 - accuracy: 1.0000\n",
      "1772/1772 [==============================] - 1s 486us/sample - loss: 1.0294 - accuracy: 0.7060\n",
      "train accuracy: 100.000%\n",
      "test accuracy: 70.598%\n"
     ]
    }
   ],
   "source": [
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "for time in range(25, 251, 25):\n",
    "    print(\"=================\" + str(time) + \"===================\")\n",
    "    train_score, test_score = train_data(time_period=time)\n",
    "    train_scores.append(train_score[1])\n",
    "    test_scores.append(test_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17a472ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracies: \n",
      "[0.91695404, 0.9801724, 0.98821837, 0.9961207, 0.99899423, 0.9992816, 0.99755746, 0.9994253, 0.9974138, 1.0]\n",
      "Test accuracies: \n",
      "[0.3860045, 0.53724605, 0.5846501, 0.65688485, 0.7003386, 0.70259595, 0.68453723, 0.69808125, 0.68340856, 0.70598197]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Train accuracies: \")\n",
    "print(train_scores)\n",
    "print(\"Test accuracies: \")\n",
    "print(test_scores)\n",
    "\n",
    "# plot\n",
    "plt.plot(range(25, 251, 25), train_scores, label='train accuracies')\n",
    "plt.plot(range(25, 251, 25), test_scores, label='test accuracies')\n",
    "plt.legend()\n",
    "plt.title(\"Classification Accuracies over Time Period (CNN)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63060fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_model(time_period=250):   \n",
    "    \n",
    "    # Building the CNN model using sequential class\n",
    "    hybrid_cnn_lstm_model = Sequential()\n",
    "\n",
    "    # Conv. block 1\n",
    "    hybrid_cnn_lstm_model.add(Conv2D(filters=100, kernel_size=(10,1), padding='same', activation='elu', input_shape=(time_period,1,22)))\n",
    "    hybrid_cnn_lstm_model.add(MaxPooling2D(pool_size=(3,1), padding='same')) # Read the keras documentation\n",
    "    hybrid_cnn_lstm_model.add(BatchNormalization())\n",
    "    hybrid_cnn_lstm_model.add(Dropout(0.5))\n",
    "\n",
    "    # Conv. block 2\n",
    "    hybrid_cnn_lstm_model.add(Conv2D(filters=100, kernel_size=(10,1), padding='same', activation='elu'))\n",
    "    hybrid_cnn_lstm_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "    hybrid_cnn_lstm_model.add(BatchNormalization())\n",
    "    hybrid_cnn_lstm_model.add(Dropout(0.5))\n",
    "\n",
    "    # Conv. block 3\n",
    "    hybrid_cnn_lstm_model.add(Conv2D(filters=100, kernel_size=(10,1), padding='same', activation='elu'))\n",
    "    hybrid_cnn_lstm_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "    hybrid_cnn_lstm_model.add(BatchNormalization())\n",
    "    hybrid_cnn_lstm_model.add(Dropout(0.5))\n",
    "\n",
    "    # Conv. block 4\n",
    "    #hybrid_cnn_lstm_model.add(Conv2D(filters=100, kernel_size=(10,1), padding='same', activation='elu'))\n",
    "    #hybrid_cnn_lstm_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "    #hybrid_cnn_lstm_model.add(BatchNormalization())\n",
    "    #hybrid_cnn_lstm_model.add(Dropout(0.5))\n",
    "\n",
    "    # FC+LSTM layers\n",
    "    hybrid_cnn_lstm_model.add(Flatten()) # Adding a flattening operation to the output of CNN block\n",
    "    hybrid_cnn_lstm_model.add(Dense((100))) # FC layer with 100 units\n",
    "    hybrid_cnn_lstm_model.add(Reshape((100,1))) # Reshape my output of FC layer so that it's compatible\n",
    "    hybrid_cnn_lstm_model.add(LSTM(100, dropout=0.5, recurrent_dropout=0.1, input_shape=(100,1), return_sequences=True))\n",
    "\n",
    "    hybrid_cnn_lstm_model.add(LSTM(70, dropout=0.5, recurrent_dropout=0.1, return_sequences=False))\n",
    "    # Output layer with Softmax activation \n",
    "    hybrid_cnn_lstm_model.add(Dense(4, activation='softmax')) # Output FC layer with softmax activation\n",
    "\n",
    "\n",
    "    hybrid_cnn_lstm_model.compile(loss='categorical_crossentropy', optimizer=hybrid_cnn_lstm_optimizer, metrics=['accuracy'])\n",
    "\n",
    "    # Printing the model summary\n",
    "    hybrid_cnn_lstm_model.summary()\n",
    "    \n",
    "    return hybrid_cnn_lstm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6776556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "learning_rate = 2e-3\n",
    "epochs = 50\n",
    "hybrid_cnn_lstm_optimizer = optimizers.Adam(lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bbd2b859",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_train_data(time_period=250):\n",
    "    # different period of time\n",
    "    x_train_time = x_train[:,:time_period,:,:]\n",
    "    y_train_time = y_train\n",
    "    x_valid_time = x_valid[:,:time_period,:,:]\n",
    "    y_valid_time = y_valid\n",
    "    x_test_time = x_test[:,:time_period,:,:]\n",
    "    y_test_time = y_test\n",
    "    \n",
    "    \n",
    "    model = hybrid_model(time_period)\n",
    "\n",
    "    # Training and validating the model\n",
    "    cnn_model_results = model.fit(x_train_time,\n",
    "                 y_train_time,\n",
    "                 batch_size=200,\n",
    "                 epochs=epochs,\n",
    "                 validation_data=(x_valid_time, y_valid_time), verbose=True)\n",
    "    \n",
    "    train_score = model.evaluate(x_train_time, y_train_time)\n",
    "    \n",
    "    test_score = model.evaluate(x_test_time, y_test_time)\n",
    "\n",
    "    print('train {:s}: {:.3f}%'.format(model.metrics_names[1], train_score[1]*100))\n",
    "    print('test {:s}: {:.3f}%'.format(model.metrics_names[1], test_score[1]*100))\n",
    "    #print(model.summary())\n",
    "    \n",
    "    return train_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6c1e54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================25===================\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_40 (Conv2D)           (None, 25, 1, 100)        22100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_40 (MaxPooling (None, 9, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 9, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 9, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 9, 1, 100)         100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_41 (MaxPooling (None, 3, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_41 (Batc (None, 3, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 3, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 3, 1, 100)         100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_42 (MaxPooling (None, 1, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_42 (Batc (None, 1, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 1, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 100, 1)            0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 100, 100)          40800     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 70)                47880     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 4)                 284       \n",
      "=================================================================\n",
      "Total params: 322,564\n",
      "Trainable params: 321,964\n",
      "Non-trainable params: 600\n",
      "_________________________________________________________________\n",
      "Train on 6960 samples, validate on 1500 samples\n",
      "Epoch 1/50\n",
      "6960/6960 [==============================] - 44s 6ms/sample - loss: 1.3783 - accuracy: 0.2772 - val_loss: 1.4113 - val_accuracy: 0.2733\n",
      "Epoch 2/50\n",
      "6960/6960 [==============================] - 28s 4ms/sample - loss: 1.3692 - accuracy: 0.2947 - val_loss: 1.3634 - val_accuracy: 0.3087\n",
      "Epoch 3/50\n",
      "6960/6960 [==============================] - 29s 4ms/sample - loss: 1.3560 - accuracy: 0.3135 - val_loss: 1.3411 - val_accuracy: 0.3300\n",
      "Epoch 4/50\n",
      "6960/6960 [==============================] - 28s 4ms/sample - loss: 1.3453 - accuracy: 0.3364 - val_loss: 1.3301 - val_accuracy: 0.3453\n",
      "Epoch 5/50\n",
      "6960/6960 [==============================] - 30s 4ms/sample - loss: 1.3194 - accuracy: 0.3572 - val_loss: 1.2966 - val_accuracy: 0.3767\n",
      "Epoch 6/50\n",
      "6960/6960 [==============================] - 27s 4ms/sample - loss: 1.2994 - accuracy: 0.3826 - val_loss: 1.2787 - val_accuracy: 0.4020\n",
      "Epoch 7/50\n",
      "6960/6960 [==============================] - 30s 4ms/sample - loss: 1.2788 - accuracy: 0.3994 - val_loss: 1.2807 - val_accuracy: 0.3787\n",
      "Epoch 8/50\n",
      "6960/6960 [==============================] - 29s 4ms/sample - loss: 1.2622 - accuracy: 0.4106 - val_loss: 1.2760 - val_accuracy: 0.4020\n",
      "Epoch 9/50\n",
      "6960/6960 [==============================] - 28s 4ms/sample - loss: 1.2378 - accuracy: 0.4231 - val_loss: 1.2333 - val_accuracy: 0.4253\n",
      "Epoch 10/50\n",
      "6960/6960 [==============================] - 29s 4ms/sample - loss: 1.2202 - accuracy: 0.4450 - val_loss: 1.2088 - val_accuracy: 0.4507\n",
      "Epoch 11/50\n",
      "6960/6960 [==============================] - 27s 4ms/sample - loss: 1.2092 - accuracy: 0.4497 - val_loss: 1.1922 - val_accuracy: 0.4780\n",
      "Epoch 12/50\n",
      "6960/6960 [==============================] - 28s 4ms/sample - loss: 1.1845 - accuracy: 0.4678 - val_loss: 1.1464 - val_accuracy: 0.4913\n",
      "Epoch 13/50\n",
      "6960/6960 [==============================] - 29s 4ms/sample - loss: 1.1533 - accuracy: 0.4836 - val_loss: 1.1404 - val_accuracy: 0.4973\n",
      "Epoch 14/50\n",
      "6960/6960 [==============================] - 28s 4ms/sample - loss: 1.1680 - accuracy: 0.4750 - val_loss: 1.1336 - val_accuracy: 0.5080\n",
      "Epoch 15/50\n",
      "6960/6960 [==============================] - 28s 4ms/sample - loss: 1.1403 - accuracy: 0.4934 - val_loss: 1.1155 - val_accuracy: 0.5093\n",
      "Epoch 16/50\n",
      "6960/6960 [==============================] - 28s 4ms/sample - loss: 1.1234 - accuracy: 0.5065 - val_loss: 1.0876 - val_accuracy: 0.5220\n",
      "Epoch 17/50\n",
      "6960/6960 [==============================] - 28s 4ms/sample - loss: 1.1026 - accuracy: 0.5181 - val_loss: 1.0515 - val_accuracy: 0.5440\n",
      "Epoch 18/50\n",
      "6960/6960 [==============================] - 31s 4ms/sample - loss: 1.0911 - accuracy: 0.5286 - val_loss: 1.0217 - val_accuracy: 0.5807\n",
      "Epoch 19/50\n",
      "6960/6960 [==============================] - 29s 4ms/sample - loss: 1.0739 - accuracy: 0.5296 - val_loss: 1.0059 - val_accuracy: 0.5793\n",
      "Epoch 20/50\n",
      "6960/6960 [==============================] - 30s 4ms/sample - loss: 1.0516 - accuracy: 0.5507 - val_loss: 1.0008 - val_accuracy: 0.5927\n",
      "Epoch 21/50\n",
      "6960/6960 [==============================] - 29s 4ms/sample - loss: 1.0535 - accuracy: 0.5461 - val_loss: 1.0283 - val_accuracy: 0.5580\n",
      "Epoch 22/50\n",
      "6960/6960 [==============================] - 30s 4ms/sample - loss: 1.0284 - accuracy: 0.5532 - val_loss: 0.9765 - val_accuracy: 0.6060\n",
      "Epoch 23/50\n",
      "6960/6960 [==============================] - 27s 4ms/sample - loss: 1.0203 - accuracy: 0.5614 - val_loss: 0.9338 - val_accuracy: 0.6087\n",
      "Epoch 24/50\n",
      "6960/6960 [==============================] - 28s 4ms/sample - loss: 1.0165 - accuracy: 0.5658 - val_loss: 0.9848 - val_accuracy: 0.5900\n",
      "Epoch 25/50\n",
      "6960/6960 [==============================] - 28s 4ms/sample - loss: 1.0077 - accuracy: 0.5672 - val_loss: 0.9406 - val_accuracy: 0.6147\n",
      "Epoch 26/50\n",
      "6960/6960 [==============================] - 28s 4ms/sample - loss: 0.9850 - accuracy: 0.5780 - val_loss: 0.9189 - val_accuracy: 0.6160\n",
      "Epoch 27/50\n",
      "6960/6960 [==============================] - 27s 4ms/sample - loss: 0.9730 - accuracy: 0.5859 - val_loss: 0.9097 - val_accuracy: 0.6347\n",
      "Epoch 28/50\n",
      "6960/6960 [==============================] - 30s 4ms/sample - loss: 0.9585 - accuracy: 0.6019 - val_loss: 0.8927 - val_accuracy: 0.6433\n",
      "Epoch 29/50\n",
      "6960/6960 [==============================] - 29s 4ms/sample - loss: 0.9346 - accuracy: 0.6066 - val_loss: 0.8912 - val_accuracy: 0.6527\n",
      "Epoch 30/50\n",
      "6960/6960 [==============================] - 27s 4ms/sample - loss: 0.9566 - accuracy: 0.6007 - val_loss: 0.8797 - val_accuracy: 0.6507\n",
      "Epoch 31/50\n",
      "6960/6960 [==============================] - 29s 4ms/sample - loss: 0.9267 - accuracy: 0.6083 - val_loss: 0.8663 - val_accuracy: 0.6633\n",
      "Epoch 32/50\n",
      "6960/6960 [==============================] - 28s 4ms/sample - loss: 0.9191 - accuracy: 0.6187 - val_loss: 0.8569 - val_accuracy: 0.6493\n",
      "Epoch 33/50\n",
      "6960/6960 [==============================] - 29s 4ms/sample - loss: 0.9205 - accuracy: 0.6088 - val_loss: 0.8149 - val_accuracy: 0.6820\n",
      "Epoch 34/50\n",
      "6960/6960 [==============================] - 29s 4ms/sample - loss: 0.9034 - accuracy: 0.6251 - val_loss: 0.8348 - val_accuracy: 0.6787\n",
      "Epoch 35/50\n",
      "6960/6960 [==============================] - 30s 4ms/sample - loss: 0.8992 - accuracy: 0.6276 - val_loss: 0.8118 - val_accuracy: 0.6947\n",
      "Epoch 36/50\n",
      "6960/6960 [==============================] - 28s 4ms/sample - loss: 0.8846 - accuracy: 0.6355 - val_loss: 0.8102 - val_accuracy: 0.6940\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6960/6960 [==============================] - 30s 4ms/sample - loss: 0.8782 - accuracy: 0.6289 - val_loss: 0.7789 - val_accuracy: 0.6993\n",
      "Epoch 38/50\n",
      "6960/6960 [==============================] - 27s 4ms/sample - loss: 0.8605 - accuracy: 0.6385 - val_loss: 0.7784 - val_accuracy: 0.7213\n",
      "Epoch 39/50\n",
      "6960/6960 [==============================] - 30s 4ms/sample - loss: 0.8481 - accuracy: 0.6435 - val_loss: 0.7656 - val_accuracy: 0.7093\n",
      "Epoch 40/50\n",
      "6960/6960 [==============================] - 28s 4ms/sample - loss: 0.8497 - accuracy: 0.6471 - val_loss: 0.7494 - val_accuracy: 0.7153\n",
      "Epoch 41/50\n",
      "6960/6960 [==============================] - 27s 4ms/sample - loss: 0.8546 - accuracy: 0.6405 - val_loss: 0.7690 - val_accuracy: 0.7027\n",
      "Epoch 42/50\n",
      "6960/6960 [==============================] - 28s 4ms/sample - loss: 0.8416 - accuracy: 0.6493 - val_loss: 0.7839 - val_accuracy: 0.7240\n",
      "Epoch 43/50\n",
      "6960/6960 [==============================] - 30s 4ms/sample - loss: 0.8352 - accuracy: 0.6480 - val_loss: 0.7347 - val_accuracy: 0.7340\n",
      "Epoch 44/50\n",
      "6960/6960 [==============================] - 28s 4ms/sample - loss: 0.8340 - accuracy: 0.6555 - val_loss: 0.7692 - val_accuracy: 0.7313\n",
      "Epoch 45/50\n",
      "6960/6960 [==============================] - 29s 4ms/sample - loss: 0.8271 - accuracy: 0.6589 - val_loss: 0.7218 - val_accuracy: 0.7513\n",
      "Epoch 46/50\n",
      "6960/6960 [==============================] - 29s 4ms/sample - loss: 0.8156 - accuracy: 0.6667 - val_loss: 0.6825 - val_accuracy: 0.7427\n",
      "Epoch 47/50\n",
      "6960/6960 [==============================] - 30s 4ms/sample - loss: 0.8039 - accuracy: 0.6718 - val_loss: 0.7270 - val_accuracy: 0.7540\n",
      "Epoch 48/50\n",
      "6960/6960 [==============================] - 28s 4ms/sample - loss: 0.8056 - accuracy: 0.6675 - val_loss: 0.7137 - val_accuracy: 0.7447\n",
      "Epoch 49/50\n",
      "6960/6960 [==============================] - 28s 4ms/sample - loss: 0.8053 - accuracy: 0.6693 - val_loss: 0.7310 - val_accuracy: 0.7413\n",
      "Epoch 50/50\n",
      "6960/6960 [==============================] - 29s 4ms/sample - loss: 0.7967 - accuracy: 0.6718 - val_loss: 0.6970 - val_accuracy: 0.7553\n",
      "6960/6960 [==============================] - 10s 1ms/sample - loss: 0.4848 - accuracy: 0.9029\n",
      "1772/1772 [==============================] - 3s 2ms/sample - loss: 1.4664 - accuracy: 0.3849\n",
      "train accuracy: 90.287%\n",
      "test accuracy: 38.488%\n",
      "=================50===================\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_43 (Conv2D)           (None, 50, 1, 100)        22100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_43 (MaxPooling (None, 17, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_43 (Batc (None, 17, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 17, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 17, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_44 (MaxPooling (None, 6, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_44 (Batc (None, 6, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 6, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 6, 1, 100)         100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_45 (MaxPooling (None, 2, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_45 (Batc (None, 2, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 2, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 100, 1)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100, 100)          40800     \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 70)                47880     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 4)                 284       \n",
      "=================================================================\n",
      "Total params: 332,564\n",
      "Trainable params: 331,964\n",
      "Non-trainable params: 600\n",
      "_________________________________________________________________\n",
      "Train on 6960 samples, validate on 1500 samples\n",
      "Epoch 1/50\n",
      "6960/6960 [==============================] - 59s 8ms/sample - loss: 1.3888 - accuracy: 0.2636 - val_loss: 1.3863 - val_accuracy: 0.2753\n",
      "Epoch 2/50\n",
      "6960/6960 [==============================] - 42s 6ms/sample - loss: 1.3597 - accuracy: 0.3249 - val_loss: 1.5211 - val_accuracy: 0.2840\n",
      "Epoch 3/50\n",
      "6960/6960 [==============================] - 41s 6ms/sample - loss: 1.3322 - accuracy: 0.3652 - val_loss: 1.4008 - val_accuracy: 0.2987\n",
      "Epoch 4/50\n",
      "6960/6960 [==============================] - 42s 6ms/sample - loss: 1.3079 - accuracy: 0.3822 - val_loss: 1.3565 - val_accuracy: 0.3800\n",
      "Epoch 5/50\n",
      "6960/6960 [==============================] - 41s 6ms/sample - loss: 1.2788 - accuracy: 0.4036 - val_loss: 1.2637 - val_accuracy: 0.4193\n",
      "Epoch 6/50\n",
      "6960/6960 [==============================] - 41s 6ms/sample - loss: 1.2463 - accuracy: 0.4287 - val_loss: 1.1777 - val_accuracy: 0.4647\n",
      "Epoch 7/50\n",
      "6960/6960 [==============================] - 41s 6ms/sample - loss: 1.2193 - accuracy: 0.4471 - val_loss: 1.1510 - val_accuracy: 0.4987\n",
      "Epoch 8/50\n",
      "6960/6960 [==============================] - 38s 6ms/sample - loss: 1.1825 - accuracy: 0.4874 - val_loss: 1.0978 - val_accuracy: 0.5247\n",
      "Epoch 9/50\n",
      "6960/6960 [==============================] - 42s 6ms/sample - loss: 1.1509 - accuracy: 0.5010 - val_loss: 1.0584 - val_accuracy: 0.5453\n",
      "Epoch 10/50\n",
      "6960/6960 [==============================] - 36s 5ms/sample - loss: 1.1079 - accuracy: 0.5190 - val_loss: 1.0031 - val_accuracy: 0.5820\n",
      "Epoch 11/50\n",
      "6960/6960 [==============================] - 39s 6ms/sample - loss: 1.0871 - accuracy: 0.5376 - val_loss: 1.0395 - val_accuracy: 0.5507\n",
      "Epoch 12/50\n",
      "6960/6960 [==============================] - 41s 6ms/sample - loss: 1.0700 - accuracy: 0.5397 - val_loss: 0.9399 - val_accuracy: 0.6153\n",
      "Epoch 13/50\n",
      "6960/6960 [==============================] - 42s 6ms/sample - loss: 1.0248 - accuracy: 0.5644 - val_loss: 0.9072 - val_accuracy: 0.6447\n",
      "Epoch 14/50\n",
      "6960/6960 [==============================] - 41s 6ms/sample - loss: 1.0017 - accuracy: 0.5776 - val_loss: 0.8752 - val_accuracy: 0.6373\n",
      "Epoch 15/50\n",
      "6960/6960 [==============================] - 42s 6ms/sample - loss: 0.9653 - accuracy: 0.5917 - val_loss: 0.8564 - val_accuracy: 0.6640\n",
      "Epoch 16/50\n",
      "6960/6960 [==============================] - 43s 6ms/sample - loss: 0.9464 - accuracy: 0.6010 - val_loss: 0.8181 - val_accuracy: 0.6907\n",
      "Epoch 17/50\n",
      "6960/6960 [==============================] - 43s 6ms/sample - loss: 0.9152 - accuracy: 0.6231 - val_loss: 0.8015 - val_accuracy: 0.7080\n",
      "Epoch 18/50\n",
      "6960/6960 [==============================] - 42s 6ms/sample - loss: 0.8999 - accuracy: 0.6236 - val_loss: 0.7922 - val_accuracy: 0.7013\n",
      "Epoch 19/50\n",
      "6960/6960 [==============================] - 41s 6ms/sample - loss: 0.8830 - accuracy: 0.6306 - val_loss: 0.7329 - val_accuracy: 0.7400\n",
      "Epoch 20/50\n",
      "6960/6960 [==============================] - 44s 6ms/sample - loss: 0.8446 - accuracy: 0.6511 - val_loss: 0.6991 - val_accuracy: 0.7433\n",
      "Epoch 21/50\n",
      "6960/6960 [==============================] - 43s 6ms/sample - loss: 0.8253 - accuracy: 0.6632 - val_loss: 0.6655 - val_accuracy: 0.7620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50\n",
      "6960/6960 [==============================] - 42s 6ms/sample - loss: 0.8085 - accuracy: 0.6680 - val_loss: 0.6599 - val_accuracy: 0.7633\n",
      "Epoch 23/50\n",
      "6960/6960 [==============================] - 41s 6ms/sample - loss: 0.8087 - accuracy: 0.6693 - val_loss: 0.6327 - val_accuracy: 0.7867\n",
      "Epoch 24/50\n",
      "6960/6960 [==============================] - 41s 6ms/sample - loss: 0.7850 - accuracy: 0.6770 - val_loss: 0.6449 - val_accuracy: 0.7640\n",
      "Epoch 25/50\n",
      "6960/6960 [==============================] - 41s 6ms/sample - loss: 0.7717 - accuracy: 0.6869 - val_loss: 0.6012 - val_accuracy: 0.7973\n",
      "Epoch 26/50\n",
      "6960/6960 [==============================] - 42s 6ms/sample - loss: 0.7450 - accuracy: 0.7039 - val_loss: 0.5853 - val_accuracy: 0.8060\n",
      "Epoch 27/50\n",
      "6960/6960 [==============================] - 41s 6ms/sample - loss: 0.7285 - accuracy: 0.7046 - val_loss: 0.5723 - val_accuracy: 0.8113\n",
      "Epoch 28/50\n",
      "6960/6960 [==============================] - 40s 6ms/sample - loss: 0.7201 - accuracy: 0.7096 - val_loss: 0.5690 - val_accuracy: 0.8080\n",
      "Epoch 29/50\n",
      "6960/6960 [==============================] - 43s 6ms/sample - loss: 0.7144 - accuracy: 0.7042 - val_loss: 0.5500 - val_accuracy: 0.8213\n",
      "Epoch 30/50\n",
      "6960/6960 [==============================] - 41s 6ms/sample - loss: 0.6910 - accuracy: 0.7218 - val_loss: 0.5116 - val_accuracy: 0.8260\n",
      "Epoch 31/50\n",
      "6960/6960 [==============================] - 42s 6ms/sample - loss: 0.6745 - accuracy: 0.7256 - val_loss: 0.5031 - val_accuracy: 0.8433\n",
      "Epoch 32/50\n",
      "6960/6960 [==============================] - 43s 6ms/sample - loss: 0.6730 - accuracy: 0.7221 - val_loss: 0.5056 - val_accuracy: 0.8353\n",
      "Epoch 33/50\n",
      "6960/6960 [==============================] - 40s 6ms/sample - loss: 0.6583 - accuracy: 0.7356 - val_loss: 0.4848 - val_accuracy: 0.8340\n",
      "Epoch 34/50\n",
      "6960/6960 [==============================] - 43s 6ms/sample - loss: 0.6367 - accuracy: 0.7409 - val_loss: 0.4465 - val_accuracy: 0.8513\n",
      "Epoch 35/50\n",
      "6960/6960 [==============================] - 40s 6ms/sample - loss: 0.6379 - accuracy: 0.7404 - val_loss: 0.4570 - val_accuracy: 0.8440\n",
      "Epoch 36/50\n",
      "6960/6960 [==============================] - 41s 6ms/sample - loss: 0.6115 - accuracy: 0.7533 - val_loss: 0.4366 - val_accuracy: 0.8560\n",
      "Epoch 37/50\n",
      "6960/6960 [==============================] - 41s 6ms/sample - loss: 0.6074 - accuracy: 0.7511 - val_loss: 0.4182 - val_accuracy: 0.8687\n",
      "Epoch 38/50\n",
      "6960/6960 [==============================] - 41s 6ms/sample - loss: 0.6048 - accuracy: 0.7555 - val_loss: 0.4191 - val_accuracy: 0.8700\n",
      "Epoch 39/50\n",
      "6960/6960 [==============================] - 41s 6ms/sample - loss: 0.6195 - accuracy: 0.7514 - val_loss: 0.4480 - val_accuracy: 0.8547\n",
      "Epoch 40/50\n",
      "6960/6960 [==============================] - 43s 6ms/sample - loss: 0.5761 - accuracy: 0.7717 - val_loss: 0.4142 - val_accuracy: 0.8687\n",
      "Epoch 41/50\n",
      "6960/6960 [==============================] - 44s 6ms/sample - loss: 0.5675 - accuracy: 0.7749 - val_loss: 0.3961 - val_accuracy: 0.8773\n",
      "Epoch 42/50\n",
      "6960/6960 [==============================] - 41s 6ms/sample - loss: 0.5838 - accuracy: 0.7631 - val_loss: 0.3618 - val_accuracy: 0.8887\n",
      "Epoch 43/50\n",
      "6960/6960 [==============================] - 41s 6ms/sample - loss: 0.5623 - accuracy: 0.7759 - val_loss: 0.3653 - val_accuracy: 0.8933\n",
      "Epoch 44/50\n",
      "6960/6960 [==============================] - 43s 6ms/sample - loss: 0.5606 - accuracy: 0.7703 - val_loss: 0.3653 - val_accuracy: 0.8900\n",
      "Epoch 45/50\n",
      "6960/6960 [==============================] - 43s 6ms/sample - loss: 0.5516 - accuracy: 0.7782 - val_loss: 0.3362 - val_accuracy: 0.8907\n",
      "Epoch 46/50\n",
      "6960/6960 [==============================] - 42s 6ms/sample - loss: 0.5387 - accuracy: 0.7855 - val_loss: 0.3510 - val_accuracy: 0.8940\n",
      "Epoch 47/50\n",
      "6960/6960 [==============================] - 40s 6ms/sample - loss: 0.5277 - accuracy: 0.7889 - val_loss: 0.3490 - val_accuracy: 0.8947\n",
      "Epoch 48/50\n",
      "6960/6960 [==============================] - 41s 6ms/sample - loss: 0.5352 - accuracy: 0.7855 - val_loss: 0.3369 - val_accuracy: 0.9027\n",
      "Epoch 49/50\n",
      "6960/6960 [==============================] - 41s 6ms/sample - loss: 0.5273 - accuracy: 0.7843 - val_loss: 0.3215 - val_accuracy: 0.9013\n",
      "Epoch 50/50\n",
      "6960/6960 [==============================] - 42s 6ms/sample - loss: 0.4998 - accuracy: 0.7973 - val_loss: 0.3038 - val_accuracy: 0.9060\n",
      "6960/6960 [==============================] - 15s 2ms/sample - loss: 0.1618 - accuracy: 0.9799\n",
      "1772/1772 [==============================] - 3s 2ms/sample - loss: 1.2875 - accuracy: 0.5017\n",
      "train accuracy: 97.989%\n",
      "test accuracy: 50.169%\n",
      "=================75===================\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_46 (Conv2D)           (None, 75, 1, 100)        22100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_46 (MaxPooling (None, 25, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_46 (Batc (None, 25, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_46 (Dropout)         (None, 25, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 25, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_47 (MaxPooling (None, 9, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_47 (Batc (None, 9, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_47 (Dropout)         (None, 9, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_48 (Conv2D)           (None, 9, 1, 100)         100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_48 (MaxPooling (None, 3, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_48 (Batc (None, 3, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_48 (Dropout)         (None, 3, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 100, 1)            0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 100, 100)          40800     \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 70)                47880     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 4)                 284       \n",
      "=================================================================\n",
      "Total params: 342,564\n",
      "Trainable params: 341,964\n",
      "Non-trainable params: 600\n",
      "_________________________________________________________________\n",
      "Train on 6960 samples, validate on 1500 samples\n",
      "Epoch 1/50\n",
      "6960/6960 [==============================] - 58s 8ms/sample - loss: 1.3881 - accuracy: 0.2728 - val_loss: 1.3969 - val_accuracy: 0.2520\n",
      "Epoch 2/50\n",
      "6960/6960 [==============================] - 43s 6ms/sample - loss: 1.3651 - accuracy: 0.3175 - val_loss: 1.3522 - val_accuracy: 0.3320\n",
      "Epoch 3/50\n",
      "6960/6960 [==============================] - 42s 6ms/sample - loss: 1.3318 - accuracy: 0.3634 - val_loss: 1.3368 - val_accuracy: 0.3687\n",
      "Epoch 4/50\n",
      "6960/6960 [==============================] - 42s 6ms/sample - loss: 1.2934 - accuracy: 0.3907 - val_loss: 1.3092 - val_accuracy: 0.3967\n",
      "Epoch 5/50\n",
      "6960/6960 [==============================] - 43s 6ms/sample - loss: 1.2536 - accuracy: 0.4194 - val_loss: 1.2603 - val_accuracy: 0.4347\n",
      "Epoch 6/50\n",
      "6960/6960 [==============================] - 42s 6ms/sample - loss: 1.2340 - accuracy: 0.4295 - val_loss: 1.2329 - val_accuracy: 0.4367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50\n",
      "6960/6960 [==============================] - 43s 6ms/sample - loss: 1.2007 - accuracy: 0.4572 - val_loss: 1.1785 - val_accuracy: 0.5020\n",
      "Epoch 8/50\n",
      "6960/6960 [==============================] - 37s 5ms/sample - loss: 1.1679 - accuracy: 0.4716 - val_loss: 1.1011 - val_accuracy: 0.5233\n",
      "Epoch 9/50\n",
      "6960/6960 [==============================] - 39s 6ms/sample - loss: 1.1521 - accuracy: 0.4838 - val_loss: 1.0226 - val_accuracy: 0.5580\n",
      "Epoch 10/50\n",
      "6960/6960 [==============================] - 42s 6ms/sample - loss: 1.1204 - accuracy: 0.4914 - val_loss: 1.0084 - val_accuracy: 0.5640\n",
      "Epoch 11/50\n",
      "6960/6960 [==============================] - 40s 6ms/sample - loss: 1.0871 - accuracy: 0.5188 - val_loss: 0.9761 - val_accuracy: 0.5600\n",
      "Epoch 12/50\n",
      "6960/6960 [==============================] - 41s 6ms/sample - loss: 1.0779 - accuracy: 0.5203 - val_loss: 0.9450 - val_accuracy: 0.6040\n",
      "Epoch 13/50\n",
      "6960/6960 [==============================] - 40s 6ms/sample - loss: 1.0505 - accuracy: 0.5349 - val_loss: 0.9223 - val_accuracy: 0.6173\n",
      "Epoch 14/50\n",
      "6960/6960 [==============================] - 40s 6ms/sample - loss: 1.0264 - accuracy: 0.5491 - val_loss: 0.8945 - val_accuracy: 0.6413\n",
      "Epoch 15/50\n",
      "6960/6960 [==============================] - 43s 6ms/sample - loss: 0.9938 - accuracy: 0.5665 - val_loss: 0.8974 - val_accuracy: 0.6473\n",
      "Epoch 16/50\n",
      "6960/6960 [==============================] - 41s 6ms/sample - loss: 0.9665 - accuracy: 0.5789 - val_loss: 0.8415 - val_accuracy: 0.6647\n",
      "Epoch 17/50\n",
      "6960/6960 [==============================] - 40s 6ms/sample - loss: 0.9433 - accuracy: 0.5978 - val_loss: 0.7792 - val_accuracy: 0.7120\n",
      "Epoch 18/50\n",
      "6960/6960 [==============================] - 42s 6ms/sample - loss: 0.9291 - accuracy: 0.6052 - val_loss: 0.7928 - val_accuracy: 0.6933\n",
      "Epoch 19/50\n",
      "6960/6960 [==============================] - 41s 6ms/sample - loss: 0.8875 - accuracy: 0.6295 - val_loss: 0.7379 - val_accuracy: 0.7180\n",
      "Epoch 20/50\n",
      "6960/6960 [==============================] - 41s 6ms/sample - loss: 0.8672 - accuracy: 0.6402 - val_loss: 0.7152 - val_accuracy: 0.7393\n",
      "Epoch 21/50\n",
      "6960/6960 [==============================] - 42s 6ms/sample - loss: 0.8441 - accuracy: 0.6481 - val_loss: 0.7040 - val_accuracy: 0.7480\n",
      "Epoch 22/50\n",
      "6960/6960 [==============================] - 39s 6ms/sample - loss: 0.8260 - accuracy: 0.6645 - val_loss: 0.6449 - val_accuracy: 0.7660\n",
      "Epoch 23/50\n",
      "6960/6960 [==============================] - 41s 6ms/sample - loss: 0.8101 - accuracy: 0.6667 - val_loss: 0.6248 - val_accuracy: 0.7827\n",
      "Epoch 24/50\n",
      "6960/6960 [==============================] - 42s 6ms/sample - loss: 0.7832 - accuracy: 0.6795 - val_loss: 0.6190 - val_accuracy: 0.7773\n",
      "Epoch 25/50\n",
      "6960/6960 [==============================] - 42s 6ms/sample - loss: 0.7656 - accuracy: 0.6954 - val_loss: 0.5971 - val_accuracy: 0.8107\n",
      "Epoch 26/50\n",
      "6960/6960 [==============================] - 41s 6ms/sample - loss: 0.7497 - accuracy: 0.6947 - val_loss: 0.5564 - val_accuracy: 0.8273\n",
      "Epoch 27/50\n",
      "6960/6960 [==============================] - 40s 6ms/sample - loss: 0.7360 - accuracy: 0.7055 - val_loss: 0.5541 - val_accuracy: 0.8373\n",
      "Epoch 28/50\n",
      "6960/6960 [==============================] - 41s 6ms/sample - loss: 0.6963 - accuracy: 0.7159 - val_loss: 0.5009 - val_accuracy: 0.8333\n",
      "Epoch 29/50\n",
      "6960/6960 [==============================] - 41s 6ms/sample - loss: 0.6856 - accuracy: 0.7247 - val_loss: 0.5221 - val_accuracy: 0.8373\n",
      "Epoch 30/50\n",
      "6960/6960 [==============================] - 41s 6ms/sample - loss: 0.6565 - accuracy: 0.7325 - val_loss: 0.4689 - val_accuracy: 0.8520\n",
      "Epoch 31/50\n",
      "6960/6960 [==============================] - 40s 6ms/sample - loss: 0.6445 - accuracy: 0.7450 - val_loss: 0.4623 - val_accuracy: 0.8500\n",
      "Epoch 32/50\n",
      "6960/6960 [==============================] - 41s 6ms/sample - loss: 0.6589 - accuracy: 0.7263 - val_loss: 0.4935 - val_accuracy: 0.8640\n",
      "Epoch 33/50\n",
      "6960/6960 [==============================] - 39s 6ms/sample - loss: 0.6241 - accuracy: 0.7481 - val_loss: 0.4133 - val_accuracy: 0.8813\n",
      "Epoch 34/50\n",
      "6960/6960 [==============================] - 42s 6ms/sample - loss: 0.6160 - accuracy: 0.7496 - val_loss: 0.4205 - val_accuracy: 0.8733\n",
      "Epoch 35/50\n",
      "6960/6960 [==============================] - 42s 6ms/sample - loss: 0.6003 - accuracy: 0.7586 - val_loss: 0.3954 - val_accuracy: 0.8887\n",
      "Epoch 36/50\n",
      "6960/6960 [==============================] - 43s 6ms/sample - loss: 0.5885 - accuracy: 0.7595 - val_loss: 0.4038 - val_accuracy: 0.8927\n",
      "Epoch 37/50\n",
      "6960/6960 [==============================] - 41s 6ms/sample - loss: 0.5854 - accuracy: 0.7636 - val_loss: 0.4248 - val_accuracy: 0.8707\n",
      "Epoch 38/50\n",
      "6960/6960 [==============================] - 42s 6ms/sample - loss: 0.5704 - accuracy: 0.7688 - val_loss: 0.3875 - val_accuracy: 0.9060\n",
      "Epoch 39/50\n",
      "6960/6960 [==============================] - 40s 6ms/sample - loss: 0.5582 - accuracy: 0.7753 - val_loss: 0.3932 - val_accuracy: 0.8893\n",
      "Epoch 40/50\n",
      "6960/6960 [==============================] - 40s 6ms/sample - loss: 0.5565 - accuracy: 0.7809 - val_loss: 0.3873 - val_accuracy: 0.8960\n",
      "Epoch 41/50\n",
      "6960/6960 [==============================] - 43s 6ms/sample - loss: 0.5593 - accuracy: 0.7728 - val_loss: 0.3401 - val_accuracy: 0.9140\n",
      "Epoch 42/50\n",
      "6960/6960 [==============================] - 40s 6ms/sample - loss: 0.5335 - accuracy: 0.7843 - val_loss: 0.3448 - val_accuracy: 0.9073\n",
      "Epoch 43/50\n",
      "6960/6960 [==============================] - 41s 6ms/sample - loss: 0.5321 - accuracy: 0.7874 - val_loss: 0.3451 - val_accuracy: 0.9120\n",
      "Epoch 44/50\n",
      "6960/6960 [==============================] - 42s 6ms/sample - loss: 0.5254 - accuracy: 0.7872 - val_loss: 0.3283 - val_accuracy: 0.9167\n",
      "Epoch 45/50\n",
      "6960/6960 [==============================] - 41s 6ms/sample - loss: 0.5151 - accuracy: 0.7914 - val_loss: 0.3357 - val_accuracy: 0.9213\n",
      "Epoch 46/50\n",
      "6960/6960 [==============================] - 42s 6ms/sample - loss: 0.4997 - accuracy: 0.8036 - val_loss: 0.3029 - val_accuracy: 0.9307\n",
      "Epoch 47/50\n",
      "6960/6960 [==============================] - 43s 6ms/sample - loss: 0.5130 - accuracy: 0.7960 - val_loss: 0.3193 - val_accuracy: 0.9307\n",
      "Epoch 48/50\n",
      "6960/6960 [==============================] - 41s 6ms/sample - loss: 0.4765 - accuracy: 0.8078 - val_loss: 0.2926 - val_accuracy: 0.9440\n",
      "Epoch 49/50\n",
      "6960/6960 [==============================] - 41s 6ms/sample - loss: 0.4804 - accuracy: 0.8073 - val_loss: 0.2641 - val_accuracy: 0.9460\n",
      "Epoch 50/50\n",
      "6960/6960 [==============================] - 42s 6ms/sample - loss: 0.4883 - accuracy: 0.8036 - val_loss: 0.2870 - val_accuracy: 0.9427\n",
      "6960/6960 [==============================] - 13s 2ms/sample - loss: 0.1736 - accuracy: 0.9864\n",
      "1772/1772 [==============================] - 2s 1ms/sample - loss: 1.1469 - accuracy: 0.5468\n",
      "train accuracy: 98.635%\n",
      "test accuracy: 54.684%\n",
      "=================100===================\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_49 (Conv2D)           (None, 100, 1, 100)       22100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_49 (MaxPooling (None, 34, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_49 (Batc (None, 34, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 34, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_50 (Conv2D)           (None, 34, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_50 (MaxPooling (None, 12, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_50 (Batc (None, 12, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_50 (Dropout)         (None, 12, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_51 (Conv2D)           (None, 12, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_51 (MaxPooling (None, 4, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_51 (Batc (None, 4, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_51 (Dropout)         (None, 4, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 100)               40100     \n",
      "_________________________________________________________________\n",
      "reshape_3 (Reshape)          (None, 100, 1)            0         \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 100, 100)          40800     \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 70)                47880     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 4)                 284       \n",
      "=================================================================\n",
      "Total params: 352,564\n",
      "Trainable params: 351,964\n",
      "Non-trainable params: 600\n",
      "_________________________________________________________________\n",
      "Train on 6960 samples, validate on 1500 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6960/6960 [==============================] - 60s 9ms/sample - loss: 1.3953 - accuracy: 0.2642 - val_loss: 1.3732 - val_accuracy: 0.2887\n",
      "Epoch 2/50\n",
      "6960/6960 [==============================] - 43s 6ms/sample - loss: 1.3647 - accuracy: 0.3193 - val_loss: 1.4323 - val_accuracy: 0.2960\n",
      "Epoch 3/50\n",
      "6960/6960 [==============================] - 46s 7ms/sample - loss: 1.3184 - accuracy: 0.3743 - val_loss: 1.4028 - val_accuracy: 0.2947\n",
      "Epoch 4/50\n",
      "6960/6960 [==============================] - 45s 7ms/sample - loss: 1.2631 - accuracy: 0.4205 - val_loss: 1.3774 - val_accuracy: 0.3513\n",
      "Epoch 5/50\n",
      "6960/6960 [==============================] - 46s 7ms/sample - loss: 1.2227 - accuracy: 0.4420 - val_loss: 1.2043 - val_accuracy: 0.4520\n",
      "Epoch 6/50\n",
      "6960/6960 [==============================] - 45s 6ms/sample - loss: 1.1730 - accuracy: 0.4707 - val_loss: 1.0780 - val_accuracy: 0.5200\n",
      "Epoch 7/50\n",
      "6960/6960 [==============================] - 46s 7ms/sample - loss: 1.1448 - accuracy: 0.4849 - val_loss: 1.0403 - val_accuracy: 0.5420\n",
      "Epoch 8/50\n",
      "6960/6960 [==============================] - 47s 7ms/sample - loss: 1.1234 - accuracy: 0.4921 - val_loss: 1.0105 - val_accuracy: 0.5420\n",
      "Epoch 9/50\n",
      "6960/6960 [==============================] - 45s 7ms/sample - loss: 1.0961 - accuracy: 0.5050 - val_loss: 0.9645 - val_accuracy: 0.5680\n",
      "Epoch 10/50\n",
      "6960/6960 [==============================] - 45s 6ms/sample - loss: 1.0542 - accuracy: 0.5220 - val_loss: 0.9349 - val_accuracy: 0.5773\n",
      "Epoch 11/50\n",
      "6960/6960 [==============================] - 46s 7ms/sample - loss: 1.0349 - accuracy: 0.5417 - val_loss: 0.9111 - val_accuracy: 0.5913\n",
      "Epoch 12/50\n",
      "6960/6960 [==============================] - 45s 6ms/sample - loss: 1.0177 - accuracy: 0.5409 - val_loss: 1.0012 - val_accuracy: 0.5240\n",
      "Epoch 13/50\n",
      "6960/6960 [==============================] - 47s 7ms/sample - loss: 1.0030 - accuracy: 0.5540 - val_loss: 0.8880 - val_accuracy: 0.5913\n",
      "Epoch 14/50\n",
      "6960/6960 [==============================] - 45s 7ms/sample - loss: 0.9761 - accuracy: 0.5665 - val_loss: 0.8352 - val_accuracy: 0.6280\n",
      "Epoch 15/50\n",
      "6960/6960 [==============================] - 46s 7ms/sample - loss: 0.9450 - accuracy: 0.5754 - val_loss: 0.8060 - val_accuracy: 0.6547\n",
      "Epoch 16/50\n",
      "6960/6960 [==============================] - 41s 6ms/sample - loss: 0.9428 - accuracy: 0.5889 - val_loss: 0.8174 - val_accuracy: 0.6633\n",
      "Epoch 17/50\n",
      "6960/6960 [==============================] - 45s 6ms/sample - loss: 0.9063 - accuracy: 0.6024 - val_loss: 0.7724 - val_accuracy: 0.6873\n",
      "Epoch 18/50\n",
      "6960/6960 [==============================] - 45s 7ms/sample - loss: 0.8973 - accuracy: 0.6062 - val_loss: 0.7698 - val_accuracy: 0.6740\n",
      "Epoch 19/50\n",
      "6960/6960 [==============================] - 47s 7ms/sample - loss: 0.8656 - accuracy: 0.6266 - val_loss: 0.7669 - val_accuracy: 0.6873\n",
      "Epoch 20/50\n",
      "6960/6960 [==============================] - 45s 7ms/sample - loss: 0.8516 - accuracy: 0.6305 - val_loss: 0.7381 - val_accuracy: 0.7093\n",
      "Epoch 21/50\n",
      "6960/6960 [==============================] - 45s 6ms/sample - loss: 0.8466 - accuracy: 0.6348 - val_loss: 0.6725 - val_accuracy: 0.7373\n",
      "Epoch 22/50\n",
      "6960/6960 [==============================] - 45s 7ms/sample - loss: 0.8054 - accuracy: 0.6588 - val_loss: 0.6928 - val_accuracy: 0.7213\n",
      "Epoch 23/50\n",
      "6960/6960 [==============================] - 46s 7ms/sample - loss: 0.7953 - accuracy: 0.6569 - val_loss: 0.6341 - val_accuracy: 0.7567\n",
      "Epoch 24/50\n",
      "6960/6960 [==============================] - 45s 6ms/sample - loss: 0.7699 - accuracy: 0.6697 - val_loss: 0.6462 - val_accuracy: 0.7547\n",
      "Epoch 25/50\n",
      "6960/6960 [==============================] - 46s 7ms/sample - loss: 0.7649 - accuracy: 0.6782 - val_loss: 0.5833 - val_accuracy: 0.7887\n",
      "Epoch 26/50\n",
      "6960/6960 [==============================] - 46s 7ms/sample - loss: 0.7526 - accuracy: 0.6838 - val_loss: 0.6289 - val_accuracy: 0.7587\n",
      "Epoch 27/50\n",
      "6960/6960 [==============================] - 45s 6ms/sample - loss: 0.7218 - accuracy: 0.6953 - val_loss: 0.5538 - val_accuracy: 0.7993\n",
      "Epoch 28/50\n",
      "6960/6960 [==============================] - 46s 7ms/sample - loss: 0.7096 - accuracy: 0.6990 - val_loss: 0.5056 - val_accuracy: 0.8247\n",
      "Epoch 29/50\n",
      "6960/6960 [==============================] - 45s 6ms/sample - loss: 0.6946 - accuracy: 0.7118 - val_loss: 0.5018 - val_accuracy: 0.8407\n",
      "Epoch 30/50\n",
      "6960/6960 [==============================] - 46s 7ms/sample - loss: 0.6871 - accuracy: 0.7124 - val_loss: 0.5101 - val_accuracy: 0.8267\n",
      "Epoch 31/50\n",
      "6960/6960 [==============================] - 47s 7ms/sample - loss: 0.6450 - accuracy: 0.7401 - val_loss: 0.5233 - val_accuracy: 0.8200\n",
      "Epoch 32/50\n",
      "6960/6960 [==============================] - 47s 7ms/sample - loss: 0.6405 - accuracy: 0.7368 - val_loss: 0.4670 - val_accuracy: 0.8600\n",
      "Epoch 33/50\n",
      "6960/6960 [==============================] - 47s 7ms/sample - loss: 0.6476 - accuracy: 0.7378 - val_loss: 0.4327 - val_accuracy: 0.8707\n",
      "Epoch 34/50\n",
      "6960/6960 [==============================] - 45s 6ms/sample - loss: 0.6238 - accuracy: 0.7431 - val_loss: 0.4361 - val_accuracy: 0.8667\n",
      "Epoch 35/50\n",
      "6960/6960 [==============================] - 47s 7ms/sample - loss: 0.6204 - accuracy: 0.7527 - val_loss: 0.4263 - val_accuracy: 0.8813\n",
      "Epoch 36/50\n",
      "6960/6960 [==============================] - 45s 7ms/sample - loss: 0.5961 - accuracy: 0.7570 - val_loss: 0.3863 - val_accuracy: 0.8880\n",
      "Epoch 37/50\n",
      "6960/6960 [==============================] - 47s 7ms/sample - loss: 0.5871 - accuracy: 0.7616 - val_loss: 0.3695 - val_accuracy: 0.8927\n",
      "Epoch 38/50\n",
      "6960/6960 [==============================] - 45s 7ms/sample - loss: 0.5661 - accuracy: 0.7708 - val_loss: 0.3880 - val_accuracy: 0.8900\n",
      "Epoch 39/50\n",
      "6960/6960 [==============================] - 45s 6ms/sample - loss: 0.5480 - accuracy: 0.7782 - val_loss: 0.3747 - val_accuracy: 0.9000\n",
      "Epoch 40/50\n",
      "6960/6960 [==============================] - 47s 7ms/sample - loss: 0.5472 - accuracy: 0.7777 - val_loss: 0.3650 - val_accuracy: 0.9060\n",
      "Epoch 41/50\n",
      "6960/6960 [==============================] - 47s 7ms/sample - loss: 0.5355 - accuracy: 0.7828 - val_loss: 0.3782 - val_accuracy: 0.8933\n",
      "Epoch 42/50\n",
      "6960/6960 [==============================] - 45s 7ms/sample - loss: 0.5371 - accuracy: 0.7833 - val_loss: 0.3527 - val_accuracy: 0.9100\n",
      "Epoch 43/50\n",
      "6960/6960 [==============================] - 44s 6ms/sample - loss: 0.5086 - accuracy: 0.7963 - val_loss: 0.3352 - val_accuracy: 0.9200\n",
      "Epoch 44/50\n",
      "6960/6960 [==============================] - 47s 7ms/sample - loss: 0.5062 - accuracy: 0.7960 - val_loss: 0.3348 - val_accuracy: 0.9153\n",
      "Epoch 45/50\n",
      "6960/6960 [==============================] - 46s 7ms/sample - loss: 0.4960 - accuracy: 0.8066 - val_loss: 0.2971 - val_accuracy: 0.9220\n",
      "Epoch 46/50\n",
      "6960/6960 [==============================] - 45s 6ms/sample - loss: 0.5057 - accuracy: 0.7976 - val_loss: 0.3173 - val_accuracy: 0.9180\n",
      "Epoch 47/50\n",
      "6960/6960 [==============================] - 45s 6ms/sample - loss: 0.4919 - accuracy: 0.8040 - val_loss: 0.3022 - val_accuracy: 0.9220\n",
      "Epoch 48/50\n",
      "6960/6960 [==============================] - 46s 7ms/sample - loss: 0.4839 - accuracy: 0.7996 - val_loss: 0.2835 - val_accuracy: 0.9267\n",
      "Epoch 49/50\n",
      "6960/6960 [==============================] - 45s 6ms/sample - loss: 0.4748 - accuracy: 0.8079 - val_loss: 0.2746 - val_accuracy: 0.9253\n",
      "Epoch 50/50\n",
      "6960/6960 [==============================] - 48s 7ms/sample - loss: 0.4537 - accuracy: 0.8132 - val_loss: 0.2992 - val_accuracy: 0.9280\n",
      "6960/6960 [==============================] - 15s 2ms/sample - loss: 0.1874 - accuracy: 0.9790\n",
      "1772/1772 [==============================] - 5s 3ms/sample - loss: 1.1156 - accuracy: 0.5790\n",
      "train accuracy: 97.902%\n",
      "test accuracy: 57.901%\n",
      "=================125===================\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_52 (Conv2D)           (None, 125, 1, 100)       22100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_52 (MaxPooling (None, 42, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_52 (Batc (None, 42, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_52 (Dropout)         (None, 42, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_53 (Conv2D)           (None, 42, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_53 (MaxPooling (None, 14, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_53 (Batc (None, 14, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_53 (Dropout)         (None, 14, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_54 (Conv2D)           (None, 14, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_54 (MaxPooling (None, 5, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_54 (Batc (None, 5, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_54 (Dropout)         (None, 5, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 100)               50100     \n",
      "_________________________________________________________________\n",
      "reshape_4 (Reshape)          (None, 100, 1)            0         \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 100, 100)          40800     \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 70)                47880     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 4)                 284       \n",
      "=================================================================\n",
      "Total params: 362,564\n",
      "Trainable params: 361,964\n",
      "Non-trainable params: 600\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6960 samples, validate on 1500 samples\n",
      "Epoch 1/50\n",
      "6960/6960 [==============================] - 67s 10ms/sample - loss: 1.3882 - accuracy: 0.2800 - val_loss: 1.3644 - val_accuracy: 0.3133\n",
      "Epoch 2/50\n",
      "6960/6960 [==============================] - 53s 8ms/sample - loss: 1.3426 - accuracy: 0.3480 - val_loss: 1.3343 - val_accuracy: 0.3593\n",
      "Epoch 3/50\n",
      "6960/6960 [==============================] - 53s 8ms/sample - loss: 1.2668 - accuracy: 0.4161 - val_loss: 1.2353 - val_accuracy: 0.4307\n",
      "Epoch 4/50\n",
      "6960/6960 [==============================] - 54s 8ms/sample - loss: 1.2037 - accuracy: 0.4632 - val_loss: 1.1614 - val_accuracy: 0.4867\n",
      "Epoch 5/50\n",
      "6960/6960 [==============================] - 54s 8ms/sample - loss: 1.1763 - accuracy: 0.4690 - val_loss: 1.1780 - val_accuracy: 0.4893\n",
      "Epoch 6/50\n",
      "6960/6960 [==============================] - 52s 7ms/sample - loss: 1.1345 - accuracy: 0.4925 - val_loss: 1.0454 - val_accuracy: 0.5473\n",
      "Epoch 7/50\n",
      "6960/6960 [==============================] - 52s 8ms/sample - loss: 1.0980 - accuracy: 0.5095 - val_loss: 0.9798 - val_accuracy: 0.5747\n",
      "Epoch 8/50\n",
      "6960/6960 [==============================] - 53s 8ms/sample - loss: 1.0869 - accuracy: 0.5139 - val_loss: 0.9521 - val_accuracy: 0.6080\n",
      "Epoch 9/50\n",
      "6960/6960 [==============================] - 54s 8ms/sample - loss: 1.0280 - accuracy: 0.5500 - val_loss: 0.9683 - val_accuracy: 0.5773\n",
      "Epoch 10/50\n",
      "6960/6960 [==============================] - 55s 8ms/sample - loss: 0.9966 - accuracy: 0.5707 - val_loss: 0.9173 - val_accuracy: 0.6193\n",
      "Epoch 11/50\n",
      "6960/6960 [==============================] - 55s 8ms/sample - loss: 0.9715 - accuracy: 0.5773 - val_loss: 0.8726 - val_accuracy: 0.6513\n",
      "Epoch 12/50\n",
      "6960/6960 [==============================] - 53s 8ms/sample - loss: 0.9323 - accuracy: 0.6011 - val_loss: 0.8426 - val_accuracy: 0.6767\n",
      "Epoch 13/50\n",
      "6960/6960 [==============================] - 53s 8ms/sample - loss: 0.9218 - accuracy: 0.6017 - val_loss: 0.7868 - val_accuracy: 0.6867\n",
      "Epoch 14/50\n",
      "6960/6960 [==============================] - 53s 8ms/sample - loss: 0.8867 - accuracy: 0.6141 - val_loss: 0.7656 - val_accuracy: 0.7040\n",
      "Epoch 15/50\n",
      "6960/6960 [==============================] - 52s 8ms/sample - loss: 0.8730 - accuracy: 0.6336 - val_loss: 0.7270 - val_accuracy: 0.7140\n",
      "Epoch 16/50\n",
      "6960/6960 [==============================] - 54s 8ms/sample - loss: 0.8325 - accuracy: 0.6460 - val_loss: 0.7225 - val_accuracy: 0.7240\n",
      "Epoch 17/50\n",
      "6960/6960 [==============================] - 53s 8ms/sample - loss: 0.8128 - accuracy: 0.6570 - val_loss: 0.6426 - val_accuracy: 0.7593\n",
      "Epoch 18/50\n",
      "6960/6960 [==============================] - 53s 8ms/sample - loss: 0.7945 - accuracy: 0.6703 - val_loss: 0.6455 - val_accuracy: 0.7653\n",
      "Epoch 19/50\n",
      "6960/6960 [==============================] - 50s 7ms/sample - loss: 0.7762 - accuracy: 0.6764 - val_loss: 0.6435 - val_accuracy: 0.7807\n",
      "Epoch 20/50\n",
      "6960/6960 [==============================] - 53s 8ms/sample - loss: 0.7495 - accuracy: 0.6792 - val_loss: 0.6033 - val_accuracy: 0.7787\n",
      "Epoch 21/50\n",
      "6960/6960 [==============================] - 55s 8ms/sample - loss: 0.7148 - accuracy: 0.7062 - val_loss: 0.5365 - val_accuracy: 0.8300\n",
      "Epoch 22/50\n",
      "6960/6960 [==============================] - 54s 8ms/sample - loss: 0.6965 - accuracy: 0.7112 - val_loss: 0.5403 - val_accuracy: 0.8280\n",
      "Epoch 23/50\n",
      "6960/6960 [==============================] - 53s 8ms/sample - loss: 0.6730 - accuracy: 0.7280 - val_loss: 0.4844 - val_accuracy: 0.8580\n",
      "Epoch 24/50\n",
      "6960/6960 [==============================] - 54s 8ms/sample - loss: 0.6630 - accuracy: 0.7310 - val_loss: 0.4833 - val_accuracy: 0.8387\n",
      "Epoch 25/50\n",
      "6960/6960 [==============================] - 54s 8ms/sample - loss: 0.6432 - accuracy: 0.7409 - val_loss: 0.4146 - val_accuracy: 0.8813\n",
      "Epoch 26/50\n",
      "6960/6960 [==============================] - 54s 8ms/sample - loss: 0.6158 - accuracy: 0.7559 - val_loss: 0.3996 - val_accuracy: 0.8980\n",
      "Epoch 27/50\n",
      "6960/6960 [==============================] - 53s 8ms/sample - loss: 0.6105 - accuracy: 0.7534 - val_loss: 0.3707 - val_accuracy: 0.8913\n",
      "Epoch 28/50\n",
      "6960/6960 [==============================] - 55s 8ms/sample - loss: 0.6052 - accuracy: 0.7619 - val_loss: 0.3481 - val_accuracy: 0.9067\n",
      "Epoch 29/50\n",
      "6960/6960 [==============================] - 54s 8ms/sample - loss: 0.5722 - accuracy: 0.7728 - val_loss: 0.3610 - val_accuracy: 0.8973\n",
      "Epoch 30/50\n",
      "6960/6960 [==============================] - 52s 7ms/sample - loss: 0.5490 - accuracy: 0.7790 - val_loss: 0.3066 - val_accuracy: 0.9073\n",
      "Epoch 31/50\n",
      "6960/6960 [==============================] - 54s 8ms/sample - loss: 0.5467 - accuracy: 0.7784 - val_loss: 0.3128 - val_accuracy: 0.9180\n",
      "Epoch 32/50\n",
      "6960/6960 [==============================] - 54s 8ms/sample - loss: 0.5316 - accuracy: 0.7839 - val_loss: 0.2848 - val_accuracy: 0.9207\n",
      "Epoch 33/50\n",
      "6960/6960 [==============================] - 51s 7ms/sample - loss: 0.5335 - accuracy: 0.7846 - val_loss: 0.2955 - val_accuracy: 0.9180\n",
      "Epoch 34/50\n",
      "6960/6960 [==============================] - 52s 8ms/sample - loss: 0.5023 - accuracy: 0.8006 - val_loss: 0.2816 - val_accuracy: 0.9273\n",
      "Epoch 35/50\n",
      "6960/6960 [==============================] - 52s 8ms/sample - loss: 0.4878 - accuracy: 0.7987 - val_loss: 0.2454 - val_accuracy: 0.9340\n",
      "Epoch 36/50\n",
      "6960/6960 [==============================] - 53s 8ms/sample - loss: 0.4746 - accuracy: 0.8144 - val_loss: 0.2512 - val_accuracy: 0.9360\n",
      "Epoch 37/50\n",
      "6960/6960 [==============================] - 53s 8ms/sample - loss: 0.4675 - accuracy: 0.8083 - val_loss: 0.2618 - val_accuracy: 0.9493\n",
      "Epoch 38/50\n",
      "6960/6960 [==============================] - 54s 8ms/sample - loss: 0.4618 - accuracy: 0.8112 - val_loss: 0.2297 - val_accuracy: 0.9400\n",
      "Epoch 39/50\n",
      "6960/6960 [==============================] - 54s 8ms/sample - loss: 0.4526 - accuracy: 0.8162 - val_loss: 0.1982 - val_accuracy: 0.9640\n",
      "Epoch 40/50\n",
      "6960/6960 [==============================] - 53s 8ms/sample - loss: 0.4448 - accuracy: 0.8260 - val_loss: 0.1769 - val_accuracy: 0.9620\n",
      "Epoch 41/50\n",
      "6960/6960 [==============================] - 54s 8ms/sample - loss: 0.4330 - accuracy: 0.8243 - val_loss: 0.1880 - val_accuracy: 0.9593\n",
      "Epoch 42/50\n",
      "6960/6960 [==============================] - 54s 8ms/sample - loss: 0.4089 - accuracy: 0.8358 - val_loss: 0.1648 - val_accuracy: 0.9613\n",
      "Epoch 43/50\n",
      "6960/6960 [==============================] - 51s 7ms/sample - loss: 0.4102 - accuracy: 0.8326 - val_loss: 0.1414 - val_accuracy: 0.9740\n",
      "Epoch 44/50\n",
      "6960/6960 [==============================] - 54s 8ms/sample - loss: 0.3996 - accuracy: 0.8374 - val_loss: 0.1651 - val_accuracy: 0.9660\n",
      "Epoch 45/50\n",
      "6960/6960 [==============================] - 53s 8ms/sample - loss: 0.4116 - accuracy: 0.8345 - val_loss: 0.1698 - val_accuracy: 0.9667\n",
      "Epoch 46/50\n",
      "6960/6960 [==============================] - 53s 8ms/sample - loss: 0.3893 - accuracy: 0.8388 - val_loss: 0.1314 - val_accuracy: 0.9773\n",
      "Epoch 47/50\n",
      "6960/6960 [==============================] - 55s 8ms/sample - loss: 0.3839 - accuracy: 0.8467 - val_loss: 0.1246 - val_accuracy: 0.9793\n",
      "Epoch 48/50\n",
      "6960/6960 [==============================] - 53s 8ms/sample - loss: 0.3847 - accuracy: 0.8412 - val_loss: 0.1364 - val_accuracy: 0.9773\n",
      "Epoch 49/50\n",
      "6960/6960 [==============================] - 53s 8ms/sample - loss: 0.3785 - accuracy: 0.8430 - val_loss: 0.1470 - val_accuracy: 0.9687\n",
      "Epoch 50/50\n",
      "6960/6960 [==============================] - 52s 7ms/sample - loss: 0.3525 - accuracy: 0.8556 - val_loss: 0.1227 - val_accuracy: 0.9740\n",
      "6960/6960 [==============================] - 16s 2ms/sample - loss: 0.0655 - accuracy: 0.9932s - loss: 0.065\n",
      "1772/1772 [==============================] - 4s 2ms/sample - loss: 1.1992 - accuracy: 0.6016\n",
      "train accuracy: 99.325%\n",
      "test accuracy: 60.158%\n",
      "=================150===================\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_55 (Conv2D)           (None, 150, 1, 100)       22100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_55 (MaxPooling (None, 50, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_55 (Batc (None, 50, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_55 (Dropout)         (None, 50, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_56 (Conv2D)           (None, 50, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_56 (MaxPooling (None, 17, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_56 (Batc (None, 17, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_56 (Dropout)         (None, 17, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_57 (Conv2D)           (None, 17, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_57 (MaxPooling (None, 6, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_57 (Batc (None, 6, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_57 (Dropout)         (None, 6, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 100)               60100     \n",
      "_________________________________________________________________\n",
      "reshape_5 (Reshape)          (None, 100, 1)            0         \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 100, 100)          40800     \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 70)                47880     \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 4)                 284       \n",
      "=================================================================\n",
      "Total params: 372,564\n",
      "Trainable params: 371,964\n",
      "Non-trainable params: 600\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6960 samples, validate on 1500 samples\n",
      "Epoch 1/50\n",
      "6960/6960 [==============================] - 65s 9ms/sample - loss: 1.3959 - accuracy: 0.2635 - val_loss: 1.4509 - val_accuracy: 0.2467\n",
      "Epoch 2/50\n",
      "6960/6960 [==============================] - 54s 8ms/sample - loss: 1.3543 - accuracy: 0.3207 - val_loss: 1.3513 - val_accuracy: 0.3120\n",
      "Epoch 3/50\n",
      "6960/6960 [==============================] - 51s 7ms/sample - loss: 1.2986 - accuracy: 0.3852 - val_loss: 1.3249 - val_accuracy: 0.3693\n",
      "Epoch 4/50\n",
      "6960/6960 [==============================] - 56s 8ms/sample - loss: 1.2525 - accuracy: 0.4185 - val_loss: 1.1676 - val_accuracy: 0.4807\n",
      "Epoch 5/50\n",
      "6960/6960 [==============================] - 55s 8ms/sample - loss: 1.1654 - accuracy: 0.4700 - val_loss: 1.0997 - val_accuracy: 0.5167\n",
      "Epoch 6/50\n",
      "6960/6960 [==============================] - 54s 8ms/sample - loss: 1.1164 - accuracy: 0.4989 - val_loss: 1.0298 - val_accuracy: 0.5460\n",
      "Epoch 7/50\n",
      "6960/6960 [==============================] - 54s 8ms/sample - loss: 1.0705 - accuracy: 0.5204 - val_loss: 1.0056 - val_accuracy: 0.5600\n",
      "Epoch 8/50\n",
      "6960/6960 [==============================] - 54s 8ms/sample - loss: 1.0200 - accuracy: 0.5471 - val_loss: 0.9322 - val_accuracy: 0.5993\n",
      "Epoch 9/50\n",
      "6960/6960 [==============================] - 54s 8ms/sample - loss: 0.9874 - accuracy: 0.5704 - val_loss: 0.9033 - val_accuracy: 0.6093\n",
      "Epoch 10/50\n",
      "6960/6960 [==============================] - 54s 8ms/sample - loss: 0.9557 - accuracy: 0.5882 - val_loss: 0.8509 - val_accuracy: 0.6507\n",
      "Epoch 11/50\n",
      "6960/6960 [==============================] - 54s 8ms/sample - loss: 0.9015 - accuracy: 0.6102 - val_loss: 0.7805 - val_accuracy: 0.6780\n",
      "Epoch 12/50\n",
      "6960/6960 [==============================] - 52s 8ms/sample - loss: 0.8845 - accuracy: 0.6211 - val_loss: 0.7949 - val_accuracy: 0.6787\n",
      "Epoch 13/50\n",
      "6960/6960 [==============================] - 53s 8ms/sample - loss: 0.8630 - accuracy: 0.6388 - val_loss: 0.6965 - val_accuracy: 0.7527\n",
      "Epoch 14/50\n",
      "6960/6960 [==============================] - 54s 8ms/sample - loss: 0.8171 - accuracy: 0.6592 - val_loss: 0.6787 - val_accuracy: 0.7560\n",
      "Epoch 15/50\n",
      "6960/6960 [==============================] - 54s 8ms/sample - loss: 0.7875 - accuracy: 0.6802 - val_loss: 0.6190 - val_accuracy: 0.7587\n",
      "Epoch 16/50\n",
      "6960/6960 [==============================] - 54s 8ms/sample - loss: 0.7572 - accuracy: 0.6898 - val_loss: 0.5825 - val_accuracy: 0.7927\n",
      "Epoch 17/50\n",
      "6960/6960 [==============================] - 55s 8ms/sample - loss: 0.7150 - accuracy: 0.7060 - val_loss: 0.5269 - val_accuracy: 0.8180\n",
      "Epoch 18/50\n",
      "6960/6960 [==============================] - 54s 8ms/sample - loss: 0.6790 - accuracy: 0.7286 - val_loss: 0.6442 - val_accuracy: 0.7380\n",
      "Epoch 19/50\n",
      "6960/6960 [==============================] - 53s 8ms/sample - loss: 0.6629 - accuracy: 0.7339 - val_loss: 0.4723 - val_accuracy: 0.8387\n",
      "Epoch 20/50\n",
      "6960/6960 [==============================] - 54s 8ms/sample - loss: 0.6534 - accuracy: 0.7414 - val_loss: 0.4528 - val_accuracy: 0.8627\n",
      "Epoch 21/50\n",
      "6960/6960 [==============================] - 54s 8ms/sample - loss: 0.6022 - accuracy: 0.7658 - val_loss: 0.4055 - val_accuracy: 0.8713\n",
      "Epoch 22/50\n",
      "6960/6960 [==============================] - 53s 8ms/sample - loss: 0.5802 - accuracy: 0.7671 - val_loss: 0.3801 - val_accuracy: 0.8887\n",
      "Epoch 23/50\n",
      "6960/6960 [==============================] - 49s 7ms/sample - loss: 0.5853 - accuracy: 0.7684 - val_loss: 0.3873 - val_accuracy: 0.8967\n",
      "Epoch 24/50\n",
      "6960/6960 [==============================] - 55s 8ms/sample - loss: 0.5339 - accuracy: 0.7882 - val_loss: 0.3588 - val_accuracy: 0.8940\n",
      "Epoch 25/50\n",
      "6960/6960 [==============================] - 55s 8ms/sample - loss: 0.5166 - accuracy: 0.7958 - val_loss: 0.3307 - val_accuracy: 0.9033\n",
      "Epoch 26/50\n",
      "6960/6960 [==============================] - 54s 8ms/sample - loss: 0.5133 - accuracy: 0.7994 - val_loss: 0.3135 - val_accuracy: 0.9180\n",
      "Epoch 27/50\n",
      "6960/6960 [==============================] - 55s 8ms/sample - loss: 0.4855 - accuracy: 0.8040 - val_loss: 0.2725 - val_accuracy: 0.9287\n",
      "Epoch 28/50\n",
      "6960/6960 [==============================] - 55s 8ms/sample - loss: 0.4818 - accuracy: 0.8108 - val_loss: 0.2430 - val_accuracy: 0.9373\n",
      "Epoch 29/50\n",
      "6960/6960 [==============================] - 54s 8ms/sample - loss: 0.4645 - accuracy: 0.8118 - val_loss: 0.2357 - val_accuracy: 0.9373\n",
      "Epoch 30/50\n",
      "6960/6960 [==============================] - 56s 8ms/sample - loss: 0.4484 - accuracy: 0.8220 - val_loss: 0.2346 - val_accuracy: 0.9340\n",
      "Epoch 31/50\n",
      "6960/6960 [==============================] - 55s 8ms/sample - loss: 0.4429 - accuracy: 0.8253 - val_loss: 0.1915 - val_accuracy: 0.9420\n",
      "Epoch 32/50\n",
      "6960/6960 [==============================] - 55s 8ms/sample - loss: 0.4449 - accuracy: 0.8217 - val_loss: 0.1905 - val_accuracy: 0.9553\n",
      "Epoch 33/50\n",
      "6960/6960 [==============================] - 54s 8ms/sample - loss: 0.4307 - accuracy: 0.8299 - val_loss: 0.1865 - val_accuracy: 0.9553\n",
      "Epoch 34/50\n",
      "6960/6960 [==============================] - 54s 8ms/sample - loss: 0.4079 - accuracy: 0.8365 - val_loss: 0.1709 - val_accuracy: 0.9580\n",
      "Epoch 35/50\n",
      "6960/6960 [==============================] - 56s 8ms/sample - loss: 0.3872 - accuracy: 0.8467 - val_loss: 0.1640 - val_accuracy: 0.9607\n",
      "Epoch 36/50\n",
      "6960/6960 [==============================] - 54s 8ms/sample - loss: 0.3806 - accuracy: 0.8480 - val_loss: 0.1294 - val_accuracy: 0.9680\n",
      "Epoch 37/50\n",
      "6960/6960 [==============================] - 57s 8ms/sample - loss: 0.3786 - accuracy: 0.8483 - val_loss: 0.1480 - val_accuracy: 0.9600\n",
      "Epoch 38/50\n",
      "6960/6960 [==============================] - 56s 8ms/sample - loss: 0.3829 - accuracy: 0.8474 - val_loss: 0.1264 - val_accuracy: 0.9707\n",
      "Epoch 39/50\n",
      "6960/6960 [==============================] - 53s 8ms/sample - loss: 0.3770 - accuracy: 0.8471 - val_loss: 0.1284 - val_accuracy: 0.9713\n",
      "Epoch 40/50\n",
      "6960/6960 [==============================] - 55s 8ms/sample - loss: 0.3626 - accuracy: 0.8546 - val_loss: 0.1366 - val_accuracy: 0.9713\n",
      "Epoch 41/50\n",
      "6960/6960 [==============================] - 53s 8ms/sample - loss: 0.3527 - accuracy: 0.8591 - val_loss: 0.1213 - val_accuracy: 0.9740\n",
      "Epoch 42/50\n",
      "6960/6960 [==============================] - 55s 8ms/sample - loss: 0.3552 - accuracy: 0.8560 - val_loss: 0.1270 - val_accuracy: 0.9640\n",
      "Epoch 43/50\n",
      "6960/6960 [==============================] - 54s 8ms/sample - loss: 0.3473 - accuracy: 0.8580 - val_loss: 0.1398 - val_accuracy: 0.9633\n",
      "Epoch 44/50\n",
      "6960/6960 [==============================] - 55s 8ms/sample - loss: 0.3275 - accuracy: 0.8682 - val_loss: 0.1559 - val_accuracy: 0.9500\n",
      "Epoch 45/50\n",
      "6960/6960 [==============================] - 56s 8ms/sample - loss: 0.3279 - accuracy: 0.8685 - val_loss: 0.1411 - val_accuracy: 0.9613\n",
      "Epoch 46/50\n",
      "6960/6960 [==============================] - 54s 8ms/sample - loss: 0.3192 - accuracy: 0.8698 - val_loss: 0.1104 - val_accuracy: 0.9727\n",
      "Epoch 47/50\n",
      "6960/6960 [==============================] - 57s 8ms/sample - loss: 0.3221 - accuracy: 0.8647 - val_loss: 0.1093 - val_accuracy: 0.9727\n",
      "Epoch 48/50\n",
      "6960/6960 [==============================] - 53s 8ms/sample - loss: 0.3163 - accuracy: 0.8723 - val_loss: 0.0890 - val_accuracy: 0.9840\n",
      "Epoch 49/50\n",
      "6960/6960 [==============================] - 54s 8ms/sample - loss: 0.3118 - accuracy: 0.8726 - val_loss: 0.0868 - val_accuracy: 0.9773\n",
      "Epoch 50/50\n",
      "6960/6960 [==============================] - 56s 8ms/sample - loss: 0.2912 - accuracy: 0.8852 - val_loss: 0.0722 - val_accuracy: 0.9873\n",
      "6960/6960 [==============================] - 16s 2ms/sample - loss: 0.0322 - accuracy: 0.9976\n",
      "1772/1772 [==============================] - 4s 2ms/sample - loss: 1.0579 - accuracy: 0.6574\n",
      "train accuracy: 99.756%\n",
      "test accuracy: 65.745%\n",
      "=================175===================\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_58 (Conv2D)           (None, 175, 1, 100)       22100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_58 (MaxPooling (None, 59, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_58 (Batc (None, 59, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_58 (Dropout)         (None, 59, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_59 (Conv2D)           (None, 59, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_59 (MaxPooling (None, 20, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_59 (Batc (None, 20, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_59 (Dropout)         (None, 20, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_60 (Conv2D)           (None, 20, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_60 (MaxPooling (None, 7, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_60 (Batc (None, 7, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_60 (Dropout)         (None, 7, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 700)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 100)               70100     \n",
      "_________________________________________________________________\n",
      "reshape_6 (Reshape)          (None, 100, 1)            0         \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 100, 100)          40800     \n",
      "_________________________________________________________________\n",
      "lstm_13 (LSTM)               (None, 70)                47880     \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 4)                 284       \n",
      "=================================================================\n",
      "Total params: 382,564\n",
      "Trainable params: 381,964\n",
      "Non-trainable params: 600\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6960 samples, validate on 1500 samples\n",
      "Epoch 1/50\n",
      "6960/6960 [==============================] - 73s 10ms/sample - loss: 1.3849 - accuracy: 0.2884 - val_loss: 1.4196 - val_accuracy: 0.2520\n",
      "Epoch 2/50\n",
      "6960/6960 [==============================] - 59s 8ms/sample - loss: 1.3264 - accuracy: 0.3496 - val_loss: 1.3484 - val_accuracy: 0.3327\n",
      "Epoch 3/50\n",
      "6960/6960 [==============================] - 58s 8ms/sample - loss: 1.2607 - accuracy: 0.4014 - val_loss: 1.2893 - val_accuracy: 0.3920\n",
      "Epoch 4/50\n",
      "6960/6960 [==============================] - 59s 9ms/sample - loss: 1.1968 - accuracy: 0.4532 - val_loss: 1.1695 - val_accuracy: 0.4760\n",
      "Epoch 5/50\n",
      "6960/6960 [==============================] - 56s 8ms/sample - loss: 1.1201 - accuracy: 0.4984 - val_loss: 1.0782 - val_accuracy: 0.5187\n",
      "Epoch 6/50\n",
      "6960/6960 [==============================] - 58s 8ms/sample - loss: 1.0884 - accuracy: 0.5197 - val_loss: 1.0704 - val_accuracy: 0.5213\n",
      "Epoch 7/50\n",
      "6960/6960 [==============================] - 58s 8ms/sample - loss: 1.0433 - accuracy: 0.5447 - val_loss: 0.9651 - val_accuracy: 0.5933\n",
      "Epoch 8/50\n",
      "6960/6960 [==============================] - 58s 8ms/sample - loss: 1.0005 - accuracy: 0.5639 - val_loss: 0.9237 - val_accuracy: 0.5947\n",
      "Epoch 9/50\n",
      "6960/6960 [==============================] - 58s 8ms/sample - loss: 0.9596 - accuracy: 0.5886 - val_loss: 0.8790 - val_accuracy: 0.6233\n",
      "Epoch 10/50\n",
      "6960/6960 [==============================] - 58s 8ms/sample - loss: 0.9327 - accuracy: 0.6007 - val_loss: 0.8230 - val_accuracy: 0.6800\n",
      "Epoch 11/50\n",
      "6960/6960 [==============================] - 59s 8ms/sample - loss: 0.8989 - accuracy: 0.6167 - val_loss: 0.7571 - val_accuracy: 0.7253\n",
      "Epoch 12/50\n",
      "6960/6960 [==============================] - 58s 8ms/sample - loss: 0.8614 - accuracy: 0.6399 - val_loss: 0.7278 - val_accuracy: 0.7167\n",
      "Epoch 13/50\n",
      "6960/6960 [==============================] - 61s 9ms/sample - loss: 0.8267 - accuracy: 0.6619 - val_loss: 0.6585 - val_accuracy: 0.7553\n",
      "Epoch 14/50\n",
      "6960/6960 [==============================] - 58s 8ms/sample - loss: 0.8042 - accuracy: 0.6777 - val_loss: 0.6612 - val_accuracy: 0.7567\n",
      "Epoch 15/50\n",
      "6960/6960 [==============================] - 57s 8ms/sample - loss: 0.7671 - accuracy: 0.6976 - val_loss: 0.5893 - val_accuracy: 0.7913\n",
      "Epoch 16/50\n",
      "6960/6960 [==============================] - 56s 8ms/sample - loss: 0.7277 - accuracy: 0.7098 - val_loss: 0.5528 - val_accuracy: 0.8040\n",
      "Epoch 17/50\n",
      "6960/6960 [==============================] - 58s 8ms/sample - loss: 0.7036 - accuracy: 0.7175 - val_loss: 0.5219 - val_accuracy: 0.8280\n",
      "Epoch 18/50\n",
      "6960/6960 [==============================] - 57s 8ms/sample - loss: 0.6767 - accuracy: 0.7346 - val_loss: 0.5291 - val_accuracy: 0.8113\n",
      "Epoch 19/50\n",
      "6960/6960 [==============================] - 59s 8ms/sample - loss: 0.6410 - accuracy: 0.7443 - val_loss: 0.4699 - val_accuracy: 0.8513\n",
      "Epoch 20/50\n",
      "6960/6960 [==============================] - 59s 8ms/sample - loss: 0.5968 - accuracy: 0.7677 - val_loss: 0.4206 - val_accuracy: 0.8767\n",
      "Epoch 21/50\n",
      "6960/6960 [==============================] - 57s 8ms/sample - loss: 0.5986 - accuracy: 0.7591 - val_loss: 0.4506 - val_accuracy: 0.8640\n",
      "Epoch 22/50\n",
      "6960/6960 [==============================] - 58s 8ms/sample - loss: 0.5526 - accuracy: 0.7759 - val_loss: 0.3943 - val_accuracy: 0.8833\n",
      "Epoch 23/50\n",
      "6960/6960 [==============================] - 59s 8ms/sample - loss: 0.5530 - accuracy: 0.7807 - val_loss: 0.3728 - val_accuracy: 0.8967\n",
      "Epoch 24/50\n",
      "6960/6960 [==============================] - 58s 8ms/sample - loss: 0.5206 - accuracy: 0.7907 - val_loss: 0.3253 - val_accuracy: 0.9140\n",
      "Epoch 25/50\n",
      "6960/6960 [==============================] - 56s 8ms/sample - loss: 0.5206 - accuracy: 0.7971 - val_loss: 0.3435 - val_accuracy: 0.9133\n",
      "Epoch 26/50\n",
      "6960/6960 [==============================] - 55s 8ms/sample - loss: 0.5004 - accuracy: 0.8027 - val_loss: 0.3168 - val_accuracy: 0.9213\n",
      "Epoch 27/50\n",
      "6960/6960 [==============================] - 59s 9ms/sample - loss: 0.4826 - accuracy: 0.8046 - val_loss: 0.2854 - val_accuracy: 0.9320\n",
      "Epoch 28/50\n",
      "6960/6960 [==============================] - 60s 9ms/sample - loss: 0.4552 - accuracy: 0.8193 - val_loss: 0.3009 - val_accuracy: 0.9153\n",
      "Epoch 29/50\n",
      "6960/6960 [==============================] - 59s 8ms/sample - loss: 0.4529 - accuracy: 0.8207 - val_loss: 0.2418 - val_accuracy: 0.9380\n",
      "Epoch 30/50\n",
      "6960/6960 [==============================] - 58s 8ms/sample - loss: 0.4402 - accuracy: 0.8241 - val_loss: 0.2628 - val_accuracy: 0.9273\n",
      "Epoch 31/50\n",
      "6960/6960 [==============================] - 59s 9ms/sample - loss: 0.4393 - accuracy: 0.8180 - val_loss: 0.2092 - val_accuracy: 0.9493\n",
      "Epoch 32/50\n",
      "6960/6960 [==============================] - 58s 8ms/sample - loss: 0.4195 - accuracy: 0.8348 - val_loss: 0.1858 - val_accuracy: 0.9567\n",
      "Epoch 33/50\n",
      "6960/6960 [==============================] - 58s 8ms/sample - loss: 0.4112 - accuracy: 0.8386 - val_loss: 0.1895 - val_accuracy: 0.9627\n",
      "Epoch 34/50\n",
      "6960/6960 [==============================] - 59s 9ms/sample - loss: 0.4027 - accuracy: 0.8361 - val_loss: 0.1920 - val_accuracy: 0.9473\n",
      "Epoch 35/50\n",
      "6960/6960 [==============================] - 59s 8ms/sample - loss: 0.3900 - accuracy: 0.8461 - val_loss: 0.1935 - val_accuracy: 0.9520\n",
      "Epoch 36/50\n",
      "6960/6960 [==============================] - 59s 8ms/sample - loss: 0.3767 - accuracy: 0.8486 - val_loss: 0.1429 - val_accuracy: 0.9660\n",
      "Epoch 37/50\n",
      "6960/6960 [==============================] - 59s 8ms/sample - loss: 0.3888 - accuracy: 0.8445 - val_loss: 0.1670 - val_accuracy: 0.9673\n",
      "Epoch 38/50\n",
      "6960/6960 [==============================] - 58s 8ms/sample - loss: 0.3673 - accuracy: 0.8542 - val_loss: 0.1567 - val_accuracy: 0.9620\n",
      "Epoch 39/50\n",
      "6960/6960 [==============================] - 60s 9ms/sample - loss: 0.3583 - accuracy: 0.8507 - val_loss: 0.1624 - val_accuracy: 0.9680\n",
      "Epoch 40/50\n",
      "6960/6960 [==============================] - 61s 9ms/sample - loss: 0.3625 - accuracy: 0.8578 - val_loss: 0.1352 - val_accuracy: 0.9767\n",
      "Epoch 41/50\n",
      "6960/6960 [==============================] - 58s 8ms/sample - loss: 0.3414 - accuracy: 0.8534 - val_loss: 0.1439 - val_accuracy: 0.9740\n",
      "Epoch 42/50\n",
      "6960/6960 [==============================] - 59s 9ms/sample - loss: 0.3342 - accuracy: 0.8667 - val_loss: 0.1153 - val_accuracy: 0.9807\n",
      "Epoch 43/50\n",
      "6960/6960 [==============================] - 58s 8ms/sample - loss: 0.3360 - accuracy: 0.8618 - val_loss: 0.1220 - val_accuracy: 0.9780\n",
      "Epoch 44/50\n",
      "6960/6960 [==============================] - 58s 8ms/sample - loss: 0.3204 - accuracy: 0.8680 - val_loss: 0.1174 - val_accuracy: 0.9793\n",
      "Epoch 45/50\n",
      "6960/6960 [==============================] - 58s 8ms/sample - loss: 0.3252 - accuracy: 0.8651 - val_loss: 0.1151 - val_accuracy: 0.9780\n",
      "Epoch 46/50\n",
      "6960/6960 [==============================] - 58s 8ms/sample - loss: 0.3175 - accuracy: 0.8740 - val_loss: 0.1068 - val_accuracy: 0.9793\n",
      "Epoch 47/50\n",
      "6960/6960 [==============================] - 58s 8ms/sample - loss: 0.3149 - accuracy: 0.8743 - val_loss: 0.1158 - val_accuracy: 0.9813\n",
      "Epoch 48/50\n",
      "6960/6960 [==============================] - 59s 8ms/sample - loss: 0.3155 - accuracy: 0.8718 - val_loss: 0.1259 - val_accuracy: 0.9820\n",
      "Epoch 49/50\n",
      "6960/6960 [==============================] - 59s 8ms/sample - loss: 0.3146 - accuracy: 0.8708 - val_loss: 0.0779 - val_accuracy: 0.9880\n",
      "Epoch 50/50\n",
      "6960/6960 [==============================] - 59s 8ms/sample - loss: 0.2930 - accuracy: 0.8810 - val_loss: 0.0788 - val_accuracy: 0.9907\n",
      "6960/6960 [==============================] - 17s 2ms/sample - loss: 0.0361 - accuracy: 0.9983\n",
      "1772/1772 [==============================] - 4s 2ms/sample - loss: 1.1209 - accuracy: 0.6518\n",
      "train accuracy: 99.828%\n",
      "test accuracy: 65.181%\n",
      "=================200===================\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_61 (Conv2D)           (None, 200, 1, 100)       22100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_61 (MaxPooling (None, 67, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_61 (Batc (None, 67, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_61 (Dropout)         (None, 67, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_62 (Conv2D)           (None, 67, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_62 (MaxPooling (None, 23, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_62 (Batc (None, 23, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_62 (Dropout)         (None, 23, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_63 (Conv2D)           (None, 23, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_63 (MaxPooling (None, 8, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_63 (Batc (None, 8, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_63 (Dropout)         (None, 8, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 100)               80100     \n",
      "_________________________________________________________________\n",
      "reshape_7 (Reshape)          (None, 100, 1)            0         \n",
      "_________________________________________________________________\n",
      "lstm_14 (LSTM)               (None, 100, 100)          40800     \n",
      "_________________________________________________________________\n",
      "lstm_15 (LSTM)               (None, 70)                47880     \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 4)                 284       \n",
      "=================================================================\n",
      "Total params: 392,564\n",
      "Trainable params: 391,964\n",
      "Non-trainable params: 600\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6960 samples, validate on 1500 samples\n",
      "Epoch 1/50\n",
      "6960/6960 [==============================] - 82s 12ms/sample - loss: 1.3909 - accuracy: 0.2695 - val_loss: 1.4422 - val_accuracy: 0.2447\n",
      "Epoch 2/50\n",
      "6960/6960 [==============================] - 61s 9ms/sample - loss: 1.3495 - accuracy: 0.3431 - val_loss: 1.4872 - val_accuracy: 0.3153\n",
      "Epoch 3/50\n",
      "6960/6960 [==============================] - 58s 8ms/sample - loss: 1.2787 - accuracy: 0.4014 - val_loss: 1.3377 - val_accuracy: 0.3800\n",
      "Epoch 4/50\n",
      "6960/6960 [==============================] - 58s 8ms/sample - loss: 1.2244 - accuracy: 0.4358 - val_loss: 1.2872 - val_accuracy: 0.4313\n",
      "Epoch 5/50\n",
      "6960/6960 [==============================] - 58s 8ms/sample - loss: 1.1843 - accuracy: 0.4632 - val_loss: 1.1612 - val_accuracy: 0.4593\n",
      "Epoch 6/50\n",
      "6960/6960 [==============================] - 58s 8ms/sample - loss: 1.1189 - accuracy: 0.5010 - val_loss: 1.1320 - val_accuracy: 0.4807\n",
      "Epoch 7/50\n",
      "6960/6960 [==============================] - 56s 8ms/sample - loss: 1.0863 - accuracy: 0.5157 - val_loss: 1.0268 - val_accuracy: 0.5520\n",
      "Epoch 8/50\n",
      "6960/6960 [==============================] - 58s 8ms/sample - loss: 1.0569 - accuracy: 0.5379 - val_loss: 0.9845 - val_accuracy: 0.5787\n",
      "Epoch 9/50\n",
      "6960/6960 [==============================] - 63s 9ms/sample - loss: 0.9963 - accuracy: 0.5596 - val_loss: 0.9157 - val_accuracy: 0.6180\n",
      "Epoch 10/50\n",
      "6960/6960 [==============================] - 68s 10ms/sample - loss: 0.9557 - accuracy: 0.5866 - val_loss: 0.8700 - val_accuracy: 0.6427\n",
      "Epoch 11/50\n",
      "6960/6960 [==============================] - 69s 10ms/sample - loss: 0.9356 - accuracy: 0.5957 - val_loss: 0.8630 - val_accuracy: 0.6727\n",
      "Epoch 12/50\n",
      "6960/6960 [==============================] - 73s 10ms/sample - loss: 0.8891 - accuracy: 0.6279 - val_loss: 0.7893 - val_accuracy: 0.7093\n",
      "Epoch 13/50\n",
      "6960/6960 [==============================] - 73s 10ms/sample - loss: 0.8505 - accuracy: 0.6473 - val_loss: 0.7497 - val_accuracy: 0.7113\n",
      "Epoch 14/50\n",
      "6960/6960 [==============================] - 72s 10ms/sample - loss: 0.8203 - accuracy: 0.6562 - val_loss: 0.6927 - val_accuracy: 0.7540\n",
      "Epoch 15/50\n",
      "6960/6960 [==============================] - 75s 11ms/sample - loss: 0.7846 - accuracy: 0.6806 - val_loss: 0.6237 - val_accuracy: 0.7847\n",
      "Epoch 16/50\n",
      "6960/6960 [==============================] - 73s 10ms/sample - loss: 0.7376 - accuracy: 0.7037 - val_loss: 0.5962 - val_accuracy: 0.7873\n",
      "Epoch 17/50\n",
      "6960/6960 [==============================] - 71s 10ms/sample - loss: 0.7264 - accuracy: 0.7013 - val_loss: 0.5583 - val_accuracy: 0.8080\n",
      "Epoch 18/50\n",
      "6960/6960 [==============================] - 72s 10ms/sample - loss: 0.6992 - accuracy: 0.7171 - val_loss: 0.5275 - val_accuracy: 0.8140\n",
      "Epoch 19/50\n",
      "6960/6960 [==============================] - 75s 11ms/sample - loss: 0.6477 - accuracy: 0.7385 - val_loss: 0.5092 - val_accuracy: 0.8180\n",
      "Epoch 20/50\n",
      "6960/6960 [==============================] - 70s 10ms/sample - loss: 0.6269 - accuracy: 0.7534 - val_loss: 0.4468 - val_accuracy: 0.8513\n",
      "Epoch 21/50\n",
      "6960/6960 [==============================] - 74s 11ms/sample - loss: 0.6048 - accuracy: 0.7628 - val_loss: 0.4093 - val_accuracy: 0.8667\n",
      "Epoch 22/50\n",
      "6960/6960 [==============================] - 72s 10ms/sample - loss: 0.5754 - accuracy: 0.7746 - val_loss: 0.3925 - val_accuracy: 0.8787\n",
      "Epoch 23/50\n",
      "6960/6960 [==============================] - 74s 11ms/sample - loss: 0.5537 - accuracy: 0.7841 - val_loss: 0.3711 - val_accuracy: 0.8867\n",
      "Epoch 24/50\n",
      "6960/6960 [==============================] - 74s 11ms/sample - loss: 0.5368 - accuracy: 0.7899 - val_loss: 0.3589 - val_accuracy: 0.8980\n",
      "Epoch 25/50\n",
      "6960/6960 [==============================] - 73s 10ms/sample - loss: 0.5145 - accuracy: 0.7957 - val_loss: 0.3138 - val_accuracy: 0.9180\n",
      "Epoch 26/50\n",
      "6960/6960 [==============================] - 73s 11ms/sample - loss: 0.5126 - accuracy: 0.7968 - val_loss: 0.3429 - val_accuracy: 0.8913\n",
      "Epoch 27/50\n",
      "6960/6960 [==============================] - 63s 9ms/sample - loss: 0.4816 - accuracy: 0.8093 - val_loss: 0.2627 - val_accuracy: 0.9307\n",
      "Epoch 28/50\n",
      "6960/6960 [==============================] - 71s 10ms/sample - loss: 0.4723 - accuracy: 0.8139 - val_loss: 0.2378 - val_accuracy: 0.9467\n",
      "Epoch 29/50\n",
      "6960/6960 [==============================] - 71s 10ms/sample - loss: 0.4642 - accuracy: 0.8148 - val_loss: 0.2340 - val_accuracy: 0.9387\n",
      "Epoch 30/50\n",
      "6960/6960 [==============================] - 73s 10ms/sample - loss: 0.4373 - accuracy: 0.8230 - val_loss: 0.2164 - val_accuracy: 0.9400\n",
      "Epoch 31/50\n",
      "6960/6960 [==============================] - 70s 10ms/sample - loss: 0.4257 - accuracy: 0.8312 - val_loss: 0.2019 - val_accuracy: 0.9487\n",
      "Epoch 32/50\n",
      "6960/6960 [==============================] - 73s 10ms/sample - loss: 0.4066 - accuracy: 0.8356 - val_loss: 0.1980 - val_accuracy: 0.9500\n",
      "Epoch 33/50\n",
      "6960/6960 [==============================] - 75s 11ms/sample - loss: 0.4057 - accuracy: 0.8351 - val_loss: 0.1905 - val_accuracy: 0.9500\n",
      "Epoch 34/50\n",
      "6960/6960 [==============================] - 72s 10ms/sample - loss: 0.3983 - accuracy: 0.8457 - val_loss: 0.1836 - val_accuracy: 0.9500\n",
      "Epoch 35/50\n",
      "6960/6960 [==============================] - 73s 11ms/sample - loss: 0.3908 - accuracy: 0.8477 - val_loss: 0.1805 - val_accuracy: 0.9660\n",
      "Epoch 36/50\n",
      "6960/6960 [==============================] - 74s 11ms/sample - loss: 0.3691 - accuracy: 0.8568 - val_loss: 0.1606 - val_accuracy: 0.9693\n",
      "Epoch 37/50\n",
      "6960/6960 [==============================] - 71s 10ms/sample - loss: 0.3606 - accuracy: 0.8550 - val_loss: 0.1472 - val_accuracy: 0.9667\n",
      "Epoch 38/50\n",
      "6960/6960 [==============================] - 73s 10ms/sample - loss: 0.3671 - accuracy: 0.8524 - val_loss: 0.1532 - val_accuracy: 0.9660\n",
      "Epoch 39/50\n",
      "6960/6960 [==============================] - 74s 11ms/sample - loss: 0.3551 - accuracy: 0.8611 - val_loss: 0.1368 - val_accuracy: 0.9740\n",
      "Epoch 40/50\n",
      "6960/6960 [==============================] - 84s 12ms/sample - loss: 0.3409 - accuracy: 0.8612 - val_loss: 0.1293 - val_accuracy: 0.9740\n",
      "Epoch 41/50\n",
      "6960/6960 [==============================] - 90s 13ms/sample - loss: 0.3185 - accuracy: 0.8718 - val_loss: 0.0977 - val_accuracy: 0.9820\n",
      "Epoch 42/50\n",
      "6960/6960 [==============================] - 95s 14ms/sample - loss: 0.3246 - accuracy: 0.8705 - val_loss: 0.1229 - val_accuracy: 0.9747\n",
      "Epoch 43/50\n",
      "6960/6960 [==============================] - 93s 13ms/sample - loss: 0.3266 - accuracy: 0.8690 - val_loss: 0.1009 - val_accuracy: 0.9833\n",
      "Epoch 44/50\n",
      "6960/6960 [==============================] - 90s 13ms/sample - loss: 0.3192 - accuracy: 0.8736 - val_loss: 0.0965 - val_accuracy: 0.9827\n",
      "Epoch 45/50\n",
      "6960/6960 [==============================] - 89s 13ms/sample - loss: 0.3275 - accuracy: 0.8698 - val_loss: 0.0819 - val_accuracy: 0.9880\n",
      "Epoch 46/50\n",
      "6960/6960 [==============================] - 92s 13ms/sample - loss: 0.3043 - accuracy: 0.8777 - val_loss: 0.0955 - val_accuracy: 0.9793\n",
      "Epoch 47/50\n",
      "6960/6960 [==============================] - 88s 13ms/sample - loss: 0.3021 - accuracy: 0.8772 - val_loss: 0.0946 - val_accuracy: 0.9807\n",
      "Epoch 48/50\n",
      "6960/6960 [==============================] - 90s 13ms/sample - loss: 0.2897 - accuracy: 0.8816 - val_loss: 0.0793 - val_accuracy: 0.9873\n",
      "Epoch 49/50\n",
      "6960/6960 [==============================] - 90s 13ms/sample - loss: 0.2882 - accuracy: 0.8803 - val_loss: 0.0694 - val_accuracy: 0.9907\n",
      "Epoch 50/50\n",
      "6960/6960 [==============================] - 89s 13ms/sample - loss: 0.2818 - accuracy: 0.8810 - val_loss: 0.0778 - val_accuracy: 0.9867\n",
      "6960/6960 [==============================] - 27s 4ms/sample - loss: 0.0328 - accuracy: 0.9968\n",
      "1772/1772 [==============================] - 7s 4ms/sample - loss: 1.1480 - accuracy: 0.6625\n",
      "train accuracy: 99.684%\n",
      "test accuracy: 66.253%\n",
      "=================225===================\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_64 (Conv2D)           (None, 225, 1, 100)       22100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_64 (MaxPooling (None, 75, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_64 (Batc (None, 75, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_64 (Dropout)         (None, 75, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_65 (Conv2D)           (None, 75, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_65 (MaxPooling (None, 25, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_65 (Batc (None, 25, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_65 (Dropout)         (None, 25, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_66 (Conv2D)           (None, 25, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_66 (MaxPooling (None, 9, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_66 (Batc (None, 9, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_66 (Dropout)         (None, 9, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_18 (Flatten)         (None, 900)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 100)               90100     \n",
      "_________________________________________________________________\n",
      "reshape_8 (Reshape)          (None, 100, 1)            0         \n",
      "_________________________________________________________________\n",
      "lstm_16 (LSTM)               (None, 100, 100)          40800     \n",
      "_________________________________________________________________\n",
      "lstm_17 (LSTM)               (None, 70)                47880     \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 4)                 284       \n",
      "=================================================================\n",
      "Total params: 402,564\n",
      "Trainable params: 401,964\n",
      "Non-trainable params: 600\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6960 samples, validate on 1500 samples\n",
      "Epoch 1/50\n",
      "6960/6960 [==============================] - 157s 23ms/sample - loss: 1.3796 - accuracy: 0.2898 - val_loss: 1.7431 - val_accuracy: 0.2700\n",
      "Epoch 2/50\n",
      "6960/6960 [==============================] - 92s 13ms/sample - loss: 1.2950 - accuracy: 0.3848 - val_loss: 1.3078 - val_accuracy: 0.3973\n",
      "Epoch 3/50\n",
      "6960/6960 [==============================] - 93s 13ms/sample - loss: 1.2009 - accuracy: 0.4487 - val_loss: 1.2906 - val_accuracy: 0.4273\n",
      "Epoch 4/50\n",
      "6960/6960 [==============================] - 96s 14ms/sample - loss: 1.1325 - accuracy: 0.4882 - val_loss: 1.1056 - val_accuracy: 0.5073\n",
      "Epoch 5/50\n",
      "6960/6960 [==============================] - 85s 12ms/sample - loss: 1.0874 - accuracy: 0.5080 - val_loss: 1.0310 - val_accuracy: 0.5487\n",
      "Epoch 6/50\n",
      "6960/6960 [==============================] - 84s 12ms/sample - loss: 1.0232 - accuracy: 0.5338 - val_loss: 0.9945 - val_accuracy: 0.5573\n",
      "Epoch 7/50\n",
      "6960/6960 [==============================] - 90s 13ms/sample - loss: 0.9861 - accuracy: 0.5625 - val_loss: 0.9083 - val_accuracy: 0.6180\n",
      "Epoch 8/50\n",
      "6960/6960 [==============================] - 93s 13ms/sample - loss: 0.9377 - accuracy: 0.5833 - val_loss: 0.8538 - val_accuracy: 0.6347\n",
      "Epoch 9/50\n",
      "6960/6960 [==============================] - 89s 13ms/sample - loss: 0.8994 - accuracy: 0.6014 - val_loss: 0.8238 - val_accuracy: 0.6427\n",
      "Epoch 10/50\n",
      "6960/6960 [==============================] - 84s 12ms/sample - loss: 0.8685 - accuracy: 0.6149 - val_loss: 0.7948 - val_accuracy: 0.6380\n",
      "Epoch 11/50\n",
      "6960/6960 [==============================] - 88s 13ms/sample - loss: 0.8479 - accuracy: 0.6261 - val_loss: 0.7353 - val_accuracy: 0.6900\n",
      "Epoch 12/50\n",
      "6960/6960 [==============================] - 88s 13ms/sample - loss: 0.8129 - accuracy: 0.6463 - val_loss: 0.7048 - val_accuracy: 0.6973\n",
      "Epoch 13/50\n",
      "6960/6960 [==============================] - 86s 12ms/sample - loss: 0.8016 - accuracy: 0.6532 - val_loss: 0.7059 - val_accuracy: 0.7067\n",
      "Epoch 14/50\n",
      "6960/6960 [==============================] - 85s 12ms/sample - loss: 0.7762 - accuracy: 0.6665 - val_loss: 0.6195 - val_accuracy: 0.7507\n",
      "Epoch 15/50\n",
      "6960/6960 [==============================] - 86s 12ms/sample - loss: 0.7558 - accuracy: 0.6853 - val_loss: 0.6209 - val_accuracy: 0.7560\n",
      "Epoch 16/50\n",
      "6960/6960 [==============================] - 81s 12ms/sample - loss: 0.7088 - accuracy: 0.6981 - val_loss: 0.6120 - val_accuracy: 0.7613\n",
      "Epoch 17/50\n",
      "6960/6960 [==============================] - 81s 12ms/sample - loss: 0.6712 - accuracy: 0.7253 - val_loss: 0.5316 - val_accuracy: 0.8080\n",
      "Epoch 18/50\n",
      "6960/6960 [==============================] - 85s 12ms/sample - loss: 0.6626 - accuracy: 0.7237 - val_loss: 0.5195 - val_accuracy: 0.8120\n",
      "Epoch 19/50\n",
      "6960/6960 [==============================] - 80s 11ms/sample - loss: 0.6450 - accuracy: 0.7405 - val_loss: 0.4548 - val_accuracy: 0.8547\n",
      "Epoch 20/50\n",
      "6960/6960 [==============================] - 79s 11ms/sample - loss: 0.6243 - accuracy: 0.7497 - val_loss: 0.4320 - val_accuracy: 0.8487\n",
      "Epoch 21/50\n",
      "6960/6960 [==============================] - 88s 13ms/sample - loss: 0.5934 - accuracy: 0.7585 - val_loss: 0.3974 - val_accuracy: 0.8540\n",
      "Epoch 22/50\n",
      "6960/6960 [==============================] - 85s 12ms/sample - loss: 0.5566 - accuracy: 0.7763 - val_loss: 0.4152 - val_accuracy: 0.8493\n",
      "Epoch 23/50\n",
      "6960/6960 [==============================] - 80s 12ms/sample - loss: 0.5513 - accuracy: 0.7829 - val_loss: 0.3551 - val_accuracy: 0.8873\n",
      "Epoch 24/50\n",
      "6960/6960 [==============================] - 82s 12ms/sample - loss: 0.5344 - accuracy: 0.7858 - val_loss: 0.3469 - val_accuracy: 0.8920\n",
      "Epoch 25/50\n",
      "6960/6960 [==============================] - 82s 12ms/sample - loss: 0.5253 - accuracy: 0.7884 - val_loss: 0.3148 - val_accuracy: 0.9200\n",
      "Epoch 26/50\n",
      "6960/6960 [==============================] - 78s 11ms/sample - loss: 0.5029 - accuracy: 0.7971 - val_loss: 0.2710 - val_accuracy: 0.9140\n",
      "Epoch 27/50\n",
      "6960/6960 [==============================] - 78s 11ms/sample - loss: 0.4994 - accuracy: 0.7989 - val_loss: 0.2776 - val_accuracy: 0.9087\n",
      "Epoch 28/50\n",
      "6960/6960 [==============================] - 79s 11ms/sample - loss: 0.4666 - accuracy: 0.8142 - val_loss: 0.2437 - val_accuracy: 0.9300\n",
      "Epoch 29/50\n",
      "6960/6960 [==============================] - 72s 10ms/sample - loss: 0.4680 - accuracy: 0.8116 - val_loss: 0.2335 - val_accuracy: 0.9373\n",
      "Epoch 30/50\n",
      "6960/6960 [==============================] - 75s 11ms/sample - loss: 0.4628 - accuracy: 0.8148 - val_loss: 0.2185 - val_accuracy: 0.9413\n",
      "Epoch 31/50\n",
      "6960/6960 [==============================] - 78s 11ms/sample - loss: 0.4305 - accuracy: 0.8259 - val_loss: 0.2601 - val_accuracy: 0.9260\n",
      "Epoch 32/50\n",
      "6960/6960 [==============================] - 78s 11ms/sample - loss: 0.4183 - accuracy: 0.8306 - val_loss: 0.2095 - val_accuracy: 0.9353\n",
      "Epoch 33/50\n",
      "6960/6960 [==============================] - 83s 12ms/sample - loss: 0.4034 - accuracy: 0.8411 - val_loss: 0.1957 - val_accuracy: 0.9440\n",
      "Epoch 34/50\n",
      "6960/6960 [==============================] - 77s 11ms/sample - loss: 0.3992 - accuracy: 0.8411 - val_loss: 0.1721 - val_accuracy: 0.9653\n",
      "Epoch 35/50\n",
      "6960/6960 [==============================] - 81s 12ms/sample - loss: 0.3913 - accuracy: 0.8404 - val_loss: 0.1512 - val_accuracy: 0.9587\n",
      "Epoch 36/50\n",
      "6960/6960 [==============================] - 78s 11ms/sample - loss: 0.3744 - accuracy: 0.8503 - val_loss: 0.1589 - val_accuracy: 0.9633\n",
      "Epoch 37/50\n",
      "6960/6960 [==============================] - 77s 11ms/sample - loss: 0.3769 - accuracy: 0.8509 - val_loss: 0.1330 - val_accuracy: 0.9713\n",
      "Epoch 38/50\n",
      "6960/6960 [==============================] - 81s 12ms/sample - loss: 0.3652 - accuracy: 0.8497 - val_loss: 0.1583 - val_accuracy: 0.9633\n",
      "Epoch 39/50\n",
      "6960/6960 [==============================] - 83s 12ms/sample - loss: 0.3524 - accuracy: 0.8605 - val_loss: 0.1411 - val_accuracy: 0.9660\n",
      "Epoch 40/50\n",
      "6960/6960 [==============================] - 79s 11ms/sample - loss: 0.3393 - accuracy: 0.8636 - val_loss: 0.1130 - val_accuracy: 0.9813\n",
      "Epoch 41/50\n",
      "6960/6960 [==============================] - 79s 11ms/sample - loss: 0.3386 - accuracy: 0.8618 - val_loss: 0.1010 - val_accuracy: 0.9840\n",
      "Epoch 42/50\n",
      "6960/6960 [==============================] - 85s 12ms/sample - loss: 0.3244 - accuracy: 0.8697 - val_loss: 0.1358 - val_accuracy: 0.9713\n",
      "Epoch 43/50\n",
      "6960/6960 [==============================] - 80s 11ms/sample - loss: 0.3308 - accuracy: 0.8678 - val_loss: 0.1077 - val_accuracy: 0.9767\n",
      "Epoch 44/50\n",
      "6960/6960 [==============================] - 81s 12ms/sample - loss: 0.3075 - accuracy: 0.8760 - val_loss: 0.0898 - val_accuracy: 0.9867\n",
      "Epoch 45/50\n",
      "6960/6960 [==============================] - 80s 12ms/sample - loss: 0.3244 - accuracy: 0.8658 - val_loss: 0.0903 - val_accuracy: 0.9833\n",
      "Epoch 46/50\n",
      "6960/6960 [==============================] - 80s 11ms/sample - loss: 0.3028 - accuracy: 0.8769 - val_loss: 0.1068 - val_accuracy: 0.9793\n",
      "Epoch 47/50\n",
      "6960/6960 [==============================] - 78s 11ms/sample - loss: 0.2955 - accuracy: 0.8809 - val_loss: 0.0857 - val_accuracy: 0.9867\n",
      "Epoch 48/50\n",
      "6960/6960 [==============================] - 79s 11ms/sample - loss: 0.3028 - accuracy: 0.8743 - val_loss: 0.0850 - val_accuracy: 0.9880\n",
      "Epoch 49/50\n",
      "6960/6960 [==============================] - 82s 12ms/sample - loss: 0.2889 - accuracy: 0.8780 - val_loss: 0.0864 - val_accuracy: 0.9813\n",
      "Epoch 50/50\n",
      "6960/6960 [==============================] - 85s 12ms/sample - loss: 0.2924 - accuracy: 0.8820 - val_loss: 0.0805 - val_accuracy: 0.9873\n",
      "6960/6960 [==============================] - 24s 3ms/sample - loss: 0.0370 - accuracy: 0.9964\n",
      "1772/1772 [==============================] - 6s 3ms/sample - loss: 1.1613 - accuracy: 0.6467\n",
      "train accuracy: 99.641%\n",
      "test accuracy: 64.673%\n",
      "=================250===================\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_67 (Conv2D)           (None, 250, 1, 100)       22100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_67 (MaxPooling (None, 84, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_67 (Batc (None, 84, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_67 (Dropout)         (None, 84, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_68 (Conv2D)           (None, 84, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_68 (MaxPooling (None, 28, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_68 (Batc (None, 28, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_68 (Dropout)         (None, 28, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_69 (Conv2D)           (None, 28, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_69 (MaxPooling (None, 10, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_69 (Batc (None, 10, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_69 (Dropout)         (None, 10, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "flatten_19 (Flatten)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 100)               100100    \n",
      "_________________________________________________________________\n",
      "reshape_9 (Reshape)          (None, 100, 1)            0         \n",
      "_________________________________________________________________\n",
      "lstm_18 (LSTM)               (None, 100, 100)          40800     \n",
      "_________________________________________________________________\n",
      "lstm_19 (LSTM)               (None, 70)                47880     \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 4)                 284       \n",
      "=================================================================\n",
      "Total params: 412,564\n",
      "Trainable params: 411,964\n",
      "Non-trainable params: 600\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6960 samples, validate on 1500 samples\n",
      "Epoch 1/50\n",
      "6960/6960 [==============================] - 126s 18ms/sample - loss: 1.3905 - accuracy: 0.2743 - val_loss: 1.4658 - val_accuracy: 0.2620\n",
      "Epoch 2/50\n",
      "6960/6960 [==============================] - 79s 11ms/sample - loss: 1.3167 - accuracy: 0.3595 - val_loss: 1.4051 - val_accuracy: 0.3460\n",
      "Epoch 3/50\n",
      "6960/6960 [==============================] - 81s 12ms/sample - loss: 1.2383 - accuracy: 0.4233 - val_loss: 1.3937 - val_accuracy: 0.4047\n",
      "Epoch 4/50\n",
      "6960/6960 [==============================] - 82s 12ms/sample - loss: 1.1501 - accuracy: 0.4739 - val_loss: 1.1543 - val_accuracy: 0.4833\n",
      "Epoch 5/50\n",
      "6960/6960 [==============================] - 85s 12ms/sample - loss: 1.0753 - accuracy: 0.5118 - val_loss: 1.0323 - val_accuracy: 0.5480\n",
      "Epoch 6/50\n",
      "6960/6960 [==============================] - 82s 12ms/sample - loss: 1.0330 - accuracy: 0.5333 - val_loss: 0.9178 - val_accuracy: 0.5987\n",
      "Epoch 7/50\n",
      "6960/6960 [==============================] - 82s 12ms/sample - loss: 0.9850 - accuracy: 0.5629 - val_loss: 0.8628 - val_accuracy: 0.6320\n",
      "Epoch 8/50\n",
      "6960/6960 [==============================] - 84s 12ms/sample - loss: 0.9336 - accuracy: 0.5833 - val_loss: 0.8531 - val_accuracy: 0.6453\n",
      "Epoch 9/50\n",
      "6960/6960 [==============================] - 84s 12ms/sample - loss: 0.9050 - accuracy: 0.5980 - val_loss: 0.8004 - val_accuracy: 0.6587\n",
      "Epoch 10/50\n",
      "6960/6960 [==============================] - 83s 12ms/sample - loss: 0.8420 - accuracy: 0.6272 - val_loss: 0.7511 - val_accuracy: 0.6813\n",
      "Epoch 11/50\n",
      "6960/6960 [==============================] - 83s 12ms/sample - loss: 0.8544 - accuracy: 0.6297 - val_loss: 0.7316 - val_accuracy: 0.6900\n",
      "Epoch 12/50\n",
      "6960/6960 [==============================] - 81s 12ms/sample - loss: 0.8060 - accuracy: 0.6588 - val_loss: 0.6820 - val_accuracy: 0.7453\n",
      "Epoch 13/50\n",
      "6960/6960 [==============================] - 82s 12ms/sample - loss: 0.7630 - accuracy: 0.6750 - val_loss: 0.6275 - val_accuracy: 0.7547\n",
      "Epoch 14/50\n",
      "6960/6960 [==============================] - 81s 12ms/sample - loss: 0.7312 - accuracy: 0.6895 - val_loss: 0.5615 - val_accuracy: 0.7807\n",
      "Epoch 15/50\n",
      "6960/6960 [==============================] - 87s 12ms/sample - loss: 0.6904 - accuracy: 0.7124 - val_loss: 0.5770 - val_accuracy: 0.7907\n",
      "Epoch 16/50\n",
      "6960/6960 [==============================] - 87s 12ms/sample - loss: 0.6522 - accuracy: 0.7401 - val_loss: 0.5262 - val_accuracy: 0.8227\n",
      "Epoch 17/50\n",
      "6960/6960 [==============================] - 86s 12ms/sample - loss: 0.6428 - accuracy: 0.7420 - val_loss: 0.4435 - val_accuracy: 0.8587\n",
      "Epoch 18/50\n",
      "6960/6960 [==============================] - 86s 12ms/sample - loss: 0.5880 - accuracy: 0.7649 - val_loss: 0.3950 - val_accuracy: 0.8687\n",
      "Epoch 19/50\n",
      "6960/6960 [==============================] - 87s 13ms/sample - loss: 0.5672 - accuracy: 0.7740 - val_loss: 0.3309 - val_accuracy: 0.9007\n",
      "Epoch 20/50\n",
      "6960/6960 [==============================] - 85s 12ms/sample - loss: 0.5315 - accuracy: 0.7920 - val_loss: 0.3539 - val_accuracy: 0.8833\n",
      "Epoch 21/50\n",
      "6960/6960 [==============================] - 85s 12ms/sample - loss: 0.5227 - accuracy: 0.7964 - val_loss: 0.2998 - val_accuracy: 0.9087\n",
      "Epoch 22/50\n",
      "6960/6960 [==============================] - 83s 12ms/sample - loss: 0.4874 - accuracy: 0.8033 - val_loss: 0.2836 - val_accuracy: 0.9260\n",
      "Epoch 23/50\n",
      "6960/6960 [==============================] - 85s 12ms/sample - loss: 0.4786 - accuracy: 0.8125 - val_loss: 0.2882 - val_accuracy: 0.9067\n",
      "Epoch 24/50\n",
      "6960/6960 [==============================] - 88s 13ms/sample - loss: 0.4576 - accuracy: 0.8138 - val_loss: 0.2434 - val_accuracy: 0.9307\n",
      "Epoch 25/50\n",
      "6960/6960 [==============================] - 83s 12ms/sample - loss: 0.4253 - accuracy: 0.8335 - val_loss: 0.2231 - val_accuracy: 0.9420\n",
      "Epoch 26/50\n",
      "6960/6960 [==============================] - 84s 12ms/sample - loss: 0.4209 - accuracy: 0.8356 - val_loss: 0.2031 - val_accuracy: 0.9400\n",
      "Epoch 27/50\n",
      "6960/6960 [==============================] - 85s 12ms/sample - loss: 0.4030 - accuracy: 0.8391 - val_loss: 0.1735 - val_accuracy: 0.9547\n",
      "Epoch 28/50\n",
      "6960/6960 [==============================] - 81s 12ms/sample - loss: 0.3997 - accuracy: 0.8407 - val_loss: 0.1781 - val_accuracy: 0.9607\n",
      "Epoch 29/50\n",
      "6960/6960 [==============================] - 83s 12ms/sample - loss: 0.3839 - accuracy: 0.8486 - val_loss: 0.1663 - val_accuracy: 0.9513\n",
      "Epoch 30/50\n",
      "6960/6960 [==============================] - 82s 12ms/sample - loss: 0.3597 - accuracy: 0.8550 - val_loss: 0.1420 - val_accuracy: 0.9620\n",
      "Epoch 31/50\n",
      "6960/6960 [==============================] - 79s 11ms/sample - loss: 0.3651 - accuracy: 0.8555 - val_loss: 0.1841 - val_accuracy: 0.9587\n",
      "Epoch 32/50\n",
      "6960/6960 [==============================] - 79s 11ms/sample - loss: 0.3509 - accuracy: 0.8625 - val_loss: 0.1450 - val_accuracy: 0.9593\n",
      "Epoch 33/50\n",
      "6960/6960 [==============================] - 84s 12ms/sample - loss: 0.3331 - accuracy: 0.8649 - val_loss: 0.1242 - val_accuracy: 0.9753\n",
      "Epoch 34/50\n",
      "6960/6960 [==============================] - 73s 11ms/sample - loss: 0.3331 - accuracy: 0.8626 - val_loss: 0.1191 - val_accuracy: 0.9707\n",
      "Epoch 35/50\n",
      "6960/6960 [==============================] - 84s 12ms/sample - loss: 0.3217 - accuracy: 0.8698 - val_loss: 0.1252 - val_accuracy: 0.9620\n",
      "Epoch 36/50\n",
      "6960/6960 [==============================] - 83s 12ms/sample - loss: 0.3092 - accuracy: 0.8772 - val_loss: 0.1091 - val_accuracy: 0.9793\n",
      "Epoch 37/50\n",
      "6960/6960 [==============================] - 84s 12ms/sample - loss: 0.3138 - accuracy: 0.8711 - val_loss: 0.0998 - val_accuracy: 0.9800\n",
      "Epoch 38/50\n",
      "6960/6960 [==============================] - 82s 12ms/sample - loss: 0.3012 - accuracy: 0.8770 - val_loss: 0.0958 - val_accuracy: 0.9833\n",
      "Epoch 39/50\n",
      "6960/6960 [==============================] - 86s 12ms/sample - loss: 0.2864 - accuracy: 0.8845 - val_loss: 0.0831 - val_accuracy: 0.9860\n",
      "Epoch 40/50\n",
      "6960/6960 [==============================] - 84s 12ms/sample - loss: 0.2723 - accuracy: 0.8886 - val_loss: 0.0685 - val_accuracy: 0.9873\n",
      "Epoch 41/50\n",
      "6960/6960 [==============================] - 89s 13ms/sample - loss: 0.2764 - accuracy: 0.8882 - val_loss: 0.0852 - val_accuracy: 0.9800\n",
      "Epoch 42/50\n",
      "6960/6960 [==============================] - 89s 13ms/sample - loss: 0.2761 - accuracy: 0.8861 - val_loss: 0.0784 - val_accuracy: 0.9860\n",
      "Epoch 43/50\n",
      "6960/6960 [==============================] - 88s 13ms/sample - loss: 0.2704 - accuracy: 0.8865 - val_loss: 0.0653 - val_accuracy: 0.9867\n",
      "Epoch 44/50\n",
      "6960/6960 [==============================] - 87s 12ms/sample - loss: 0.2681 - accuracy: 0.8914 - val_loss: 0.0670 - val_accuracy: 0.9867\n",
      "Epoch 45/50\n",
      "6960/6960 [==============================] - 85s 12ms/sample - loss: 0.2680 - accuracy: 0.8861 - val_loss: 0.0574 - val_accuracy: 0.9893\n",
      "Epoch 46/50\n",
      "6960/6960 [==============================] - 86s 12ms/sample - loss: 0.2412 - accuracy: 0.9043 - val_loss: 0.0639 - val_accuracy: 0.9887\n",
      "Epoch 47/50\n",
      "6960/6960 [==============================] - 81s 12ms/sample - loss: 0.2579 - accuracy: 0.8947 - val_loss: 0.0594 - val_accuracy: 0.9887\n",
      "Epoch 48/50\n",
      "6960/6960 [==============================] - 86s 12ms/sample - loss: 0.2573 - accuracy: 0.8905 - val_loss: 0.0599 - val_accuracy: 0.9887\n",
      "Epoch 49/50\n",
      "6960/6960 [==============================] - 83s 12ms/sample - loss: 0.2456 - accuracy: 0.8976 - val_loss: 0.0504 - val_accuracy: 0.9907\n",
      "Epoch 50/50\n",
      "6960/6960 [==============================] - 72s 10ms/sample - loss: 0.2459 - accuracy: 0.8960 - val_loss: 0.0539 - val_accuracy: 0.9913\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.0198 - accuracy: 0.9970\n",
      "1772/1772 [==============================] - 6s 3ms/sample - loss: 1.1295 - accuracy: 0.65860s - loss: 1.1324 - accura\n",
      "train accuracy: 99.698%\n",
      "test accuracy: 65.858%\n"
     ]
    }
   ],
   "source": [
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "for time in range(25, 251, 25):\n",
    "    print(\"=================\" + str(time) + \"===================\")\n",
    "    train_score, test_score = hybrid_train_data(time_period=time)\n",
    "    train_scores.append(train_score[1])\n",
    "    test_scores.append(test_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8733a867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracies: \n",
      "[0.9028736, 0.97988504, 0.9863506, 0.979023, 0.99324715, 0.99755746, 0.9982759, 0.9968391, 0.99640805, 0.99698275]\n",
      "Test accuracies: \n",
      "[0.38487583, 0.501693, 0.5468397, 0.5790068, 0.60158014, 0.6574492, 0.6518059, 0.6625282, 0.64672685, 0.65857786]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Train accuracies: \")\n",
    "print(train_scores)\n",
    "print(\"Test accuracies: \")\n",
    "print(test_scores)\n",
    "\n",
    "# plot\n",
    "plt.plot(range(25, 251, 25), train_scores, label='train accuracies')\n",
    "plt.plot(range(25, 251, 25), test_scores, label='test accuracies')\n",
    "plt.legend()\n",
    "plt.title(\"Classification Accuracies over Time Period (CNN+LSTM)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82141f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
