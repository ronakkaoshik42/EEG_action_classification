{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1a04ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten,Dropout\n",
    "from tensorflow.keras.layers import Conv1D,Conv2D,BatchNormalization,MaxPooling1D,MaxPooling2D,Reshape, Dense, Embedding, LSTM,GRU, Bidirectional, TimeDistributed\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import optimizers\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9a06fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8788016f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training/Valid data shape: (2115, 22, 1000)\n",
      "Test data shape: (443, 22, 1000)\n",
      "Training/Valid target shape: (2115,)\n",
      "Test target shape: (443,)\n",
      "Person train/valid shape: (2115,)\n",
      "Person test shape: (443, 1)\n"
     ]
    }
   ],
   "source": [
    "X_test = np.load(\"X_test.npy\")\n",
    "y_test = np.load(\"y_test.npy\")\n",
    "person_train_valid = np.load(\"person_train_valid.npy\").reshape(2115)\n",
    "X_train_valid = np.load(\"X_train_valid.npy\")\n",
    "y_train_valid = np.load(\"y_train_valid.npy\")\n",
    "person_test = np.load(\"person_test.npy\")\n",
    "\n",
    "## Printing the shapes of the numpy arrays\n",
    "\n",
    "print ('Training/Valid data shape: {}'.format(X_train_valid.shape))\n",
    "print ('Test data shape: {}'.format(X_test.shape))\n",
    "print ('Training/Valid target shape: {}'.format(y_train_valid.shape))\n",
    "print ('Test target shape: {}'.format(y_test.shape))\n",
    "print ('Person train/valid shape: {}'.format(person_train_valid.shape))\n",
    "print ('Person test shape: {}'.format(person_test.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dc37e11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x22abe451e08>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Adjusting the labels to {0,1,2,3}\n",
    "\n",
    "# Cue onset left - 0\n",
    "# Cue onset right - 1\n",
    "# Cue onset foot - 2\n",
    "# Cue onset tongue - 3\n",
    "\n",
    "y_train_valid -= 769\n",
    "y_test -= 769\n",
    "## Visualizing the data\n",
    "\n",
    "ch_data = X_train_valid[:,8,:]\n",
    "\n",
    "\n",
    "class_0_ind = np.where(y_train_valid == 0)\n",
    "ch_data_class_0 = ch_data[class_0_ind]\n",
    "avg_ch_data_class_0 = np.mean(ch_data_class_0,axis=0)\n",
    "\n",
    "\n",
    "class_1_ind = np.where(y_train_valid == 1)\n",
    "ch_data_class_1 = ch_data[class_1_ind]\n",
    "avg_ch_data_class_1 = np.mean(ch_data_class_1,axis=0)\n",
    "\n",
    "class_2_ind = np.where(y_train_valid == 2)\n",
    "ch_data_class_2 = ch_data[class_2_ind]\n",
    "avg_ch_data_class_2 = np.mean(ch_data_class_2,axis=0)\n",
    "\n",
    "class_3_ind = np.where(y_train_valid == 3)\n",
    "ch_data_class_3 = ch_data[class_3_ind]\n",
    "avg_ch_data_class_3 = np.mean(ch_data_class_3,axis=0)\n",
    "\n",
    "\n",
    "plt.plot(np.arange(1000),avg_ch_data_class_0)\n",
    "plt.plot(np.arange(1000),avg_ch_data_class_1)\n",
    "plt.plot(np.arange(1000),avg_ch_data_class_2)\n",
    "plt.plot(np.arange(1000),avg_ch_data_class_3)\n",
    "plt.axvline(x=500, label='line at t=500',c='cyan')\n",
    "\n",
    "plt.legend([\"Cue Onset left\", \"Cue Onset right\", \"Cue onset foot\", \"Cue onset tongue\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96abeefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prep(X,y,p,sub_sample,average,noise):\n",
    "    \n",
    "    total_X = None\n",
    "    total_y = None\n",
    "    total_p = None\n",
    "    # Trimming the data (sample,22,1000) -> (sample,22,500)\n",
    "    X = X[:,:,0:500]\n",
    "    print('Shape of X after trimming:',X.shape)\n",
    "    \n",
    "    # Maxpooling the data (sample,22,1000) -> (sample,22,500/sub_sample)\n",
    "    X_max = np.max(X.reshape(X.shape[0], X.shape[1], -1, sub_sample), axis=3)\n",
    "    \n",
    "    \n",
    "    total_X = X_max\n",
    "    total_y = y\n",
    "    total_p = p\n",
    "\n",
    "    print('Shape of X after maxpooling:',total_X.shape)\n",
    "    \n",
    "    # Averaging + noise \n",
    "    X_average = np.mean(X.reshape(X.shape[0], X.shape[1], -1, average),axis=3)\n",
    "    X_average = X_average + np.random.normal(0.0, 0.5, X_average.shape)\n",
    "    \n",
    "    total_X = np.vstack((total_X, X_average))\n",
    "    total_y = np.hstack((total_y, y))\n",
    "    total_p = np.hstack((total_p, p))\n",
    "    print('Shape of X after averaging+noise and concatenating:',total_X.shape)\n",
    "    \n",
    "    # Subsampling\n",
    "    \n",
    "    for i in range(sub_sample):\n",
    "        \n",
    "        X_subsample = X[:, :, i::sub_sample] + \\\n",
    "                            (np.random.normal(0.0, 0.5, X[:, :,i::sub_sample].shape) if noise else 0.0)\n",
    "            \n",
    "        total_X = np.vstack((total_X, X_subsample))\n",
    "        total_y = np.hstack((total_y, y))\n",
    "        total_p = np.hstack((total_p, p))\n",
    "        \n",
    "    \n",
    "    print('Shape of X after subsampling and concatenating:',total_X.shape)\n",
    "    return total_X,total_y, total_p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54455cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X after trimming: (2115, 22, 500)\n",
      "Shape of X after maxpooling: (2115, 22, 250)\n",
      "Shape of X after averaging+noise and concatenating: (4230, 22, 250)\n",
      "Shape of X after subsampling and concatenating: (8460, 22, 250)\n",
      "Shape of X after trimming: (443, 22, 500)\n",
      "Shape of X after maxpooling: (443, 22, 250)\n",
      "Shape of X after averaging+noise and concatenating: (886, 22, 250)\n",
      "Shape of X after subsampling and concatenating: (1772, 22, 250)\n",
      "(8460,)\n",
      "(8460, 22, 250)\n",
      "(8460,)\n",
      "(1772, 22, 250)\n",
      "(1772,)\n",
      "Shape of training set: (6960, 22, 250)\n",
      "Shape of validation set: (1500, 22, 250)\n",
      "Shape of training labels: (6960,)\n",
      "Shape of validation labels: (1500,)\n",
      "Shape of training labels after categorical conversion: (6960, 4)\n",
      "Shape of validation labels after categorical conversion: (1500, 4)\n",
      "Shape of test labels after categorical conversion: (1772, 4)\n",
      "Shape of training set after adding width info: (6960, 22, 250, 1)\n",
      "Shape of validation set after adding width info: (1500, 22, 250, 1)\n",
      "Shape of test set after adding width info: (1772, 22, 250, 1)\n",
      "Shape of training set after dimension reshaping: (6960, 250, 1, 22)\n",
      "Shape of validation set after dimension reshaping: (1500, 250, 1, 22)\n",
      "Shape of test set after dimension reshaping: (1772, 250, 1, 22)\n"
     ]
    }
   ],
   "source": [
    "## Preprocessing the dataset\n",
    "X_train_valid_prep,y_train_valid_prep,person_train_valid_prep = data_prep(X_train_valid,y_train_valid,person_train_valid,2,2,True)\n",
    "X_test_prep,y_test_prep,person_test_prep = data_prep(X_test,y_test,person_test,2,2,True)\n",
    "stratif_labels = []\n",
    "for i in range(person_train_valid_prep.shape[0]):\n",
    "    stratif_labels.append(str(person_train_valid_prep[i].astype('int'))+str(y_train_valid_prep[i]))\n",
    "print(person_train_valid_prep.shape)\n",
    "print(X_train_valid_prep.shape)\n",
    "print(y_train_valid_prep.shape)\n",
    "print(X_test_prep.shape)\n",
    "print(y_test_prep.shape)\n",
    "\n",
    "\n",
    "\n",
    "## Random splitting and reshaping the data\n",
    "\n",
    "# First generating the training and validation indices using random splitting\n",
    "ind_valid = np.random.choice(8460, 1500, replace=False)\n",
    "ind_train = np.array(list(set(range(8460)).difference(set(ind_valid))))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(X_train_valid_prep,y_train_valid_prep,test_size=1500/8460,stratify=stratif_labels)\n",
    "\n",
    "# Creating the training and validation sets using the generated indices\n",
    "# (x_train, x_valid) = X_train_valid_prep[ind_train], X_train_valid_prep[ind_valid] \n",
    "# (y_train, y_valid) = y_train_valid_prep[ind_train], y_train_valid_prep[ind_valid]\n",
    "print('Shape of training set:',x_train.shape)\n",
    "print('Shape of validation set:',x_valid.shape)\n",
    "print('Shape of training labels:',y_train.shape)\n",
    "print('Shape of validation labels:',y_valid.shape)\n",
    "\n",
    "\n",
    "# Converting the labels to categorical variables for multiclass classification\n",
    "y_train = to_categorical(y_train, 4)\n",
    "y_valid = to_categorical(y_valid, 4)\n",
    "y_test = to_categorical(y_test_prep, 4)\n",
    "print('Shape of training labels after categorical conversion:',y_train.shape)\n",
    "print('Shape of validation labels after categorical conversion:',y_valid.shape)\n",
    "print('Shape of test labels after categorical conversion:',y_test.shape)\n",
    "\n",
    "# Adding width of the segment to be 1\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
    "x_valid = x_valid.reshape(x_valid.shape[0], x_valid.shape[1], x_train.shape[2], 1)\n",
    "x_test = X_test_prep.reshape(X_test_prep.shape[0], X_test_prep.shape[1], X_test_prep.shape[2], 1)\n",
    "print('Shape of training set after adding width info:',x_train.shape)\n",
    "print('Shape of validation set after adding width info:',x_valid.shape)\n",
    "print('Shape of test set after adding width info:',x_test.shape)\n",
    "\n",
    "\n",
    "# Reshaping the training and validation dataset\n",
    "x_train = np.swapaxes(x_train, 1,3)\n",
    "x_train = np.swapaxes(x_train, 1,2)\n",
    "x_valid = np.swapaxes(x_valid, 1,3)\n",
    "x_valid = np.swapaxes(x_valid, 1,2)\n",
    "x_test = np.swapaxes(x_test, 1,3)\n",
    "x_test = np.swapaxes(x_test, 1,2)\n",
    "print('Shape of training set after dimension reshaping:',x_train.shape)\n",
    "print('Shape of validation set after dimension reshaping:',x_valid.shape)\n",
    "print('Shape of test set after dimension reshaping:',x_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f124a502",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model(time_period=1000):   \n",
    "    time_period = min(time_period, 250)\n",
    "    \n",
    "    # Building the CNN model using sequential class\n",
    "    basic_cnn_model = Sequential()\n",
    "    \n",
    "    # Conv. block 1\n",
    "    basic_cnn_model.add(Conv2D(filters=100, kernel_size=(10,1), padding='same', activation='elu', input_shape=(time_period,1,22)))\n",
    "    basic_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same')) # Read the keras documentation\n",
    "    basic_cnn_model.add(BatchNormalization())\n",
    "    basic_cnn_model.add(Dropout(0.5))\n",
    "\n",
    "    # Conv. block 2\n",
    "    basic_cnn_model.add(Conv2D(filters=100, kernel_size=(10,1), padding='same', activation='elu'))\n",
    "    basic_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "    basic_cnn_model.add(BatchNormalization())\n",
    "    basic_cnn_model.add(Dropout(0.5))\n",
    "\n",
    "    # Conv. block 3\n",
    "    basic_cnn_model.add(Conv2D(filters=100, kernel_size=(10,1), padding='same', activation='elu'))\n",
    "    basic_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "    basic_cnn_model.add(BatchNormalization())\n",
    "    basic_cnn_model.add(Dropout(0.5))\n",
    "\n",
    "    # Conv. block 4\n",
    "    basic_cnn_model.add(Conv2D(filters=100, kernel_size=(10,1), padding='same', activation='elu'))\n",
    "    basic_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "    basic_cnn_model.add(BatchNormalization())\n",
    "    basic_cnn_model.add(Dropout(0.5))\n",
    "\n",
    "    # Output layer with Softmax activation\n",
    "    basic_cnn_model.add(Flatten()) # Flattens the input\n",
    "    basic_cnn_model.add(Dense(4, activation='softmax')) # Output FC layer with softmax activation\n",
    "    \n",
    "    cnn_optimizer = optimizers.Adam(learning_rate)\n",
    "    \n",
    "    basic_cnn_model.compile(loss='categorical_crossentropy',\n",
    "                     optimizer=cnn_optimizer,\n",
    "                     metrics=['accuracy'])\n",
    "\n",
    "    # Printing the model summary\n",
    "    basic_cnn_model.summary()\n",
    "    \n",
    "    return basic_cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75d1bbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "learning_rate = 1.5e-3\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f11adcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_data(time_period=1000):\n",
    "    # different period of time\n",
    "    x_train_time = x_train[:,:time_period,:,:]\n",
    "    y_train_time = y_train\n",
    "    x_valid_time = x_valid[:,:time_period,:,:]\n",
    "    y_valid_time = y_valid\n",
    "    x_test_time = x_test[:,:time_period,:,:]\n",
    "    y_test_time = y_test\n",
    "    \n",
    "    \n",
    "    model = cnn_model(time_period)\n",
    "\n",
    "    # Training and validating the model\n",
    "    cnn_model_results = model.fit(x_train_time,\n",
    "                 y_train_time,\n",
    "                 batch_size=200,\n",
    "                 epochs=epochs,\n",
    "                 validation_data=(x_valid_time, y_valid_time), verbose=True)\n",
    "    \n",
    "    train_score = model.evaluate(x_train_time, y_train_time)\n",
    "    \n",
    "    test_score = model.evaluate(x_test_time, y_test_time)\n",
    "\n",
    "    print('train {:s}: {:.3f}%'.format(model.metrics_names[1], train_score[1]*100))\n",
    "    print('test {:s}: {:.3f}%'.format(model.metrics_names[1], test_score[1]*100))\n",
    "    #print(model.summary())\n",
    "    \n",
    "    return train_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fecc482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================25===================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 25, 1, 100)        22100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 9, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 9, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 9, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 9, 1, 100)         100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 3, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 3, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 3, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 3, 1, 100)         100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 1, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 1, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 1, 1, 100)         100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 1, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 1, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 404       \n",
      "=================================================================\n",
      "Total params: 324,404\n",
      "Trainable params: 323,604\n",
      "Non-trainable params: 800\n",
      "_________________________________________________________________\n",
      "Train on 6960 samples, validate on 1500 samples\n",
      "Epoch 1/50\n",
      "6960/6960 [==============================] - 11s 2ms/sample - loss: 1.9143 - accuracy: 0.2690 - val_loss: 1.5159 - val_accuracy: 0.3207\n",
      "Epoch 2/50\n",
      "6960/6960 [==============================] - 4s 580us/sample - loss: 1.6981 - accuracy: 0.2733 - val_loss: 1.5288 - val_accuracy: 0.3107\n",
      "Epoch 3/50\n",
      "6960/6960 [==============================] - 2s 323us/sample - loss: 1.5919 - accuracy: 0.2849 - val_loss: 1.3705 - val_accuracy: 0.3387\n",
      "Epoch 4/50\n",
      "6960/6960 [==============================] - 2s 341us/sample - loss: 1.5023 - accuracy: 0.2855 - val_loss: 1.3346 - val_accuracy: 0.3500\n",
      "Epoch 5/50\n",
      "6960/6960 [==============================] - 4s 588us/sample - loss: 1.4367 - accuracy: 0.3106 - val_loss: 1.3164 - val_accuracy: 0.3707\n",
      "Epoch 6/50\n",
      "6960/6960 [==============================] - 2s 313us/sample - loss: 1.3932 - accuracy: 0.3322 - val_loss: 1.2997 - val_accuracy: 0.3780\n",
      "Epoch 7/50\n",
      "6960/6960 [==============================] - 2s 324us/sample - loss: 1.3494 - accuracy: 0.3467 - val_loss: 1.2879 - val_accuracy: 0.3933\n",
      "Epoch 8/50\n",
      "6960/6960 [==============================] - 2s 281us/sample - loss: 1.3208 - accuracy: 0.3659 - val_loss: 1.2804 - val_accuracy: 0.3873\n",
      "Epoch 9/50\n",
      "6960/6960 [==============================] - 4s 551us/sample - loss: 1.2940 - accuracy: 0.3927 - val_loss: 1.2633 - val_accuracy: 0.4167\n",
      "Epoch 10/50\n",
      "6960/6960 [==============================] - 2s 356us/sample - loss: 1.2819 - accuracy: 0.3964 - val_loss: 1.2538 - val_accuracy: 0.4453\n",
      "Epoch 11/50\n",
      "6960/6960 [==============================] - 3s 384us/sample - loss: 1.2621 - accuracy: 0.4131 - val_loss: 1.2382 - val_accuracy: 0.4553\n",
      "Epoch 12/50\n",
      "6960/6960 [==============================] - 3s 456us/sample - loss: 1.2438 - accuracy: 0.4228 - val_loss: 1.2176 - val_accuracy: 0.4700\n",
      "Epoch 13/50\n",
      "6960/6960 [==============================] - 3s 360us/sample - loss: 1.2310 - accuracy: 0.4353 - val_loss: 1.1944 - val_accuracy: 0.4700\n",
      "Epoch 14/50\n",
      "6960/6960 [==============================] - 4s 642us/sample - loss: 1.2269 - accuracy: 0.4355 - val_loss: 1.1907 - val_accuracy: 0.4693\n",
      "Epoch 15/50\n",
      "6960/6960 [==============================] - 2s 321us/sample - loss: 1.2056 - accuracy: 0.4580 - val_loss: 1.1830 - val_accuracy: 0.4707\n",
      "Epoch 16/50\n",
      "6960/6960 [==============================] - 4s 521us/sample - loss: 0.8833 - accuracy: 0.6434 - val_loss: 0.7826 - val_accuracy: 0.6867\n",
      "Epoch 36/50\n",
      "6960/6960 [==============================] - 4s 504us/sample - loss: 0.8802 - accuracy: 0.6338 - val_loss: 0.7634 - val_accuracy: 0.7053\n",
      "Epoch 37/50\n",
      "6960/6960 [==============================] - 5s 651us/sample - loss: 0.8693 - accuracy: 0.6476 - val_loss: 0.7540 - val_accuracy: 0.7127\n",
      "Epoch 38/50\n",
      "6960/6960 [==============================] - 3s 499us/sample - loss: 0.8607 - accuracy: 0.6514 - val_loss: 0.7459 - val_accuracy: 0.7180\n",
      "Epoch 39/50\n",
      "6960/6960 [==============================] - 4s 636us/sample - loss: 0.8357 - accuracy: 0.6647 - val_loss: 0.7110 - val_accuracy: 0.7253\n",
      "Epoch 40/50\n",
      "6960/6960 [==============================] - 3s 465us/sample - loss: 0.8205 - accuracy: 0.6651 - val_loss: 0.7024 - val_accuracy: 0.7307\n",
      "Epoch 41/50\n",
      "6960/6960 [==============================] - 4s 622us/sample - loss: 0.8224 - accuracy: 0.6721 - val_loss: 0.6931 - val_accuracy: 0.7320\n",
      "Epoch 42/50\n",
      "6960/6960 [==============================] - 3s 400us/sample - loss: 0.8071 - accuracy: 0.6757 - val_loss: 0.6739 - val_accuracy: 0.7533\n",
      "Epoch 43/50\n",
      "6960/6960 [==============================] - 4s 637us/sample - loss: 0.8215 - accuracy: 0.6687 - val_loss: 0.6733 - val_accuracy: 0.7440\n",
      "Epoch 44/50\n",
      "6960/6960 [==============================] - 3s 430us/sample - loss: 0.7745 - accuracy: 0.6892 - val_loss: 0.6338 - val_accuracy: 0.7653\n",
      "Epoch 45/50\n",
      "6960/6960 [==============================] - 3s 471us/sample - loss: 0.7711 - accuracy: 0.6932 - val_loss: 0.6284 - val_accuracy: 0.7633\n",
      "Epoch 46/50\n",
      "6960/6960 [==============================] - 3s 404us/sample - loss: 0.7519 - accuracy: 0.6999 - val_loss: 0.6111 - val_accuracy: 0.7913\n",
      "Epoch 47/50\n",
      "6960/6960 [==============================] - 4s 618us/sample - loss: 0.7548 - accuracy: 0.6935 - val_loss: 0.5964 - val_accuracy: 0.7940\n",
      "Epoch 48/50\n",
      "6960/6960 [==============================] - 3s 464us/sample - loss: 0.7448 - accuracy: 0.7062 - val_loss: 0.6030 - val_accuracy: 0.7760\n",
      "Epoch 49/50\n",
      "6960/6960 [==============================] - 3s 454us/sample - loss: 0.7274 - accuracy: 0.7132 - val_loss: 0.5654 - val_accuracy: 0.7980\n",
      "Epoch 50/50\n",
      "6960/6960 [==============================] - 3s 472us/sample - loss: 0.7243 - accuracy: 0.7161 - val_loss: 0.5863 - val_accuracy: 0.7907\n",
      "6960/6960 [==============================] - 2s 239us/sample - loss: 0.3073 - accuracy: 0.9159\n",
      "1772/1772 [==============================] - 0s 239us/sample - loss: 1.6601 - accuracy: 0.4063\n",
      "train accuracy: 91.595%\n",
      "test accuracy: 40.632%\n",
      "=================50===================\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 50, 1, 100)        22100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 17, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 17, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 17, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 17, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 6, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 6, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 6, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 6, 1, 100)         100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 2, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 2, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 2, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 2, 1, 100)         100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 1, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 1, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 1, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 404       \n",
      "=================================================================\n",
      "Total params: 324,404\n",
      "Trainable params: 323,604\n",
      "Non-trainable params: 800\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6960 samples, validate on 1500 samples\n",
      "Epoch 1/50\n",
      "6960/6960 [==============================] - 17s 2ms/sample - loss: 1.9959 - accuracy: 0.2772 - val_loss: 2.1107 - val_accuracy: 0.2673\n",
      "Epoch 2/50\n",
      "6960/6960 [==============================] - 5s 706us/sample - loss: 1.7036 - accuracy: 0.2829 - val_loss: 1.6491 - val_accuracy: 0.3160\n",
      "Epoch 3/50\n",
      "6960/6960 [==============================] - 5s 682us/sample - loss: 1.5569 - accuracy: 0.3033 - val_loss: 1.4540 - val_accuracy: 0.3527\n",
      "Epoch 4/50\n",
      "6960/6960 [==============================] - 5s 780us/sample - loss: 1.4582 - accuracy: 0.3273 - val_loss: 1.3259 - val_accuracy: 0.3987\n",
      "Epoch 5/50\n",
      "6960/6960 [==============================] - 6s 871us/sample - loss: 1.3994 - accuracy: 0.3539 - val_loss: 1.2776 - val_accuracy: 0.4093\n",
      "Epoch 6/50\n",
      "6960/6960 [==============================] - 5s 656us/sample - loss: 1.3487 - accuracy: 0.3800 - val_loss: 1.2356 - val_accuracy: 0.4447\n",
      "Epoch 7/50\n",
      "6960/6960 [==============================] - 6s 854us/sample - loss: 1.3082 - accuracy: 0.3978 - val_loss: 1.2192 - val_accuracy: 0.4633\n",
      "Epoch 8/50\n",
      "6960/6960 [==============================] - 4s 628us/sample - loss: 1.2718 - accuracy: 0.4152 - val_loss: 1.2063 - val_accuracy: 0.4760\n",
      "Epoch 9/50\n",
      "6960/6960 [==============================] - 5s 660us/sample - loss: 1.2451 - accuracy: 0.4431 - val_loss: 1.1624 - val_accuracy: 0.4993\n",
      "Epoch 10/50\n",
      "6960/6960 [==============================] - 5s 788us/sample - loss: 1.2092 - accuracy: 0.4589 - val_loss: 1.1386 - val_accuracy: 0.5033\n",
      "Epoch 11/50\n",
      "6960/6960 [==============================] - 5s 686us/sample - loss: 1.1785 - accuracy: 0.4800 - val_loss: 1.1461 - val_accuracy: 0.4887\n",
      "Epoch 12/50\n",
      "6960/6960 [==============================] - 6s 811us/sample - loss: 1.1681 - accuracy: 0.4888 - val_loss: 1.0857 - val_accuracy: 0.5220\n",
      "Epoch 13/50\n",
      "6960/6960 [==============================] - 5s 704us/sample - loss: 1.1197 - accuracy: 0.5099 - val_loss: 1.0534 - val_accuracy: 0.5420\n",
      "Epoch 14/50\n",
      "6960/6960 [==============================] - 5s 745us/sample - loss: 1.1031 - accuracy: 0.5234 - val_loss: 1.0321 - val_accuracy: 0.5480\n",
      "Epoch 15/50\n",
      "6960/6960 [==============================] - 5s 777us/sample - loss: 1.0729 - accuracy: 0.5405 - val_loss: 1.0062 - val_accuracy: 0.5753\n",
      "Epoch 16/50\n",
      "6960/6960 [==============================] - 5s 750us/sample - loss: 0.5652 - accuracy: 0.7783 - val_loss: 0.3297 - val_accuracy: 0.8920\n",
      "Epoch 44/50\n",
      "6960/6960 [==============================] - 6s 846us/sample - loss: 0.5464 - accuracy: 0.7846 - val_loss: 0.3293 - val_accuracy: 0.8860\n",
      "Epoch 45/50\n",
      "6960/6960 [==============================] - 5s 707us/sample - loss: 0.5426 - accuracy: 0.7899 - val_loss: 0.3123 - val_accuracy: 0.8913\n",
      "Epoch 46/50\n",
      "6960/6960 [==============================] - 6s 812us/sample - loss: 0.5308 - accuracy: 0.7917 - val_loss: 0.3172 - val_accuracy: 0.8913\n",
      "Epoch 47/50\n",
      "6960/6960 [==============================] - 5s 714us/sample - loss: 0.5124 - accuracy: 0.8060 - val_loss: 0.2723 - val_accuracy: 0.9160\n",
      "Epoch 48/50\n",
      "6960/6960 [==============================] - 5s 751us/sample - loss: 0.5056 - accuracy: 0.8043 - val_loss: 0.2823 - val_accuracy: 0.9040\n",
      "Epoch 49/50\n",
      "6960/6960 [==============================] - 6s 893us/sample - loss: 0.5044 - accuracy: 0.8129 - val_loss: 0.2649 - val_accuracy: 0.9093\n",
      "Epoch 50/50\n",
      "6960/6960 [==============================] - 5s 676us/sample - loss: 0.5087 - accuracy: 0.8037 - val_loss: 0.2525 - val_accuracy: 0.9253\n",
      "6960/6960 [==============================] - 3s 465us/sample - loss: 0.1183 - accuracy: 0.9795\n",
      "1772/1772 [==============================] - 1s 374us/sample - loss: 1.3148 - accuracy: 0.5463\n",
      "train accuracy: 97.945%\n",
      "test accuracy: 54.628%\n",
      "=================75===================\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 75, 1, 100)        22100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 25, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 25, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 25, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 25, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 9, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 9, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 9, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 9, 1, 100)         100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 3, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 3, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 3, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 3, 1, 100)         100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 1, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 1, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 1, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 404       \n",
      "=================================================================\n",
      "Total params: 324,404\n",
      "Trainable params: 323,604\n",
      "Non-trainable params: 800\n",
      "_________________________________________________________________\n",
      "Train on 6960 samples, validate on 1500 samples\n",
      "Epoch 1/50\n",
      "6960/6960 [==============================] - 18s 3ms/sample - loss: 1.9824 - accuracy: 0.2915 - val_loss: 1.8839 - val_accuracy: 0.2720\n",
      "Epoch 2/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 1.6683 - accuracy: 0.3056 - val_loss: 1.5083 - val_accuracy: 0.3000\n",
      "Epoch 3/50\n",
      "6960/6960 [==============================] - 7s 1ms/sample - loss: 1.5341 - accuracy: 0.3227 - val_loss: 1.5056 - val_accuracy: 0.3247\n",
      "Epoch 4/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 1.4337 - accuracy: 0.3417 - val_loss: 1.2671 - val_accuracy: 0.4147\n",
      "Epoch 5/50\n",
      "6960/6960 [==============================] - 7s 970us/sample - loss: 1.3595 - accuracy: 0.3751 - val_loss: 1.2232 - val_accuracy: 0.4340\n",
      "Epoch 6/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 1.3088 - accuracy: 0.4093 - val_loss: 1.1894 - val_accuracy: 0.4587\n",
      "Epoch 7/50\n",
      "6960/6960 [==============================] - 7s 1ms/sample - loss: 1.2663 - accuracy: 0.4284 - val_loss: 1.1625 - val_accuracy: 0.4853\n",
      "Epoch 8/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 1.2255 - accuracy: 0.4547 - val_loss: 1.1351 - val_accuracy: 0.5047\n",
      "Epoch 9/50\n",
      "6960/6960 [==============================] - 6s 896us/sample - loss: 1.1745 - accuracy: 0.4925 - val_loss: 1.1023 - val_accuracy: 0.5360\n",
      "Epoch 10/50\n",
      "6960/6960 [==============================] - 9s 1ms/sample - loss: 1.1602 - accuracy: 0.4930 - val_loss: 1.0787 - val_accuracy: 0.5487\n",
      "Epoch 11/50\n",
      "6960/6960 [==============================] - 7s 954us/sample - loss: 1.1323 - accuracy: 0.5136 - val_loss: 1.0347 - val_accuracy: 0.5700\n",
      "Epoch 12/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6960/6960 [==============================] - 7s 1ms/sample - loss: 1.0959 - accuracy: 0.5250 - val_loss: 0.9927 - val_accuracy: 0.5913\n",
      "Epoch 13/50\n",
      "6960/6960 [==============================] - 7s 1ms/sample - loss: 1.0630 - accuracy: 0.5438 - val_loss: 0.9727 - val_accuracy: 0.5900\n",
      "Epoch 14/50\n",
      "6960/6960 [==============================] - 5s 739us/sample - loss: 1.0399 - accuracy: 0.5624 - val_loss: 0.9281 - val_accuracy: 0.6187\n",
      "Epoch 15/50\n",
      "6960/6960 [==============================] - 5s 723us/sample - loss: 1.0054 - accuracy: 0.5769 - val_loss: 0.8790 - val_accuracy: 0.6460\n",
      "Epoch 16/50\n",
      "6960/6960 [==============================] - 5s 652us/sample - loss: 0.9822 - accuracy: 0.5884 - val_loss: 0.8688 - val_accuracy: 0.6473\n",
      "Epoch 17/50\n",
      "6960/6960 [==============================] - 7s 943us/sample - loss: 0.9615 - accuracy: 0.6027 - val_loss: 0.8209 - val_accuracy: 0.6700\n",
      "Epoch 18/50\n",
      "6960/6960 [==============================] - 6s 845us/sample - loss: 0.9345 - accuracy: 0.6129 - val_loss: 0.7925 - val_accuracy: 0.6933\n",
      "Epoch 19/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 0.9045 - accuracy: 0.6290 - val_loss: 0.7405 - val_accuracy: 0.7040\n",
      "Epoch 20/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 0.8668 - accuracy: 0.6448 - val_loss: 0.7526 - val_accuracy: 0.7040\n",
      "Epoch 21/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 0.8545 - accuracy: 0.6565 - val_loss: 0.6761 - val_accuracy: 0.7333\n",
      "Epoch 22/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 0.8250 - accuracy: 0.6655 - val_loss: 0.6420 - val_accuracy: 0.7773\n",
      "Epoch 23/50\n",
      "6960/6960 [==============================] - 7s 1ms/sample - loss: 0.8184 - accuracy: 0.6710 - val_loss: 0.6109 - val_accuracy: 0.7753\n",
      "Epoch 24/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 0.7700 - accuracy: 0.6924 - val_loss: 0.6074 - val_accuracy: 0.7620\n",
      "Epoch 25/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 0.7611 - accuracy: 0.6987 - val_loss: 0.5532 - val_accuracy: 0.7953\n",
      "Epoch 26/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 0.7360 - accuracy: 0.7126 - val_loss: 0.5247 - val_accuracy: 0.8060\n",
      "Epoch 27/50\n",
      "6960/6960 [==============================] - 9s 1ms/sample - loss: 0.7124 - accuracy: 0.7178 - val_loss: 0.4820 - val_accuracy: 0.8480\n",
      "Epoch 28/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 0.6864 - accuracy: 0.7333 - val_loss: 0.4545 - val_accuracy: 0.8493\n",
      "Epoch 29/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 0.6585 - accuracy: 0.7434 - val_loss: 0.4609 - val_accuracy: 0.8380\n",
      "Epoch 30/50\n",
      "6960/6960 [==============================] - 7s 988us/sample - loss: 0.6615 - accuracy: 0.7408 - val_loss: 0.4492 - val_accuracy: 0.8553\n",
      "Epoch 31/50\n",
      "6960/6960 [==============================] - 7s 1ms/sample - loss: 0.6345 - accuracy: 0.7560 - val_loss: 0.4178 - val_accuracy: 0.8580\n",
      "Epoch 32/50\n",
      "6960/6960 [==============================] - 9s 1ms/sample - loss: 0.6158 - accuracy: 0.7655 - val_loss: 0.3874 - val_accuracy: 0.8733\n",
      "Epoch 33/50\n",
      "6960/6960 [==============================] - 7s 992us/sample - loss: 0.5905 - accuracy: 0.7734 - val_loss: 0.4985 - val_accuracy: 0.8067\n",
      "Epoch 34/50\n",
      "6960/6960 [==============================] - 7s 1ms/sample - loss: 0.5756 - accuracy: 0.7747 - val_loss: 0.3445 - val_accuracy: 0.8887\n",
      "Epoch 35/50\n",
      "6960/6960 [==============================] - 7s 937us/sample - loss: 0.5701 - accuracy: 0.7753 - val_loss: 0.3591 - val_accuracy: 0.8853\n",
      "Epoch 36/50\n",
      "6960/6960 [==============================] - 6s 827us/sample - loss: 0.5701 - accuracy: 0.7796 - val_loss: 0.3208 - val_accuracy: 0.9053\n",
      "Epoch 37/50\n",
      "6960/6960 [==============================] - 6s 888us/sample - loss: 0.5379 - accuracy: 0.7894 - val_loss: 0.3225 - val_accuracy: 0.8940\n",
      "Epoch 38/50\n",
      "6960/6960 [==============================] - 6s 926us/sample - loss: 0.5322 - accuracy: 0.7901 - val_loss: 0.2780 - val_accuracy: 0.9187\n",
      "Epoch 39/50\n",
      "6960/6960 [==============================] - 7s 971us/sample - loss: 0.4048 - accuracy: 0.8437 - val_loss: 0.1819 - val_accuracy: 0.9473\n",
      "Epoch 49/50\n",
      "6960/6960 [==============================] - 7s 957us/sample - loss: 0.4248 - accuracy: 0.8378 - val_loss: 0.1850 - val_accuracy: 0.9427\n",
      "Epoch 50/50\n",
      "6960/6960 [==============================] - 7s 956us/sample - loss: 0.4133 - accuracy: 0.8444 - val_loss: 0.1644 - val_accuracy: 0.9533\n",
      "6960/6960 [==============================] - 2s 350us/sample - loss: 0.0603 - accuracy: 0.9911\n",
      "1772/1772 [==============================] - 1s 358us/sample - loss: 1.2504 - accuracy: 0.5869\n",
      "train accuracy: 99.109%\n",
      "test accuracy: 58.691%\n",
      "=================100===================\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 100, 1, 100)       22100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 34, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 34, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 34, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 34, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 12, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 12, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 12, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 12, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 4, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 4, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 4, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 4, 1, 100)         100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 2, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 2, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 2, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 804       \n",
      "=================================================================\n",
      "Total params: 324,804\n",
      "Trainable params: 324,004\n",
      "Non-trainable params: 800\n",
      "_________________________________________________________________\n",
      "Train on 6960 samples, validate on 1500 samples\n",
      "Epoch 1/50\n",
      "6960/6960 [==============================] - 13s 2ms/sample - loss: 2.0283 - accuracy: 0.2816 - val_loss: 2.5094 - val_accuracy: 0.2847\n",
      "Epoch 2/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 1.6514 - accuracy: 0.3122 - val_loss: 1.8104 - val_accuracy: 0.3467\n",
      "Epoch 3/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 1.4770 - accuracy: 0.3349 - val_loss: 1.3337 - val_accuracy: 0.3827\n",
      "Epoch 4/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 1.3700 - accuracy: 0.3739 - val_loss: 1.1993 - val_accuracy: 0.4720\n",
      "Epoch 5/50\n",
      "6960/6960 [==============================] - 9s 1ms/sample - loss: 1.2947 - accuracy: 0.4155 - val_loss: 1.1253 - val_accuracy: 0.5140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 1.2120 - accuracy: 0.4636 - val_loss: 1.0882 - val_accuracy: 0.5260\n",
      "Epoch 7/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 1.1775 - accuracy: 0.4826 - val_loss: 1.0698 - val_accuracy: 0.5300\n",
      "Epoch 8/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 1.1321 - accuracy: 0.5056 - val_loss: 1.0504 - val_accuracy: 0.5513\n",
      "Epoch 9/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 1.0984 - accuracy: 0.5266 - val_loss: 1.0084 - val_accuracy: 0.5600\n",
      "Epoch 10/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 1.0505 - accuracy: 0.5582 - val_loss: 0.9707 - val_accuracy: 0.5987\n",
      "Epoch 11/50\n",
      "6960/6960 [==============================] - 7s 1ms/sample - loss: 1.0239 - accuracy: 0.5672 - val_loss: 0.9856 - val_accuracy: 0.5753\n",
      "Epoch 12/50\n",
      "6960/6960 [==============================] - 7s 1ms/sample - loss: 0.9958 - accuracy: 0.5843 - val_loss: 0.8819 - val_accuracy: 0.6367\n",
      "Epoch 13/50\n",
      "6960/6960 [==============================] - 6s 817us/sample - loss: 0.9583 - accuracy: 0.5943 - val_loss: 0.8597 - val_accuracy: 0.6447\n",
      "Epoch 14/50\n",
      "6960/6960 [==============================] - 6s 857us/sample - loss: 0.9294 - accuracy: 0.6172 - val_loss: 0.8053 - val_accuracy: 0.6867\n",
      "Epoch 15/50\n",
      "6960/6960 [==============================] - 6s 933us/sample - loss: 0.8933 - accuracy: 0.6313 - val_loss: 0.7675 - val_accuracy: 0.6953\n",
      "Epoch 16/50\n",
      "6960/6960 [==============================] - 9s 1ms/sample - loss: 0.8790 - accuracy: 0.6394 - val_loss: 0.7550 - val_accuracy: 0.6900\n",
      "Epoch 17/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 0.8268 - accuracy: 0.6615 - val_loss: 0.7110 - val_accuracy: 0.7000\n",
      "Epoch 18/50\n",
      "6960/6960 [==============================] - 7s 1ms/sample - loss: 0.8086 - accuracy: 0.6796 - val_loss: 0.6322 - val_accuracy: 0.7520\n",
      "Epoch 19/50\n",
      "6960/6960 [==============================] - 9s 1ms/sample - loss: 0.7877 - accuracy: 0.6920 - val_loss: 0.6248 - val_accuracy: 0.7473\n",
      "Epoch 20/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 0.7530 - accuracy: 0.6958 - val_loss: 0.5888 - val_accuracy: 0.7720\n",
      "Epoch 21/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 0.7264 - accuracy: 0.7116 - val_loss: 0.5254 - val_accuracy: 0.8027\n",
      "Epoch 22/50\n",
      "6960/6960 [==============================] - 9s 1ms/sample - loss: 0.7071 - accuracy: 0.7282 - val_loss: 0.5440 - val_accuracy: 0.7913\n",
      "Epoch 23/50\n",
      "6960/6960 [==============================] - 7s 1ms/sample - loss: 0.6707 - accuracy: 0.7330 - val_loss: 0.4725 - val_accuracy: 0.8347\n",
      "Epoch 24/50\n",
      "6960/6960 [==============================] - 9s 1ms/sample - loss: 0.6386 - accuracy: 0.7473 - val_loss: 0.4514 - val_accuracy: 0.8340\n",
      "Epoch 25/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 0.6261 - accuracy: 0.7547 - val_loss: 0.3982 - val_accuracy: 0.8587\n",
      "Epoch 26/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 0.5930 - accuracy: 0.7629 - val_loss: 0.3685 - val_accuracy: 0.8680\n",
      "Epoch 27/50\n",
      "6960/6960 [==============================] - 10s 1ms/sample - loss: 0.6041 - accuracy: 0.7657 - val_loss: 0.3951 - val_accuracy: 0.8627\n",
      "Epoch 28/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 0.5641 - accuracy: 0.7828 - val_loss: 0.3533 - val_accuracy: 0.8847\n",
      "Epoch 29/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 0.5424 - accuracy: 0.7898 - val_loss: 0.3405 - val_accuracy: 0.8727\n",
      "Epoch 30/50\n",
      "6960/6960 [==============================] - 9s 1ms/sample - loss: 0.5190 - accuracy: 0.7999 - val_loss: 0.2897 - val_accuracy: 0.9133\n",
      "Epoch 31/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 0.5026 - accuracy: 0.8026 - val_loss: 0.2864 - val_accuracy: 0.9020\n",
      "Epoch 32/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 0.5156 - accuracy: 0.8001 - val_loss: 0.3400 - val_accuracy: 0.8753\n",
      "Epoch 33/50\n",
      "6960/6960 [==============================] - 9s 1ms/sample - loss: 0.4970 - accuracy: 0.8085 - val_loss: 0.2846 - val_accuracy: 0.9107\n",
      "Epoch 34/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 0.4452 - accuracy: 0.8309 - val_loss: 0.2444 - val_accuracy: 0.9147\n",
      "Epoch 35/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 0.4606 - accuracy: 0.8148 - val_loss: 0.2318 - val_accuracy: 0.9300\n",
      "Epoch 36/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 0.4330 - accuracy: 0.8353 - val_loss: 0.2345 - val_accuracy: 0.9273\n",
      "Epoch 37/50\n",
      "6960/6960 [==============================] - 10s 1ms/sample - loss: 0.4248 - accuracy: 0.8359 - val_loss: 0.1818 - val_accuracy: 0.9473\n",
      "Epoch 38/50\n",
      "6960/6960 [==============================] - 7s 1ms/sample - loss: 0.3999 - accuracy: 0.8453 - val_loss: 0.1650 - val_accuracy: 0.9553\n",
      "Epoch 39/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 0.4093 - accuracy: 0.8411 - val_loss: 0.1874 - val_accuracy: 0.9407\n",
      "Epoch 40/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 0.3931 - accuracy: 0.8474 - val_loss: 0.1772 - val_accuracy: 0.9473\n",
      "Epoch 41/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 0.3971 - accuracy: 0.8496 - val_loss: 0.1488 - val_accuracy: 0.9587\n",
      "Epoch 42/50\n",
      "6960/6960 [==============================] - 7s 1ms/sample - loss: 0.3748 - accuracy: 0.8626 - val_loss: 0.1442 - val_accuracy: 0.9613\n",
      "Epoch 43/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 0.3522 - accuracy: 0.8674 - val_loss: 0.1263 - val_accuracy: 0.9687\n",
      "Epoch 44/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 0.3487 - accuracy: 0.8708 - val_loss: 0.1222 - val_accuracy: 0.9713\n",
      "Epoch 45/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 0.3326 - accuracy: 0.8737 - val_loss: 0.1248 - val_accuracy: 0.9693\n",
      "Epoch 46/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 0.3337 - accuracy: 0.8736 - val_loss: 0.1289 - val_accuracy: 0.9700\n",
      "Epoch 47/50\n",
      "6960/6960 [==============================] - 9s 1ms/sample - loss: 0.3337 - accuracy: 0.8753 - val_loss: 0.1131 - val_accuracy: 0.9693\n",
      "Epoch 48/50\n",
      "6960/6960 [==============================] - 7s 945us/sample - loss: 0.3287 - accuracy: 0.8774 - val_loss: 0.1049 - val_accuracy: 0.9747\n",
      "Epoch 49/50\n",
      "6960/6960 [==============================] - 9s 1ms/sample - loss: 0.3227 - accuracy: 0.8784 - val_loss: 0.1105 - val_accuracy: 0.9687\n",
      "Epoch 50/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 0.3360 - accuracy: 0.8701 - val_loss: 0.1002 - val_accuracy: 0.9727\n",
      "6960/6960 [==============================] - ETA: 0s - loss: 0.0300 - accuracy: 0.99 - 3s 447us/sample - loss: 0.0301 - accuracy: 0.9966\n",
      "1772/1772 [==============================] - 1s 493us/sample - loss: 1.2308 - accuracy: 0.6287\n",
      "train accuracy: 99.655%\n",
      "test accuracy: 62.867%\n",
      "=================125===================\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 125, 1, 100)       22100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 42, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 42, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 42, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 42, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 14, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 14, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 14, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 14, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 5, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 5, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 5, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 5, 1, 100)         100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 2, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 2, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 2, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4)                 804       \n",
      "=================================================================\n",
      "Total params: 324,804\n",
      "Trainable params: 324,004\n",
      "Non-trainable params: 800\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6960 samples, validate on 1500 samples\n",
      "Epoch 1/50\n",
      "6960/6960 [==============================] - 14s 2ms/sample - loss: 2.0616 - accuracy: 0.2861 - val_loss: 3.7665 - val_accuracy: 0.2953\n",
      "Epoch 2/50\n",
      "6960/6960 [==============================] - 9s 1ms/sample - loss: 1.6354 - accuracy: 0.3282 - val_loss: 1.6271 - val_accuracy: 0.3507\n",
      "Epoch 3/50\n",
      "6960/6960 [==============================] - 10s 1ms/sample - loss: 1.4731 - accuracy: 0.3624 - val_loss: 1.3562 - val_accuracy: 0.4240\n",
      "Epoch 4/50\n",
      "6960/6960 [==============================] - 10s 1ms/sample - loss: 1.3195 - accuracy: 0.4158 - val_loss: 1.0981 - val_accuracy: 0.5327\n",
      "Epoch 5/50\n",
      "6960/6960 [==============================] - 9s 1ms/sample - loss: 1.2450 - accuracy: 0.4454 - val_loss: 1.0638 - val_accuracy: 0.5513\n",
      "Epoch 6/50\n",
      "6960/6960 [==============================] - 10s 1ms/sample - loss: 1.1753 - accuracy: 0.4849 - val_loss: 1.0183 - val_accuracy: 0.5767\n",
      "Epoch 7/50\n",
      "6960/6960 [==============================] - 10s 1ms/sample - loss: 1.1322 - accuracy: 0.5119 - val_loss: 1.0064 - val_accuracy: 0.5800\n",
      "Epoch 8/50\n",
      "6960/6960 [==============================] - 10s 1ms/sample - loss: 1.0762 - accuracy: 0.5405 - val_loss: 0.9337 - val_accuracy: 0.6253\n",
      "Epoch 9/50\n",
      "6960/6960 [==============================] - 9s 1ms/sample - loss: 1.0338 - accuracy: 0.5661 - val_loss: 0.9237 - val_accuracy: 0.6300\n",
      "Epoch 10/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 0.9937 - accuracy: 0.5816 - val_loss: 0.8895 - val_accuracy: 0.6487\n",
      "Epoch 11/50\n",
      "6960/6960 [==============================] - 7s 944us/sample - loss: 0.9414 - accuracy: 0.6190 - val_loss: 0.8185 - val_accuracy: 0.6860\n",
      "Epoch 12/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 0.9174 - accuracy: 0.6231 - val_loss: 0.7745 - val_accuracy: 0.7113\n",
      "Epoch 13/50\n",
      "6960/6960 [==============================] - 11s 2ms/sample - loss: 0.8678 - accuracy: 0.6474 - val_loss: 0.7064 - val_accuracy: 0.7307\n",
      "Epoch 14/50\n",
      "6960/6960 [==============================] - 9s 1ms/sample - loss: 0.8255 - accuracy: 0.6628 - val_loss: 0.6509 - val_accuracy: 0.7467\n",
      "Epoch 15/50\n",
      "6960/6960 [==============================] - 10s 1ms/sample - loss: 0.7842 - accuracy: 0.6898 - val_loss: 0.6127 - val_accuracy: 0.7627\n",
      "Epoch 16/50\n",
      "6960/6960 [==============================] - 10s 1ms/sample - loss: 0.7623 - accuracy: 0.6957 - val_loss: 0.5841 - val_accuracy: 0.7860\n",
      "Epoch 17/50\n",
      "6960/6960 [==============================] - 10s 1ms/sample - loss: 0.7325 - accuracy: 0.7053 - val_loss: 0.5231 - val_accuracy: 0.8053\n",
      "Epoch 18/50\n",
      "6960/6960 [==============================] - 10s 1ms/sample - loss: 0.7167 - accuracy: 0.7148 - val_loss: 0.5918 - val_accuracy: 0.7613\n",
      "Epoch 19/50\n",
      "6960/6960 [==============================] - 10s 1ms/sample - loss: 0.6790 - accuracy: 0.7361 - val_loss: 0.4534 - val_accuracy: 0.8440\n",
      "Epoch 20/50\n",
      "6960/6960 [==============================] - 10s 1ms/sample - loss: 0.6598 - accuracy: 0.7362 - val_loss: 0.4216 - val_accuracy: 0.8547\n",
      "Epoch 21/50\n",
      "6960/6960 [==============================] - 10s 1ms/sample - loss: 0.6163 - accuracy: 0.7583 - val_loss: 0.4030 - val_accuracy: 0.8640\n",
      "Epoch 22/50\n",
      "6960/6960 [==============================] - 11s 2ms/sample - loss: 0.5888 - accuracy: 0.7693 - val_loss: 0.3820 - val_accuracy: 0.8673\n",
      "Epoch 23/50\n",
      "6960/6960 [==============================] - 11s 2ms/sample - loss: 0.5698 - accuracy: 0.7783 - val_loss: 0.3681 - val_accuracy: 0.8633\n",
      "Epoch 24/50\n",
      "6960/6960 [==============================] - 10s 1ms/sample - loss: 0.5471 - accuracy: 0.7897 - val_loss: 0.3522 - val_accuracy: 0.8673\n",
      "Epoch 25/50\n",
      "6960/6960 [==============================] - 9s 1ms/sample - loss: 0.5348 - accuracy: 0.7951 - val_loss: 0.2933 - val_accuracy: 0.9027\n",
      "Epoch 26/50\n",
      "6960/6960 [==============================] - 9s 1ms/sample - loss: 0.5313 - accuracy: 0.7970 - val_loss: 0.3065 - val_accuracy: 0.8947\n",
      "Epoch 27/50\n",
      "6960/6960 [==============================] - 11s 2ms/sample - loss: 0.4987 - accuracy: 0.8079 - val_loss: 0.2503 - val_accuracy: 0.9140\n",
      "Epoch 28/50\n",
      "6960/6960 [==============================] - 9s 1ms/sample - loss: 0.4835 - accuracy: 0.8145 - val_loss: 0.2470 - val_accuracy: 0.9200\n",
      "Epoch 29/50\n",
      "6960/6960 [==============================] - 9s 1ms/sample - loss: 0.4540 - accuracy: 0.8284 - val_loss: 0.2082 - val_accuracy: 0.9300\n",
      "Epoch 30/50\n",
      "6960/6960 [==============================] - 11s 2ms/sample - loss: 0.4579 - accuracy: 0.8231 - val_loss: 0.2563 - val_accuracy: 0.9087\n",
      "Epoch 31/50\n",
      "6960/6960 [==============================] - 10s 1ms/sample - loss: 0.4430 - accuracy: 0.8282 - val_loss: 0.2209 - val_accuracy: 0.9267\n",
      "Epoch 32/50\n",
      "6960/6960 [==============================] - 9s 1ms/sample - loss: 0.4095 - accuracy: 0.8428 - val_loss: 0.1871 - val_accuracy: 0.9367\n",
      "Epoch 33/50\n",
      "6960/6960 [==============================] - 10s 2ms/sample - loss: 0.3924 - accuracy: 0.8507 - val_loss: 0.1478 - val_accuracy: 0.9547\n",
      "Epoch 34/50\n",
      "6960/6960 [==============================] - 9s 1ms/sample - loss: 0.3990 - accuracy: 0.8522 - val_loss: 0.1434 - val_accuracy: 0.9600\n",
      "Epoch 35/50\n",
      "6960/6960 [==============================] - 11s 2ms/sample - loss: 0.3757 - accuracy: 0.8583 - val_loss: 0.1528 - val_accuracy: 0.9493\n",
      "Epoch 36/50\n",
      "6960/6960 [==============================] - 10s 1ms/sample - loss: 0.3722 - accuracy: 0.8579 - val_loss: 0.1422 - val_accuracy: 0.9567\n",
      "Epoch 37/50\n",
      "6960/6960 [==============================] - 10s 1ms/sample - loss: 0.3597 - accuracy: 0.8641 - val_loss: 0.1286 - val_accuracy: 0.9607\n",
      "Epoch 38/50\n",
      "6960/6960 [==============================] - 11s 2ms/sample - loss: 0.3358 - accuracy: 0.8695 - val_loss: 0.1185 - val_accuracy: 0.9667\n",
      "Epoch 39/50\n",
      "6960/6960 [==============================] - 10s 1ms/sample - loss: 0.3420 - accuracy: 0.8756 - val_loss: 0.0998 - val_accuracy: 0.9667\n",
      "Epoch 40/50\n",
      "6960/6960 [==============================] - 10s 1ms/sample - loss: 0.3319 - accuracy: 0.8761 - val_loss: 0.1132 - val_accuracy: 0.9707\n",
      "Epoch 41/50\n",
      "6960/6960 [==============================] - 10s 1ms/sample - loss: 0.3292 - accuracy: 0.8777 - val_loss: 0.0932 - val_accuracy: 0.9727\n",
      "Epoch 42/50\n",
      "6960/6960 [==============================] - 10s 1ms/sample - loss: 0.3035 - accuracy: 0.8833 - val_loss: 0.0838 - val_accuracy: 0.9767\n",
      "Epoch 43/50\n",
      "6960/6960 [==============================] - 11s 2ms/sample - loss: 0.3058 - accuracy: 0.8858 - val_loss: 0.0881 - val_accuracy: 0.9767\n",
      "Epoch 44/50\n",
      "6960/6960 [==============================] - 10s 1ms/sample - loss: 0.2891 - accuracy: 0.8922 - val_loss: 0.0925 - val_accuracy: 0.9767\n",
      "Epoch 45/50\n",
      "6960/6960 [==============================] - 10s 1ms/sample - loss: 0.2879 - accuracy: 0.8908 - val_loss: 0.0833 - val_accuracy: 0.9820\n",
      "Epoch 46/50\n",
      "6960/6960 [==============================] - 10s 1ms/sample - loss: 0.2766 - accuracy: 0.8922 - val_loss: 0.0770 - val_accuracy: 0.9760\n",
      "Epoch 47/50\n",
      "6960/6960 [==============================] - 9s 1ms/sample - loss: 0.2809 - accuracy: 0.8935 - val_loss: 0.0589 - val_accuracy: 0.9880\n",
      "Epoch 48/50\n",
      "6960/6960 [==============================] - 10s 1ms/sample - loss: 0.2679 - accuracy: 0.9010 - val_loss: 0.0641 - val_accuracy: 0.9780\n",
      "Epoch 49/50\n",
      "6960/6960 [==============================] - 10s 1ms/sample - loss: 0.2584 - accuracy: 0.9034 - val_loss: 0.0693 - val_accuracy: 0.9793\n",
      "Epoch 50/50\n",
      "6960/6960 [==============================] - 10s 1ms/sample - loss: 0.2638 - accuracy: 0.9037 - val_loss: 0.0504 - val_accuracy: 0.9900\n",
      "6960/6960 [==============================] - 4s 579us/sample - loss: 0.0156 - accuracy: 0.9994\n",
      "1772/1772 [==============================] - 1s 487us/sample - loss: 1.0240 - accuracy: 0.6998\n",
      "train accuracy: 99.943%\n",
      "test accuracy: 69.977%\n",
      "=================150===================\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_20 (Conv2D)           (None, 150, 1, 100)       22100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 50, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 50, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 50, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 50, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 17, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 17, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 17, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 17, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 6, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 6, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 6, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 6, 1, 100)         100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 2, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 2, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 2, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4)                 804       \n",
      "=================================================================\n",
      "Total params: 324,804\n",
      "Trainable params: 324,004\n",
      "Non-trainable params: 800\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6960 samples, validate on 1500 samples\n",
      "Epoch 1/50\n",
      "6960/6960 [==============================] - 18s 3ms/sample - loss: 2.0260 - accuracy: 0.2894 - val_loss: 2.9833 - val_accuracy: 0.3433\n",
      "Epoch 2/50\n",
      "6960/6960 [==============================] - 12s 2ms/sample - loss: 1.6509 - accuracy: 0.3122 - val_loss: 2.2709 - val_accuracy: 0.3160\n",
      "Epoch 3/50\n",
      "6960/6960 [==============================] - 11s 2ms/sample - loss: 1.4534 - accuracy: 0.3566 - val_loss: 1.4120 - val_accuracy: 0.4067\n",
      "Epoch 4/50\n",
      "6960/6960 [==============================] - 11s 2ms/sample - loss: 1.3241 - accuracy: 0.4171 - val_loss: 1.1417 - val_accuracy: 0.5240\n",
      "Epoch 5/50\n",
      "6960/6960 [==============================] - 11s 2ms/sample - loss: 1.2347 - accuracy: 0.4592 - val_loss: 1.0405 - val_accuracy: 0.5600\n",
      "Epoch 6/50\n",
      "6960/6960 [==============================] - 11s 2ms/sample - loss: 1.1695 - accuracy: 0.4843 - val_loss: 1.0296 - val_accuracy: 0.5667\n",
      "Epoch 7/50\n",
      "6960/6960 [==============================] - 12s 2ms/sample - loss: 1.0968 - accuracy: 0.5263 - val_loss: 0.9457 - val_accuracy: 0.6167\n",
      "Epoch 8/50\n",
      "6960/6960 [==============================] - 11s 2ms/sample - loss: 1.0324 - accuracy: 0.5618 - val_loss: 0.9128 - val_accuracy: 0.6227\n",
      "Epoch 9/50\n",
      "6960/6960 [==============================] - 9s 1ms/sample - loss: 0.9901 - accuracy: 0.5884 - val_loss: 0.8714 - val_accuracy: 0.6527\n",
      "Epoch 10/50\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 0.9484 - accuracy: 0.6101 - val_loss: 0.8014 - val_accuracy: 0.6740\n",
      "Epoch 11/50\n",
      "6960/6960 [==============================] - 12s 2ms/sample - loss: 0.9101 - accuracy: 0.6254 - val_loss: 0.7585 - val_accuracy: 0.6967\n",
      "Epoch 12/50\n",
      "6960/6960 [==============================] - 11s 2ms/sample - loss: 0.8572 - accuracy: 0.6569 - val_loss: 0.6855 - val_accuracy: 0.7273\n",
      "Epoch 13/50\n",
      "6960/6960 [==============================] - 12s 2ms/sample - loss: 0.8333 - accuracy: 0.6622 - val_loss: 0.6727 - val_accuracy: 0.7380\n",
      "Epoch 14/50\n",
      "6960/6960 [==============================] - 12s 2ms/sample - loss: 0.8128 - accuracy: 0.6714 - val_loss: 0.6323 - val_accuracy: 0.7540\n",
      "Epoch 15/50\n",
      "6960/6960 [==============================] - 12s 2ms/sample - loss: 0.7600 - accuracy: 0.6960 - val_loss: 0.5842 - val_accuracy: 0.7813\n",
      "Epoch 16/50\n",
      "6960/6960 [==============================] - 12s 2ms/sample - loss: 0.7432 - accuracy: 0.7080 - val_loss: 0.6123 - val_accuracy: 0.7720\n",
      "Epoch 17/50\n",
      "6960/6960 [==============================] - 12s 2ms/sample - loss: 0.7158 - accuracy: 0.7141 - val_loss: 0.5073 - val_accuracy: 0.8187\n",
      "Epoch 18/50\n",
      "6960/6960 [==============================] - 11s 2ms/sample - loss: 0.6704 - accuracy: 0.7328 - val_loss: 0.5092 - val_accuracy: 0.8167\n",
      "Epoch 19/50\n",
      "6960/6960 [==============================] - 12s 2ms/sample - loss: 0.6549 - accuracy: 0.7394 - val_loss: 0.4631 - val_accuracy: 0.8307\n",
      "Epoch 20/50\n",
      "6960/6960 [==============================] - 12s 2ms/sample - loss: 0.6275 - accuracy: 0.7466 - val_loss: 0.4579 - val_accuracy: 0.8367\n",
      "Epoch 21/50\n",
      "6960/6960 [==============================] - 10s 1ms/sample - loss: 0.5942 - accuracy: 0.7701 - val_loss: 0.4722 - val_accuracy: 0.8100\n",
      "Epoch 22/50\n",
      "6960/6960 [==============================] - 12s 2ms/sample - loss: 0.5712 - accuracy: 0.7777 - val_loss: 0.4164 - val_accuracy: 0.8420\n",
      "Epoch 23/50\n",
      "6960/6960 [==============================] - 12s 2ms/sample - loss: 0.5567 - accuracy: 0.7869 - val_loss: 0.3653 - val_accuracy: 0.8680\n",
      "Epoch 24/50\n",
      "6960/6960 [==============================] - 11s 2ms/sample - loss: 0.5377 - accuracy: 0.7938 - val_loss: 0.3178 - val_accuracy: 0.8900\n",
      "Epoch 25/50\n",
      "6960/6960 [==============================] - 11s 2ms/sample - loss: 0.5079 - accuracy: 0.8073 - val_loss: 0.2907 - val_accuracy: 0.8987\n",
      "Epoch 26/50\n",
      "6960/6960 [==============================] - 14s 2ms/sample - loss: 0.4812 - accuracy: 0.8142 - val_loss: 0.2769 - val_accuracy: 0.9120\n",
      "Epoch 27/50\n",
      "6960/6960 [==============================] - 12s 2ms/sample - loss: 0.4664 - accuracy: 0.8203 - val_loss: 0.2633 - val_accuracy: 0.9107\n",
      "Epoch 28/50\n",
      "6960/6960 [==============================] - 11s 2ms/sample - loss: 0.4523 - accuracy: 0.8282 - val_loss: 0.2215 - val_accuracy: 0.9287\n",
      "Epoch 29/50\n",
      "6960/6960 [==============================] - 12s 2ms/sample - loss: 0.4379 - accuracy: 0.8345 - val_loss: 0.2362 - val_accuracy: 0.9160\n",
      "Epoch 30/50\n",
      "6960/6960 [==============================] - 13s 2ms/sample - loss: 0.4197 - accuracy: 0.8394 - val_loss: 0.2216 - val_accuracy: 0.9347\n",
      "Epoch 31/50\n",
      "6960/6960 [==============================] - 11s 2ms/sample - loss: 0.4208 - accuracy: 0.8364 - val_loss: 0.1821 - val_accuracy: 0.9407\n",
      "Epoch 32/50\n",
      "6960/6960 [==============================] - 12s 2ms/sample - loss: 0.3844 - accuracy: 0.8550 - val_loss: 0.1737 - val_accuracy: 0.9380\n",
      "Epoch 33/50\n",
      "6960/6960 [==============================] - 12s 2ms/sample - loss: 0.3758 - accuracy: 0.8555 - val_loss: 0.1493 - val_accuracy: 0.9560\n",
      "Epoch 34/50\n",
      "6960/6960 [==============================] - 13s 2ms/sample - loss: 0.3682 - accuracy: 0.8612 - val_loss: 0.1351 - val_accuracy: 0.9633\n",
      "Epoch 35/50\n",
      "6960/6960 [==============================] - 12s 2ms/sample - loss: 0.3649 - accuracy: 0.8606 - val_loss: 0.1522 - val_accuracy: 0.9533\n",
      "Epoch 36/50\n",
      "6960/6960 [==============================] - 11s 2ms/sample - loss: 0.3327 - accuracy: 0.8750 - val_loss: 0.1195 - val_accuracy: 0.9713\n",
      "Epoch 37/50\n",
      "6960/6960 [==============================] - 12s 2ms/sample - loss: 0.3263 - accuracy: 0.8767 - val_loss: 0.1325 - val_accuracy: 0.9660\n",
      "Epoch 38/50\n",
      "6960/6960 [==============================] - 13s 2ms/sample - loss: 0.3343 - accuracy: 0.8739 - val_loss: 0.1171 - val_accuracy: 0.9693\n",
      "Epoch 39/50\n",
      "6960/6960 [==============================] - 13s 2ms/sample - loss: 0.3228 - accuracy: 0.8780 - val_loss: 0.1090 - val_accuracy: 0.9733\n",
      "Epoch 40/50\n",
      "6960/6960 [==============================] - 11s 2ms/sample - loss: 0.3159 - accuracy: 0.8774 - val_loss: 0.0981 - val_accuracy: 0.9733\n",
      "Epoch 41/50\n",
      "6960/6960 [==============================] - 13s 2ms/sample - loss: 0.2961 - accuracy: 0.8874 - val_loss: 0.0904 - val_accuracy: 0.9767\n",
      "Epoch 42/50\n",
      "6960/6960 [==============================] - 11s 2ms/sample - loss: 0.2817 - accuracy: 0.8957 - val_loss: 0.1014 - val_accuracy: 0.9713\n",
      "Epoch 43/50\n",
      "6960/6960 [==============================] - 12s 2ms/sample - loss: 0.2862 - accuracy: 0.8925 - val_loss: 0.0867 - val_accuracy: 0.9767\n",
      "Epoch 44/50\n",
      "6960/6960 [==============================] - 13s 2ms/sample - loss: 0.2859 - accuracy: 0.8930 - val_loss: 0.1218 - val_accuracy: 0.9653\n",
      "Epoch 45/50\n",
      "6960/6960 [==============================] - 11s 2ms/sample - loss: 0.2830 - accuracy: 0.8971 - val_loss: 0.0801 - val_accuracy: 0.9767\n",
      "Epoch 46/50\n",
      "6960/6960 [==============================] - 12s 2ms/sample - loss: 0.2712 - accuracy: 0.8973 - val_loss: 0.0715 - val_accuracy: 0.9827\n",
      "Epoch 47/50\n",
      "6960/6960 [==============================] - 12s 2ms/sample - loss: 0.2677 - accuracy: 0.9006 - val_loss: 0.0871 - val_accuracy: 0.9780\n",
      "Epoch 48/50\n",
      "6960/6960 [==============================] - 11s 2ms/sample - loss: 0.2587 - accuracy: 0.9037 - val_loss: 0.0545 - val_accuracy: 0.9887\n",
      "Epoch 49/50\n",
      "6960/6960 [==============================] - 12s 2ms/sample - loss: 0.2543 - accuracy: 0.9089 - val_loss: 0.0623 - val_accuracy: 0.9880\n",
      "Epoch 50/50\n",
      "6960/6960 [==============================] - 13s 2ms/sample - loss: 0.2514 - accuracy: 0.9108 - val_loss: 0.0558 - val_accuracy: 0.9867\n",
      "6960/6960 [==============================] - 5s 776us/sample - loss: 0.0153 - accuracy: 0.9993\n",
      "1772/1772 [==============================] - 1s 544us/sample - loss: 0.9426 - accuracy: 0.7269\n",
      "train accuracy: 99.928%\n",
      "test accuracy: 72.686%\n",
      "=================175===================\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_24 (Conv2D)           (None, 175, 1, 100)       22100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 59, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 59, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 59, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 59, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 20, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 20, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 20, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 20, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 7, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 7, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 7, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 7, 1, 100)         100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 3, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 3, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 3, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 4)                 1204      \n",
      "=================================================================\n",
      "Total params: 325,204\n",
      "Trainable params: 324,404\n",
      "Non-trainable params: 800\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6960 samples, validate on 1500 samples\n",
      "Epoch 1/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 2.0000 - accuracy: 0.3112 - val_loss: 3.2603 - val_accuracy: 0.3287\n",
      "Epoch 2/50\n",
      "6960/6960 [==============================] - 13s 2ms/sample - loss: 1.5793 - accuracy: 0.3572 - val_loss: 2.2218 - val_accuracy: 0.3620\n",
      "Epoch 3/50\n",
      "6960/6960 [==============================] - 14s 2ms/sample - loss: 1.3679 - accuracy: 0.4167 - val_loss: 1.3398 - val_accuracy: 0.4847\n",
      "Epoch 4/50\n",
      "6960/6960 [==============================] - 14s 2ms/sample - loss: 1.2303 - accuracy: 0.4807 - val_loss: 1.0763 - val_accuracy: 0.5720\n",
      "Epoch 5/50\n",
      "6960/6960 [==============================] - 15s 2ms/sample - loss: 1.1204 - accuracy: 0.5266 - val_loss: 0.9298 - val_accuracy: 0.6167\n",
      "Epoch 6/50\n",
      "6960/6960 [==============================] - 13s 2ms/sample - loss: 1.0625 - accuracy: 0.5580 - val_loss: 0.8894 - val_accuracy: 0.6347\n",
      "Epoch 7/50\n",
      "6960/6960 [==============================] - 14s 2ms/sample - loss: 1.0005 - accuracy: 0.5806 - val_loss: 0.9292 - val_accuracy: 0.6187\n",
      "Epoch 8/50\n",
      "6960/6960 [==============================] - 10s 1ms/sample - loss: 0.9653 - accuracy: 0.6052 - val_loss: 0.8389 - val_accuracy: 0.6673\n",
      "Epoch 9/50\n",
      "6960/6960 [==============================] - 12s 2ms/sample - loss: 0.9091 - accuracy: 0.6283 - val_loss: 0.7993 - val_accuracy: 0.6840\n",
      "Epoch 10/50\n",
      "6960/6960 [==============================] - 12s 2ms/sample - loss: 0.8903 - accuracy: 0.6299 - val_loss: 0.7442 - val_accuracy: 0.7260\n",
      "Epoch 11/50\n",
      "6960/6960 [==============================] - 14s 2ms/sample - loss: 0.8306 - accuracy: 0.6698 - val_loss: 0.6978 - val_accuracy: 0.7307\n",
      "Epoch 12/50\n",
      "6960/6960 [==============================] - 14s 2ms/sample - loss: 0.8065 - accuracy: 0.6767 - val_loss: 0.6604 - val_accuracy: 0.7453\n",
      "Epoch 13/50\n",
      "6960/6960 [==============================] - 14s 2ms/sample - loss: 0.7767 - accuracy: 0.6845 - val_loss: 0.6450 - val_accuracy: 0.7480\n",
      "Epoch 14/50\n",
      "6960/6960 [==============================] - 14s 2ms/sample - loss: 0.7447 - accuracy: 0.7045 - val_loss: 0.6354 - val_accuracy: 0.7520\n",
      "Epoch 15/50\n",
      "6960/6960 [==============================] - 14s 2ms/sample - loss: 0.7082 - accuracy: 0.7180 - val_loss: 0.5569 - val_accuracy: 0.7960\n",
      "Epoch 16/50\n",
      "6960/6960 [==============================] - 14s 2ms/sample - loss: 0.6955 - accuracy: 0.7223 - val_loss: 0.5157 - val_accuracy: 0.8147\n",
      "Epoch 17/50\n",
      "6960/6960 [==============================] - 15s 2ms/sample - loss: 0.6788 - accuracy: 0.7333 - val_loss: 0.5338 - val_accuracy: 0.7827\n",
      "Epoch 18/50\n",
      "6960/6960 [==============================] - 14s 2ms/sample - loss: 0.6338 - accuracy: 0.7490 - val_loss: 0.4484 - val_accuracy: 0.8433\n",
      "Epoch 19/50\n",
      "6960/6960 [==============================] - 13s 2ms/sample - loss: 0.6049 - accuracy: 0.7675 - val_loss: 0.4327 - val_accuracy: 0.8367\n",
      "Epoch 20/50\n",
      "6960/6960 [==============================] - 15s 2ms/sample - loss: 0.5793 - accuracy: 0.7730 - val_loss: 0.3942 - val_accuracy: 0.8540\n",
      "Epoch 21/50\n",
      "6960/6960 [==============================] - 13s 2ms/sample - loss: 0.5553 - accuracy: 0.7866 - val_loss: 0.3732 - val_accuracy: 0.8680\n",
      "Epoch 22/50\n",
      "6960/6960 [==============================] - 13s 2ms/sample - loss: 0.5239 - accuracy: 0.7977 - val_loss: 0.3636 - val_accuracy: 0.8633\n",
      "Epoch 23/50\n",
      "6960/6960 [==============================] - 16s 2ms/sample - loss: 0.5052 - accuracy: 0.7991 - val_loss: 0.3436 - val_accuracy: 0.8760\n",
      "Epoch 24/50\n",
      "6960/6960 [==============================] - 13s 2ms/sample - loss: 0.4926 - accuracy: 0.8083 - val_loss: 0.3069 - val_accuracy: 0.8860\n",
      "Epoch 25/50\n",
      "6960/6960 [==============================] - 14s 2ms/sample - loss: 0.4772 - accuracy: 0.8139 - val_loss: 0.2820 - val_accuracy: 0.9033\n",
      "Epoch 26/50\n",
      "6960/6960 [==============================] - 14s 2ms/sample - loss: 0.4488 - accuracy: 0.8261 - val_loss: 0.2723 - val_accuracy: 0.9073\n",
      "Epoch 27/50\n",
      "6960/6960 [==============================] - 13s 2ms/sample - loss: 0.4311 - accuracy: 0.8381 - val_loss: 0.2387 - val_accuracy: 0.9247\n",
      "Epoch 28/50\n",
      "6960/6960 [==============================] - 14s 2ms/sample - loss: 0.4221 - accuracy: 0.8351 - val_loss: 0.2359 - val_accuracy: 0.9207\n",
      "Epoch 29/50\n",
      "6960/6960 [==============================] - 13s 2ms/sample - loss: 0.3949 - accuracy: 0.8500 - val_loss: 0.2098 - val_accuracy: 0.9380\n",
      "Epoch 30/50\n",
      "6960/6960 [==============================] - 14s 2ms/sample - loss: 0.3829 - accuracy: 0.8556 - val_loss: 0.1684 - val_accuracy: 0.9513\n",
      "Epoch 31/50\n",
      "6960/6960 [==============================] - 14s 2ms/sample - loss: 0.3648 - accuracy: 0.8606 - val_loss: 0.1979 - val_accuracy: 0.9320\n",
      "Epoch 32/50\n",
      "6960/6960 [==============================] - 14s 2ms/sample - loss: 0.3689 - accuracy: 0.8595 - val_loss: 0.1470 - val_accuracy: 0.9647\n",
      "Epoch 33/50\n",
      "6960/6960 [==============================] - 13s 2ms/sample - loss: 0.3408 - accuracy: 0.8664 - val_loss: 0.1733 - val_accuracy: 0.9400\n",
      "Epoch 34/50\n",
      "6960/6960 [==============================] - 14s 2ms/sample - loss: 0.3303 - accuracy: 0.8769 - val_loss: 0.1583 - val_accuracy: 0.9540\n",
      "Epoch 35/50\n",
      "6960/6960 [==============================] - 14s 2ms/sample - loss: 0.3191 - accuracy: 0.8769 - val_loss: 0.1689 - val_accuracy: 0.9460\n",
      "Epoch 36/50\n",
      "6960/6960 [==============================] - 14s 2ms/sample - loss: 0.3214 - accuracy: 0.8816 - val_loss: 0.1239 - val_accuracy: 0.9673\n",
      "Epoch 37/50\n",
      "6960/6960 [==============================] - 13s 2ms/sample - loss: 0.3217 - accuracy: 0.8773 - val_loss: 0.1104 - val_accuracy: 0.9707\n",
      "Epoch 38/50\n",
      "6960/6960 [==============================] - 15s 2ms/sample - loss: 0.2937 - accuracy: 0.8879 - val_loss: 0.0978 - val_accuracy: 0.9753\n",
      "Epoch 39/50\n",
      "6960/6960 [==============================] - 12s 2ms/sample - loss: 0.2973 - accuracy: 0.8852 - val_loss: 0.0963 - val_accuracy: 0.9773\n",
      "Epoch 40/50\n",
      "6960/6960 [==============================] - 14s 2ms/sample - loss: 0.2770 - accuracy: 0.8968 - val_loss: 0.0974 - val_accuracy: 0.9760\n",
      "Epoch 41/50\n",
      "6960/6960 [==============================] - 14s 2ms/sample - loss: 0.2780 - accuracy: 0.8960 - val_loss: 0.0775 - val_accuracy: 0.9800\n",
      "Epoch 42/50\n",
      "6960/6960 [==============================] - 13s 2ms/sample - loss: 0.2534 - accuracy: 0.9063 - val_loss: 0.0783 - val_accuracy: 0.9780\n",
      "Epoch 43/50\n",
      "6960/6960 [==============================] - 14s 2ms/sample - loss: 0.2583 - accuracy: 0.9034 - val_loss: 0.0776 - val_accuracy: 0.9807\n",
      "Epoch 44/50\n",
      "6960/6960 [==============================] - 14s 2ms/sample - loss: 0.2488 - accuracy: 0.9068 - val_loss: 0.0659 - val_accuracy: 0.9860\n",
      "Epoch 45/50\n",
      "6960/6960 [==============================] - 14s 2ms/sample - loss: 0.2553 - accuracy: 0.9045 - val_loss: 0.0790 - val_accuracy: 0.9807\n",
      "Epoch 46/50\n",
      "6960/6960 [==============================] - 13s 2ms/sample - loss: 0.2358 - accuracy: 0.9135 - val_loss: 0.0531 - val_accuracy: 0.9893\n",
      "Epoch 47/50\n",
      "6960/6960 [==============================] - 13s 2ms/sample - loss: 0.2491 - accuracy: 0.9099 - val_loss: 0.0619 - val_accuracy: 0.9860\n",
      "Epoch 48/50\n",
      "6960/6960 [==============================] - 15s 2ms/sample - loss: 0.2290 - accuracy: 0.9103 - val_loss: 0.0597 - val_accuracy: 0.9900\n",
      "Epoch 49/50\n",
      "6960/6960 [==============================] - 13s 2ms/sample - loss: 0.2318 - accuracy: 0.9135 - val_loss: 0.0601 - val_accuracy: 0.9873\n",
      "Epoch 50/50\n",
      "6960/6960 [==============================] - 14s 2ms/sample - loss: 0.2175 - accuracy: 0.9198 - val_loss: 0.0351 - val_accuracy: 0.9947\n",
      "6960/6960 [==============================] - 5s 757us/sample - loss: 0.0109 - accuracy: 0.9997\n",
      "1772/1772 [==============================] - 1s 781us/sample - loss: 1.1346 - accuracy: 0.6789\n",
      "train accuracy: 99.971%\n",
      "test accuracy: 67.889%\n",
      "=================200===================\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_28 (Conv2D)           (None, 200, 1, 100)       22100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 67, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 67, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 67, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 67, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 23, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 23, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 23, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 23, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling (None, 8, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 8, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 8, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 8, 1, 100)         100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling (None, 3, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 3, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 3, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 4)                 1204      \n",
      "=================================================================\n",
      "Total params: 325,204\n",
      "Trainable params: 324,404\n",
      "Non-trainable params: 800\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6960 samples, validate on 1500 samples\n",
      "Epoch 1/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 1.9839 - accuracy: 0.3030 - val_loss: 3.4281 - val_accuracy: 0.3240\n",
      "Epoch 2/50\n",
      "6960/6960 [==============================] - 15s 2ms/sample - loss: 1.6158 - accuracy: 0.3339 - val_loss: 1.9090 - val_accuracy: 0.3907\n",
      "Epoch 3/50\n",
      "6960/6960 [==============================] - 15s 2ms/sample - loss: 1.3876 - accuracy: 0.3981 - val_loss: 1.2049 - val_accuracy: 0.4927\n",
      "Epoch 4/50\n",
      "6960/6960 [==============================] - 15s 2ms/sample - loss: 1.2553 - accuracy: 0.4526 - val_loss: 1.0441 - val_accuracy: 0.5840\n",
      "Epoch 5/50\n",
      "6960/6960 [==============================] - 17s 2ms/sample - loss: 1.1502 - accuracy: 0.5106 - val_loss: 1.0098 - val_accuracy: 0.5947\n",
      "Epoch 6/50\n",
      "6960/6960 [==============================] - 15s 2ms/sample - loss: 1.0792 - accuracy: 0.5486 - val_loss: 0.9299 - val_accuracy: 0.6247\n",
      "Epoch 7/50\n",
      "6960/6960 [==============================] - 14s 2ms/sample - loss: 1.0010 - accuracy: 0.5819 - val_loss: 0.8678 - val_accuracy: 0.6547\n",
      "Epoch 8/50\n",
      "6960/6960 [==============================] - 10s 1ms/sample - loss: 0.9393 - accuracy: 0.6155 - val_loss: 0.8783 - val_accuracy: 0.6393\n",
      "Epoch 9/50\n",
      "6960/6960 [==============================] - 16s 2ms/sample - loss: 0.9028 - accuracy: 0.6303 - val_loss: 0.7779 - val_accuracy: 0.6913\n",
      "Epoch 10/50\n",
      "6960/6960 [==============================] - 15s 2ms/sample - loss: 0.8402 - accuracy: 0.6618 - val_loss: 0.7239 - val_accuracy: 0.7133\n",
      "Epoch 11/50\n",
      "6960/6960 [==============================] - 16s 2ms/sample - loss: 0.8132 - accuracy: 0.6693 - val_loss: 0.6736 - val_accuracy: 0.7407\n",
      "Epoch 12/50\n",
      "6960/6960 [==============================] - 15s 2ms/sample - loss: 0.7761 - accuracy: 0.6853 - val_loss: 0.6400 - val_accuracy: 0.7380\n",
      "Epoch 13/50\n",
      "6960/6960 [==============================] - 16s 2ms/sample - loss: 0.7453 - accuracy: 0.6984 - val_loss: 0.5847 - val_accuracy: 0.7747\n",
      "Epoch 14/50\n",
      "6960/6960 [==============================] - 15s 2ms/sample - loss: 0.7045 - accuracy: 0.7204 - val_loss: 0.5335 - val_accuracy: 0.8053\n",
      "Epoch 15/50\n",
      "6960/6960 [==============================] - 16s 2ms/sample - loss: 0.6811 - accuracy: 0.7351 - val_loss: 0.4943 - val_accuracy: 0.8120\n",
      "Epoch 16/50\n",
      "6960/6960 [==============================] - 15s 2ms/sample - loss: 0.6491 - accuracy: 0.7468 - val_loss: 0.4902 - val_accuracy: 0.8113\n",
      "Epoch 17/50\n",
      "6960/6960 [==============================] - 15s 2ms/sample - loss: 0.6158 - accuracy: 0.7568 - val_loss: 0.4274 - val_accuracy: 0.8453\n",
      "Epoch 18/50\n",
      "6960/6960 [==============================] - 15s 2ms/sample - loss: 0.5788 - accuracy: 0.7769 - val_loss: 0.4140 - val_accuracy: 0.8427\n",
      "Epoch 19/50\n",
      "6960/6960 [==============================] - 16s 2ms/sample - loss: 0.5619 - accuracy: 0.7833 - val_loss: 0.3692 - val_accuracy: 0.8713\n",
      "Epoch 20/50\n",
      "6960/6960 [==============================] - 16s 2ms/sample - loss: 0.5212 - accuracy: 0.7989 - val_loss: 0.3384 - val_accuracy: 0.8860\n",
      "Epoch 21/50\n",
      "6960/6960 [==============================] - 15s 2ms/sample - loss: 0.5087 - accuracy: 0.8066 - val_loss: 0.3582 - val_accuracy: 0.8693\n",
      "Epoch 22/50\n",
      "6960/6960 [==============================] - 15s 2ms/sample - loss: 0.4812 - accuracy: 0.8174 - val_loss: 0.3017 - val_accuracy: 0.8900\n",
      "Epoch 23/50\n",
      "6960/6960 [==============================] - 15s 2ms/sample - loss: 0.4774 - accuracy: 0.8131 - val_loss: 0.2672 - val_accuracy: 0.9053\n",
      "Epoch 24/50\n",
      "6960/6960 [==============================] - 16s 2ms/sample - loss: 0.4484 - accuracy: 0.8313 - val_loss: 0.2507 - val_accuracy: 0.9187\n",
      "Epoch 25/50\n",
      "6960/6960 [==============================] - 15s 2ms/sample - loss: 0.4239 - accuracy: 0.8385 - val_loss: 0.2676 - val_accuracy: 0.9053\n",
      "Epoch 26/50\n",
      "6960/6960 [==============================] - 16s 2ms/sample - loss: 0.4323 - accuracy: 0.8398 - val_loss: 0.2342 - val_accuracy: 0.9207\n",
      "Epoch 27/50\n",
      "6960/6960 [==============================] - 15s 2ms/sample - loss: 0.3877 - accuracy: 0.8559 - val_loss: 0.2234 - val_accuracy: 0.9187\n",
      "Epoch 28/50\n",
      "6960/6960 [==============================] - 15s 2ms/sample - loss: 0.3823 - accuracy: 0.8569 - val_loss: 0.1767 - val_accuracy: 0.9453\n",
      "Epoch 29/50\n",
      "6960/6960 [==============================] - 16s 2ms/sample - loss: 0.3666 - accuracy: 0.8573 - val_loss: 0.1683 - val_accuracy: 0.9447\n",
      "Epoch 30/50\n",
      "6960/6960 [==============================] - 15s 2ms/sample - loss: 0.3514 - accuracy: 0.8648 - val_loss: 0.1519 - val_accuracy: 0.9553\n",
      "Epoch 31/50\n",
      "6960/6960 [==============================] - 16s 2ms/sample - loss: 0.3498 - accuracy: 0.8657 - val_loss: 0.1700 - val_accuracy: 0.9467\n",
      "Epoch 32/50\n",
      "6960/6960 [==============================] - 16s 2ms/sample - loss: 0.3376 - accuracy: 0.8731 - val_loss: 0.1305 - val_accuracy: 0.9600\n",
      "Epoch 33/50\n",
      "6960/6960 [==============================] - 15s 2ms/sample - loss: 0.3275 - accuracy: 0.8757 - val_loss: 0.1429 - val_accuracy: 0.9600\n",
      "Epoch 34/50\n",
      "6960/6960 [==============================] - 16s 2ms/sample - loss: 0.3169 - accuracy: 0.8799 - val_loss: 0.1082 - val_accuracy: 0.9720\n",
      "Epoch 35/50\n",
      "6960/6960 [==============================] - 15s 2ms/sample - loss: 0.2914 - accuracy: 0.8861 - val_loss: 0.1129 - val_accuracy: 0.9693\n",
      "Epoch 36/50\n",
      "6960/6960 [==============================] - 16s 2ms/sample - loss: 0.2954 - accuracy: 0.8858 - val_loss: 0.0922 - val_accuracy: 0.9813\n",
      "Epoch 37/50\n",
      "6960/6960 [==============================] - 15s 2ms/sample - loss: 0.2807 - accuracy: 0.8944 - val_loss: 0.0999 - val_accuracy: 0.9827\n",
      "Epoch 38/50\n",
      "6960/6960 [==============================] - 16s 2ms/sample - loss: 0.2628 - accuracy: 0.8994 - val_loss: 0.1316 - val_accuracy: 0.9573\n",
      "Epoch 39/50\n",
      "6960/6960 [==============================] - 15s 2ms/sample - loss: 0.2702 - accuracy: 0.8990 - val_loss: 0.0690 - val_accuracy: 0.9860\n",
      "Epoch 40/50\n",
      "6960/6960 [==============================] - 15s 2ms/sample - loss: 0.2535 - accuracy: 0.9052 - val_loss: 0.0672 - val_accuracy: 0.9873\n",
      "Epoch 41/50\n",
      "6960/6960 [==============================] - 17s 2ms/sample - loss: 0.2526 - accuracy: 0.9083 - val_loss: 0.0719 - val_accuracy: 0.9840\n",
      "Epoch 42/50\n",
      "6960/6960 [==============================] - 16s 2ms/sample - loss: 0.2394 - accuracy: 0.9105 - val_loss: 0.0536 - val_accuracy: 0.9907\n",
      "Epoch 43/50\n",
      "6960/6960 [==============================] - 16s 2ms/sample - loss: 0.2439 - accuracy: 0.9115 - val_loss: 0.0603 - val_accuracy: 0.9880\n",
      "Epoch 44/50\n",
      "6960/6960 [==============================] - 16s 2ms/sample - loss: 0.2361 - accuracy: 0.9124 - val_loss: 0.0491 - val_accuracy: 0.9920\n",
      "Epoch 45/50\n",
      "6960/6960 [==============================] - 16s 2ms/sample - loss: 0.2197 - accuracy: 0.9205 - val_loss: 0.0602 - val_accuracy: 0.9893\n",
      "Epoch 46/50\n",
      "6960/6960 [==============================] - 15s 2ms/sample - loss: 0.2347 - accuracy: 0.9149 - val_loss: 0.0369 - val_accuracy: 0.9953\n",
      "Epoch 47/50\n",
      "6960/6960 [==============================] - 15s 2ms/sample - loss: 0.2025 - accuracy: 0.9231 - val_loss: 0.0495 - val_accuracy: 0.9900\n",
      "Epoch 48/50\n",
      "6960/6960 [==============================] - 16s 2ms/sample - loss: 0.1911 - accuracy: 0.9282 - val_loss: 0.0499 - val_accuracy: 0.9920\n",
      "Epoch 49/50\n",
      "6960/6960 [==============================] - 16s 2ms/sample - loss: 0.2222 - accuracy: 0.9162 - val_loss: 0.0385 - val_accuracy: 0.9920\n",
      "Epoch 50/50\n",
      "6960/6960 [==============================] - 15s 2ms/sample - loss: 0.2098 - accuracy: 0.9261 - val_loss: 0.0472 - val_accuracy: 0.9893\n",
      "6960/6960 [==============================] - 5s 750us/sample - loss: 0.0110 - accuracy: 0.9994\n",
      "1772/1772 [==============================] - 1s 625us/sample - loss: 1.0720 - accuracy: 0.7065\n",
      "train accuracy: 99.943%\n",
      "test accuracy: 70.655%\n",
      "=================225===================\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_32 (Conv2D)           (None, 225, 1, 100)       22100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_32 (MaxPooling (None, 75, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 75, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 75, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 75, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_33 (MaxPooling (None, 25, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 25, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 25, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 25, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_34 (MaxPooling (None, 9, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 9, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 9, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 9, 1, 100)         100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_35 (MaxPooling (None, 3, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 3, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 3, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 4)                 1204      \n",
      "=================================================================\n",
      "Total params: 325,204\n",
      "Trainable params: 324,404\n",
      "Non-trainable params: 800\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6960 samples, validate on 1500 samples\n",
      "Epoch 1/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 1.9793 - accuracy: 0.3200 - val_loss: 2.7724 - val_accuracy: 0.3407\n",
      "Epoch 2/50\n",
      "6960/6960 [==============================] - 16s 2ms/sample - loss: 1.5708 - accuracy: 0.3547 - val_loss: 2.6122 - val_accuracy: 0.3460\n",
      "Epoch 3/50\n",
      "6960/6960 [==============================] - 17s 2ms/sample - loss: 1.3710 - accuracy: 0.4152 - val_loss: 1.2282 - val_accuracy: 0.5047\n",
      "Epoch 4/50\n",
      "6960/6960 [==============================] - 17s 2ms/sample - loss: 1.2151 - accuracy: 0.4805 - val_loss: 1.0370 - val_accuracy: 0.5787\n",
      "Epoch 5/50\n",
      "6960/6960 [==============================] - 17s 2ms/sample - loss: 1.1295 - accuracy: 0.5220 - val_loss: 1.0960 - val_accuracy: 0.5647\n",
      "Epoch 6/50\n",
      "6960/6960 [==============================] - 16s 2ms/sample - loss: 1.0479 - accuracy: 0.5682 - val_loss: 0.8959 - val_accuracy: 0.6460\n",
      "Epoch 7/50\n",
      "6960/6960 [==============================] - 13s 2ms/sample - loss: 0.9824 - accuracy: 0.5901 - val_loss: 0.8636 - val_accuracy: 0.6453\n",
      "Epoch 8/50\n",
      "6960/6960 [==============================] - 16s 2ms/sample - loss: 0.9428 - accuracy: 0.6167 - val_loss: 0.8038 - val_accuracy: 0.6727\n",
      "Epoch 9/50\n",
      "6960/6960 [==============================] - 16s 2ms/sample - loss: 0.8875 - accuracy: 0.6445 - val_loss: 0.7863 - val_accuracy: 0.6867\n",
      "Epoch 10/50\n",
      "6960/6960 [==============================] - 17s 2ms/sample - loss: 0.8699 - accuracy: 0.6497 - val_loss: 0.7321 - val_accuracy: 0.7240\n",
      "Epoch 11/50\n",
      "6960/6960 [==============================] - 16s 2ms/sample - loss: 0.8158 - accuracy: 0.6705 - val_loss: 0.7288 - val_accuracy: 0.7020\n",
      "Epoch 12/50\n",
      "6960/6960 [==============================] - 16s 2ms/sample - loss: 0.7825 - accuracy: 0.6909 - val_loss: 0.6095 - val_accuracy: 0.7787\n",
      "Epoch 13/50\n",
      "6960/6960 [==============================] - 17s 2ms/sample - loss: 0.7429 - accuracy: 0.7083 - val_loss: 0.5684 - val_accuracy: 0.7947\n",
      "Epoch 14/50\n",
      "6960/6960 [==============================] - 18s 3ms/sample - loss: 0.6918 - accuracy: 0.7246 - val_loss: 0.5175 - val_accuracy: 0.8173\n",
      "Epoch 15/50\n",
      "6960/6960 [==============================] - 17s 2ms/sample - loss: 0.6690 - accuracy: 0.7408 - val_loss: 0.5297 - val_accuracy: 0.7960\n",
      "Epoch 16/50\n",
      "6960/6960 [==============================] - 17s 2ms/sample - loss: 0.6316 - accuracy: 0.7552 - val_loss: 0.4447 - val_accuracy: 0.8407\n",
      "Epoch 17/50\n",
      "6960/6960 [==============================] - 17s 2ms/sample - loss: 0.5982 - accuracy: 0.7684 - val_loss: 0.4425 - val_accuracy: 0.8293\n",
      "Epoch 18/50\n",
      "6960/6960 [==============================] - 18s 3ms/sample - loss: 0.5731 - accuracy: 0.7773 - val_loss: 0.4535 - val_accuracy: 0.8473\n",
      "Epoch 19/50\n",
      "6960/6960 [==============================] - 17s 2ms/sample - loss: 0.5502 - accuracy: 0.7914 - val_loss: 0.3542 - val_accuracy: 0.8847\n",
      "Epoch 20/50\n",
      "6960/6960 [==============================] - 17s 2ms/sample - loss: 0.5487 - accuracy: 0.7881 - val_loss: 0.3670 - val_accuracy: 0.8753\n",
      "Epoch 21/50\n",
      "6960/6960 [==============================] - 17s 2ms/sample - loss: 0.5000 - accuracy: 0.8082 - val_loss: 0.3162 - val_accuracy: 0.8947\n",
      "Epoch 22/50\n",
      "6960/6960 [==============================] - 16s 2ms/sample - loss: 0.4928 - accuracy: 0.8106 - val_loss: 0.3071 - val_accuracy: 0.8993\n",
      "Epoch 23/50\n",
      "6960/6960 [==============================] - 18s 3ms/sample - loss: 0.4599 - accuracy: 0.8226 - val_loss: 0.2769 - val_accuracy: 0.9087\n",
      "Epoch 24/50\n",
      "6960/6960 [==============================] - 17s 2ms/sample - loss: 0.4562 - accuracy: 0.8312 - val_loss: 0.2678 - val_accuracy: 0.9133\n",
      "Epoch 25/50\n",
      "6960/6960 [==============================] - 17s 3ms/sample - loss: 0.4230 - accuracy: 0.8376 - val_loss: 0.2317 - val_accuracy: 0.9280\n",
      "Epoch 26/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.3963 - accuracy: 0.8491 - val_loss: 0.2007 - val_accuracy: 0.9347\n",
      "Epoch 27/50\n",
      "6960/6960 [==============================] - 17s 2ms/sample - loss: 0.3844 - accuracy: 0.8539 - val_loss: 0.2092 - val_accuracy: 0.9340\n",
      "Epoch 28/50\n",
      "6960/6960 [==============================] - 18s 3ms/sample - loss: 0.3874 - accuracy: 0.8582 - val_loss: 0.1607 - val_accuracy: 0.9453\n",
      "Epoch 29/50\n",
      "6960/6960 [==============================] - 17s 3ms/sample - loss: 0.3581 - accuracy: 0.8651 - val_loss: 0.1517 - val_accuracy: 0.9473\n",
      "Epoch 30/50\n",
      "6960/6960 [==============================] - 17s 2ms/sample - loss: 0.3344 - accuracy: 0.8727 - val_loss: 0.1423 - val_accuracy: 0.9580\n",
      "Epoch 31/50\n",
      "6960/6960 [==============================] - 16s 2ms/sample - loss: 0.3321 - accuracy: 0.8774 - val_loss: 0.1168 - val_accuracy: 0.9700\n",
      "Epoch 32/50\n",
      "6960/6960 [==============================] - 17s 2ms/sample - loss: 0.3182 - accuracy: 0.8826 - val_loss: 0.1208 - val_accuracy: 0.9653\n",
      "Epoch 33/50\n",
      "6960/6960 [==============================] - 18s 3ms/sample - loss: 0.3214 - accuracy: 0.8770 - val_loss: 0.1172 - val_accuracy: 0.9653\n",
      "Epoch 34/50\n",
      "6960/6960 [==============================] - 17s 2ms/sample - loss: 0.3249 - accuracy: 0.8763 - val_loss: 0.1309 - val_accuracy: 0.9647\n",
      "Epoch 35/50\n",
      "6960/6960 [==============================] - 17s 2ms/sample - loss: 0.3102 - accuracy: 0.8833 - val_loss: 0.1032 - val_accuracy: 0.9767\n",
      "Epoch 36/50\n",
      "6960/6960 [==============================] - 18s 3ms/sample - loss: 0.2873 - accuracy: 0.8902 - val_loss: 0.0900 - val_accuracy: 0.9773\n",
      "Epoch 37/50\n",
      "6960/6960 [==============================] - 17s 2ms/sample - loss: 0.2754 - accuracy: 0.9024 - val_loss: 0.0832 - val_accuracy: 0.9780\n",
      "Epoch 38/50\n",
      "6960/6960 [==============================] - 16s 2ms/sample - loss: 0.2669 - accuracy: 0.8970 - val_loss: 0.0765 - val_accuracy: 0.9820\n",
      "Epoch 39/50\n",
      "6960/6960 [==============================] - 17s 2ms/sample - loss: 0.2574 - accuracy: 0.9065 - val_loss: 0.0714 - val_accuracy: 0.9827\n",
      "Epoch 40/50\n",
      "6960/6960 [==============================] - 15s 2ms/sample - loss: 0.2567 - accuracy: 0.9049 - val_loss: 0.0637 - val_accuracy: 0.9840\n",
      "Epoch 41/50\n",
      "6960/6960 [==============================] - 16s 2ms/sample - loss: 0.2624 - accuracy: 0.9007 - val_loss: 0.0685 - val_accuracy: 0.9847\n",
      "Epoch 42/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.2294 - accuracy: 0.9139 - val_loss: 0.0666 - val_accuracy: 0.9860\n",
      "Epoch 43/50\n",
      "6960/6960 [==============================] - 17s 2ms/sample - loss: 0.2284 - accuracy: 0.9154 - val_loss: 0.0711 - val_accuracy: 0.9813\n",
      "Epoch 44/50\n",
      "6960/6960 [==============================] - 17s 2ms/sample - loss: 0.2279 - accuracy: 0.9151 - val_loss: 0.0503 - val_accuracy: 0.9860\n",
      "Epoch 45/50\n",
      "6960/6960 [==============================] - 17s 2ms/sample - loss: 0.2220 - accuracy: 0.9167 - val_loss: 0.0466 - val_accuracy: 0.9907\n",
      "Epoch 46/50\n",
      "6960/6960 [==============================] - 17s 2ms/sample - loss: 0.2172 - accuracy: 0.9211 - val_loss: 0.0483 - val_accuracy: 0.9867\n",
      "Epoch 47/50\n",
      "6960/6960 [==============================] - 18s 3ms/sample - loss: 0.2049 - accuracy: 0.9239 - val_loss: 0.0481 - val_accuracy: 0.9900\n",
      "Epoch 48/50\n",
      "6960/6960 [==============================] - 16s 2ms/sample - loss: 0.2035 - accuracy: 0.9217 - val_loss: 0.0355 - val_accuracy: 0.9920\n",
      "Epoch 49/50\n",
      "6960/6960 [==============================] - 16s 2ms/sample - loss: 0.2076 - accuracy: 0.9237 - val_loss: 0.0406 - val_accuracy: 0.9907\n",
      "Epoch 50/50\n",
      "6960/6960 [==============================] - 16s 2ms/sample - loss: 0.2256 - accuracy: 0.9154 - val_loss: 0.0652 - val_accuracy: 0.9807\n",
      "6960/6960 [==============================] - 7s 967us/sample - loss: 0.0191 - accuracy: 0.9977\n",
      "1772/1772 [==============================] - 1s 702us/sample - loss: 1.1088 - accuracy: 0.6919\n",
      "train accuracy: 99.770%\n",
      "test accuracy: 69.187%\n",
      "=================250===================\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_36 (Conv2D)           (None, 250, 1, 100)       22100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_36 (MaxPooling (None, 84, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 84, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 84, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 84, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_37 (MaxPooling (None, 28, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 28, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 28, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 28, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_38 (MaxPooling (None, 10, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 10, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 10, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 10, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_39 (MaxPooling (None, 4, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (None, 4, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 4, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 4)                 1604      \n",
      "=================================================================\n",
      "Total params: 325,604\n",
      "Trainable params: 324,804\n",
      "Non-trainable params: 800\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6960 samples, validate on 1500 samples\n",
      "Epoch 1/50\n",
      "6960/6960 [==============================] - 24s 3ms/sample - loss: 2.0165 - accuracy: 0.3060 - val_loss: 3.4374 - val_accuracy: 0.3740\n",
      "Epoch 2/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 1.5668 - accuracy: 0.3575 - val_loss: 1.8215 - val_accuracy: 0.4120\n",
      "Epoch 3/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 1.3268 - accuracy: 0.4385 - val_loss: 1.1579 - val_accuracy: 0.5513\n",
      "Epoch 4/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 1.1882 - accuracy: 0.4924 - val_loss: 0.9578 - val_accuracy: 0.6247\n",
      "Epoch 5/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 1.0844 - accuracy: 0.5467 - val_loss: 0.9451 - val_accuracy: 0.6200\n",
      "Epoch 6/50\n",
      "6960/6960 [==============================] - 15s 2ms/sample - loss: 1.0228 - accuracy: 0.5730 - val_loss: 0.8801 - val_accuracy: 0.6640\n",
      "Epoch 7/50\n",
      "6960/6960 [==============================] - 16s 2ms/sample - loss: 0.9613 - accuracy: 0.6052 - val_loss: 0.8729 - val_accuracy: 0.6260\n",
      "Epoch 8/50\n",
      "6960/6960 [==============================] - 18s 3ms/sample - loss: 0.9088 - accuracy: 0.6320 - val_loss: 0.8068 - val_accuracy: 0.6833\n",
      "Epoch 9/50\n",
      "6960/6960 [==============================] - 18s 3ms/sample - loss: 0.8505 - accuracy: 0.6566 - val_loss: 0.7477 - val_accuracy: 0.7200\n",
      "Epoch 10/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 0.8127 - accuracy: 0.6726 - val_loss: 0.6734 - val_accuracy: 0.7553\n",
      "Epoch 11/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.7781 - accuracy: 0.6917 - val_loss: 0.6805 - val_accuracy: 0.7373\n",
      "Epoch 12/50\n",
      "6960/6960 [==============================] - 18s 3ms/sample - loss: 0.7453 - accuracy: 0.7036 - val_loss: 0.5838 - val_accuracy: 0.7720\n",
      "Epoch 13/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 0.7119 - accuracy: 0.7249 - val_loss: 0.5697 - val_accuracy: 0.7773\n",
      "Epoch 14/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.6583 - accuracy: 0.7454 - val_loss: 0.5846 - val_accuracy: 0.7747\n",
      "Epoch 15/50\n",
      "6960/6960 [==============================] - 18s 3ms/sample - loss: 0.6414 - accuracy: 0.7526 - val_loss: 0.5098 - val_accuracy: 0.7987\n",
      "Epoch 16/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.5976 - accuracy: 0.7659 - val_loss: 0.4555 - val_accuracy: 0.8327\n",
      "Epoch 17/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.5714 - accuracy: 0.7816 - val_loss: 0.3949 - val_accuracy: 0.8593\n",
      "Epoch 18/50\n",
      "6960/6960 [==============================] - 18s 3ms/sample - loss: 0.5538 - accuracy: 0.7825 - val_loss: 0.3859 - val_accuracy: 0.8527\n",
      "Epoch 19/50\n",
      "6960/6960 [==============================] - 18s 3ms/sample - loss: 0.5379 - accuracy: 0.7951 - val_loss: 0.3665 - val_accuracy: 0.8633\n",
      "Epoch 20/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 0.5029 - accuracy: 0.8062 - val_loss: 0.3200 - val_accuracy: 0.8920\n",
      "Epoch 21/50\n",
      "6960/6960 [==============================] - 18s 3ms/sample - loss: 0.4882 - accuracy: 0.8142 - val_loss: 0.2759 - val_accuracy: 0.9080\n",
      "Epoch 22/50\n",
      "6960/6960 [==============================] - 18s 3ms/sample - loss: 0.4486 - accuracy: 0.8284 - val_loss: 0.2687 - val_accuracy: 0.9073\n",
      "Epoch 23/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.4337 - accuracy: 0.8366 - val_loss: 0.2426 - val_accuracy: 0.9187\n",
      "Epoch 24/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.4194 - accuracy: 0.8438 - val_loss: 0.2087 - val_accuracy: 0.9327\n",
      "Epoch 25/50\n",
      "6960/6960 [==============================] - 17s 3ms/sample - loss: 0.3986 - accuracy: 0.8421 - val_loss: 0.2059 - val_accuracy: 0.9367\n",
      "Epoch 26/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 0.3790 - accuracy: 0.8537 - val_loss: 0.1761 - val_accuracy: 0.9413\n",
      "Epoch 27/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.3623 - accuracy: 0.8632 - val_loss: 0.1686 - val_accuracy: 0.9493\n",
      "Epoch 28/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.3347 - accuracy: 0.8757 - val_loss: 0.1665 - val_accuracy: 0.9440\n",
      "Epoch 29/50\n",
      "6960/6960 [==============================] - 18s 3ms/sample - loss: 0.3281 - accuracy: 0.8728 - val_loss: 0.1304 - val_accuracy: 0.9633\n",
      "Epoch 30/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.3258 - accuracy: 0.8776 - val_loss: 0.1668 - val_accuracy: 0.9480\n",
      "Epoch 31/50\n",
      "6960/6960 [==============================] - 18s 3ms/sample - loss: 0.3192 - accuracy: 0.8796 - val_loss: 0.1051 - val_accuracy: 0.9733\n",
      "Epoch 32/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.2924 - accuracy: 0.8904 - val_loss: 0.1156 - val_accuracy: 0.9680\n",
      "Epoch 33/50\n",
      "6960/6960 [==============================] - 18s 3ms/sample - loss: 0.2921 - accuracy: 0.8907 - val_loss: 0.0836 - val_accuracy: 0.9813\n",
      "Epoch 34/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 0.2770 - accuracy: 0.8950 - val_loss: 0.1001 - val_accuracy: 0.9720\n",
      "Epoch 35/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 0.2707 - accuracy: 0.8978 - val_loss: 0.0886 - val_accuracy: 0.9773\n",
      "Epoch 36/50\n",
      "6960/6960 [==============================] - 18s 3ms/sample - loss: 0.2621 - accuracy: 0.8986 - val_loss: 0.0729 - val_accuracy: 0.9833\n",
      "Epoch 37/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 0.2644 - accuracy: 0.9000 - val_loss: 0.0729 - val_accuracy: 0.9820\n",
      "Epoch 38/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.2430 - accuracy: 0.9132 - val_loss: 0.0808 - val_accuracy: 0.9753\n",
      "Epoch 39/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.2470 - accuracy: 0.9101 - val_loss: 0.0714 - val_accuracy: 0.9833\n",
      "Epoch 40/50\n",
      "6960/6960 [==============================] - 18s 3ms/sample - loss: 0.2376 - accuracy: 0.9124 - val_loss: 0.0694 - val_accuracy: 0.9753\n",
      "Epoch 41/50\n",
      "6960/6960 [==============================] - 17s 2ms/sample - loss: 0.2394 - accuracy: 0.9112 - val_loss: 0.0510 - val_accuracy: 0.9907\n",
      "Epoch 42/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 0.2216 - accuracy: 0.9168 - val_loss: 0.0496 - val_accuracy: 0.9887\n",
      "Epoch 43/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.2222 - accuracy: 0.9207 - val_loss: 0.0413 - val_accuracy: 0.9900\n",
      "Epoch 44/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 0.2059 - accuracy: 0.9221 - val_loss: 0.0427 - val_accuracy: 0.9913\n",
      "Epoch 45/50\n",
      "6960/6960 [==============================] - 17s 2ms/sample - loss: 0.2026 - accuracy: 0.9233 - val_loss: 0.0525 - val_accuracy: 0.9847\n",
      "Epoch 46/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.2241 - accuracy: 0.9171 - val_loss: 0.0455 - val_accuracy: 0.9893\n",
      "Epoch 47/50\n",
      "6960/6960 [==============================] - 18s 3ms/sample - loss: 0.2002 - accuracy: 0.9269 - val_loss: 0.0409 - val_accuracy: 0.9893\n",
      "Epoch 48/50\n",
      "6960/6960 [==============================] - 18s 3ms/sample - loss: 0.1872 - accuracy: 0.9290 - val_loss: 0.0378 - val_accuracy: 0.9913\n",
      "Epoch 49/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 0.1878 - accuracy: 0.9315 - val_loss: 0.0426 - val_accuracy: 0.9867\n",
      "Epoch 50/50\n",
      "6960/6960 [==============================] - 18s 3ms/sample - loss: 0.1796 - accuracy: 0.9368 - val_loss: 0.0325 - val_accuracy: 0.9933\n",
      "6960/6960 [==============================] - 7s 995us/sample - loss: 0.0082 - accuracy: 0.9999\n",
      "1772/1772 [==============================] - 1s 701us/sample - loss: 1.0720 - accuracy: 0.7071\n",
      "train accuracy: 99.986%\n",
      "test accuracy: 70.711%\n"
     ]
    }
   ],
   "source": [
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "for time in range(25, 251, 25):\n",
    "    print(\"=================\" + str(time) + \"===================\")\n",
    "    train_score, test_score = train_data(time_period=time)\n",
    "    train_scores.append(train_score[1])\n",
    "    test_scores.append(test_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38476021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracies: \n",
      "[0.9159483, 0.97945404, 0.99109197, 0.99655175, 0.9994253, 0.9992816, 0.99971265, 0.9994253, 0.99770117, 0.9998563]\n",
      "Test accuracies: \n",
      "[0.40632054, 0.5462754, 0.58690745, 0.6286682, 0.69977427, 0.7268623, 0.6788939, 0.70654625, 0.6918736, 0.7071106]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Train accuracies: \")\n",
    "print(train_scores)\n",
    "print(\"Test accuracies: \")\n",
    "print(test_scores)\n",
    "\n",
    "# plot\n",
    "plt.plot(range(25, 251, 25), train_scores, label='train accuracies')\n",
    "plt.plot(range(25, 251, 25), test_scores, label='test accuracies')\n",
    "plt.legend()\n",
    "plt.title(\"Classification Accuracies over Time Period (CNN)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f68fac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_model(time_period=250):   \n",
    "    \n",
    "    # Building the CNN model using sequential class\n",
    "    hybrid_cnn_lstm_model = Sequential()\n",
    "\n",
    "    # Conv. block 1\n",
    "    hybrid_cnn_lstm_model.add(Conv2D(filters=100, kernel_size=(10,1), padding='same', activation='elu', input_shape=(time_period,1,22)))\n",
    "    hybrid_cnn_lstm_model.add(MaxPooling2D(pool_size=(3,1), padding='same')) # Read the keras documentation\n",
    "    hybrid_cnn_lstm_model.add(BatchNormalization())\n",
    "    hybrid_cnn_lstm_model.add(Dropout(0.5))\n",
    "\n",
    "    # Conv. block 2\n",
    "    hybrid_cnn_lstm_model.add(Conv2D(filters=100, kernel_size=(10,1), padding='same', activation='elu'))\n",
    "    hybrid_cnn_lstm_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "    hybrid_cnn_lstm_model.add(BatchNormalization())\n",
    "    hybrid_cnn_lstm_model.add(Dropout(0.5))\n",
    "\n",
    "    # Conv. block 3\n",
    "    hybrid_cnn_lstm_model.add(Conv2D(filters=100, kernel_size=(10,1), padding='same', activation='elu'))\n",
    "    hybrid_cnn_lstm_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "    hybrid_cnn_lstm_model.add(BatchNormalization())\n",
    "    hybrid_cnn_lstm_model.add(Dropout(0.5))\n",
    "\n",
    "    # Conv. block 4\n",
    "    #hybrid_cnn_lstm_model.add(Conv2D(filters=100, kernel_size=(10,1), padding='same', activation='elu'))\n",
    "    #hybrid_cnn_lstm_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "    #hybrid_cnn_lstm_model.add(BatchNormalization())\n",
    "    #hybrid_cnn_lstm_model.add(Dropout(0.5))\n",
    "\n",
    "    # FC+LSTM layers\n",
    "    hybrid_cnn_lstm_model.add(Flatten()) # Adding a flattening operation to the output of CNN block\n",
    "    hybrid_cnn_lstm_model.add(Dense((100))) # FC layer with 100 units\n",
    "    hybrid_cnn_lstm_model.add(Reshape((100,1))) # Reshape my output of FC layer so that it's compatible\n",
    "    hybrid_cnn_lstm_model.add(LSTM(100, dropout=0.5, recurrent_dropout=0.1, input_shape=(100,1), return_sequences=True))\n",
    "\n",
    "    hybrid_cnn_lstm_model.add(LSTM(70, dropout=0.5, recurrent_dropout=0.1, return_sequences=False))\n",
    "    # Output layer with Softmax activation \n",
    "    hybrid_cnn_lstm_model.add(Dense(4, activation='softmax')) # Output FC layer with softmax activation\n",
    "\n",
    "\n",
    "    hybrid_cnn_lstm_model.compile(loss='categorical_crossentropy', optimizer=hybrid_cnn_lstm_optimizer, metrics=['accuracy'])\n",
    "\n",
    "    # Printing the model summary\n",
    "    hybrid_cnn_lstm_model.summary()\n",
    "    \n",
    "    return hybrid_cnn_lstm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96d05ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "learning_rate = 2e-3\n",
    "epochs = 50\n",
    "hybrid_cnn_lstm_optimizer = optimizers.Adam(lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a18af78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_train_data(time_period=250):\n",
    "    # different period of time\n",
    "    x_train_time = x_train[:,:time_period,:,:]\n",
    "    y_train_time = y_train\n",
    "    x_valid_time = x_valid[:,:time_period,:,:]\n",
    "    y_valid_time = y_valid\n",
    "    x_test_time = x_test[:,:time_period,:,:]\n",
    "    y_test_time = y_test\n",
    "    \n",
    "    \n",
    "    model = hybrid_model(time_period)\n",
    "\n",
    "    # Training and validating the model\n",
    "    cnn_model_results = model.fit(x_train_time,\n",
    "                 y_train_time,\n",
    "                 batch_size=200,\n",
    "                 epochs=epochs,\n",
    "                 validation_data=(x_valid_time, y_valid_time), verbose=True)\n",
    "    \n",
    "    train_score = model.evaluate(x_train_time, y_train_time)\n",
    "    \n",
    "    test_score = model.evaluate(x_test_time, y_test_time)\n",
    "\n",
    "    print('train {:s}: {:.3f}%'.format(model.metrics_names[1], train_score[1]*100))\n",
    "    print('test {:s}: {:.3f}%'.format(model.metrics_names[1], test_score[1]*100))\n",
    "    #print(model.summary())\n",
    "    \n",
    "    return train_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a7603c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================25===================\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_40 (Conv2D)           (None, 25, 1, 100)        22100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_40 (MaxPooling (None, 9, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 9, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 9, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 9, 1, 100)         100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_41 (MaxPooling (None, 3, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_41 (Batc (None, 3, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 3, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 3, 1, 100)         100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_42 (MaxPooling (None, 1, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_42 (Batc (None, 1, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 1, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 100, 1)            0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 100, 100)          40800     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 70)                47880     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 4)                 284       \n",
      "=================================================================\n",
      "Total params: 322,564\n",
      "Trainable params: 321,964\n",
      "Non-trainable params: 600\n",
      "_________________________________________________________________\n",
      "Train on 6960 samples, validate on 1500 samples\n",
      "Epoch 1/50\n",
      "6960/6960 [==============================] - 68s 10ms/sample - loss: 1.3868 - accuracy: 0.2599 - val_loss: 1.3970 - val_accuracy: 0.2707\n",
      "Epoch 2/50\n",
      "6960/6960 [==============================] - 30s 4ms/sample - loss: 1.3686 - accuracy: 0.2940 - val_loss: 1.3358 - val_accuracy: 0.3373\n",
      "Epoch 3/50\n",
      "6960/6960 [==============================] - 35s 5ms/sample - loss: 1.3512 - accuracy: 0.3102 - val_loss: 1.3168 - val_accuracy: 0.3667\n",
      "Epoch 4/50\n",
      "6960/6960 [==============================] - 39s 6ms/sample - loss: 1.3225 - accuracy: 0.3616 - val_loss: 1.3311 - val_accuracy: 0.3807\n",
      "Epoch 5/50\n",
      "6960/6960 [==============================] - 39s 6ms/sample - loss: 1.3012 - accuracy: 0.3690 - val_loss: 1.2746 - val_accuracy: 0.4120\n",
      "Epoch 6/50\n",
      "6960/6960 [==============================] - 39s 6ms/sample - loss: 1.2819 - accuracy: 0.3888 - val_loss: 1.2528 - val_accuracy: 0.4160\n",
      "Epoch 7/50\n",
      "6960/6960 [==============================] - 39s 6ms/sample - loss: 1.2574 - accuracy: 0.4115 - val_loss: 1.2593 - val_accuracy: 0.4360\n",
      "Epoch 8/50\n",
      "6960/6960 [==============================] - 39s 6ms/sample - loss: 1.2436 - accuracy: 0.4270 - val_loss: 1.2248 - val_accuracy: 0.4573\n",
      "Epoch 9/50\n",
      "6960/6960 [==============================] - 39s 6ms/sample - loss: 1.2251 - accuracy: 0.4348 - val_loss: 1.2283 - val_accuracy: 0.4540\n",
      "Epoch 10/50\n",
      "6960/6960 [==============================] - 37s 5ms/sample - loss: 1.2125 - accuracy: 0.4497 - val_loss: 1.2106 - val_accuracy: 0.4533\n",
      "Epoch 11/50\n",
      "6960/6960 [==============================] - 38s 6ms/sample - loss: 1.1999 - accuracy: 0.4596 - val_loss: 1.1677 - val_accuracy: 0.4987\n",
      "Epoch 12/50\n",
      "6960/6960 [==============================] - 38s 5ms/sample - loss: 1.1787 - accuracy: 0.4770 - val_loss: 1.2608 - val_accuracy: 0.4053\n",
      "Epoch 13/50\n",
      "6960/6960 [==============================] - 37s 5ms/sample - loss: 1.2108 - accuracy: 0.4588 - val_loss: 1.1566 - val_accuracy: 0.5080\n",
      "Epoch 14/50\n",
      "6960/6960 [==============================] - 38s 5ms/sample - loss: 1.1668 - accuracy: 0.4861 - val_loss: 1.1235 - val_accuracy: 0.5273\n",
      "Epoch 15/50\n",
      "6960/6960 [==============================] - 38s 5ms/sample - loss: 1.1486 - accuracy: 0.4990 - val_loss: 1.1023 - val_accuracy: 0.5373\n",
      "Epoch 16/50\n",
      "6960/6960 [==============================] - 41s 6ms/sample - loss: 1.1275 - accuracy: 0.5060 - val_loss: 1.0766 - val_accuracy: 0.5580\n",
      "Epoch 17/50\n",
      "6960/6960 [==============================] - 39s 6ms/sample - loss: 1.1087 - accuracy: 0.5197 - val_loss: 1.0574 - val_accuracy: 0.5727\n",
      "Epoch 18/50\n",
      "6960/6960 [==============================] - 40s 6ms/sample - loss: 1.1008 - accuracy: 0.5210 - val_loss: 1.0484 - val_accuracy: 0.5580\n",
      "Epoch 19/50\n",
      "6960/6960 [==============================] - 38s 5ms/sample - loss: 1.0869 - accuracy: 0.5284 - val_loss: 1.0206 - val_accuracy: 0.5860\n",
      "Epoch 20/50\n",
      "6960/6960 [==============================] - 38s 5ms/sample - loss: 1.0678 - accuracy: 0.5414 - val_loss: 0.9987 - val_accuracy: 0.5880\n",
      "Epoch 21/50\n",
      "6960/6960 [==============================] - 38s 5ms/sample - loss: 1.0508 - accuracy: 0.5474 - val_loss: 0.9752 - val_accuracy: 0.6033\n",
      "Epoch 22/50\n",
      "6960/6960 [==============================] - 38s 5ms/sample - loss: 1.0470 - accuracy: 0.5517 - val_loss: 0.9612 - val_accuracy: 0.6247\n",
      "Epoch 23/50\n",
      "6960/6960 [==============================] - 40s 6ms/sample - loss: 1.0260 - accuracy: 0.5638 - val_loss: 0.9933 - val_accuracy: 0.5880\n",
      "Epoch 24/50\n",
      "6960/6960 [==============================] - 39s 6ms/sample - loss: 1.0211 - accuracy: 0.5615 - val_loss: 0.9441 - val_accuracy: 0.6440\n",
      "Epoch 25/50\n",
      "6960/6960 [==============================] - 39s 6ms/sample - loss: 1.0171 - accuracy: 0.5708 - val_loss: 0.9449 - val_accuracy: 0.6073\n",
      "Epoch 26/50\n",
      "6960/6960 [==============================] - 39s 6ms/sample - loss: 0.9931 - accuracy: 0.5861 - val_loss: 0.9503 - val_accuracy: 0.6280\n",
      "Epoch 27/50\n",
      "6960/6960 [==============================] - 37s 5ms/sample - loss: 0.9878 - accuracy: 0.5787 - val_loss: 0.9026 - val_accuracy: 0.6507\n",
      "Epoch 28/50\n",
      "6960/6960 [==============================] - 41s 6ms/sample - loss: 0.9717 - accuracy: 0.5927 - val_loss: 0.8830 - val_accuracy: 0.6753\n",
      "Epoch 29/50\n",
      "6960/6960 [==============================] - 38s 5ms/sample - loss: 0.9564 - accuracy: 0.5977 - val_loss: 0.8863 - val_accuracy: 0.6613\n",
      "Epoch 30/50\n",
      "6960/6960 [==============================] - 39s 6ms/sample - loss: 0.9603 - accuracy: 0.5976 - val_loss: 0.8719 - val_accuracy: 0.6600\n",
      "Epoch 31/50\n",
      "6960/6960 [==============================] - 42s 6ms/sample - loss: 0.9587 - accuracy: 0.6016 - val_loss: 0.8622 - val_accuracy: 0.6773\n",
      "Epoch 32/50\n",
      "6960/6960 [==============================] - 37s 5ms/sample - loss: 0.9377 - accuracy: 0.6070 - val_loss: 0.8730 - val_accuracy: 0.6653\n",
      "Epoch 33/50\n",
      "6960/6960 [==============================] - 39s 6ms/sample - loss: 0.9227 - accuracy: 0.6149 - val_loss: 0.8130 - val_accuracy: 0.6807\n",
      "Epoch 34/50\n",
      "6960/6960 [==============================] - 39s 6ms/sample - loss: 0.9134 - accuracy: 0.6221 - val_loss: 0.8148 - val_accuracy: 0.6953\n",
      "Epoch 35/50\n",
      "6960/6960 [==============================] - 40s 6ms/sample - loss: 0.9105 - accuracy: 0.6204 - val_loss: 0.7994 - val_accuracy: 0.6960\n",
      "Epoch 36/50\n",
      "6960/6960 [==============================] - 38s 6ms/sample - loss: 0.9013 - accuracy: 0.6213 - val_loss: 0.8096 - val_accuracy: 0.7107\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6960/6960 [==============================] - 40s 6ms/sample - loss: 0.8855 - accuracy: 0.6305 - val_loss: 0.8175 - val_accuracy: 0.7080\n",
      "Epoch 38/50\n",
      "6960/6960 [==============================] - 38s 5ms/sample - loss: 0.8873 - accuracy: 0.6293 - val_loss: 0.8032 - val_accuracy: 0.7120\n",
      "Epoch 39/50\n",
      "6960/6960 [==============================] - 40s 6ms/sample - loss: 0.8809 - accuracy: 0.6336 - val_loss: 0.7714 - val_accuracy: 0.7140\n",
      "Epoch 40/50\n",
      "6960/6960 [==============================] - 31s 4ms/sample - loss: 0.8646 - accuracy: 0.6447 - val_loss: 0.7618 - val_accuracy: 0.7327\n",
      "Epoch 41/50\n",
      "6960/6960 [==============================] - 36s 5ms/sample - loss: 0.8581 - accuracy: 0.6529 - val_loss: 0.7289 - val_accuracy: 0.7400\n",
      "Epoch 42/50\n",
      "6960/6960 [==============================] - 36s 5ms/sample - loss: 0.8507 - accuracy: 0.6438 - val_loss: 0.7450 - val_accuracy: 0.7280\n",
      "Epoch 43/50\n",
      "6960/6960 [==============================] - 36s 5ms/sample - loss: 0.8401 - accuracy: 0.6506 - val_loss: 0.7178 - val_accuracy: 0.7527\n",
      "Epoch 44/50\n",
      "6960/6960 [==============================] - 36s 5ms/sample - loss: 0.8279 - accuracy: 0.6591 - val_loss: 0.7328 - val_accuracy: 0.7340\n",
      "Epoch 45/50\n",
      "6960/6960 [==============================] - 36s 5ms/sample - loss: 0.8351 - accuracy: 0.6509 - val_loss: 0.6994 - val_accuracy: 0.7500\n",
      "Epoch 46/50\n",
      "6960/6960 [==============================] - 35s 5ms/sample - loss: 0.8282 - accuracy: 0.6586 - val_loss: 0.6975 - val_accuracy: 0.7507\n",
      "Epoch 47/50\n",
      "6960/6960 [==============================] - 36s 5ms/sample - loss: 0.8150 - accuracy: 0.6642 - val_loss: 0.6814 - val_accuracy: 0.7693\n",
      "Epoch 48/50\n",
      "6960/6960 [==============================] - 34s 5ms/sample - loss: 0.7860 - accuracy: 0.6774 - val_loss: 0.6838 - val_accuracy: 0.7613\n",
      "Epoch 49/50\n",
      "6960/6960 [==============================] - 34s 5ms/sample - loss: 0.8103 - accuracy: 0.6677 - val_loss: 0.6582 - val_accuracy: 0.7787\n",
      "Epoch 50/50\n",
      "6960/6960 [==============================] - 35s 5ms/sample - loss: 0.7892 - accuracy: 0.6649 - val_loss: 0.6715 - val_accuracy: 0.7920\n",
      "6960/6960 [==============================] - 14s 2ms/sample - loss: 0.4503 - accuracy: 0.9095\n",
      "1772/1772 [==============================] - 3s 2ms/sample - loss: 1.4495 - accuracy: 0.4137\n",
      "train accuracy: 90.948%\n",
      "test accuracy: 41.366%\n",
      "=================50===================\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_43 (Conv2D)           (None, 50, 1, 100)        22100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_43 (MaxPooling (None, 17, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_43 (Batc (None, 17, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 17, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 17, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_44 (MaxPooling (None, 6, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_44 (Batc (None, 6, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 6, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 6, 1, 100)         100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_45 (MaxPooling (None, 2, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_45 (Batc (None, 2, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 2, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 100, 1)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100, 100)          40800     \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 70)                47880     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 4)                 284       \n",
      "=================================================================\n",
      "Total params: 332,564\n",
      "Trainable params: 331,964\n",
      "Non-trainable params: 600\n",
      "_________________________________________________________________\n",
      "Train on 6960 samples, validate on 1500 samples\n",
      "Epoch 1/50\n",
      "6960/6960 [==============================] - 54s 8ms/sample - loss: 1.3909 - accuracy: 0.2608 - val_loss: 1.3900 - val_accuracy: 0.2573\n",
      "Epoch 2/50\n",
      "6960/6960 [==============================] - 37s 5ms/sample - loss: 1.3637 - accuracy: 0.3164 - val_loss: 1.4555 - val_accuracy: 0.2600\n",
      "Epoch 3/50\n",
      "6960/6960 [==============================] - 39s 6ms/sample - loss: 1.3353 - accuracy: 0.3552 - val_loss: 1.4345 - val_accuracy: 0.2967\n",
      "Epoch 4/50\n",
      "6960/6960 [==============================] - 40s 6ms/sample - loss: 1.3255 - accuracy: 0.3684 - val_loss: 1.3776 - val_accuracy: 0.3313\n",
      "Epoch 5/50\n",
      "6960/6960 [==============================] - 39s 6ms/sample - loss: 1.2770 - accuracy: 0.4045 - val_loss: 1.2917 - val_accuracy: 0.4180\n",
      "Epoch 6/50\n",
      "6960/6960 [==============================] - 42s 6ms/sample - loss: 1.2592 - accuracy: 0.4172 - val_loss: 1.2224 - val_accuracy: 0.4513\n",
      "Epoch 7/50\n",
      "6960/6960 [==============================] - 38s 6ms/sample - loss: 1.2189 - accuracy: 0.4463 - val_loss: 1.1565 - val_accuracy: 0.4907\n",
      "Epoch 8/50\n",
      "6960/6960 [==============================] - 40s 6ms/sample - loss: 1.1981 - accuracy: 0.4483 - val_loss: 1.1346 - val_accuracy: 0.4860\n",
      "Epoch 9/50\n",
      "6960/6960 [==============================] - 40s 6ms/sample - loss: 1.1755 - accuracy: 0.4611 - val_loss: 1.1126 - val_accuracy: 0.5080\n",
      "Epoch 10/50\n",
      "6960/6960 [==============================] - 40s 6ms/sample - loss: 1.1369 - accuracy: 0.4823 - val_loss: 1.0604 - val_accuracy: 0.5467\n",
      "Epoch 11/50\n",
      "6960/6960 [==============================] - 41s 6ms/sample - loss: 1.1118 - accuracy: 0.5003 - val_loss: 1.0237 - val_accuracy: 0.5880\n",
      "Epoch 12/50\n",
      "6960/6960 [==============================] - 42s 6ms/sample - loss: 1.0848 - accuracy: 0.5158 - val_loss: 1.0062 - val_accuracy: 0.5893\n",
      "Epoch 13/50\n",
      "6960/6960 [==============================] - 40s 6ms/sample - loss: 1.0569 - accuracy: 0.5247 - val_loss: 0.9575 - val_accuracy: 0.6027\n",
      "Epoch 14/50\n",
      "6960/6960 [==============================] - 40s 6ms/sample - loss: 1.0177 - accuracy: 0.5466 - val_loss: 0.9265 - val_accuracy: 0.6173\n",
      "Epoch 15/50\n",
      "6960/6960 [==============================] - 40s 6ms/sample - loss: 1.0121 - accuracy: 0.5523 - val_loss: 0.9366 - val_accuracy: 0.6153\n",
      "Epoch 16/50\n",
      "6960/6960 [==============================] - 38s 5ms/sample - loss: 0.9906 - accuracy: 0.5605 - val_loss: 0.8849 - val_accuracy: 0.6487\n",
      "Epoch 17/50\n",
      "6960/6960 [==============================] - 40s 6ms/sample - loss: 0.9565 - accuracy: 0.5864 - val_loss: 0.8566 - val_accuracy: 0.6600\n",
      "Epoch 18/50\n",
      "6960/6960 [==============================] - 40s 6ms/sample - loss: 0.9504 - accuracy: 0.5892 - val_loss: 0.8538 - val_accuracy: 0.6540\n",
      "Epoch 19/50\n",
      "6960/6960 [==============================] - 40s 6ms/sample - loss: 0.9259 - accuracy: 0.6132 - val_loss: 0.8494 - val_accuracy: 0.6540\n",
      "Epoch 20/50\n",
      "6960/6960 [==============================] - 41s 6ms/sample - loss: 0.9133 - accuracy: 0.6085 - val_loss: 0.8162 - val_accuracy: 0.6953\n",
      "Epoch 21/50\n",
      "6960/6960 [==============================] - 41s 6ms/sample - loss: 0.8785 - accuracy: 0.6256 - val_loss: 0.7735 - val_accuracy: 0.7247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50\n",
      "6960/6960 [==============================] - 40s 6ms/sample - loss: 0.8755 - accuracy: 0.6231 - val_loss: 0.7528 - val_accuracy: 0.7320\n",
      "Epoch 23/50\n",
      "6960/6960 [==============================] - 42s 6ms/sample - loss: 0.8505 - accuracy: 0.6434 - val_loss: 0.7254 - val_accuracy: 0.7320\n",
      "Epoch 24/50\n",
      "6960/6960 [==============================] - 40s 6ms/sample - loss: 0.8229 - accuracy: 0.6539 - val_loss: 0.7249 - val_accuracy: 0.7307\n",
      "Epoch 25/50\n",
      "6960/6960 [==============================] - 41s 6ms/sample - loss: 0.8076 - accuracy: 0.6615 - val_loss: 0.6851 - val_accuracy: 0.7567\n",
      "Epoch 26/50\n",
      "6960/6960 [==============================] - 40s 6ms/sample - loss: 0.8090 - accuracy: 0.6580 - val_loss: 0.6879 - val_accuracy: 0.7480\n",
      "Epoch 27/50\n",
      "6960/6960 [==============================] - 39s 6ms/sample - loss: 0.7826 - accuracy: 0.6701 - val_loss: 0.6247 - val_accuracy: 0.7833\n",
      "Epoch 28/50\n",
      "6960/6960 [==============================] - 40s 6ms/sample - loss: 0.7661 - accuracy: 0.6858 - val_loss: 0.6230 - val_accuracy: 0.7880\n",
      "Epoch 29/50\n",
      "6960/6960 [==============================] - 38s 5ms/sample - loss: 0.7489 - accuracy: 0.6957 - val_loss: 0.6161 - val_accuracy: 0.7833\n",
      "Epoch 30/50\n",
      "6960/6960 [==============================] - 39s 6ms/sample - loss: 0.7258 - accuracy: 0.7026 - val_loss: 0.6091 - val_accuracy: 0.7967\n",
      "Epoch 31/50\n",
      "6960/6960 [==============================] - 41s 6ms/sample - loss: 0.7409 - accuracy: 0.6948 - val_loss: 0.6158 - val_accuracy: 0.7980\n",
      "Epoch 32/50\n",
      "6960/6960 [==============================] - 41s 6ms/sample - loss: 0.7167 - accuracy: 0.7013 - val_loss: 0.6147 - val_accuracy: 0.7887\n",
      "Epoch 33/50\n",
      "6960/6960 [==============================] - 41s 6ms/sample - loss: 0.7150 - accuracy: 0.7014 - val_loss: 0.5571 - val_accuracy: 0.8180\n",
      "Epoch 34/50\n",
      "6960/6960 [==============================] - 40s 6ms/sample - loss: 0.6894 - accuracy: 0.7191 - val_loss: 0.5356 - val_accuracy: 0.8380\n",
      "Epoch 35/50\n",
      "6960/6960 [==============================] - 39s 6ms/sample - loss: 0.6878 - accuracy: 0.7190 - val_loss: 0.5199 - val_accuracy: 0.8340\n",
      "Epoch 36/50\n",
      "6960/6960 [==============================] - 41s 6ms/sample - loss: 0.6709 - accuracy: 0.7296 - val_loss: 0.5000 - val_accuracy: 0.8347\n",
      "Epoch 37/50\n",
      "6960/6960 [==============================] - 41s 6ms/sample - loss: 0.6457 - accuracy: 0.7371 - val_loss: 0.5290 - val_accuracy: 0.8487\n",
      "Epoch 38/50\n",
      "6960/6960 [==============================] - 40s 6ms/sample - loss: 0.6394 - accuracy: 0.7411 - val_loss: 0.4810 - val_accuracy: 0.8547\n",
      "Epoch 39/50\n",
      "6960/6960 [==============================] - 39s 6ms/sample - loss: 0.6452 - accuracy: 0.7309 - val_loss: 0.4725 - val_accuracy: 0.8647\n",
      "Epoch 40/50\n",
      "6960/6960 [==============================] - 40s 6ms/sample - loss: 0.6235 - accuracy: 0.7430 - val_loss: 0.4346 - val_accuracy: 0.8727\n",
      "Epoch 41/50\n",
      "6960/6960 [==============================] - 40s 6ms/sample - loss: 0.6184 - accuracy: 0.7445 - val_loss: 0.4476 - val_accuracy: 0.8747\n",
      "Epoch 42/50\n",
      "6960/6960 [==============================] - 40s 6ms/sample - loss: 0.5989 - accuracy: 0.7606 - val_loss: 0.4312 - val_accuracy: 0.8767\n",
      "Epoch 43/50\n",
      "6960/6960 [==============================] - 35s 5ms/sample - loss: 0.5981 - accuracy: 0.7529 - val_loss: 0.4981 - val_accuracy: 0.8720\n",
      "Epoch 44/50\n",
      "6960/6960 [==============================] - 40s 6ms/sample - loss: 0.5949 - accuracy: 0.7588 - val_loss: 0.4338 - val_accuracy: 0.8780\n",
      "Epoch 45/50\n",
      "6960/6960 [==============================] - 39s 6ms/sample - loss: 0.5841 - accuracy: 0.7614 - val_loss: 0.4725 - val_accuracy: 0.8827\n",
      "Epoch 46/50\n",
      "6960/6960 [==============================] - 40s 6ms/sample - loss: 0.5788 - accuracy: 0.7675 - val_loss: 0.4138 - val_accuracy: 0.9027\n",
      "Epoch 47/50\n",
      "6960/6960 [==============================] - 41s 6ms/sample - loss: 0.5757 - accuracy: 0.7661 - val_loss: 0.4091 - val_accuracy: 0.9000\n",
      "Epoch 48/50\n",
      "6960/6960 [==============================] - 40s 6ms/sample - loss: 0.5602 - accuracy: 0.7750 - val_loss: 0.4195 - val_accuracy: 0.8933\n",
      "Epoch 49/50\n",
      "6960/6960 [==============================] - 41s 6ms/sample - loss: 0.5523 - accuracy: 0.7772 - val_loss: 0.3851 - val_accuracy: 0.9007\n",
      "Epoch 50/50\n",
      "6960/6960 [==============================] - 42s 6ms/sample - loss: 0.5321 - accuracy: 0.7833 - val_loss: 0.3760 - val_accuracy: 0.8920\n",
      "6960/6960 [==============================] - 15s 2ms/sample - loss: 0.2282 - accuracy: 0.9655\n",
      "1772/1772 [==============================] - 4s 2ms/sample - loss: 1.2465 - accuracy: 0.5113\n",
      "train accuracy: 96.552%\n",
      "test accuracy: 51.129%\n",
      "=================75===================\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_46 (Conv2D)           (None, 75, 1, 100)        22100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_46 (MaxPooling (None, 25, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_46 (Batc (None, 25, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_46 (Dropout)         (None, 25, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 25, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_47 (MaxPooling (None, 9, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_47 (Batc (None, 9, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_47 (Dropout)         (None, 9, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_48 (Conv2D)           (None, 9, 1, 100)         100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_48 (MaxPooling (None, 3, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_48 (Batc (None, 3, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_48 (Dropout)         (None, 3, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 100, 1)            0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 100, 100)          40800     \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 70)                47880     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 4)                 284       \n",
      "=================================================================\n",
      "Total params: 342,564\n",
      "Trainable params: 341,964\n",
      "Non-trainable params: 600\n",
      "_________________________________________________________________\n",
      "Train on 6960 samples, validate on 1500 samples\n",
      "Epoch 1/50\n",
      "6960/6960 [==============================] - 65s 9ms/sample - loss: 1.3918 - accuracy: 0.2649 - val_loss: 1.3802 - val_accuracy: 0.3047\n",
      "Epoch 2/50\n",
      "6960/6960 [==============================] - 49s 7ms/sample - loss: 1.3668 - accuracy: 0.3194 - val_loss: 1.3483 - val_accuracy: 0.3240\n",
      "Epoch 3/50\n",
      "6960/6960 [==============================] - 48s 7ms/sample - loss: 1.3336 - accuracy: 0.3553 - val_loss: 1.3256 - val_accuracy: 0.3840\n",
      "Epoch 4/50\n",
      "6960/6960 [==============================] - 48s 7ms/sample - loss: 1.2909 - accuracy: 0.3966 - val_loss: 1.3160 - val_accuracy: 0.3900\n",
      "Epoch 5/50\n",
      "6960/6960 [==============================] - 49s 7ms/sample - loss: 1.2529 - accuracy: 0.4230 - val_loss: 1.2299 - val_accuracy: 0.4427\n",
      "Epoch 6/50\n",
      "6960/6960 [==============================] - 49s 7ms/sample - loss: 1.2168 - accuracy: 0.4425 - val_loss: 1.1915 - val_accuracy: 0.4800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50\n",
      "6960/6960 [==============================] - 49s 7ms/sample - loss: 1.1851 - accuracy: 0.4670 - val_loss: 1.1547 - val_accuracy: 0.5027\n",
      "Epoch 8/50\n",
      "6960/6960 [==============================] - 48s 7ms/sample - loss: 1.1474 - accuracy: 0.4921 - val_loss: 1.1418 - val_accuracy: 0.4900\n",
      "Epoch 9/50\n",
      "6960/6960 [==============================] - 49s 7ms/sample - loss: 1.1130 - accuracy: 0.5057 - val_loss: 1.0443 - val_accuracy: 0.5413\n",
      "Epoch 10/50\n",
      "6960/6960 [==============================] - 49s 7ms/sample - loss: 1.0952 - accuracy: 0.5147 - val_loss: 1.0043 - val_accuracy: 0.5607\n",
      "Epoch 11/50\n",
      "6960/6960 [==============================] - 49s 7ms/sample - loss: 1.0684 - accuracy: 0.5200 - val_loss: 1.0120 - val_accuracy: 0.5647\n",
      "Epoch 12/50\n",
      "6960/6960 [==============================] - 49s 7ms/sample - loss: 1.0376 - accuracy: 0.5467 - val_loss: 0.9457 - val_accuracy: 0.6087\n",
      "Epoch 13/50\n",
      "6960/6960 [==============================] - 48s 7ms/sample - loss: 1.0051 - accuracy: 0.5566 - val_loss: 0.9291 - val_accuracy: 0.6253\n",
      "Epoch 14/50\n",
      "6960/6960 [==============================] - 50s 7ms/sample - loss: 0.9989 - accuracy: 0.5629 - val_loss: 0.9634 - val_accuracy: 0.6033\n",
      "Epoch 15/50\n",
      "6960/6960 [==============================] - 49s 7ms/sample - loss: 0.9705 - accuracy: 0.5750 - val_loss: 0.9080 - val_accuracy: 0.6567\n",
      "Epoch 16/50\n",
      "6960/6960 [==============================] - 47s 7ms/sample - loss: 0.9562 - accuracy: 0.5858 - val_loss: 0.8526 - val_accuracy: 0.6560\n",
      "Epoch 17/50\n",
      "6960/6960 [==============================] - 48s 7ms/sample - loss: 0.9260 - accuracy: 0.6079 - val_loss: 0.8393 - val_accuracy: 0.6807\n",
      "Epoch 18/50\n",
      "6960/6960 [==============================] - 48s 7ms/sample - loss: 0.8880 - accuracy: 0.6221 - val_loss: 0.8075 - val_accuracy: 0.6713\n",
      "Epoch 19/50\n",
      "6960/6960 [==============================] - 48s 7ms/sample - loss: 0.8797 - accuracy: 0.6356 - val_loss: 0.8004 - val_accuracy: 0.7053\n",
      "Epoch 20/50\n",
      "6960/6960 [==============================] - 47s 7ms/sample - loss: 0.8420 - accuracy: 0.6468 - val_loss: 0.7406 - val_accuracy: 0.7293\n",
      "Epoch 21/50\n",
      "6960/6960 [==============================] - 49s 7ms/sample - loss: 0.8192 - accuracy: 0.6530 - val_loss: 0.6929 - val_accuracy: 0.7567\n",
      "Epoch 22/50\n",
      "6960/6960 [==============================] - 49s 7ms/sample - loss: 0.7982 - accuracy: 0.6737 - val_loss: 0.7326 - val_accuracy: 0.7360\n",
      "Epoch 23/50\n",
      "6960/6960 [==============================] - 49s 7ms/sample - loss: 0.7848 - accuracy: 0.6790 - val_loss: 0.6531 - val_accuracy: 0.7907\n",
      "Epoch 24/50\n",
      "6960/6960 [==============================] - 51s 7ms/sample - loss: 0.7669 - accuracy: 0.6875 - val_loss: 0.6556 - val_accuracy: 0.7793\n",
      "Epoch 25/50\n",
      "6960/6960 [==============================] - 49s 7ms/sample - loss: 0.7542 - accuracy: 0.6935 - val_loss: 0.6343 - val_accuracy: 0.7787\n",
      "Epoch 26/50\n",
      "6960/6960 [==============================] - 49s 7ms/sample - loss: 0.7273 - accuracy: 0.7029 - val_loss: 0.5664 - val_accuracy: 0.8120\n",
      "Epoch 27/50\n",
      "6960/6960 [==============================] - 47s 7ms/sample - loss: 0.7053 - accuracy: 0.7172 - val_loss: 0.5647 - val_accuracy: 0.8313\n",
      "Epoch 28/50\n",
      "6960/6960 [==============================] - 49s 7ms/sample - loss: 0.7087 - accuracy: 0.7138 - val_loss: 0.5650 - val_accuracy: 0.8300\n",
      "Epoch 29/50\n",
      "6960/6960 [==============================] - 49s 7ms/sample - loss: 0.6791 - accuracy: 0.7259 - val_loss: 0.5557 - val_accuracy: 0.8387\n",
      "Epoch 30/50\n",
      "6960/6960 [==============================] - 50s 7ms/sample - loss: 0.6754 - accuracy: 0.7297 - val_loss: 0.5306 - val_accuracy: 0.8473\n",
      "Epoch 31/50\n",
      "6960/6960 [==============================] - 50s 7ms/sample - loss: 0.6550 - accuracy: 0.7353 - val_loss: 0.5169 - val_accuracy: 0.8440\n",
      "Epoch 32/50\n",
      "6960/6960 [==============================] - 48s 7ms/sample - loss: 0.6481 - accuracy: 0.7372 - val_loss: 0.5213 - val_accuracy: 0.8600\n",
      "Epoch 33/50\n",
      "6960/6960 [==============================] - 52s 7ms/sample - loss: 0.6289 - accuracy: 0.7466 - val_loss: 0.4541 - val_accuracy: 0.8647\n",
      "Epoch 34/50\n",
      "6960/6960 [==============================] - 48s 7ms/sample - loss: 0.6099 - accuracy: 0.7542 - val_loss: 0.4293 - val_accuracy: 0.8760\n",
      "Epoch 35/50\n",
      "6960/6960 [==============================] - 50s 7ms/sample - loss: 0.5842 - accuracy: 0.7649 - val_loss: 0.4400 - val_accuracy: 0.8760\n",
      "Epoch 36/50\n",
      "6960/6960 [==============================] - 49s 7ms/sample - loss: 0.5991 - accuracy: 0.7583 - val_loss: 0.4602 - val_accuracy: 0.8707\n",
      "Epoch 37/50\n",
      "6960/6960 [==============================] - 45s 6ms/sample - loss: 0.5853 - accuracy: 0.7682 - val_loss: 0.4235 - val_accuracy: 0.8840\n",
      "Epoch 38/50\n",
      "6960/6960 [==============================] - 47s 7ms/sample - loss: 0.5713 - accuracy: 0.7704 - val_loss: 0.4448 - val_accuracy: 0.8753\n",
      "Epoch 39/50\n",
      "6960/6960 [==============================] - 48s 7ms/sample - loss: 0.5508 - accuracy: 0.7820 - val_loss: 0.3921 - val_accuracy: 0.8920\n",
      "Epoch 40/50\n",
      "6960/6960 [==============================] - 49s 7ms/sample - loss: 0.5463 - accuracy: 0.7810 - val_loss: 0.3887 - val_accuracy: 0.9047\n",
      "Epoch 41/50\n",
      "6960/6960 [==============================] - 50s 7ms/sample - loss: 0.5458 - accuracy: 0.7803 - val_loss: 0.3698 - val_accuracy: 0.9107\n",
      "Epoch 42/50\n",
      "6960/6960 [==============================] - 48s 7ms/sample - loss: 0.5364 - accuracy: 0.7901 - val_loss: 0.3683 - val_accuracy: 0.9047\n",
      "Epoch 43/50\n",
      "6960/6960 [==============================] - 50s 7ms/sample - loss: 0.5321 - accuracy: 0.7829 - val_loss: 0.3367 - val_accuracy: 0.9200\n",
      "Epoch 44/50\n",
      "6960/6960 [==============================] - 49s 7ms/sample - loss: 0.5064 - accuracy: 0.7978 - val_loss: 0.3320 - val_accuracy: 0.9133\n",
      "Epoch 45/50\n",
      "6960/6960 [==============================] - 50s 7ms/sample - loss: 0.5119 - accuracy: 0.7966 - val_loss: 0.3596 - val_accuracy: 0.9133\n",
      "Epoch 46/50\n",
      "6960/6960 [==============================] - 47s 7ms/sample - loss: 0.5087 - accuracy: 0.7999 - val_loss: 0.3277 - val_accuracy: 0.9200\n",
      "Epoch 47/50\n",
      "6960/6960 [==============================] - 51s 7ms/sample - loss: 0.4876 - accuracy: 0.8072 - val_loss: 0.3033 - val_accuracy: 0.9187\n",
      "Epoch 48/50\n",
      "6960/6960 [==============================] - 46s 7ms/sample - loss: 0.5068 - accuracy: 0.7981 - val_loss: 0.2862 - val_accuracy: 0.9280\n",
      "Epoch 49/50\n",
      "6960/6960 [==============================] - 52s 7ms/sample - loss: 0.4908 - accuracy: 0.8006 - val_loss: 0.2821 - val_accuracy: 0.9327\n",
      "Epoch 50/50\n",
      "6960/6960 [==============================] - 49s 7ms/sample - loss: 0.4744 - accuracy: 0.8069 - val_loss: 0.2764 - val_accuracy: 0.9353\n",
      "6960/6960 [==============================] - 17s 2ms/sample - loss: 0.1464 - accuracy: 0.9833\n",
      "1772/1772 [==============================] - 4s 2ms/sample - loss: 1.2728 - accuracy: 0.5406\n",
      "train accuracy: 98.333%\n",
      "test accuracy: 54.063%\n",
      "=================100===================\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_49 (Conv2D)           (None, 100, 1, 100)       22100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_49 (MaxPooling (None, 34, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_49 (Batc (None, 34, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 34, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_50 (Conv2D)           (None, 34, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_50 (MaxPooling (None, 12, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_50 (Batc (None, 12, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_50 (Dropout)         (None, 12, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_51 (Conv2D)           (None, 12, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_51 (MaxPooling (None, 4, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_51 (Batc (None, 4, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_51 (Dropout)         (None, 4, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 100)               40100     \n",
      "_________________________________________________________________\n",
      "reshape_3 (Reshape)          (None, 100, 1)            0         \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 100, 100)          40800     \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 70)                47880     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 4)                 284       \n",
      "=================================================================\n",
      "Total params: 352,564\n",
      "Trainable params: 351,964\n",
      "Non-trainable params: 600\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6960 samples, validate on 1500 samples\n",
      "Epoch 1/50\n",
      "6960/6960 [==============================] - 69s 10ms/sample - loss: 1.3913 - accuracy: 0.2845 - val_loss: 1.4118 - val_accuracy: 0.2573\n",
      "Epoch 2/50\n",
      "6960/6960 [==============================] - 51s 7ms/sample - loss: 1.3601 - accuracy: 0.3295 - val_loss: 1.3807 - val_accuracy: 0.2840\n",
      "Epoch 3/50\n",
      "6960/6960 [==============================] - 53s 8ms/sample - loss: 1.3040 - accuracy: 0.3876 - val_loss: 1.2915 - val_accuracy: 0.4093\n",
      "Epoch 4/50\n",
      "6960/6960 [==============================] - 51s 7ms/sample - loss: 1.2464 - accuracy: 0.4237 - val_loss: 1.2799 - val_accuracy: 0.4147\n",
      "Epoch 5/50\n",
      "6960/6960 [==============================] - 51s 7ms/sample - loss: 1.2042 - accuracy: 0.4532 - val_loss: 1.2642 - val_accuracy: 0.4040\n",
      "Epoch 6/50\n",
      "6960/6960 [==============================] - 54s 8ms/sample - loss: 1.1728 - accuracy: 0.4628 - val_loss: 1.1165 - val_accuracy: 0.5040\n",
      "Epoch 7/50\n",
      "6960/6960 [==============================] - 51s 7ms/sample - loss: 1.1326 - accuracy: 0.4911 - val_loss: 1.0703 - val_accuracy: 0.5247\n",
      "Epoch 8/50\n",
      "6960/6960 [==============================] - 52s 7ms/sample - loss: 1.0909 - accuracy: 0.5105 - val_loss: 1.0165 - val_accuracy: 0.5473\n",
      "Epoch 9/50\n",
      "6960/6960 [==============================] - 54s 8ms/sample - loss: 1.0763 - accuracy: 0.5136 - val_loss: 1.0103 - val_accuracy: 0.5827\n",
      "Epoch 10/50\n",
      "6960/6960 [==============================] - 51s 7ms/sample - loss: 1.0456 - accuracy: 0.5322 - val_loss: 0.9837 - val_accuracy: 0.5787\n",
      "Epoch 11/50\n",
      "6960/6960 [==============================] - 51s 7ms/sample - loss: 1.0167 - accuracy: 0.5454 - val_loss: 0.9433 - val_accuracy: 0.6000\n",
      "Epoch 12/50\n",
      "6960/6960 [==============================] - 52s 7ms/sample - loss: 0.9900 - accuracy: 0.5549 - val_loss: 0.8912 - val_accuracy: 0.6153\n",
      "Epoch 13/50\n",
      "6960/6960 [==============================] - 51s 7ms/sample - loss: 0.9755 - accuracy: 0.5678 - val_loss: 0.8925 - val_accuracy: 0.6220\n",
      "Epoch 14/50\n",
      "6960/6960 [==============================] - 54s 8ms/sample - loss: 0.9491 - accuracy: 0.5846 - val_loss: 0.8747 - val_accuracy: 0.6553\n",
      "Epoch 15/50\n",
      "6960/6960 [==============================] - 53s 8ms/sample - loss: 0.9202 - accuracy: 0.5966 - val_loss: 0.8659 - val_accuracy: 0.6520\n",
      "Epoch 16/50\n",
      "6960/6960 [==============================] - 51s 7ms/sample - loss: 0.8954 - accuracy: 0.6032 - val_loss: 0.7767 - val_accuracy: 0.6807\n",
      "Epoch 17/50\n",
      "6960/6960 [==============================] - 51s 7ms/sample - loss: 0.8831 - accuracy: 0.6154 - val_loss: 0.7881 - val_accuracy: 0.6853\n",
      "Epoch 18/50\n",
      "6960/6960 [==============================] - 52s 7ms/sample - loss: 0.8657 - accuracy: 0.6244 - val_loss: 0.7691 - val_accuracy: 0.7060\n",
      "Epoch 19/50\n",
      "6960/6960 [==============================] - 53s 8ms/sample - loss: 0.8431 - accuracy: 0.6303 - val_loss: 0.7319 - val_accuracy: 0.7087\n",
      "Epoch 20/50\n",
      "6960/6960 [==============================] - 50s 7ms/sample - loss: 0.8217 - accuracy: 0.6471 - val_loss: 0.7265 - val_accuracy: 0.7260\n",
      "Epoch 21/50\n",
      "6960/6960 [==============================] - 52s 7ms/sample - loss: 0.8119 - accuracy: 0.6463 - val_loss: 0.7030 - val_accuracy: 0.7480\n",
      "Epoch 22/50\n",
      "6960/6960 [==============================] - 53s 8ms/sample - loss: 0.7784 - accuracy: 0.6700 - val_loss: 0.6917 - val_accuracy: 0.7647\n",
      "Epoch 23/50\n",
      "6960/6960 [==============================] - 53s 8ms/sample - loss: 0.7565 - accuracy: 0.6813 - val_loss: 0.6176 - val_accuracy: 0.7947\n",
      "Epoch 24/50\n",
      "6960/6960 [==============================] - 51s 7ms/sample - loss: 0.7495 - accuracy: 0.6807 - val_loss: 0.6227 - val_accuracy: 0.8040\n",
      "Epoch 25/50\n",
      "6960/6960 [==============================] - 52s 7ms/sample - loss: 0.7247 - accuracy: 0.6940 - val_loss: 0.5604 - val_accuracy: 0.8320\n",
      "Epoch 26/50\n",
      "6960/6960 [==============================] - 52s 7ms/sample - loss: 0.7146 - accuracy: 0.7072 - val_loss: 0.5561 - val_accuracy: 0.8413\n",
      "Epoch 27/50\n",
      "6960/6960 [==============================] - 52s 7ms/sample - loss: 0.6920 - accuracy: 0.7154 - val_loss: 0.5280 - val_accuracy: 0.8467\n",
      "Epoch 28/50\n",
      "6960/6960 [==============================] - 50s 7ms/sample - loss: 0.6767 - accuracy: 0.7207 - val_loss: 0.5031 - val_accuracy: 0.8580\n",
      "Epoch 29/50\n",
      "6960/6960 [==============================] - 51s 7ms/sample - loss: 0.6575 - accuracy: 0.7305 - val_loss: 0.5379 - val_accuracy: 0.8493\n",
      "Epoch 30/50\n",
      "6960/6960 [==============================] - 52s 7ms/sample - loss: 0.6444 - accuracy: 0.7336 - val_loss: 0.4861 - val_accuracy: 0.8600\n",
      "Epoch 31/50\n",
      "6960/6960 [==============================] - 51s 7ms/sample - loss: 0.6509 - accuracy: 0.7374 - val_loss: 0.4740 - val_accuracy: 0.8660\n",
      "Epoch 32/50\n",
      "6960/6960 [==============================] - 51s 7ms/sample - loss: 0.6021 - accuracy: 0.7615 - val_loss: 0.4543 - val_accuracy: 0.8687\n",
      "Epoch 33/50\n",
      "6960/6960 [==============================] - 49s 7ms/sample - loss: 0.6166 - accuracy: 0.7523 - val_loss: 0.4393 - val_accuracy: 0.8833\n",
      "Epoch 34/50\n",
      "6960/6960 [==============================] - 51s 7ms/sample - loss: 0.5874 - accuracy: 0.7557 - val_loss: 0.4485 - val_accuracy: 0.8920\n",
      "Epoch 35/50\n",
      "6960/6960 [==============================] - 49s 7ms/sample - loss: 0.5640 - accuracy: 0.7707 - val_loss: 0.4094 - val_accuracy: 0.8880\n",
      "Epoch 36/50\n",
      "6960/6960 [==============================] - 51s 7ms/sample - loss: 0.5487 - accuracy: 0.7809 - val_loss: 0.3632 - val_accuracy: 0.8973\n",
      "Epoch 37/50\n",
      "6960/6960 [==============================] - 49s 7ms/sample - loss: 0.5489 - accuracy: 0.7753 - val_loss: 0.3897 - val_accuracy: 0.8987\n",
      "Epoch 38/50\n",
      "6960/6960 [==============================] - 51s 7ms/sample - loss: 0.5315 - accuracy: 0.7842 - val_loss: 0.4459 - val_accuracy: 0.9227\n",
      "Epoch 39/50\n",
      "6960/6960 [==============================] - 50s 7ms/sample - loss: 0.5088 - accuracy: 0.7947 - val_loss: 0.3526 - val_accuracy: 0.9167\n",
      "Epoch 40/50\n",
      "6960/6960 [==============================] - 52s 7ms/sample - loss: 0.5215 - accuracy: 0.7925 - val_loss: 0.3441 - val_accuracy: 0.9153\n",
      "Epoch 41/50\n",
      "6960/6960 [==============================] - 49s 7ms/sample - loss: 0.5067 - accuracy: 0.7941 - val_loss: 0.3395 - val_accuracy: 0.9367\n",
      "Epoch 42/50\n",
      "6960/6960 [==============================] - 53s 8ms/sample - loss: 0.4968 - accuracy: 0.8001 - val_loss: 0.3480 - val_accuracy: 0.9353\n",
      "Epoch 43/50\n",
      "6960/6960 [==============================] - 51s 7ms/sample - loss: 0.4986 - accuracy: 0.7978 - val_loss: 0.2877 - val_accuracy: 0.9413\n",
      "Epoch 44/50\n",
      "6960/6960 [==============================] - 51s 7ms/sample - loss: 0.4681 - accuracy: 0.8145 - val_loss: 0.2961 - val_accuracy: 0.9293\n",
      "Epoch 45/50\n",
      "6960/6960 [==============================] - 50s 7ms/sample - loss: 0.4719 - accuracy: 0.8082 - val_loss: 0.2968 - val_accuracy: 0.9393\n",
      "Epoch 46/50\n",
      "6960/6960 [==============================] - 49s 7ms/sample - loss: 0.4666 - accuracy: 0.8079 - val_loss: 0.3182 - val_accuracy: 0.9347\n",
      "Epoch 47/50\n",
      "6960/6960 [==============================] - 50s 7ms/sample - loss: 0.4639 - accuracy: 0.8118 - val_loss: 0.2752 - val_accuracy: 0.9433\n",
      "Epoch 48/50\n",
      "6960/6960 [==============================] - 50s 7ms/sample - loss: 0.4428 - accuracy: 0.8228 - val_loss: 0.2713 - val_accuracy: 0.9427\n",
      "Epoch 49/50\n",
      "6960/6960 [==============================] - 50s 7ms/sample - loss: 0.4506 - accuracy: 0.8136 - val_loss: 0.2887 - val_accuracy: 0.9547\n",
      "Epoch 50/50\n",
      "6960/6960 [==============================] - 51s 7ms/sample - loss: 0.4534 - accuracy: 0.8148 - val_loss: 0.2949 - val_accuracy: 0.9453\n",
      "6960/6960 [==============================] - 17s 2ms/sample - loss: 0.1918 - accuracy: 0.9864\n",
      "1772/1772 [==============================] - 5s 3ms/sample - loss: 1.0757 - accuracy: 0.5965\n",
      "train accuracy: 98.635%\n",
      "test accuracy: 59.650%\n",
      "=================125===================\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_52 (Conv2D)           (None, 125, 1, 100)       22100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_52 (MaxPooling (None, 42, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_52 (Batc (None, 42, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_52 (Dropout)         (None, 42, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_53 (Conv2D)           (None, 42, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_53 (MaxPooling (None, 14, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_53 (Batc (None, 14, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_53 (Dropout)         (None, 14, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_54 (Conv2D)           (None, 14, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_54 (MaxPooling (None, 5, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_54 (Batc (None, 5, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_54 (Dropout)         (None, 5, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 100)               50100     \n",
      "_________________________________________________________________\n",
      "reshape_4 (Reshape)          (None, 100, 1)            0         \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 100, 100)          40800     \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 70)                47880     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 4)                 284       \n",
      "=================================================================\n",
      "Total params: 362,564\n",
      "Trainable params: 361,964\n",
      "Non-trainable params: 600\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6960 samples, validate on 1500 samples\n",
      "Epoch 1/50\n",
      "6960/6960 [==============================] - 66s 9ms/sample - loss: 1.3905 - accuracy: 0.2767 - val_loss: 1.3787 - val_accuracy: 0.2587\n",
      "Epoch 2/50\n",
      "6960/6960 [==============================] - 53s 8ms/sample - loss: 1.3534 - accuracy: 0.3352 - val_loss: 1.3999 - val_accuracy: 0.3073\n",
      "Epoch 3/50\n",
      "6960/6960 [==============================] - 53s 8ms/sample - loss: 1.2836 - accuracy: 0.4036 - val_loss: 1.3072 - val_accuracy: 0.3933\n",
      "Epoch 4/50\n",
      "6960/6960 [==============================] - 54s 8ms/sample - loss: 1.2249 - accuracy: 0.4420 - val_loss: 1.3912 - val_accuracy: 0.4100\n",
      "Epoch 5/50\n",
      "6960/6960 [==============================] - 53s 8ms/sample - loss: 1.1727 - accuracy: 0.4659 - val_loss: 1.2329 - val_accuracy: 0.4447\n",
      "Epoch 6/50\n",
      "6960/6960 [==============================] - 51s 7ms/sample - loss: 1.1411 - accuracy: 0.4878 - val_loss: 1.0928 - val_accuracy: 0.5227\n",
      "Epoch 7/50\n",
      "6960/6960 [==============================] - 53s 8ms/sample - loss: 1.1075 - accuracy: 0.5095 - val_loss: 1.0196 - val_accuracy: 0.5553\n",
      "Epoch 8/50\n",
      "6960/6960 [==============================] - 53s 8ms/sample - loss: 1.0656 - accuracy: 0.5266 - val_loss: 0.9788 - val_accuracy: 0.5787\n",
      "Epoch 9/50\n",
      "6960/6960 [==============================] - 53s 8ms/sample - loss: 1.0165 - accuracy: 0.5526 - val_loss: 0.9337 - val_accuracy: 0.6093\n",
      "Epoch 10/50\n",
      "6960/6960 [==============================] - 53s 8ms/sample - loss: 0.9935 - accuracy: 0.5615 - val_loss: 0.9217 - val_accuracy: 0.6100\n",
      "Epoch 11/50\n",
      "6960/6960 [==============================] - 52s 8ms/sample - loss: 0.9512 - accuracy: 0.5884 - val_loss: 0.8565 - val_accuracy: 0.6387\n",
      "Epoch 12/50\n",
      "6960/6960 [==============================] - 56s 8ms/sample - loss: 0.9362 - accuracy: 0.5944 - val_loss: 0.8344 - val_accuracy: 0.6553\n",
      "Epoch 13/50\n",
      "6960/6960 [==============================] - 59s 9ms/sample - loss: 0.9022 - accuracy: 0.6115 - val_loss: 0.8560 - val_accuracy: 0.6387\n",
      "Epoch 14/50\n",
      "6960/6960 [==============================] - 57s 8ms/sample - loss: 0.8725 - accuracy: 0.6297 - val_loss: 0.7439 - val_accuracy: 0.6907\n",
      "Epoch 15/50\n",
      "6960/6960 [==============================] - 59s 8ms/sample - loss: 0.8662 - accuracy: 0.6302 - val_loss: 0.8095 - val_accuracy: 0.6740\n",
      "Epoch 16/50\n",
      "6960/6960 [==============================] - 58s 8ms/sample - loss: 0.8261 - accuracy: 0.6513 - val_loss: 0.6847 - val_accuracy: 0.7353\n",
      "Epoch 17/50\n",
      "6960/6960 [==============================] - 60s 9ms/sample - loss: 0.8119 - accuracy: 0.6585 - val_loss: 0.7277 - val_accuracy: 0.7240\n",
      "Epoch 18/50\n",
      "6960/6960 [==============================] - 58s 8ms/sample - loss: 0.7974 - accuracy: 0.6705 - val_loss: 0.6525 - val_accuracy: 0.7767\n",
      "Epoch 19/50\n",
      "6960/6960 [==============================] - 61s 9ms/sample - loss: 0.7624 - accuracy: 0.6861 - val_loss: 0.6109 - val_accuracy: 0.7820\n",
      "Epoch 20/50\n",
      "6960/6960 [==============================] - 59s 9ms/sample - loss: 0.7153 - accuracy: 0.7116 - val_loss: 0.6181 - val_accuracy: 0.7833\n",
      "Epoch 21/50\n",
      "6960/6960 [==============================] - 59s 8ms/sample - loss: 0.7121 - accuracy: 0.7115 - val_loss: 0.5592 - val_accuracy: 0.7973\n",
      "Epoch 22/50\n",
      "6960/6960 [==============================] - 60s 9ms/sample - loss: 0.6890 - accuracy: 0.7230 - val_loss: 0.5283 - val_accuracy: 0.8240\n",
      "Epoch 23/50\n",
      "6960/6960 [==============================] - 58s 8ms/sample - loss: 0.6648 - accuracy: 0.7338 - val_loss: 0.4965 - val_accuracy: 0.8393\n",
      "Epoch 24/50\n",
      "6960/6960 [==============================] - 59s 8ms/sample - loss: 0.6372 - accuracy: 0.7457 - val_loss: 0.5079 - val_accuracy: 0.8193\n",
      "Epoch 25/50\n",
      "6960/6960 [==============================] - 59s 9ms/sample - loss: 0.6209 - accuracy: 0.7493 - val_loss: 0.4316 - val_accuracy: 0.8727\n",
      "Epoch 26/50\n",
      "6960/6960 [==============================] - 60s 9ms/sample - loss: 0.5895 - accuracy: 0.7705 - val_loss: 0.3967 - val_accuracy: 0.8860\n",
      "Epoch 27/50\n",
      "6960/6960 [==============================] - 60s 9ms/sample - loss: 0.5962 - accuracy: 0.7611 - val_loss: 0.4300 - val_accuracy: 0.8713\n",
      "Epoch 28/50\n",
      "6960/6960 [==============================] - 58s 8ms/sample - loss: 0.5761 - accuracy: 0.7684 - val_loss: 0.4036 - val_accuracy: 0.8733\n",
      "Epoch 29/50\n",
      "6960/6960 [==============================] - 58s 8ms/sample - loss: 0.5449 - accuracy: 0.7800 - val_loss: 0.3144 - val_accuracy: 0.9073\n",
      "Epoch 30/50\n",
      "6960/6960 [==============================] - 57s 8ms/sample - loss: 0.5390 - accuracy: 0.7849 - val_loss: 0.3242 - val_accuracy: 0.8980\n",
      "Epoch 31/50\n",
      "6960/6960 [==============================] - 56s 8ms/sample - loss: 0.5312 - accuracy: 0.7845 - val_loss: 0.3194 - val_accuracy: 0.9053\n",
      "Epoch 32/50\n",
      "6960/6960 [==============================] - 60s 9ms/sample - loss: 0.5099 - accuracy: 0.7917 - val_loss: 0.3133 - val_accuracy: 0.9140\n",
      "Epoch 33/50\n",
      "6960/6960 [==============================] - 58s 8ms/sample - loss: 0.4971 - accuracy: 0.8029 - val_loss: 0.2828 - val_accuracy: 0.9347\n",
      "Epoch 34/50\n",
      "6960/6960 [==============================] - 60s 9ms/sample - loss: 0.4860 - accuracy: 0.8046 - val_loss: 0.3321 - val_accuracy: 0.9007\n",
      "Epoch 35/50\n",
      "6960/6960 [==============================] - 61s 9ms/sample - loss: 0.4812 - accuracy: 0.8046 - val_loss: 0.2621 - val_accuracy: 0.9287\n",
      "Epoch 36/50\n",
      "6960/6960 [==============================] - 61s 9ms/sample - loss: 0.4614 - accuracy: 0.8210 - val_loss: 0.2732 - val_accuracy: 0.9333\n",
      "Epoch 37/50\n",
      "6960/6960 [==============================] - 60s 9ms/sample - loss: 0.4422 - accuracy: 0.8249 - val_loss: 0.2496 - val_accuracy: 0.9273\n",
      "Epoch 38/50\n",
      "6960/6960 [==============================] - 58s 8ms/sample - loss: 0.4599 - accuracy: 0.8119 - val_loss: 0.2639 - val_accuracy: 0.9260\n",
      "Epoch 39/50\n",
      "6960/6960 [==============================] - 61s 9ms/sample - loss: 0.4311 - accuracy: 0.8322 - val_loss: 0.2166 - val_accuracy: 0.9507\n",
      "Epoch 40/50\n",
      "6960/6960 [==============================] - 59s 8ms/sample - loss: 0.4240 - accuracy: 0.8307 - val_loss: 0.1969 - val_accuracy: 0.9553\n",
      "Epoch 41/50\n",
      "6960/6960 [==============================] - 59s 8ms/sample - loss: 0.4284 - accuracy: 0.8296 - val_loss: 0.2400 - val_accuracy: 0.9427\n",
      "Epoch 42/50\n",
      "6960/6960 [==============================] - 60s 9ms/sample - loss: 0.4171 - accuracy: 0.8295 - val_loss: 0.1839 - val_accuracy: 0.9640\n",
      "Epoch 43/50\n",
      "6960/6960 [==============================] - 60s 9ms/sample - loss: 0.3982 - accuracy: 0.8428 - val_loss: 0.1684 - val_accuracy: 0.9607\n",
      "Epoch 44/50\n",
      "6960/6960 [==============================] - 60s 9ms/sample - loss: 0.3901 - accuracy: 0.8411 - val_loss: 0.2207 - val_accuracy: 0.9507\n",
      "Epoch 45/50\n",
      "6960/6960 [==============================] - 61s 9ms/sample - loss: 0.3894 - accuracy: 0.8443 - val_loss: 0.1729 - val_accuracy: 0.9633\n",
      "Epoch 46/50\n",
      "6960/6960 [==============================] - 61s 9ms/sample - loss: 0.3711 - accuracy: 0.8536 - val_loss: 0.1423 - val_accuracy: 0.9713\n",
      "Epoch 47/50\n",
      "6960/6960 [==============================] - 58s 8ms/sample - loss: 0.3969 - accuracy: 0.8391 - val_loss: 0.1566 - val_accuracy: 0.9680\n",
      "Epoch 48/50\n",
      "6960/6960 [==============================] - 59s 8ms/sample - loss: 0.3826 - accuracy: 0.8466 - val_loss: 0.1592 - val_accuracy: 0.9667\n",
      "Epoch 49/50\n",
      "6960/6960 [==============================] - 60s 9ms/sample - loss: 0.3727 - accuracy: 0.8519 - val_loss: 0.1365 - val_accuracy: 0.9733\n",
      "Epoch 50/50\n",
      "6960/6960 [==============================] - 60s 9ms/sample - loss: 0.3537 - accuracy: 0.8573 - val_loss: 0.1519 - val_accuracy: 0.9640\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 0.0706 - accuracy: 0.9924\n",
      "1772/1772 [==============================] - 5s 3ms/sample - loss: 1.1357 - accuracy: 0.62980s - loss: 1.1366 - \n",
      "train accuracy: 99.239%\n",
      "test accuracy: 62.980%\n",
      "=================150===================\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_55 (Conv2D)           (None, 150, 1, 100)       22100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_55 (MaxPooling (None, 50, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_55 (Batc (None, 50, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_55 (Dropout)         (None, 50, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_56 (Conv2D)           (None, 50, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_56 (MaxPooling (None, 17, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_56 (Batc (None, 17, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_56 (Dropout)         (None, 17, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_57 (Conv2D)           (None, 17, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_57 (MaxPooling (None, 6, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_57 (Batc (None, 6, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_57 (Dropout)         (None, 6, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 100)               60100     \n",
      "_________________________________________________________________\n",
      "reshape_5 (Reshape)          (None, 100, 1)            0         \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 100, 100)          40800     \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 70)                47880     \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 4)                 284       \n",
      "=================================================================\n",
      "Total params: 372,564\n",
      "Trainable params: 371,964\n",
      "Non-trainable params: 600\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6960 samples, validate on 1500 samples\n",
      "Epoch 1/50\n",
      "6960/6960 [==============================] - 75s 11ms/sample - loss: 1.3919 - accuracy: 0.2700 - val_loss: 1.3861 - val_accuracy: 0.2453\n",
      "Epoch 2/50\n",
      "6960/6960 [==============================] - 60s 9ms/sample - loss: 1.3481 - accuracy: 0.3329 - val_loss: 1.3874 - val_accuracy: 0.3267\n",
      "Epoch 3/50\n",
      "6960/6960 [==============================] - 59s 8ms/sample - loss: 1.2956 - accuracy: 0.3977 - val_loss: 1.3425 - val_accuracy: 0.3927\n",
      "Epoch 4/50\n",
      "6960/6960 [==============================] - 60s 9ms/sample - loss: 1.2430 - accuracy: 0.4394 - val_loss: 1.2361 - val_accuracy: 0.4367\n",
      "Epoch 5/50\n",
      "6960/6960 [==============================] - 59s 8ms/sample - loss: 1.1726 - accuracy: 0.4777 - val_loss: 1.1619 - val_accuracy: 0.4873\n",
      "Epoch 6/50\n",
      "6960/6960 [==============================] - 59s 8ms/sample - loss: 1.1199 - accuracy: 0.5065 - val_loss: 1.0278 - val_accuracy: 0.5647\n",
      "Epoch 7/50\n",
      "6960/6960 [==============================] - 58s 8ms/sample - loss: 1.0803 - accuracy: 0.5309 - val_loss: 0.9798 - val_accuracy: 0.5953\n",
      "Epoch 8/50\n",
      "6960/6960 [==============================] - 60s 9ms/sample - loss: 1.0343 - accuracy: 0.5481 - val_loss: 0.9261 - val_accuracy: 0.6113\n",
      "Epoch 9/50\n",
      "6960/6960 [==============================] - 60s 9ms/sample - loss: 1.0057 - accuracy: 0.5644 - val_loss: 0.9735 - val_accuracy: 0.5853\n",
      "Epoch 10/50\n",
      "6960/6960 [==============================] - 58s 8ms/sample - loss: 0.9544 - accuracy: 0.5989 - val_loss: 0.8868 - val_accuracy: 0.6533\n",
      "Epoch 11/50\n",
      "6960/6960 [==============================] - 59s 8ms/sample - loss: 0.9009 - accuracy: 0.6194 - val_loss: 0.7737 - val_accuracy: 0.6973\n",
      "Epoch 12/50\n",
      "6960/6960 [==============================] - 59s 8ms/sample - loss: 0.8798 - accuracy: 0.6305 - val_loss: 0.7748 - val_accuracy: 0.7147\n",
      "Epoch 13/50\n",
      "6960/6960 [==============================] - 59s 8ms/sample - loss: 0.8318 - accuracy: 0.6557 - val_loss: 0.8089 - val_accuracy: 0.6900\n",
      "Epoch 14/50\n",
      "6960/6960 [==============================] - 61s 9ms/sample - loss: 0.8017 - accuracy: 0.6675 - val_loss: 0.7156 - val_accuracy: 0.7273\n",
      "Epoch 15/50\n",
      "6960/6960 [==============================] - 58s 8ms/sample - loss: 0.7555 - accuracy: 0.6974 - val_loss: 0.6638 - val_accuracy: 0.7373\n",
      "Epoch 16/50\n",
      "6960/6960 [==============================] - 58s 8ms/sample - loss: 0.7343 - accuracy: 0.7049 - val_loss: 0.5338 - val_accuracy: 0.8140\n",
      "Epoch 17/50\n",
      "6960/6960 [==============================] - 58s 8ms/sample - loss: 0.7057 - accuracy: 0.7207 - val_loss: 0.5504 - val_accuracy: 0.8133\n",
      "Epoch 18/50\n",
      "6960/6960 [==============================] - 58s 8ms/sample - loss: 0.6638 - accuracy: 0.7362 - val_loss: 0.5293 - val_accuracy: 0.8193\n",
      "Epoch 19/50\n",
      "6960/6960 [==============================] - 60s 9ms/sample - loss: 0.6486 - accuracy: 0.7451 - val_loss: 0.5305 - val_accuracy: 0.8280\n",
      "Epoch 20/50\n",
      "6960/6960 [==============================] - 59s 8ms/sample - loss: 0.6352 - accuracy: 0.7509 - val_loss: 0.4596 - val_accuracy: 0.8560\n",
      "Epoch 21/50\n",
      "6960/6960 [==============================] - 59s 9ms/sample - loss: 0.6066 - accuracy: 0.7603 - val_loss: 0.4236 - val_accuracy: 0.8780\n",
      "Epoch 22/50\n",
      "6960/6960 [==============================] - 61s 9ms/sample - loss: 0.5698 - accuracy: 0.7744 - val_loss: 0.3847 - val_accuracy: 0.8927\n",
      "Epoch 23/50\n",
      "6960/6960 [==============================] - 57s 8ms/sample - loss: 0.5465 - accuracy: 0.7862 - val_loss: 0.3883 - val_accuracy: 0.8873\n",
      "Epoch 24/50\n",
      "6960/6960 [==============================] - 60s 9ms/sample - loss: 0.5493 - accuracy: 0.7812 - val_loss: 0.3763 - val_accuracy: 0.8813\n",
      "Epoch 25/50\n",
      "6960/6960 [==============================] - 60s 9ms/sample - loss: 0.5137 - accuracy: 0.7958 - val_loss: 0.3137 - val_accuracy: 0.9213\n",
      "Epoch 26/50\n",
      "6960/6960 [==============================] - 54s 8ms/sample - loss: 0.5105 - accuracy: 0.7980 - val_loss: 0.3229 - val_accuracy: 0.9107\n",
      "Epoch 27/50\n",
      "6960/6960 [==============================] - 59s 8ms/sample - loss: 0.4913 - accuracy: 0.8043 - val_loss: 0.2880 - val_accuracy: 0.9433\n",
      "Epoch 28/50\n",
      "6960/6960 [==============================] - 57s 8ms/sample - loss: 0.4941 - accuracy: 0.8009 - val_loss: 0.3188 - val_accuracy: 0.9140\n",
      "Epoch 29/50\n",
      "6960/6960 [==============================] - 58s 8ms/sample - loss: 0.4542 - accuracy: 0.8200 - val_loss: 0.2711 - val_accuracy: 0.9373\n",
      "Epoch 30/50\n",
      "6960/6960 [==============================] - 60s 9ms/sample - loss: 0.4552 - accuracy: 0.8158 - val_loss: 0.2332 - val_accuracy: 0.9453\n",
      "Epoch 31/50\n",
      "6960/6960 [==============================] - 58s 8ms/sample - loss: 0.4389 - accuracy: 0.8276 - val_loss: 0.2207 - val_accuracy: 0.9567\n",
      "Epoch 32/50\n",
      "6960/6960 [==============================] - 59s 9ms/sample - loss: 0.4354 - accuracy: 0.8254 - val_loss: 0.2084 - val_accuracy: 0.9560\n",
      "Epoch 33/50\n",
      "6960/6960 [==============================] - 58s 8ms/sample - loss: 0.4306 - accuracy: 0.8306 - val_loss: 0.2096 - val_accuracy: 0.9540\n",
      "Epoch 34/50\n",
      "6960/6960 [==============================] - 59s 8ms/sample - loss: 0.4010 - accuracy: 0.8366 - val_loss: 0.2376 - val_accuracy: 0.9433\n",
      "Epoch 35/50\n",
      "6960/6960 [==============================] - 59s 8ms/sample - loss: 0.4106 - accuracy: 0.8352 - val_loss: 0.2098 - val_accuracy: 0.9573\n",
      "Epoch 36/50\n",
      "6960/6960 [==============================] - 59s 9ms/sample - loss: 0.3946 - accuracy: 0.8399 - val_loss: 0.1670 - val_accuracy: 0.9693\n",
      "Epoch 37/50\n",
      "6960/6960 [==============================] - 60s 9ms/sample - loss: 0.3768 - accuracy: 0.8427 - val_loss: 0.1688 - val_accuracy: 0.9653\n",
      "Epoch 38/50\n",
      "6960/6960 [==============================] - 60s 9ms/sample - loss: 0.3730 - accuracy: 0.8500 - val_loss: 0.1325 - val_accuracy: 0.9713\n",
      "Epoch 39/50\n",
      "6960/6960 [==============================] - 59s 9ms/sample - loss: 0.3636 - accuracy: 0.8546 - val_loss: 0.1754 - val_accuracy: 0.9520\n",
      "Epoch 40/50\n",
      "6960/6960 [==============================] - 59s 9ms/sample - loss: 0.3538 - accuracy: 0.8532 - val_loss: 0.1554 - val_accuracy: 0.9700\n",
      "Epoch 41/50\n",
      "6960/6960 [==============================] - 57s 8ms/sample - loss: 0.3528 - accuracy: 0.8589 - val_loss: 0.1261 - val_accuracy: 0.9767\n",
      "Epoch 42/50\n",
      "6960/6960 [==============================] - 58s 8ms/sample - loss: 0.3377 - accuracy: 0.8572 - val_loss: 0.1257 - val_accuracy: 0.9800\n",
      "Epoch 43/50\n",
      "6960/6960 [==============================] - 59s 8ms/sample - loss: 0.3350 - accuracy: 0.8642 - val_loss: 0.1246 - val_accuracy: 0.9827\n",
      "Epoch 44/50\n",
      "6960/6960 [==============================] - 59s 9ms/sample - loss: 0.3392 - accuracy: 0.8632 - val_loss: 0.1337 - val_accuracy: 0.9813\n",
      "Epoch 45/50\n",
      "6960/6960 [==============================] - 59s 8ms/sample - loss: 0.3244 - accuracy: 0.8697 - val_loss: 0.1134 - val_accuracy: 0.9847\n",
      "Epoch 46/50\n",
      "6960/6960 [==============================] - 59s 8ms/sample - loss: 0.3386 - accuracy: 0.8619 - val_loss: 0.1028 - val_accuracy: 0.9833\n",
      "Epoch 47/50\n",
      "6960/6960 [==============================] - 59s 9ms/sample - loss: 0.3347 - accuracy: 0.8655 - val_loss: 0.1004 - val_accuracy: 0.9853\n",
      "Epoch 48/50\n",
      "6960/6960 [==============================] - 59s 8ms/sample - loss: 0.3049 - accuracy: 0.8770 - val_loss: 0.1095 - val_accuracy: 0.9820\n",
      "Epoch 49/50\n",
      "6960/6960 [==============================] - 60s 9ms/sample - loss: 0.3163 - accuracy: 0.8724 - val_loss: 0.1055 - val_accuracy: 0.9820\n",
      "Epoch 50/50\n",
      "6960/6960 [==============================] - 59s 8ms/sample - loss: 0.3052 - accuracy: 0.8766 - val_loss: 0.0975 - val_accuracy: 0.9867\n",
      "6960/6960 [==============================] - 18s 3ms/sample - loss: 0.0428 - accuracy: 0.9987\n",
      "1772/1772 [==============================] - 5s 3ms/sample - loss: 1.0157 - accuracy: 0.6580\n",
      "train accuracy: 99.871%\n",
      "test accuracy: 65.801%\n",
      "=================175===================\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_58 (Conv2D)           (None, 175, 1, 100)       22100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_58 (MaxPooling (None, 59, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_58 (Batc (None, 59, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_58 (Dropout)         (None, 59, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_59 (Conv2D)           (None, 59, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_59 (MaxPooling (None, 20, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_59 (Batc (None, 20, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_59 (Dropout)         (None, 20, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_60 (Conv2D)           (None, 20, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_60 (MaxPooling (None, 7, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_60 (Batc (None, 7, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_60 (Dropout)         (None, 7, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 700)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 100)               70100     \n",
      "_________________________________________________________________\n",
      "reshape_6 (Reshape)          (None, 100, 1)            0         \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 100, 100)          40800     \n",
      "_________________________________________________________________\n",
      "lstm_13 (LSTM)               (None, 70)                47880     \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 4)                 284       \n",
      "=================================================================\n",
      "Total params: 382,564\n",
      "Trainable params: 381,964\n",
      "Non-trainable params: 600\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6960 samples, validate on 1500 samples\n",
      "Epoch 1/50\n",
      "6960/6960 [==============================] - 78s 11ms/sample - loss: 1.3947 - accuracy: 0.2642 - val_loss: 1.3709 - val_accuracy: 0.3073\n",
      "Epoch 2/50\n",
      "6960/6960 [==============================] - 63s 9ms/sample - loss: 1.3514 - accuracy: 0.3346 - val_loss: 1.3473 - val_accuracy: 0.3480\n",
      "Epoch 3/50\n",
      "6960/6960 [==============================] - 62s 9ms/sample - loss: 1.2928 - accuracy: 0.3858 - val_loss: 1.2930 - val_accuracy: 0.3807\n",
      "Epoch 4/50\n",
      "6960/6960 [==============================] - 63s 9ms/sample - loss: 1.2453 - accuracy: 0.4217 - val_loss: 1.2332 - val_accuracy: 0.4420\n",
      "Epoch 5/50\n",
      "6960/6960 [==============================] - 62s 9ms/sample - loss: 1.1824 - accuracy: 0.4655 - val_loss: 1.1320 - val_accuracy: 0.4987\n",
      "Epoch 6/50\n",
      "6960/6960 [==============================] - 61s 9ms/sample - loss: 1.1246 - accuracy: 0.4922 - val_loss: 1.1195 - val_accuracy: 0.5013\n",
      "Epoch 7/50\n",
      "6960/6960 [==============================] - 61s 9ms/sample - loss: 1.0835 - accuracy: 0.5269 - val_loss: 1.0286 - val_accuracy: 0.5567\n",
      "Epoch 8/50\n",
      "6960/6960 [==============================] - 63s 9ms/sample - loss: 1.0276 - accuracy: 0.5504 - val_loss: 0.9650 - val_accuracy: 0.5760\n",
      "Epoch 9/50\n",
      "6960/6960 [==============================] - 62s 9ms/sample - loss: 0.9995 - accuracy: 0.5680 - val_loss: 0.9634 - val_accuracy: 0.5747\n",
      "Epoch 10/50\n",
      "6960/6960 [==============================] - 63s 9ms/sample - loss: 0.9710 - accuracy: 0.5812 - val_loss: 0.9411 - val_accuracy: 0.6067\n",
      "Epoch 11/50\n",
      "6960/6960 [==============================] - 62s 9ms/sample - loss: 0.9228 - accuracy: 0.6068 - val_loss: 0.9021 - val_accuracy: 0.6267\n",
      "Epoch 12/50\n",
      "6960/6960 [==============================] - 61s 9ms/sample - loss: 0.8840 - accuracy: 0.6243 - val_loss: 0.9045 - val_accuracy: 0.6180\n",
      "Epoch 13/50\n",
      "6960/6960 [==============================] - 64s 9ms/sample - loss: 0.8647 - accuracy: 0.6369 - val_loss: 0.8314 - val_accuracy: 0.6660\n",
      "Epoch 14/50\n",
      "6960/6960 [==============================] - 63s 9ms/sample - loss: 0.8182 - accuracy: 0.6585 - val_loss: 0.7134 - val_accuracy: 0.7280\n",
      "Epoch 15/50\n",
      "6960/6960 [==============================] - 62s 9ms/sample - loss: 0.7746 - accuracy: 0.6876 - val_loss: 0.6359 - val_accuracy: 0.7733\n",
      "Epoch 16/50\n",
      "6960/6960 [==============================] - 63s 9ms/sample - loss: 0.7590 - accuracy: 0.6905 - val_loss: 0.6596 - val_accuracy: 0.7540\n",
      "Epoch 17/50\n",
      "6960/6960 [==============================] - 61s 9ms/sample - loss: 0.7284 - accuracy: 0.7001 - val_loss: 0.5745 - val_accuracy: 0.8053\n",
      "Epoch 18/50\n",
      "6960/6960 [==============================] - 62s 9ms/sample - loss: 0.6844 - accuracy: 0.7194 - val_loss: 0.5223 - val_accuracy: 0.8487\n",
      "Epoch 19/50\n",
      "6960/6960 [==============================] - 62s 9ms/sample - loss: 0.6597 - accuracy: 0.7368 - val_loss: 0.5091 - val_accuracy: 0.8347\n",
      "Epoch 20/50\n",
      "6960/6960 [==============================] - 62s 9ms/sample - loss: 0.6245 - accuracy: 0.7460 - val_loss: 0.4640 - val_accuracy: 0.8553\n",
      "Epoch 21/50\n",
      "6960/6960 [==============================] - 61s 9ms/sample - loss: 0.6124 - accuracy: 0.7513 - val_loss: 0.4440 - val_accuracy: 0.8413\n",
      "Epoch 22/50\n",
      "6960/6960 [==============================] - 62s 9ms/sample - loss: 0.5778 - accuracy: 0.7621 - val_loss: 0.5009 - val_accuracy: 0.8440\n",
      "Epoch 23/50\n",
      "6960/6960 [==============================] - 61s 9ms/sample - loss: 0.5638 - accuracy: 0.7763 - val_loss: 0.3707 - val_accuracy: 0.8820\n",
      "Epoch 24/50\n",
      "6960/6960 [==============================] - 58s 8ms/sample - loss: 0.5418 - accuracy: 0.7818 - val_loss: 0.3995 - val_accuracy: 0.8740\n",
      "Epoch 25/50\n",
      "6960/6960 [==============================] - 66s 9ms/sample - loss: 0.5300 - accuracy: 0.7855 - val_loss: 0.3269 - val_accuracy: 0.9207\n",
      "Epoch 26/50\n",
      "6960/6960 [==============================] - 61s 9ms/sample - loss: 0.4952 - accuracy: 0.8011 - val_loss: 0.2849 - val_accuracy: 0.9327\n",
      "Epoch 27/50\n",
      "6960/6960 [==============================] - 58s 8ms/sample - loss: 0.4731 - accuracy: 0.8083 - val_loss: 0.2682 - val_accuracy: 0.9260\n",
      "Epoch 28/50\n",
      "6960/6960 [==============================] - 58s 8ms/sample - loss: 0.4847 - accuracy: 0.8034 - val_loss: 0.2659 - val_accuracy: 0.9233\n",
      "Epoch 29/50\n",
      "6960/6960 [==============================] - 56s 8ms/sample - loss: 0.4644 - accuracy: 0.8131 - val_loss: 0.2528 - val_accuracy: 0.9320\n",
      "Epoch 30/50\n",
      "6960/6960 [==============================] - 56s 8ms/sample - loss: 0.4482 - accuracy: 0.8208 - val_loss: 0.2421 - val_accuracy: 0.9273\n",
      "Epoch 31/50\n",
      "6960/6960 [==============================] - 56s 8ms/sample - loss: 0.4328 - accuracy: 0.8224 - val_loss: 0.2194 - val_accuracy: 0.9360\n",
      "Epoch 32/50\n",
      "6960/6960 [==============================] - 58s 8ms/sample - loss: 0.4171 - accuracy: 0.8313 - val_loss: 0.1937 - val_accuracy: 0.9607\n",
      "Epoch 33/50\n",
      "6960/6960 [==============================] - 61s 9ms/sample - loss: 0.4090 - accuracy: 0.8305 - val_loss: 0.2071 - val_accuracy: 0.9607\n",
      "Epoch 34/50\n",
      "6960/6960 [==============================] - 66s 9ms/sample - loss: 0.4054 - accuracy: 0.8372 - val_loss: 0.2211 - val_accuracy: 0.9533\n",
      "Epoch 35/50\n",
      "6960/6960 [==============================] - 67s 10ms/sample - loss: 0.3817 - accuracy: 0.8463 - val_loss: 0.1728 - val_accuracy: 0.9567\n",
      "Epoch 36/50\n",
      "6960/6960 [==============================] - 70s 10ms/sample - loss: 0.3781 - accuracy: 0.8487 - val_loss: 0.1735 - val_accuracy: 0.9567\n",
      "Epoch 37/50\n",
      "6960/6960 [==============================] - 74s 11ms/sample - loss: 0.3600 - accuracy: 0.8575 - val_loss: 0.1669 - val_accuracy: 0.9653\n",
      "Epoch 38/50\n",
      "6960/6960 [==============================] - 69s 10ms/sample - loss: 0.3715 - accuracy: 0.8477 - val_loss: 0.1741 - val_accuracy: 0.9640\n",
      "Epoch 39/50\n",
      "6960/6960 [==============================] - 75s 11ms/sample - loss: 0.3645 - accuracy: 0.8534 - val_loss: 0.1474 - val_accuracy: 0.9720\n",
      "Epoch 40/50\n",
      "6960/6960 [==============================] - 71s 10ms/sample - loss: 0.3501 - accuracy: 0.8582 - val_loss: 0.1306 - val_accuracy: 0.9787\n",
      "Epoch 41/50\n",
      "6960/6960 [==============================] - 71s 10ms/sample - loss: 0.3376 - accuracy: 0.8641 - val_loss: 0.1251 - val_accuracy: 0.9767\n",
      "Epoch 42/50\n",
      "6960/6960 [==============================] - 73s 10ms/sample - loss: 0.3463 - accuracy: 0.8585 - val_loss: 0.1473 - val_accuracy: 0.9760\n",
      "Epoch 43/50\n",
      "6960/6960 [==============================] - 73s 10ms/sample - loss: 0.3306 - accuracy: 0.8639 - val_loss: 0.1267 - val_accuracy: 0.9713\n",
      "Epoch 44/50\n",
      "6960/6960 [==============================] - 71s 10ms/sample - loss: 0.3255 - accuracy: 0.8652 - val_loss: 0.1347 - val_accuracy: 0.9740\n",
      "Epoch 45/50\n",
      "6960/6960 [==============================] - 71s 10ms/sample - loss: 0.3195 - accuracy: 0.8681 - val_loss: 0.1199 - val_accuracy: 0.9833\n",
      "Epoch 46/50\n",
      "6960/6960 [==============================] - 73s 10ms/sample - loss: 0.3196 - accuracy: 0.8718 - val_loss: 0.1030 - val_accuracy: 0.9860\n",
      "Epoch 47/50\n",
      "6960/6960 [==============================] - 72s 10ms/sample - loss: 0.3097 - accuracy: 0.8764 - val_loss: 0.1125 - val_accuracy: 0.9847\n",
      "Epoch 48/50\n",
      "6960/6960 [==============================] - 73s 11ms/sample - loss: 0.3064 - accuracy: 0.8774 - val_loss: 0.0987 - val_accuracy: 0.9840\n",
      "Epoch 49/50\n",
      "6960/6960 [==============================] - 73s 10ms/sample - loss: 0.3043 - accuracy: 0.8795 - val_loss: 0.1090 - val_accuracy: 0.9840\n",
      "Epoch 50/50\n",
      "6960/6960 [==============================] - 71s 10ms/sample - loss: 0.3080 - accuracy: 0.8737 - val_loss: 0.0909 - val_accuracy: 0.9853\n",
      "6960/6960 [==============================] - 24s 3ms/sample - loss: 0.0389 - accuracy: 0.9981\n",
      "1772/1772 [==============================] - 5s 3ms/sample - loss: 0.9993 - accuracy: 0.6659\n",
      "train accuracy: 99.813%\n",
      "test accuracy: 66.591%\n",
      "=================200===================\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_61 (Conv2D)           (None, 200, 1, 100)       22100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_61 (MaxPooling (None, 67, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_61 (Batc (None, 67, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_61 (Dropout)         (None, 67, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_62 (Conv2D)           (None, 67, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_62 (MaxPooling (None, 23, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_62 (Batc (None, 23, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_62 (Dropout)         (None, 23, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_63 (Conv2D)           (None, 23, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_63 (MaxPooling (None, 8, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_63 (Batc (None, 8, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_63 (Dropout)         (None, 8, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 100)               80100     \n",
      "_________________________________________________________________\n",
      "reshape_7 (Reshape)          (None, 100, 1)            0         \n",
      "_________________________________________________________________\n",
      "lstm_14 (LSTM)               (None, 100, 100)          40800     \n",
      "_________________________________________________________________\n",
      "lstm_15 (LSTM)               (None, 70)                47880     \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 4)                 284       \n",
      "=================================================================\n",
      "Total params: 392,564\n",
      "Trainable params: 391,964\n",
      "Non-trainable params: 600\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6960 samples, validate on 1500 samples\n",
      "Epoch 1/50\n",
      "6960/6960 [==============================] - 124s 18ms/sample - loss: 1.3758 - accuracy: 0.2973 - val_loss: 1.3658 - val_accuracy: 0.3187\n",
      "Epoch 2/50\n",
      "6960/6960 [==============================] - 77s 11ms/sample - loss: 1.2966 - accuracy: 0.3859 - val_loss: 1.3641 - val_accuracy: 0.3553\n",
      "Epoch 3/50\n",
      "6960/6960 [==============================] - 79s 11ms/sample - loss: 1.2470 - accuracy: 0.4154 - val_loss: 1.3191 - val_accuracy: 0.4180\n",
      "Epoch 4/50\n",
      "6960/6960 [==============================] - 76s 11ms/sample - loss: 1.1865 - accuracy: 0.4540 - val_loss: 1.2006 - val_accuracy: 0.4507\n",
      "Epoch 5/50\n",
      "6960/6960 [==============================] - 79s 11ms/sample - loss: 1.1255 - accuracy: 0.4904 - val_loss: 1.0641 - val_accuracy: 0.5293\n",
      "Epoch 6/50\n",
      "6960/6960 [==============================] - 79s 11ms/sample - loss: 1.0709 - accuracy: 0.5152 - val_loss: 1.0167 - val_accuracy: 0.5633\n",
      "Epoch 7/50\n",
      "6960/6960 [==============================] - 79s 11ms/sample - loss: 1.0368 - accuracy: 0.5394 - val_loss: 0.9473 - val_accuracy: 0.5973\n",
      "Epoch 8/50\n",
      "6960/6960 [==============================] - 80s 11ms/sample - loss: 0.9967 - accuracy: 0.5609 - val_loss: 0.9368 - val_accuracy: 0.6107\n",
      "Epoch 9/50\n",
      "6960/6960 [==============================] - 78s 11ms/sample - loss: 0.9579 - accuracy: 0.5746 - val_loss: 0.8536 - val_accuracy: 0.6407\n",
      "Epoch 10/50\n",
      "6960/6960 [==============================] - 76s 11ms/sample - loss: 0.9242 - accuracy: 0.5928 - val_loss: 0.8754 - val_accuracy: 0.6407\n",
      "Epoch 11/50\n",
      "6960/6960 [==============================] - 79s 11ms/sample - loss: 0.8733 - accuracy: 0.6216 - val_loss: 0.8134 - val_accuracy: 0.6727\n",
      "Epoch 12/50\n",
      "6960/6960 [==============================] - 90s 13ms/sample - loss: 0.8380 - accuracy: 0.6431 - val_loss: 0.7618 - val_accuracy: 0.6940\n",
      "Epoch 13/50\n",
      "6960/6960 [==============================] - 95s 14ms/sample - loss: 0.8300 - accuracy: 0.6391 - val_loss: 0.7437 - val_accuracy: 0.7027\n",
      "Epoch 14/50\n",
      "6960/6960 [==============================] - 104s 15ms/sample - loss: 0.7945 - accuracy: 0.6603 - val_loss: 0.6947 - val_accuracy: 0.7387\n",
      "Epoch 15/50\n",
      "6960/6960 [==============================] - 99s 14ms/sample - loss: 0.7516 - accuracy: 0.6784 - val_loss: 0.6556 - val_accuracy: 0.7520\n",
      "Epoch 16/50\n",
      "6960/6960 [==============================] - 95s 14ms/sample - loss: 0.7240 - accuracy: 0.7011 - val_loss: 0.6901 - val_accuracy: 0.7400\n",
      "Epoch 17/50\n",
      "6960/6960 [==============================] - 97s 14ms/sample - loss: 0.6982 - accuracy: 0.7105 - val_loss: 0.6229 - val_accuracy: 0.7727\n",
      "Epoch 18/50\n",
      "6960/6960 [==============================] - 98s 14ms/sample - loss: 0.6769 - accuracy: 0.7220 - val_loss: 0.5042 - val_accuracy: 0.8227\n",
      "Epoch 19/50\n",
      "6960/6960 [==============================] - 96s 14ms/sample - loss: 0.6523 - accuracy: 0.7394 - val_loss: 0.5306 - val_accuracy: 0.8207\n",
      "Epoch 20/50\n",
      "6960/6960 [==============================] - 94s 14ms/sample - loss: 0.6277 - accuracy: 0.7539 - val_loss: 0.4989 - val_accuracy: 0.8353\n",
      "Epoch 21/50\n",
      "6960/6960 [==============================] - 97s 14ms/sample - loss: 0.6140 - accuracy: 0.7565 - val_loss: 0.4166 - val_accuracy: 0.8640\n",
      "Epoch 22/50\n",
      "6960/6960 [==============================] - 92s 13ms/sample - loss: 0.5817 - accuracy: 0.7658 - val_loss: 0.4109 - val_accuracy: 0.8853\n",
      "Epoch 23/50\n",
      "6960/6960 [==============================] - 87s 12ms/sample - loss: 0.5619 - accuracy: 0.7724 - val_loss: 0.3809 - val_accuracy: 0.8867\n",
      "Epoch 24/50\n",
      "6960/6960 [==============================] - 99s 14ms/sample - loss: 0.5484 - accuracy: 0.7812 - val_loss: 0.3456 - val_accuracy: 0.8980\n",
      "Epoch 25/50\n",
      "6960/6960 [==============================] - 94s 14ms/sample - loss: 0.5137 - accuracy: 0.7907 - val_loss: 0.3289 - val_accuracy: 0.9107\n",
      "Epoch 26/50\n",
      "6960/6960 [==============================] - 96s 14ms/sample - loss: 0.5077 - accuracy: 0.7937 - val_loss: 0.2986 - val_accuracy: 0.9207\n",
      "Epoch 27/50\n",
      "6960/6960 [==============================] - 93s 13ms/sample - loss: 0.4759 - accuracy: 0.8138 - val_loss: 0.3059 - val_accuracy: 0.9233\n",
      "Epoch 28/50\n",
      "6960/6960 [==============================] - 88s 13ms/sample - loss: 0.4728 - accuracy: 0.8149 - val_loss: 0.3044 - val_accuracy: 0.9180\n",
      "Epoch 29/50\n",
      "6960/6960 [==============================] - 85s 12ms/sample - loss: 0.4728 - accuracy: 0.8109 - val_loss: 0.2670 - val_accuracy: 0.9340\n",
      "Epoch 30/50\n",
      "6960/6960 [==============================] - 96s 14ms/sample - loss: 0.4341 - accuracy: 0.8261 - val_loss: 0.2572 - val_accuracy: 0.9387\n",
      "Epoch 31/50\n",
      "6960/6960 [==============================] - 96s 14ms/sample - loss: 0.4313 - accuracy: 0.8253 - val_loss: 0.2352 - val_accuracy: 0.9473\n",
      "Epoch 32/50\n",
      "6960/6960 [==============================] - 87s 13ms/sample - loss: 0.4276 - accuracy: 0.8307 - val_loss: 0.2444 - val_accuracy: 0.9520\n",
      "Epoch 33/50\n",
      "6960/6960 [==============================] - 85s 12ms/sample - loss: 0.4162 - accuracy: 0.8346 - val_loss: 0.2751 - val_accuracy: 0.9287\n",
      "Epoch 34/50\n",
      "6960/6960 [==============================] - 91s 13ms/sample - loss: 0.4020 - accuracy: 0.8397 - val_loss: 0.2344 - val_accuracy: 0.9440\n",
      "Epoch 35/50\n",
      "6960/6960 [==============================] - 91s 13ms/sample - loss: 0.4028 - accuracy: 0.8386 - val_loss: 0.1865 - val_accuracy: 0.9600\n",
      "Epoch 36/50\n",
      "6960/6960 [==============================] - 86s 12ms/sample - loss: 0.3779 - accuracy: 0.8457 - val_loss: 0.1792 - val_accuracy: 0.9593\n",
      "Epoch 37/50\n",
      "6960/6960 [==============================] - 87s 12ms/sample - loss: 0.3732 - accuracy: 0.8532 - val_loss: 0.1666 - val_accuracy: 0.9647\n",
      "Epoch 38/50\n",
      "6960/6960 [==============================] - 87s 13ms/sample - loss: 0.3578 - accuracy: 0.8580 - val_loss: 0.1524 - val_accuracy: 0.9653\n",
      "Epoch 39/50\n",
      "6960/6960 [==============================] - 85s 12ms/sample - loss: 0.3594 - accuracy: 0.8522 - val_loss: 0.1827 - val_accuracy: 0.9660\n",
      "Epoch 40/50\n",
      "6960/6960 [==============================] - 84s 12ms/sample - loss: 0.3588 - accuracy: 0.8513 - val_loss: 0.1489 - val_accuracy: 0.9680\n",
      "Epoch 41/50\n",
      "6960/6960 [==============================] - 85s 12ms/sample - loss: 0.3518 - accuracy: 0.8552 - val_loss: 0.1777 - val_accuracy: 0.9600\n",
      "Epoch 42/50\n",
      "6960/6960 [==============================] - 82s 12ms/sample - loss: 0.3546 - accuracy: 0.8516 - val_loss: 0.1601 - val_accuracy: 0.9680\n",
      "Epoch 43/50\n",
      "6960/6960 [==============================] - 88s 13ms/sample - loss: 0.3298 - accuracy: 0.8657 - val_loss: 0.1725 - val_accuracy: 0.9680\n",
      "Epoch 44/50\n",
      "6960/6960 [==============================] - 88s 13ms/sample - loss: 0.3350 - accuracy: 0.8639 - val_loss: 0.1393 - val_accuracy: 0.9740\n",
      "Epoch 45/50\n",
      "6960/6960 [==============================] - 86s 12ms/sample - loss: 0.3243 - accuracy: 0.8700 - val_loss: 0.1325 - val_accuracy: 0.9720\n",
      "Epoch 46/50\n",
      "6960/6960 [==============================] - 84s 12ms/sample - loss: 0.3037 - accuracy: 0.8772 - val_loss: 0.1215 - val_accuracy: 0.9793\n",
      "Epoch 47/50\n",
      "6960/6960 [==============================] - 83s 12ms/sample - loss: 0.3027 - accuracy: 0.8751 - val_loss: 0.1129 - val_accuracy: 0.9780\n",
      "Epoch 48/50\n",
      "6960/6960 [==============================] - 81s 12ms/sample - loss: 0.3070 - accuracy: 0.8776 - val_loss: 0.1216 - val_accuracy: 0.9720\n",
      "Epoch 49/50\n",
      "6960/6960 [==============================] - 81s 12ms/sample - loss: 0.3208 - accuracy: 0.8668 - val_loss: 0.1075 - val_accuracy: 0.9793\n",
      "Epoch 50/50\n",
      "6960/6960 [==============================] - 80s 12ms/sample - loss: 0.2914 - accuracy: 0.8823 - val_loss: 0.0991 - val_accuracy: 0.9820\n",
      "6960/6960 [==============================] - 26s 4ms/sample - loss: 0.0418 - accuracy: 0.9967\n",
      "1772/1772 [==============================] - 6s 3ms/sample - loss: 1.1007 - accuracy: 0.6479\n",
      "train accuracy: 99.670%\n",
      "test accuracy: 64.786%\n",
      "=================225===================\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_64 (Conv2D)           (None, 225, 1, 100)       22100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_64 (MaxPooling (None, 75, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_64 (Batc (None, 75, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_64 (Dropout)         (None, 75, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_65 (Conv2D)           (None, 75, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_65 (MaxPooling (None, 25, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_65 (Batc (None, 25, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_65 (Dropout)         (None, 25, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_66 (Conv2D)           (None, 25, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_66 (MaxPooling (None, 9, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_66 (Batc (None, 9, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_66 (Dropout)         (None, 9, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_18 (Flatten)         (None, 900)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 100)               90100     \n",
      "_________________________________________________________________\n",
      "reshape_8 (Reshape)          (None, 100, 1)            0         \n",
      "_________________________________________________________________\n",
      "lstm_16 (LSTM)               (None, 100, 100)          40800     \n",
      "_________________________________________________________________\n",
      "lstm_17 (LSTM)               (None, 70)                47880     \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 4)                 284       \n",
      "=================================================================\n",
      "Total params: 402,564\n",
      "Trainable params: 401,964\n",
      "Non-trainable params: 600\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6960 samples, validate on 1500 samples\n",
      "Epoch 1/50\n",
      "6960/6960 [==============================] - 132s 19ms/sample - loss: 1.3833 - accuracy: 0.2861 - val_loss: 1.3927 - val_accuracy: 0.2940\n",
      "Epoch 2/50\n",
      "6960/6960 [==============================] - 86s 12ms/sample - loss: 1.2991 - accuracy: 0.3826 - val_loss: 1.2926 - val_accuracy: 0.3940\n",
      "Epoch 3/50\n",
      "6960/6960 [==============================] - 87s 13ms/sample - loss: 1.2132 - accuracy: 0.4434 - val_loss: 1.1964 - val_accuracy: 0.4740\n",
      "Epoch 4/50\n",
      "6960/6960 [==============================] - 87s 13ms/sample - loss: 1.1561 - accuracy: 0.4761 - val_loss: 1.3808 - val_accuracy: 0.4413\n",
      "Epoch 5/50\n",
      "6960/6960 [==============================] - 86s 12ms/sample - loss: 1.1015 - accuracy: 0.5112 - val_loss: 1.0702 - val_accuracy: 0.5267\n",
      "Epoch 6/50\n",
      "6960/6960 [==============================] - 89s 13ms/sample - loss: 1.0610 - accuracy: 0.5237 - val_loss: 1.0264 - val_accuracy: 0.5547\n",
      "Epoch 7/50\n",
      "6960/6960 [==============================] - 87s 12ms/sample - loss: 1.0290 - accuracy: 0.5418 - val_loss: 0.9515 - val_accuracy: 0.5920\n",
      "Epoch 8/50\n",
      "6960/6960 [==============================] - 88s 13ms/sample - loss: 0.9798 - accuracy: 0.5694 - val_loss: 0.9489 - val_accuracy: 0.5913\n",
      "Epoch 9/50\n",
      "6960/6960 [==============================] - 91s 13ms/sample - loss: 0.9431 - accuracy: 0.5815 - val_loss: 0.8453 - val_accuracy: 0.6340\n",
      "Epoch 10/50\n",
      "6960/6960 [==============================] - 89s 13ms/sample - loss: 0.9107 - accuracy: 0.6066 - val_loss: 0.8084 - val_accuracy: 0.6673\n",
      "Epoch 11/50\n",
      "6960/6960 [==============================] - 86s 12ms/sample - loss: 0.8646 - accuracy: 0.6286 - val_loss: 0.7676 - val_accuracy: 0.6920\n",
      "Epoch 12/50\n",
      "6960/6960 [==============================] - 91s 13ms/sample - loss: 0.8451 - accuracy: 0.6466 - val_loss: 0.7762 - val_accuracy: 0.6740\n",
      "Epoch 13/50\n",
      "6960/6960 [==============================] - 92s 13ms/sample - loss: 0.8149 - accuracy: 0.6540 - val_loss: 0.7140 - val_accuracy: 0.7147\n",
      "Epoch 14/50\n",
      "6960/6960 [==============================] - 87s 12ms/sample - loss: 0.7865 - accuracy: 0.6714 - val_loss: 0.6230 - val_accuracy: 0.7720\n",
      "Epoch 15/50\n",
      "6960/6960 [==============================] - 84s 12ms/sample - loss: 0.7355 - accuracy: 0.6884 - val_loss: 0.6277 - val_accuracy: 0.7707\n",
      "Epoch 16/50\n",
      "6960/6960 [==============================] - 91s 13ms/sample - loss: 0.7086 - accuracy: 0.7141 - val_loss: 0.5909 - val_accuracy: 0.7707\n",
      "Epoch 17/50\n",
      "6960/6960 [==============================] - 87s 13ms/sample - loss: 0.6794 - accuracy: 0.7234 - val_loss: 0.5392 - val_accuracy: 0.8127\n",
      "Epoch 18/50\n",
      "6960/6960 [==============================] - 86s 12ms/sample - loss: 0.6544 - accuracy: 0.7405 - val_loss: 0.5210 - val_accuracy: 0.8180\n",
      "Epoch 19/50\n",
      "6960/6960 [==============================] - 91s 13ms/sample - loss: 0.6248 - accuracy: 0.7522 - val_loss: 0.5002 - val_accuracy: 0.8267\n",
      "Epoch 20/50\n",
      "6960/6960 [==============================] - 85s 12ms/sample - loss: 0.6069 - accuracy: 0.7614 - val_loss: 0.4303 - val_accuracy: 0.8653\n",
      "Epoch 21/50\n",
      "6960/6960 [==============================] - 85s 12ms/sample - loss: 0.5834 - accuracy: 0.7772 - val_loss: 0.4202 - val_accuracy: 0.8613\n",
      "Epoch 22/50\n",
      "6960/6960 [==============================] - 87s 13ms/sample - loss: 0.5473 - accuracy: 0.7874 - val_loss: 0.4028 - val_accuracy: 0.8653\n",
      "Epoch 23/50\n",
      "6960/6960 [==============================] - 89s 13ms/sample - loss: 0.5348 - accuracy: 0.7917 - val_loss: 0.3295 - val_accuracy: 0.9033\n",
      "Epoch 24/50\n",
      "6960/6960 [==============================] - 90s 13ms/sample - loss: 0.5112 - accuracy: 0.7971 - val_loss: 0.3217 - val_accuracy: 0.9113\n",
      "Epoch 25/50\n",
      "6960/6960 [==============================] - 89s 13ms/sample - loss: 0.4852 - accuracy: 0.8050 - val_loss: 0.2971 - val_accuracy: 0.9180\n",
      "Epoch 26/50\n",
      "6960/6960 [==============================] - 87s 13ms/sample - loss: 0.4766 - accuracy: 0.8159 - val_loss: 0.2896 - val_accuracy: 0.9240\n",
      "Epoch 27/50\n",
      "6960/6960 [==============================] - 94s 13ms/sample - loss: 0.4530 - accuracy: 0.8220 - val_loss: 0.2787 - val_accuracy: 0.9140\n",
      "Epoch 28/50\n",
      "6960/6960 [==============================] - 90s 13ms/sample - loss: 0.4431 - accuracy: 0.8292 - val_loss: 0.2563 - val_accuracy: 0.9300\n",
      "Epoch 29/50\n",
      "6960/6960 [==============================] - 87s 12ms/sample - loss: 0.4581 - accuracy: 0.8190 - val_loss: 0.2487 - val_accuracy: 0.9447\n",
      "Epoch 30/50\n",
      "6960/6960 [==============================] - 93s 13ms/sample - loss: 0.4248 - accuracy: 0.8310 - val_loss: 0.2555 - val_accuracy: 0.9400\n",
      "Epoch 31/50\n",
      "6960/6960 [==============================] - 92s 13ms/sample - loss: 0.4229 - accuracy: 0.8348 - val_loss: 0.2458 - val_accuracy: 0.9420\n",
      "Epoch 32/50\n",
      "6960/6960 [==============================] - 86s 12ms/sample - loss: 0.3957 - accuracy: 0.8437 - val_loss: 0.1923 - val_accuracy: 0.9493\n",
      "Epoch 33/50\n",
      "6960/6960 [==============================] - 89s 13ms/sample - loss: 0.3788 - accuracy: 0.8513 - val_loss: 0.1741 - val_accuracy: 0.9560\n",
      "Epoch 34/50\n",
      "6960/6960 [==============================] - 97s 14ms/sample - loss: 0.3662 - accuracy: 0.8562 - val_loss: 0.1741 - val_accuracy: 0.9533\n",
      "Epoch 35/50\n",
      "6960/6960 [==============================] - 94s 13ms/sample - loss: 0.3633 - accuracy: 0.8572 - val_loss: 0.1856 - val_accuracy: 0.9573\n",
      "Epoch 36/50\n",
      "6960/6960 [==============================] - 88s 13ms/sample - loss: 0.3670 - accuracy: 0.8543 - val_loss: 0.1887 - val_accuracy: 0.9520\n",
      "Epoch 37/50\n",
      "6960/6960 [==============================] - 94s 14ms/sample - loss: 0.3546 - accuracy: 0.8555 - val_loss: 0.1710 - val_accuracy: 0.9573\n",
      "Epoch 38/50\n",
      "6960/6960 [==============================] - 98s 14ms/sample - loss: 0.3443 - accuracy: 0.8644 - val_loss: 0.1502 - val_accuracy: 0.9580\n",
      "Epoch 39/50\n",
      "6960/6960 [==============================] - 93s 13ms/sample - loss: 0.3369 - accuracy: 0.8700 - val_loss: 0.1525 - val_accuracy: 0.9653\n",
      "Epoch 40/50\n",
      "6960/6960 [==============================] - 89s 13ms/sample - loss: 0.3230 - accuracy: 0.8728 - val_loss: 0.1805 - val_accuracy: 0.9520\n",
      "Epoch 41/50\n",
      "6960/6960 [==============================] - 93s 13ms/sample - loss: 0.3240 - accuracy: 0.8688 - val_loss: 0.1402 - val_accuracy: 0.9633\n",
      "Epoch 42/50\n",
      "6960/6960 [==============================] - 99s 14ms/sample - loss: 0.3135 - accuracy: 0.8734 - val_loss: 0.1340 - val_accuracy: 0.9693\n",
      "Epoch 43/50\n",
      "6960/6960 [==============================] - 89s 13ms/sample - loss: 0.3029 - accuracy: 0.8772 - val_loss: 0.1473 - val_accuracy: 0.9673\n",
      "Epoch 44/50\n",
      "6960/6960 [==============================] - 91s 13ms/sample - loss: 0.3157 - accuracy: 0.8740 - val_loss: 0.1554 - val_accuracy: 0.9600\n",
      "Epoch 45/50\n",
      "6960/6960 [==============================] - 95s 14ms/sample - loss: 0.2914 - accuracy: 0.8845 - val_loss: 0.1338 - val_accuracy: 0.9660\n",
      "Epoch 46/50\n",
      "6960/6960 [==============================] - 89s 13ms/sample - loss: 0.2897 - accuracy: 0.8862 - val_loss: 0.1309 - val_accuracy: 0.9653\n",
      "Epoch 47/50\n",
      "6960/6960 [==============================] - 88s 13ms/sample - loss: 0.3007 - accuracy: 0.8761 - val_loss: 0.1323 - val_accuracy: 0.9667\n",
      "Epoch 48/50\n",
      "6960/6960 [==============================] - 89s 13ms/sample - loss: 0.2840 - accuracy: 0.8830 - val_loss: 0.1220 - val_accuracy: 0.9700\n",
      "Epoch 49/50\n",
      "6960/6960 [==============================] - 91s 13ms/sample - loss: 0.2797 - accuracy: 0.8884 - val_loss: 0.1046 - val_accuracy: 0.9680\n",
      "Epoch 50/50\n",
      "6960/6960 [==============================] - 91s 13ms/sample - loss: 0.2844 - accuracy: 0.8868 - val_loss: 0.1030 - val_accuracy: 0.9760\n",
      "6960/6960 [==============================] - 29s 4ms/sample - loss: 0.0400 - accuracy: 0.9960\n",
      "1772/1772 [==============================] - 7s 4ms/sample - loss: 1.1076 - accuracy: 0.6473\n",
      "train accuracy: 99.598%\n",
      "test accuracy: 64.729%\n",
      "=================250===================\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_67 (Conv2D)           (None, 250, 1, 100)       22100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_67 (MaxPooling (None, 84, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_67 (Batc (None, 84, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_67 (Dropout)         (None, 84, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_68 (Conv2D)           (None, 84, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_68 (MaxPooling (None, 28, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_68 (Batc (None, 28, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_68 (Dropout)         (None, 28, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_69 (Conv2D)           (None, 28, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_69 (MaxPooling (None, 10, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_69 (Batc (None, 10, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_69 (Dropout)         (None, 10, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "flatten_19 (Flatten)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 100)               100100    \n",
      "_________________________________________________________________\n",
      "reshape_9 (Reshape)          (None, 100, 1)            0         \n",
      "_________________________________________________________________\n",
      "lstm_18 (LSTM)               (None, 100, 100)          40800     \n",
      "_________________________________________________________________\n",
      "lstm_19 (LSTM)               (None, 70)                47880     \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 4)                 284       \n",
      "=================================================================\n",
      "Total params: 412,564\n",
      "Trainable params: 411,964\n",
      "Non-trainable params: 600\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6960 samples, validate on 1500 samples\n",
      "Epoch 1/50\n",
      "6960/6960 [==============================] - 144s 21ms/sample - loss: 1.3818 - accuracy: 0.2889 - val_loss: 1.3579 - val_accuracy: 0.3147\n",
      "Epoch 2/50\n",
      "6960/6960 [==============================] - 96s 14ms/sample - loss: 1.2980 - accuracy: 0.3826 - val_loss: 1.2983 - val_accuracy: 0.4187\n",
      "Epoch 3/50\n",
      "6960/6960 [==============================] - 92s 13ms/sample - loss: 1.2045 - accuracy: 0.4326 - val_loss: 1.2408 - val_accuracy: 0.4440\n",
      "Epoch 4/50\n",
      "6960/6960 [==============================] - 97s 14ms/sample - loss: 1.1434 - accuracy: 0.4761 - val_loss: 1.1618 - val_accuracy: 0.4987\n",
      "Epoch 5/50\n",
      "6960/6960 [==============================] - 96s 14ms/sample - loss: 1.0984 - accuracy: 0.5030 - val_loss: 1.1551 - val_accuracy: 0.5047\n",
      "Epoch 6/50\n",
      "6960/6960 [==============================] - 99s 14ms/sample - loss: 1.0457 - accuracy: 0.5250 - val_loss: 0.9999 - val_accuracy: 0.5413\n",
      "Epoch 7/50\n",
      "6960/6960 [==============================] - 99s 14ms/sample - loss: 1.0019 - accuracy: 0.5391 - val_loss: 0.9420 - val_accuracy: 0.5813\n",
      "Epoch 8/50\n",
      "6960/6960 [==============================] - 100s 14ms/sample - loss: 0.9638 - accuracy: 0.5622 - val_loss: 0.8861 - val_accuracy: 0.6093\n",
      "Epoch 9/50\n",
      "6960/6960 [==============================] - 97s 14ms/sample - loss: 0.9324 - accuracy: 0.5830 - val_loss: 0.8337 - val_accuracy: 0.6227\n",
      "Epoch 10/50\n",
      "6960/6960 [==============================] - 99s 14ms/sample - loss: 0.8988 - accuracy: 0.5950 - val_loss: 0.8161 - val_accuracy: 0.6487\n",
      "Epoch 11/50\n",
      "6960/6960 [==============================] - 93s 13ms/sample - loss: 0.8641 - accuracy: 0.6214 - val_loss: 0.7545 - val_accuracy: 0.6773\n",
      "Epoch 12/50\n",
      "6960/6960 [==============================] - 96s 14ms/sample - loss: 0.8456 - accuracy: 0.6210 - val_loss: 0.7272 - val_accuracy: 0.6900\n",
      "Epoch 13/50\n",
      "6960/6960 [==============================] - 96s 14ms/sample - loss: 0.7973 - accuracy: 0.6468 - val_loss: 0.8179 - val_accuracy: 0.6440\n",
      "Epoch 14/50\n",
      "6960/6960 [==============================] - 82s 12ms/sample - loss: 0.7903 - accuracy: 0.6458 - val_loss: 0.6523 - val_accuracy: 0.7313\n",
      "Epoch 15/50\n",
      "6960/6960 [==============================] - 65s 9ms/sample - loss: 0.7637 - accuracy: 0.6636 - val_loss: 0.7230 - val_accuracy: 0.7100\n",
      "Epoch 16/50\n",
      "6960/6960 [==============================] - 58s 8ms/sample - loss: 0.7416 - accuracy: 0.6818 - val_loss: 0.6890 - val_accuracy: 0.7160\n",
      "Epoch 17/50\n",
      "6960/6960 [==============================] - 57s 8ms/sample - loss: 0.7187 - accuracy: 0.6958 - val_loss: 0.6077 - val_accuracy: 0.7653\n",
      "Epoch 18/50\n",
      "6960/6960 [==============================] - 58s 8ms/sample - loss: 0.6893 - accuracy: 0.7039 - val_loss: 0.6062 - val_accuracy: 0.7727\n",
      "Epoch 19/50\n",
      "6960/6960 [==============================] - 57s 8ms/sample - loss: 0.6518 - accuracy: 0.7234 - val_loss: 0.5122 - val_accuracy: 0.8160\n",
      "Epoch 20/50\n",
      "6960/6960 [==============================] - 56s 8ms/sample - loss: 0.6410 - accuracy: 0.7306 - val_loss: 0.4975 - val_accuracy: 0.8193\n",
      "Epoch 21/50\n",
      "6960/6960 [==============================] - 57s 8ms/sample - loss: 0.6126 - accuracy: 0.7448 - val_loss: 0.4786 - val_accuracy: 0.8353\n",
      "Epoch 22/50\n",
      "6960/6960 [==============================] - 56s 8ms/sample - loss: 0.5869 - accuracy: 0.7578 - val_loss: 0.4615 - val_accuracy: 0.8487\n",
      "Epoch 23/50\n",
      "6960/6960 [==============================] - 56s 8ms/sample - loss: 0.5769 - accuracy: 0.7621 - val_loss: 0.4289 - val_accuracy: 0.8687\n",
      "Epoch 24/50\n",
      "6960/6960 [==============================] - 57s 8ms/sample - loss: 0.5493 - accuracy: 0.7726 - val_loss: 0.3528 - val_accuracy: 0.8960\n",
      "Epoch 25/50\n",
      "6960/6960 [==============================] - 57s 8ms/sample - loss: 0.5450 - accuracy: 0.7799 - val_loss: 0.3483 - val_accuracy: 0.8760\n",
      "Epoch 26/50\n",
      "6960/6960 [==============================] - 58s 8ms/sample - loss: 0.5266 - accuracy: 0.7872 - val_loss: 0.3004 - val_accuracy: 0.9100\n",
      "Epoch 27/50\n",
      "6960/6960 [==============================] - 59s 8ms/sample - loss: 0.4985 - accuracy: 0.7981 - val_loss: 0.3029 - val_accuracy: 0.9073\n",
      "Epoch 28/50\n",
      "6960/6960 [==============================] - 58s 8ms/sample - loss: 0.5000 - accuracy: 0.7999 - val_loss: 0.3054 - val_accuracy: 0.9200\n",
      "Epoch 29/50\n",
      "6960/6960 [==============================] - 61s 9ms/sample - loss: 0.4737 - accuracy: 0.8065 - val_loss: 0.2885 - val_accuracy: 0.9207\n",
      "Epoch 30/50\n",
      "6960/6960 [==============================] - 60s 9ms/sample - loss: 0.4512 - accuracy: 0.8170 - val_loss: 0.2546 - val_accuracy: 0.9273\n",
      "Epoch 31/50\n",
      "6960/6960 [==============================] - 60s 9ms/sample - loss: 0.4488 - accuracy: 0.8159 - val_loss: 0.2243 - val_accuracy: 0.9380\n",
      "Epoch 32/50\n",
      "6960/6960 [==============================] - 62s 9ms/sample - loss: 0.4315 - accuracy: 0.8243 - val_loss: 0.2419 - val_accuracy: 0.9293\n",
      "Epoch 33/50\n",
      "6960/6960 [==============================] - 63s 9ms/sample - loss: 0.4072 - accuracy: 0.8375 - val_loss: 0.2201 - val_accuracy: 0.9400\n",
      "Epoch 34/50\n",
      "6960/6960 [==============================] - 56s 8ms/sample - loss: 0.4162 - accuracy: 0.8372 - val_loss: 0.2009 - val_accuracy: 0.9453\n",
      "Epoch 35/50\n",
      "6960/6960 [==============================] - 62s 9ms/sample - loss: 0.3904 - accuracy: 0.8409 - val_loss: 0.2048 - val_accuracy: 0.9447\n",
      "Epoch 36/50\n",
      "6960/6960 [==============================] - 60s 9ms/sample - loss: 0.4042 - accuracy: 0.8338 - val_loss: 0.1773 - val_accuracy: 0.9547\n",
      "Epoch 37/50\n",
      "6960/6960 [==============================] - 59s 9ms/sample - loss: 0.3815 - accuracy: 0.8471 - val_loss: 0.1506 - val_accuracy: 0.9633\n",
      "Epoch 38/50\n",
      "6960/6960 [==============================] - 58s 8ms/sample - loss: 0.3679 - accuracy: 0.8523 - val_loss: 0.1994 - val_accuracy: 0.9507\n",
      "Epoch 39/50\n",
      "6960/6960 [==============================] - 58s 8ms/sample - loss: 0.3602 - accuracy: 0.8543 - val_loss: 0.1585 - val_accuracy: 0.9633\n",
      "Epoch 40/50\n",
      "6960/6960 [==============================] - 61s 9ms/sample - loss: 0.3584 - accuracy: 0.8559 - val_loss: 0.1591 - val_accuracy: 0.9587\n",
      "Epoch 41/50\n",
      "6960/6960 [==============================] - 61s 9ms/sample - loss: 0.3512 - accuracy: 0.8605 - val_loss: 0.1219 - val_accuracy: 0.9713\n",
      "Epoch 42/50\n",
      "6960/6960 [==============================] - 63s 9ms/sample - loss: 0.3433 - accuracy: 0.8615 - val_loss: 0.1304 - val_accuracy: 0.9667\n",
      "Epoch 43/50\n",
      "6960/6960 [==============================] - 60s 9ms/sample - loss: 0.3364 - accuracy: 0.8638 - val_loss: 0.1513 - val_accuracy: 0.9640\n",
      "Epoch 44/50\n",
      "6960/6960 [==============================] - 59s 9ms/sample - loss: 0.3151 - accuracy: 0.8710 - val_loss: 0.1187 - val_accuracy: 0.9740\n",
      "Epoch 45/50\n",
      "6960/6960 [==============================] - 58s 8ms/sample - loss: 0.3086 - accuracy: 0.8698 - val_loss: 0.1256 - val_accuracy: 0.9667\n",
      "Epoch 46/50\n",
      "6960/6960 [==============================] - 59s 8ms/sample - loss: 0.3126 - accuracy: 0.8737 - val_loss: 0.1372 - val_accuracy: 0.9653\n",
      "Epoch 47/50\n",
      "6960/6960 [==============================] - 59s 9ms/sample - loss: 0.3153 - accuracy: 0.8739 - val_loss: 0.1230 - val_accuracy: 0.9680\n",
      "Epoch 48/50\n",
      "6960/6960 [==============================] - 65s 9ms/sample - loss: 0.2932 - accuracy: 0.8783 - val_loss: 0.0994 - val_accuracy: 0.9767\n",
      "Epoch 49/50\n",
      "6960/6960 [==============================] - 62s 9ms/sample - loss: 0.2916 - accuracy: 0.8805 - val_loss: 0.0961 - val_accuracy: 0.9780\n",
      "Epoch 50/50\n",
      "6960/6960 [==============================] - 62s 9ms/sample - loss: 0.2905 - accuracy: 0.8807 - val_loss: 0.0870 - val_accuracy: 0.9753\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.0357 - accuracy: 0.9963\n",
      "1772/1772 [==============================] - 5s 3ms/sample - loss: 1.1176 - accuracy: 0.6580\n",
      "train accuracy: 99.626%\n",
      "test accuracy: 65.801%\n"
     ]
    }
   ],
   "source": [
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "for time in range(25, 251, 25):\n",
    "    print(\"=================\" + str(time) + \"===================\")\n",
    "    train_score, test_score = hybrid_train_data(time_period=time)\n",
    "    train_scores.append(train_score[1])\n",
    "    test_scores.append(test_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b5ddc34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracies: \n",
      "[0.9094828, 0.9655172, 0.98333335, 0.9863506, 0.992385, 0.9987069, 0.99813217, 0.9966954, 0.995977, 0.99626434]\n",
      "Test accuracies: \n",
      "[0.4136569, 0.5112867, 0.54063207, 0.5965011, 0.62979686, 0.6580135, 0.66591424, 0.6478555, 0.6472912, 0.6580135]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Train accuracies: \")\n",
    "print(train_scores)\n",
    "print(\"Test accuracies: \")\n",
    "print(test_scores)\n",
    "\n",
    "# plot\n",
    "plt.plot(range(25, 251, 25), train_scores, label='train accuracies')\n",
    "plt.plot(range(25, 251, 25), test_scores, label='test accuracies')\n",
    "plt.legend()\n",
    "plt.title(\"Classification Accuracies over Time Period (CNN+LSTM)\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
