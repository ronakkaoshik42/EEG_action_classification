{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.python._pywrap_tensorflow_internal' has no attribute 'TFE_DEVICE_PLACEMENT_EXPLICIT'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-8bbc4a0c46d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#import keras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mActivation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mDropout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m# pylint: disable=g-bad-import-order\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m  \u001b[1;31m# pylint: disable=unused-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;31m# pylint: disable=wildcard-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m  \u001b[1;31m# pylint: disable=redefined-builtin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\tensorflow\\python\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;31m# Protocol buffers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdlopenflags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_default_dlopen_flags\u001b[0m \u001b[1;33m|\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRTLD_LOCAL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m   \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpywrap_tensorflow_internal\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m   \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpywrap_tensorflow_internal\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m   \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpywrap_tensorflow_internal\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__git_version__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_pywrap_tensorflow_internal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTFE_ContextOptionsSetConfig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[0mTFE_ContextOptionsSetConfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_pywrap_tensorflow_internal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTFE_ContextOptionsSetConfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m \u001b[0mTFE_DEVICE_PLACEMENT_EXPLICIT\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_pywrap_tensorflow_internal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTFE_DEVICE_PLACEMENT_EXPLICIT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m \u001b[0mTFE_DEVICE_PLACEMENT_WARN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_pywrap_tensorflow_internal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTFE_DEVICE_PLACEMENT_WARN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[0mTFE_DEVICE_PLACEMENT_SILENT\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_pywrap_tensorflow_internal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTFE_DEVICE_PLACEMENT_SILENT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow.python._pywrap_tensorflow_internal' has no attribute 'TFE_DEVICE_PLACEMENT_EXPLICIT'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten,Dropout\n",
    "from tensorflow.keras.layers import Conv1D,Conv2D,BatchNormalization,MaxPooling1D,MaxPooling2D,Reshape, Dense, Embedding, LSTM,GRU, Bidirectional, TimeDistributed\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import optimizers\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.load(\"X_test.npy\")\n",
    "y_test = np.load(\"y_test.npy\")\n",
    "person_train_valid = np.load(\"person_train_valid.npy\")\n",
    "X_train_valid = np.load(\"X_train_valid.npy\")\n",
    "y_train_valid = np.load(\"y_train_valid.npy\")\n",
    "person_test = np.load(\"person_test.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shape of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training/Valid data shape: (2115, 22, 1000)\n",
      "Test data shape: (443, 22, 1000)\n",
      "Training/Valid target shape: (2115,)\n",
      "Test target shape: (443,)\n",
      "Person train/valid shape: (2115, 1)\n",
      "Person test shape: (443, 1)\n"
     ]
    }
   ],
   "source": [
    "print ('Training/Valid data shape: {}'.format(X_train_valid.shape))\n",
    "print ('Test data shape: {}'.format(X_test.shape))\n",
    "print ('Training/Valid target shape: {}'.format(y_train_valid.shape))\n",
    "print ('Test target shape: {}'.format(y_test.shape))\n",
    "print ('Person train/valid shape: {}'.format(person_train_valid.shape))\n",
    "print ('Person test shape: {}'.format(person_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_train = np.where(person_train_valid==0)[0]\n",
    "index_test = np.where(person_test==0)[0]\n",
    "\n",
    "X_train_valid = X_train_valid[index_train,:,:]\n",
    "y_train_valid = y_train_valid[index_train]\n",
    "X_test = X_test[index_test,:,:]\n",
    "y_test = y_test[index_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For one participant\n",
      "Training/Valid data shape: (2115, 22, 1000)\n",
      "Test data shape: (443, 22, 1000)\n",
      "Training/Valid target shape: (2115,)\n",
      "Test target shape: (443,)\n"
     ]
    }
   ],
   "source": [
    "print('For one participant')\n",
    "print ('Training/Valid data shape: {}'.format(X_train_valid.shape))\n",
    "print ('Test data shape: {}'.format(X_test.shape))\n",
    "print ('Training/Valid target shape: {}'.format(y_train_valid.shape))\n",
    "print ('Test target shape: {}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adjusting the labels to {0,1,2,3}\n",
    "\n",
    "# Cue onset left - 0\n",
    "# Cue onset right - 1\n",
    "# Cue onset foot - 2\n",
    "# Cue onset tongue - 3\n",
    "\n",
    "y_train_valid -= 769\n",
    "y_test -= 769"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training set: (187, 22, 1000)\n",
      "Shape of validation set: (50, 22, 1000)\n",
      "Shape of training labels: (187,)\n",
      "Shape of validation labels: (50,)\n",
      "Shape of training labels after categorical conversion: (187, 4)\n",
      "Shape of validation labels after categorical conversion: (50, 4)\n",
      "Shape of test labels after categorical conversion: (443, 4)\n",
      "Shape of training set after adding width info: (187, 22, 1000, 1)\n",
      "Shape of validation set after adding width info: (50, 22, 1000, 1)\n",
      "Shape of test set after adding width info: (443, 22, 1000, 1)\n",
      "Shape of training set after dimension reshaping: (187, 1000, 1, 22)\n",
      "Shape of validation set after dimension reshaping: (50, 1000, 1, 22)\n",
      "Shape of test set after dimension reshaping: (443, 1000, 1, 22)\n"
     ]
    }
   ],
   "source": [
    "# Creating the training and validation sets\n",
    "\n",
    "# First generating the training and validation indices using random splitting\n",
    "\n",
    "num_samples = 237\n",
    "num_samples_valid = 50\n",
    "\n",
    "ind_valid = np.random.choice(num_samples, num_samples_valid, replace=False)\n",
    "ind_train = np.array(list(set(range(num_samples)).difference(set(ind_valid))))\n",
    "\n",
    "# Creating the training and validation sets using the generated indices\n",
    "(x_train, x_valid) = X_train_valid[ind_train], X_train_valid[ind_valid] \n",
    "(y_train, y_valid) = y_train_valid[ind_train], y_train_valid[ind_valid]\n",
    "\n",
    "\n",
    "# # stratified split\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# x_train, x_valid, y_train, y_valid = train_test_split(X_train_valid,y_train_valid,test_size=50/237, stratify=y_train_valid)\n",
    "\n",
    "\n",
    "\n",
    "print('Shape of training set:',x_train.shape)\n",
    "print('Shape of validation set:',x_valid.shape)\n",
    "print('Shape of training labels:',y_train.shape)\n",
    "print('Shape of validation labels:',y_valid.shape)\n",
    "\n",
    "\n",
    "# Converting the labels to categorical variables for multiclass classification\n",
    "y_train = to_categorical(y_train, 4)\n",
    "y_valid = to_categorical(y_valid, 4)\n",
    "y_test = to_categorical(y_test, 4)\n",
    "print('Shape of training labels after categorical conversion:',y_train.shape)\n",
    "print('Shape of validation labels after categorical conversion:',y_valid.shape)\n",
    "print('Shape of test labels after categorical conversion:',y_test.shape)\n",
    "\n",
    "# Adding width of the segment to be 1\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
    "x_valid = x_valid.reshape(x_valid.shape[0], x_valid.shape[1], x_train.shape[2], 1)\n",
    "x_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)\n",
    "print('Shape of training set after adding width info:',x_train.shape)\n",
    "print('Shape of validation set after adding width info:',x_valid.shape)\n",
    "print('Shape of test set after adding width info:',x_test.shape)\n",
    "\n",
    "\n",
    "# Reshaping the training and validation dataset\n",
    "x_train = np.swapaxes(x_train, 1,3)\n",
    "x_train = np.swapaxes(x_train, 1,2)\n",
    "x_valid = np.swapaxes(x_valid, 1,3)\n",
    "x_valid = np.swapaxes(x_valid, 1,2)\n",
    "x_test = np.swapaxes(x_test, 1,3)\n",
    "x_test = np.swapaxes(x_test, 1,2)\n",
    "print('Shape of training set after dimension reshaping:',x_train.shape)\n",
    "print('Shape of validation set after dimension reshaping:',x_valid.shape)\n",
    "print('Shape of test set after dimension reshaping:',x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FC Model for subject 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1000, 1, 10)       230       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 1000, 1, 10)       40        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1000, 1, 20)       220       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 1000, 1, 20)       80        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1000, 1, 50)       1050      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 1000, 1, 50)       200       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 50000)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 200004    \n",
      "=================================================================\n",
      "Total params: 201,824\n",
      "Trainable params: 201,664\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Building the FC model using sequential class\n",
    "basic_fc_model = Sequential()\n",
    "\n",
    "# First FC layer \n",
    "basic_fc_model.add(Dense(10,input_shape=(1000,1,22))) # For the first layer we have to specify the input shape\n",
    "\n",
    "# BN layer\n",
    "basic_fc_model.add(BatchNormalization())\n",
    "\n",
    "# Second FC layer\n",
    "basic_fc_model.add(Dense(20)) # We don't need to specify the input shape it's inferred from the previous layer\n",
    "\n",
    "# BN layer\n",
    "basic_fc_model.add(BatchNormalization())\n",
    "\n",
    "# Third FC layer\n",
    "basic_fc_model.add(Dense(50))\n",
    "\n",
    "# BN layer\n",
    "basic_fc_model.add(BatchNormalization())\n",
    "\n",
    "# Output layer with Softmax activation\n",
    "basic_fc_model.add(Flatten()) # Flattens the input\n",
    "basic_fc_model.add(Dense(4, activation='softmax')) # Output FC layer with softmax activation\n",
    "\n",
    "# Printing the model summary\n",
    "basic_fc_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "import tensorflow as tf\n",
    "learning_rate = 1e-3\n",
    "epochs = 50\n",
    "optimizer = tf.keras.optimizers.Adam(lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1668 samples, validate on 447 samples\n",
      "Epoch 1/50\n",
      "1668/1668 [==============================] - 4s 3ms/sample - loss: 4.5110 - accuracy: 0.3501 - val_loss: 6.6616 - val_accuracy: 0.4094\n",
      "Epoch 2/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 2.3285 - accuracy: 0.6535 - val_loss: 4.9115 - val_accuracy: 0.3982\n",
      "Epoch 3/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 1.3088 - accuracy: 0.7488 - val_loss: 4.5535 - val_accuracy: 0.4362\n",
      "Epoch 4/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 0.5619 - accuracy: 0.8603 - val_loss: 4.3292 - val_accuracy: 0.4586\n",
      "Epoch 5/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 0.5081 - accuracy: 0.8771 - val_loss: 5.0391 - val_accuracy: 0.4430\n",
      "Epoch 6/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 0.2422 - accuracy: 0.9299 - val_loss: 4.9622 - val_accuracy: 0.4362\n",
      "Epoch 7/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 0.2045 - accuracy: 0.9359 - val_loss: 5.6173 - val_accuracy: 0.4362\n",
      "Epoch 8/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 0.1190 - accuracy: 0.9688 - val_loss: 5.7418 - val_accuracy: 0.4385\n",
      "Epoch 9/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 0.0345 - accuracy: 0.9892 - val_loss: 5.8819 - val_accuracy: 0.4452\n",
      "Epoch 10/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 0.0101 - accuracy: 0.9964 - val_loss: 5.9572 - val_accuracy: 0.4564\n",
      "Epoch 11/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 6.1068 - val_accuracy: 0.4541\n",
      "Epoch 12/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 6.2344 - val_accuracy: 0.4586\n",
      "Epoch 13/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 6.3581 - val_accuracy: 0.4586\n",
      "Epoch 14/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 9.7389e-04 - accuracy: 1.0000 - val_loss: 6.4709 - val_accuracy: 0.4609\n",
      "Epoch 15/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 8.5407e-04 - accuracy: 1.0000 - val_loss: 6.5406 - val_accuracy: 0.4631\n",
      "Epoch 16/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 7.4040e-04 - accuracy: 1.0000 - val_loss: 6.6204 - val_accuracy: 0.4631\n",
      "Epoch 17/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 7.0577e-04 - accuracy: 1.0000 - val_loss: 6.6640 - val_accuracy: 0.4586\n",
      "Epoch 18/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 6.8138e-04 - accuracy: 1.0000 - val_loss: 6.7167 - val_accuracy: 0.4586\n",
      "Epoch 19/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 6.0199e-04 - accuracy: 1.0000 - val_loss: 6.7487 - val_accuracy: 0.4564\n",
      "Epoch 20/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 5.7754e-04 - accuracy: 1.0000 - val_loss: 6.7720 - val_accuracy: 0.4609\n",
      "Epoch 21/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 5.6609e-04 - accuracy: 1.0000 - val_loss: 6.7887 - val_accuracy: 0.4586\n",
      "Epoch 22/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 5.3386e-04 - accuracy: 1.0000 - val_loss: 6.8061 - val_accuracy: 0.4631\n",
      "Epoch 23/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 5.0030e-04 - accuracy: 1.0000 - val_loss: 6.8256 - val_accuracy: 0.4631\n",
      "Epoch 24/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 4.7238e-04 - accuracy: 1.0000 - val_loss: 6.8312 - val_accuracy: 0.4631\n",
      "Epoch 25/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 4.3816e-04 - accuracy: 1.0000 - val_loss: 6.8312 - val_accuracy: 0.4631\n",
      "Epoch 26/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 4.2701e-04 - accuracy: 1.0000 - val_loss: 6.8418 - val_accuracy: 0.4653\n",
      "Epoch 27/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 4.0759e-04 - accuracy: 1.0000 - val_loss: 6.8359 - val_accuracy: 0.4631\n",
      "Epoch 28/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 4.0336e-04 - accuracy: 1.0000 - val_loss: 6.8398 - val_accuracy: 0.4609\n",
      "Epoch 29/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 3.8972e-04 - accuracy: 1.0000 - val_loss: 6.8377 - val_accuracy: 0.4609\n",
      "Epoch 30/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 3.5525e-04 - accuracy: 1.0000 - val_loss: 6.8360 - val_accuracy: 0.4609\n",
      "Epoch 31/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 3.4468e-04 - accuracy: 1.0000 - val_loss: 6.8358 - val_accuracy: 0.4609\n",
      "Epoch 32/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 3.5581e-04 - accuracy: 1.0000 - val_loss: 6.8155 - val_accuracy: 0.4586\n",
      "Epoch 33/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 3.6435e-04 - accuracy: 1.0000 - val_loss: 6.8018 - val_accuracy: 0.4631\n",
      "Epoch 34/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 3.6388e-04 - accuracy: 1.0000 - val_loss: 6.8130 - val_accuracy: 0.4698\n",
      "Epoch 35/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 3.3078e-04 - accuracy: 1.0000 - val_loss: 6.8032 - val_accuracy: 0.4720\n",
      "Epoch 36/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 3.0686e-04 - accuracy: 1.0000 - val_loss: 6.8099 - val_accuracy: 0.4743\n",
      "Epoch 37/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 3.0607e-04 - accuracy: 1.0000 - val_loss: 6.8062 - val_accuracy: 0.4743\n",
      "Epoch 38/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 2.7961e-04 - accuracy: 1.0000 - val_loss: 6.8125 - val_accuracy: 0.4698\n",
      "Epoch 39/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 2.8025e-04 - accuracy: 1.0000 - val_loss: 6.8039 - val_accuracy: 0.4653\n",
      "Epoch 40/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 2.8626e-04 - accuracy: 1.0000 - val_loss: 6.7949 - val_accuracy: 0.4765\n",
      "Epoch 41/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 2.7932e-04 - accuracy: 1.0000 - val_loss: 6.7956 - val_accuracy: 0.4765\n",
      "Epoch 42/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 2.5825e-04 - accuracy: 1.0000 - val_loss: 6.8099 - val_accuracy: 0.4743\n",
      "Epoch 43/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 2.4961e-04 - accuracy: 1.0000 - val_loss: 6.7985 - val_accuracy: 0.4765\n",
      "Epoch 44/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 2.3986e-04 - accuracy: 1.0000 - val_loss: 6.8158 - val_accuracy: 0.4765\n",
      "Epoch 45/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 2.2261e-04 - accuracy: 1.0000 - val_loss: 6.8114 - val_accuracy: 0.4765\n",
      "Epoch 46/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 2.2304e-04 - accuracy: 1.0000 - val_loss: 6.8048 - val_accuracy: 0.4765\n",
      "Epoch 47/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 2.2429e-04 - accuracy: 1.0000 - val_loss: 6.8037 - val_accuracy: 0.4743\n",
      "Epoch 48/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 2.0719e-04 - accuracy: 1.0000 - val_loss: 6.7989 - val_accuracy: 0.4743\n",
      "Epoch 49/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 2.0856e-04 - accuracy: 1.0000 - val_loss: 6.8051 - val_accuracy: 0.4743\n",
      "Epoch 50/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 2.0341e-04 - accuracy: 1.0000 - val_loss: 6.8098 - val_accuracy: 0.4720\n"
     ]
    }
   ],
   "source": [
    "# Compiling the model\n",
    "basic_fc_model.compile(loss='categorical_crossentropy',\n",
    "                 optimizer=optimizer,\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "# Training and validating the model\n",
    "basic_fc_model_results = basic_fc_model.fit(x_train,\n",
    "             y_train,\n",
    "             batch_size=64,\n",
    "             epochs=epochs,\n",
    "             validation_data=(x_valid, y_valid), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting accuracy trajectory\n",
    "plt.plot(basic_fc_model_results.history['accuracy'])\n",
    "plt.plot(basic_fc_model_results.history['val_accuracy'])\n",
    "plt.title('Basic FC model accuracy trajectory')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plotting loss trajectory\n",
    "plt.plot(basic_fc_model_results.history['loss'],'o')\n",
    "plt.plot(basic_fc_model_results.history['val_loss'],'o')\n",
    "plt.title('Basic FC model loss trajectory')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of the basic FC model: 0.4401806\n"
     ]
    }
   ],
   "source": [
    "## Testing the basic FC model\n",
    "\n",
    "score = basic_fc_model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test accuracy of the basic FC model:',score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model for subject 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_40\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_92 (Conv2D)           (None, 1000, 1, 25)       5525      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_92 (MaxPooling (None, 334, 1, 25)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_101 (Bat (None, 334, 1, 25)        100       \n",
      "_________________________________________________________________\n",
      "dropout_130 (Dropout)        (None, 334, 1, 25)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_93 (Conv2D)           (None, 334, 1, 50)        12550     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_93 (MaxPooling (None, 112, 1, 50)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_102 (Bat (None, 112, 1, 50)        200       \n",
      "_________________________________________________________________\n",
      "dropout_131 (Dropout)        (None, 112, 1, 50)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_94 (Conv2D)           (None, 112, 1, 100)       50100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_94 (MaxPooling (None, 38, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_103 (Bat (None, 38, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_132 (Dropout)        (None, 38, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_95 (Conv2D)           (None, 38, 1, 200)        200200    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_95 (MaxPooling (None, 13, 1, 200)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_104 (Bat (None, 13, 1, 200)        800       \n",
      "_________________________________________________________________\n",
      "dropout_133 (Dropout)        (None, 13, 1, 200)        0         \n",
      "_________________________________________________________________\n",
      "flatten_22 (Flatten)         (None, 2600)              0         \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 4)                 10404     \n",
      "=================================================================\n",
      "Total params: 280,279\n",
      "Trainable params: 279,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Building the CNN model using sequential class\n",
    "basic_cnn_model = Sequential()\n",
    "\n",
    "# Conv. block 1\n",
    "basic_cnn_model.add(Conv2D(filters=25, kernel_size=(10,1), padding='same', activation='elu', input_shape=(1000,1,22)))\n",
    "basic_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "basic_cnn_model.add(BatchNormalization())\n",
    "basic_cnn_model.add(Dropout(0.5))\n",
    "\n",
    "# Conv. block 2\n",
    "basic_cnn_model.add(Conv2D(filters=50, kernel_size=(10,1), padding='same', activation='elu'))\n",
    "basic_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "basic_cnn_model.add(BatchNormalization())\n",
    "basic_cnn_model.add(Dropout(0.5))\n",
    "\n",
    "# Conv. block 3\n",
    "basic_cnn_model.add(Conv2D(filters=100, kernel_size=(10,1), padding='same', activation='elu'))\n",
    "basic_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "basic_cnn_model.add(BatchNormalization())\n",
    "basic_cnn_model.add(Dropout(0.5))\n",
    "\n",
    "# Conv. block 4\n",
    "basic_cnn_model.add(Conv2D(filters=200, kernel_size=(10,1), padding='same', activation='elu'))\n",
    "basic_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "basic_cnn_model.add(BatchNormalization())\n",
    "basic_cnn_model.add(Dropout(0.5))\n",
    "\n",
    "# Output layer with Softmax activation\n",
    "basic_cnn_model.add(Flatten()) # Flattens the input\n",
    "basic_cnn_model.add(Dense(4, activation='softmax')) # Output FC layer with softmax activation\n",
    "\n",
    "\n",
    "# Printing the model summary\n",
    "basic_cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "learning_rate = 1e-3\n",
    "epochs = 100\n",
    "cnn_optimizer = tf.keras.optimizers.Adam(lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1668 samples, validate on 447 samples\n",
      "Epoch 1/100\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 2.3052 - accuracy: 0.2710 - val_loss: 3.2001 - val_accuracy: 0.2662\n",
      "Epoch 2/100\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 2.0913 - accuracy: 0.3165 - val_loss: 1.7890 - val_accuracy: 0.3624\n",
      "Epoch 3/100\n",
      "1668/1668 [==============================] - 6s 4ms/sample - loss: 1.9528 - accuracy: 0.3327 - val_loss: 1.6309 - val_accuracy: 0.3468\n",
      "Epoch 4/100\n",
      "1668/1668 [==============================] - 4s 3ms/sample - loss: 1.8595 - accuracy: 0.3507 - val_loss: 1.5461 - val_accuracy: 0.3669\n",
      "Epoch 5/100\n",
      "1668/1668 [==============================] - 4s 3ms/sample - loss: 1.8100 - accuracy: 0.3597 - val_loss: 1.5399 - val_accuracy: 0.3826\n",
      "Epoch 6/100\n",
      "1668/1668 [==============================] - 6s 3ms/sample - loss: 1.6959 - accuracy: 0.3759 - val_loss: 1.5650 - val_accuracy: 0.3647\n",
      "Epoch 7/100\n",
      "1668/1668 [==============================] - 4s 3ms/sample - loss: 1.6157 - accuracy: 0.4005 - val_loss: 1.5244 - val_accuracy: 0.3781\n",
      "Epoch 8/100\n",
      "1668/1668 [==============================] - 4s 3ms/sample - loss: 1.5474 - accuracy: 0.4071 - val_loss: 1.4998 - val_accuracy: 0.3870\n",
      "Epoch 9/100\n",
      "1668/1668 [==============================] - 4s 3ms/sample - loss: 1.4782 - accuracy: 0.4161 - val_loss: 1.5376 - val_accuracy: 0.3289\n",
      "Epoch 10/100\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.4219 - accuracy: 0.4460 - val_loss: 1.4658 - val_accuracy: 0.3803\n",
      "Epoch 11/100\n",
      "1668/1668 [==============================] - 4s 3ms/sample - loss: 1.3840 - accuracy: 0.4568 - val_loss: 1.4083 - val_accuracy: 0.4027\n",
      "Epoch 12/100\n",
      "1668/1668 [==============================] - 4s 3ms/sample - loss: 1.4234 - accuracy: 0.4568 - val_loss: 1.2434 - val_accuracy: 0.4810\n",
      "Epoch 13/100\n",
      "1668/1668 [==============================] - 4s 3ms/sample - loss: 1.4274 - accuracy: 0.4664 - val_loss: 1.4158 - val_accuracy: 0.4318\n",
      "Epoch 14/100\n",
      "1668/1668 [==============================] - 6s 3ms/sample - loss: 1.3311 - accuracy: 0.4970 - val_loss: 1.3179 - val_accuracy: 0.4586\n",
      "Epoch 15/100\n",
      "1668/1668 [==============================] - 4s 3ms/sample - loss: 1.2623 - accuracy: 0.5042 - val_loss: 1.4100 - val_accuracy: 0.4430\n",
      "Epoch 16/100\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.2778 - accuracy: 0.4982 - val_loss: 1.1748 - val_accuracy: 0.4989\n",
      "Epoch 17/100\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.2183 - accuracy: 0.5204 - val_loss: 1.3164 - val_accuracy: 0.4541\n",
      "Epoch 18/100\n",
      "1668/1668 [==============================] - 4s 3ms/sample - loss: 1.2278 - accuracy: 0.5072 - val_loss: 1.1792 - val_accuracy: 0.4877\n",
      "Epoch 19/100\n",
      "1668/1668 [==============================] - 4s 3ms/sample - loss: 1.1667 - accuracy: 0.5348 - val_loss: 1.1833 - val_accuracy: 0.4877\n",
      "Epoch 20/100\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.1738 - accuracy: 0.5444 - val_loss: 1.2163 - val_accuracy: 0.4810\n",
      "Epoch 21/100\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.1067 - accuracy: 0.5689 - val_loss: 1.2077 - val_accuracy: 0.4743\n",
      "Epoch 22/100\n",
      "1668/1668 [==============================] - 4s 3ms/sample - loss: 1.1212 - accuracy: 0.5612 - val_loss: 1.1248 - val_accuracy: 0.5190\n",
      "Epoch 23/100\n",
      "1668/1668 [==============================] - 4s 3ms/sample - loss: 1.0785 - accuracy: 0.5761 - val_loss: 1.1603 - val_accuracy: 0.5257\n",
      "Epoch 24/100\n",
      "1668/1668 [==============================] - 4s 3ms/sample - loss: 1.0448 - accuracy: 0.5887 - val_loss: 1.1391 - val_accuracy: 0.5257\n",
      "Epoch 25/100\n",
      "1668/1668 [==============================] - 4s 3ms/sample - loss: 1.0561 - accuracy: 0.5941 - val_loss: 1.1603 - val_accuracy: 0.5302\n",
      "Epoch 26/100\n",
      "1668/1668 [==============================] - 4s 3ms/sample - loss: 1.0673 - accuracy: 0.5893 - val_loss: 1.2120 - val_accuracy: 0.4989\n",
      "Epoch 27/100\n",
      "1668/1668 [==============================] - 4s 3ms/sample - loss: 1.0319 - accuracy: 0.5905 - val_loss: 1.2662 - val_accuracy: 0.4698\n",
      "Epoch 28/100\n",
      "1668/1668 [==============================] - 4s 3ms/sample - loss: 0.9739 - accuracy: 0.6055 - val_loss: 1.1308 - val_accuracy: 0.5391\n",
      "Epoch 29/100\n",
      "1668/1668 [==============================] - 4s 3ms/sample - loss: 1.0038 - accuracy: 0.5815 - val_loss: 1.1380 - val_accuracy: 0.5235\n",
      "Epoch 30/100\n",
      "1668/1668 [==============================] - 4s 3ms/sample - loss: 0.9385 - accuracy: 0.6253 - val_loss: 1.0901 - val_accuracy: 0.5324\n",
      "Epoch 31/100\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.9610 - accuracy: 0.6109 - val_loss: 1.0722 - val_accuracy: 0.5548\n",
      "Epoch 32/100\n",
      "1668/1668 [==============================] - 4s 3ms/sample - loss: 0.9808 - accuracy: 0.6181 - val_loss: 1.0338 - val_accuracy: 0.6063\n",
      "Epoch 33/100\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.9035 - accuracy: 0.6517 - val_loss: 1.0164 - val_accuracy: 0.6040\n",
      "Epoch 34/100\n",
      "1668/1668 [==============================] - 4s 3ms/sample - loss: 0.8879 - accuracy: 0.6427 - val_loss: 1.0261 - val_accuracy: 0.5817\n",
      "Epoch 35/100\n",
      "1668/1668 [==============================] - 4s 3ms/sample - loss: 0.9382 - accuracy: 0.6427 - val_loss: 1.0352 - val_accuracy: 0.5861\n",
      "Epoch 36/100\n",
      "1668/1668 [==============================] - 4s 3ms/sample - loss: 0.9388 - accuracy: 0.6373 - val_loss: 1.1556 - val_accuracy: 0.5280\n",
      "Epoch 37/100\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.8366 - accuracy: 0.6721 - val_loss: 1.0992 - val_accuracy: 0.5615\n",
      "Epoch 38/100\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.9508 - accuracy: 0.6331 - val_loss: 1.0251 - val_accuracy: 0.5973\n",
      "Epoch 39/100\n",
      "1668/1668 [==============================] - 4s 3ms/sample - loss: 0.8717 - accuracy: 0.6649 - val_loss: 0.9740 - val_accuracy: 0.6085\n",
      "Epoch 40/100\n",
      "1668/1668 [==============================] - 4s 3ms/sample - loss: 0.8559 - accuracy: 0.6583 - val_loss: 1.0224 - val_accuracy: 0.5817\n",
      "Epoch 41/100\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.8278 - accuracy: 0.6871 - val_loss: 1.0723 - val_accuracy: 0.5705\n",
      "Epoch 42/100\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.8344 - accuracy: 0.6727 - val_loss: 1.0435 - val_accuracy: 0.5928\n",
      "Epoch 43/100\n",
      "1668/1668 [==============================] - 4s 3ms/sample - loss: 0.8031 - accuracy: 0.6942 - val_loss: 1.0098 - val_accuracy: 0.5996\n",
      "Epoch 44/100\n",
      "1668/1668 [==============================] - 4s 3ms/sample - loss: 0.7476 - accuracy: 0.7086 - val_loss: 0.9892 - val_accuracy: 0.6107\n",
      "Epoch 45/100\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.7887 - accuracy: 0.6882 - val_loss: 1.0351 - val_accuracy: 0.6085\n",
      "Epoch 46/100\n",
      "1668/1668 [==============================] - 4s 3ms/sample - loss: 0.7951 - accuracy: 0.7008 - val_loss: 1.0089 - val_accuracy: 0.6264\n",
      "Epoch 47/100\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.8312 - accuracy: 0.6667 - val_loss: 1.0151 - val_accuracy: 0.5973\n",
      "Epoch 48/100\n",
      "1668/1668 [==============================] - 4s 3ms/sample - loss: 0.8704 - accuracy: 0.6547 - val_loss: 1.0910 - val_accuracy: 0.5727\n",
      "Epoch 49/100\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.7591 - accuracy: 0.6948 - val_loss: 1.0745 - val_accuracy: 0.5884\n",
      "Epoch 50/100\n",
      "1668/1668 [==============================] - 4s 3ms/sample - loss: 0.7510 - accuracy: 0.7140 - val_loss: 0.9671 - val_accuracy: 0.6465\n",
      "Epoch 51/100\n",
      "1668/1668 [==============================] - 4s 3ms/sample - loss: 0.7280 - accuracy: 0.7092 - val_loss: 1.0061 - val_accuracy: 0.6353\n",
      "Epoch 52/100\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.7232 - accuracy: 0.7182 - val_loss: 0.9742 - val_accuracy: 0.6331\n",
      "Epoch 53/100\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.7045 - accuracy: 0.7314 - val_loss: 1.0172 - val_accuracy: 0.6309\n",
      "Epoch 54/100\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.7078 - accuracy: 0.7248 - val_loss: 0.9482 - val_accuracy: 0.6376\n",
      "Epoch 55/100\n",
      "1668/1668 [==============================] - 6s 3ms/sample - loss: 0.6776 - accuracy: 0.7440 - val_loss: 1.0067 - val_accuracy: 0.6353\n",
      "Epoch 56/100\n",
      "1668/1668 [==============================] - 4s 3ms/sample - loss: 0.6566 - accuracy: 0.7446 - val_loss: 0.9110 - val_accuracy: 0.6667\n",
      "Epoch 57/100\n",
      "1668/1668 [==============================] - 4s 3ms/sample - loss: 0.6477 - accuracy: 0.7512 - val_loss: 1.0207 - val_accuracy: 0.6040\n",
      "Epoch 58/100\n",
      "1668/1668 [==============================] - 4s 3ms/sample - loss: 0.6341 - accuracy: 0.7632 - val_loss: 0.9941 - val_accuracy: 0.6219\n",
      "Epoch 59/100\n",
      "1668/1668 [==============================] - 4s 3ms/sample - loss: 0.6457 - accuracy: 0.7470 - val_loss: 0.9704 - val_accuracy: 0.6555\n",
      "Epoch 60/100\n",
      "1668/1668 [==============================] - 4s 3ms/sample - loss: 0.6723 - accuracy: 0.7476 - val_loss: 0.9798 - val_accuracy: 0.6443\n",
      "Epoch 61/100\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.6026 - accuracy: 0.7680 - val_loss: 0.9607 - val_accuracy: 0.6331\n",
      "Epoch 62/100\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.6032 - accuracy: 0.7680 - val_loss: 0.9903 - val_accuracy: 0.6353\n",
      "Epoch 63/100\n",
      "1668/1668 [==============================] - 4s 3ms/sample - loss: 0.6069 - accuracy: 0.7626 - val_loss: 0.9654 - val_accuracy: 0.6331\n",
      "Epoch 64/100\n",
      "1668/1668 [==============================] - 4s 3ms/sample - loss: 0.5486 - accuracy: 0.7848 - val_loss: 0.9303 - val_accuracy: 0.6465\n",
      "Epoch 65/100\n",
      "1668/1668 [==============================] - 4s 3ms/sample - loss: 0.5813 - accuracy: 0.7746 - val_loss: 0.9222 - val_accuracy: 0.6555\n",
      "Epoch 66/100\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5725 - accuracy: 0.7782 - val_loss: 1.0027 - val_accuracy: 0.6331\n",
      "Epoch 67/100\n",
      "1668/1668 [==============================] - 4s 3ms/sample - loss: 0.5607 - accuracy: 0.7848 - val_loss: 0.9350 - val_accuracy: 0.6577\n",
      "Epoch 68/100\n",
      "1668/1668 [==============================] - 4s 3ms/sample - loss: 0.6183 - accuracy: 0.7548 - val_loss: 0.9762 - val_accuracy: 0.6532\n",
      "Epoch 69/100\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5384 - accuracy: 0.7932 - val_loss: 1.0639 - val_accuracy: 0.6242\n",
      "Epoch 70/100\n",
      "1668/1668 [==============================] - 4s 3ms/sample - loss: 0.5753 - accuracy: 0.7842 - val_loss: 0.9464 - val_accuracy: 0.6421\n",
      "Epoch 71/100\n",
      "1668/1668 [==============================] - 4s 3ms/sample - loss: 0.5961 - accuracy: 0.7728 - val_loss: 1.0358 - val_accuracy: 0.6107\n",
      "Epoch 72/100\n",
      "1668/1668 [==============================] - 4s 3ms/sample - loss: 0.5108 - accuracy: 0.8034 - val_loss: 0.9737 - val_accuracy: 0.6264\n",
      "Epoch 73/100\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5068 - accuracy: 0.8124 - val_loss: 0.9907 - val_accuracy: 0.6197\n",
      "Epoch 74/100\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5366 - accuracy: 0.7896 - val_loss: 1.0179 - val_accuracy: 0.6174\n",
      "Epoch 75/100\n",
      "1668/1668 [==============================] - 4s 3ms/sample - loss: 0.5825 - accuracy: 0.7764 - val_loss: 0.9986 - val_accuracy: 0.6421\n",
      "Epoch 76/100\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5524 - accuracy: 0.7818 - val_loss: 1.0088 - val_accuracy: 0.6376\n",
      "Epoch 77/100\n",
      "1668/1668 [==============================] - 4s 3ms/sample - loss: 0.5342 - accuracy: 0.7944 - val_loss: 1.0004 - val_accuracy: 0.6600\n",
      "Epoch 78/100\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5068 - accuracy: 0.8046 - val_loss: 1.0205 - val_accuracy: 0.6376\n",
      "Epoch 79/100\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4714 - accuracy: 0.8213 - val_loss: 0.9943 - val_accuracy: 0.6443\n",
      "Epoch 80/100\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5371 - accuracy: 0.7974 - val_loss: 1.0287 - val_accuracy: 0.6465\n",
      "Epoch 81/100\n",
      "1668/1668 [==============================] - 4s 3ms/sample - loss: 0.5394 - accuracy: 0.7986 - val_loss: 1.0169 - val_accuracy: 0.6488\n",
      "Epoch 82/100\n",
      "1668/1668 [==============================] - 4s 3ms/sample - loss: 0.4879 - accuracy: 0.8040 - val_loss: 1.0023 - val_accuracy: 0.6398\n",
      "Epoch 83/100\n",
      "1668/1668 [==============================] - 4s 3ms/sample - loss: 0.4891 - accuracy: 0.8040 - val_loss: 1.0286 - val_accuracy: 0.6331\n",
      "Epoch 84/100\n",
      "1668/1668 [==============================] - 4s 3ms/sample - loss: 0.4712 - accuracy: 0.8171 - val_loss: 0.9969 - val_accuracy: 0.6577\n",
      "Epoch 85/100\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5094 - accuracy: 0.8034 - val_loss: 1.0339 - val_accuracy: 0.6331\n",
      "Epoch 86/100\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4760 - accuracy: 0.8207 - val_loss: 1.1381 - val_accuracy: 0.6421\n",
      "Epoch 87/100\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4967 - accuracy: 0.8016 - val_loss: 1.0941 - val_accuracy: 0.6309\n",
      "Epoch 88/100\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4628 - accuracy: 0.8249 - val_loss: 1.1093 - val_accuracy: 0.6018\n",
      "Epoch 89/100\n",
      "1668/1668 [==============================] - 4s 3ms/sample - loss: 0.5346 - accuracy: 0.7962 - val_loss: 1.0404 - val_accuracy: 0.6689\n",
      "Epoch 90/100\n",
      "1668/1668 [==============================] - 4s 3ms/sample - loss: 0.4789 - accuracy: 0.8135 - val_loss: 1.0948 - val_accuracy: 0.6376\n",
      "Epoch 91/100\n",
      "1668/1668 [==============================] - 4s 3ms/sample - loss: 0.4902 - accuracy: 0.8189 - val_loss: 1.0619 - val_accuracy: 0.6331\n",
      "Epoch 92/100\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5018 - accuracy: 0.8052 - val_loss: 1.0918 - val_accuracy: 0.6309\n",
      "Epoch 93/100\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4551 - accuracy: 0.8297 - val_loss: 1.0397 - val_accuracy: 0.6443\n",
      "Epoch 94/100\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4431 - accuracy: 0.8321 - val_loss: 1.1738 - val_accuracy: 0.6309\n",
      "Epoch 95/100\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4370 - accuracy: 0.8315 - val_loss: 1.1489 - val_accuracy: 0.6376\n",
      "Epoch 96/100\n",
      "1668/1668 [==============================] - 4s 3ms/sample - loss: 0.5004 - accuracy: 0.8159 - val_loss: 1.1042 - val_accuracy: 0.6510\n",
      "Epoch 97/100\n",
      "1668/1668 [==============================] - 4s 3ms/sample - loss: 0.4157 - accuracy: 0.8375 - val_loss: 1.0911 - val_accuracy: 0.6309\n",
      "Epoch 98/100\n",
      "1668/1668 [==============================] - 4s 3ms/sample - loss: 0.4181 - accuracy: 0.8381 - val_loss: 1.0753 - val_accuracy: 0.6398\n",
      "Epoch 99/100\n",
      "1668/1668 [==============================] - 4s 3ms/sample - loss: 0.4245 - accuracy: 0.8411 - val_loss: 1.0689 - val_accuracy: 0.6421\n",
      "Epoch 100/100\n",
      "1668/1668 [==============================] - 4s 3ms/sample - loss: 0.3856 - accuracy: 0.8465 - val_loss: 1.0674 - val_accuracy: 0.6488\n"
     ]
    }
   ],
   "source": [
    "# Compiling the model\n",
    "basic_cnn_model.compile(loss='categorical_crossentropy',\n",
    "                 optimizer=cnn_optimizer,\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "# Training and validating the model\n",
    "basic_cnn_model_results = basic_cnn_model.fit(x_train,\n",
    "             y_train,\n",
    "             batch_size=64,\n",
    "             epochs=epochs,\n",
    "             validation_data=(x_valid, y_valid), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting accuracy trajectory\n",
    "plt.plot(basic_cnn_model_results.history['accuracy'])\n",
    "plt.plot(basic_cnn_model_results.history['val_accuracy'])\n",
    "plt.title('Basic CNN model accuracy trajectory')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plotting loss trajectory\n",
    "plt.plot(basic_cnn_model_results.history['loss'],'o')\n",
    "plt.plot(basic_cnn_model_results.history['val_loss'],'o')\n",
    "plt.title('Basic CNN model loss trajectory')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of the basic CNN model: 0.65011287\n"
     ]
    }
   ],
   "source": [
    "## Testing the basic CNN model\n",
    "\n",
    "cnn_score = basic_cnn_model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test accuracy of the basic CNN model:',cnn_score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 1000, 1, 25)       5525      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 334, 1, 25)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 334, 1, 25)        100       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 334, 1, 25)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 334, 1, 50)        12550     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 112, 1, 50)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 112, 1, 50)        200       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 112, 1, 50)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 112, 1, 100)       50100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 38, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 38, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 38, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 38, 1, 200)        200200    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 13, 1, 200)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 13, 1, 200)        800       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 13, 1, 200)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 1, 400)        800400    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 5, 1, 400)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 5, 1, 400)         1600      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 5, 1, 400)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2000)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4)                 8004      \n",
      "=================================================================\n",
      "Total params: 1,079,879\n",
      "Trainable params: 1,078,329\n",
      "Non-trainable params: 1,550\n",
      "_________________________________________________________________\n",
      "Train on 1668 samples, validate on 447 samples\n",
      "Epoch 1/100\n",
      "1668/1668 [==============================] - 8s 5ms/sample - loss: 2.4350 - accuracy: 0.2716 - val_loss: 3.1215 - val_accuracy: 0.2506\n",
      "Epoch 2/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 2.1684 - accuracy: 0.3189 - val_loss: 1.6867 - val_accuracy: 0.3378\n",
      "Epoch 3/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 1.9749 - accuracy: 0.2950 - val_loss: 2.7319 - val_accuracy: 0.3043\n",
      "Epoch 4/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 1.8739 - accuracy: 0.3070 - val_loss: 2.1105 - val_accuracy: 0.3266\n",
      "Epoch 5/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 1.7729 - accuracy: 0.3381 - val_loss: 1.6714 - val_accuracy: 0.3110\n",
      "Epoch 6/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 1.6209 - accuracy: 0.3633 - val_loss: 1.3176 - val_accuracy: 0.3937\n",
      "Epoch 7/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 1.6581 - accuracy: 0.3351 - val_loss: 1.4121 - val_accuracy: 0.3647\n",
      "Epoch 8/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 1.5919 - accuracy: 0.3813 - val_loss: 1.4668 - val_accuracy: 0.3647\n",
      "Epoch 9/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 1.6336 - accuracy: 0.3669 - val_loss: 1.3541 - val_accuracy: 0.3937\n",
      "Epoch 10/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 1.4896 - accuracy: 0.3933 - val_loss: 1.3460 - val_accuracy: 0.4072\n",
      "Epoch 11/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 1.4847 - accuracy: 0.4089 - val_loss: 1.4935 - val_accuracy: 0.3915\n",
      "Epoch 12/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 1.4396 - accuracy: 0.4209 - val_loss: 1.9093 - val_accuracy: 0.3468\n",
      "Epoch 13/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 1.3819 - accuracy: 0.4287 - val_loss: 1.2521 - val_accuracy: 0.4430\n",
      "Epoch 14/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 1.3687 - accuracy: 0.4400 - val_loss: 1.7039 - val_accuracy: 0.3020\n",
      "Epoch 15/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 1.3575 - accuracy: 0.4616 - val_loss: 1.3188 - val_accuracy: 0.4295\n",
      "Epoch 16/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 1.3157 - accuracy: 0.4772 - val_loss: 1.3475 - val_accuracy: 0.4004\n",
      "Epoch 17/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 1.2698 - accuracy: 0.4832 - val_loss: 1.5295 - val_accuracy: 0.4609\n",
      "Epoch 18/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 1.3027 - accuracy: 0.4892 - val_loss: 1.3087 - val_accuracy: 0.4340\n",
      "Epoch 19/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 1.2181 - accuracy: 0.4952 - val_loss: 1.4189 - val_accuracy: 0.4452\n",
      "Epoch 20/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 1.2000 - accuracy: 0.5228 - val_loss: 1.3230 - val_accuracy: 0.4743\n",
      "Epoch 21/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 1.2050 - accuracy: 0.5198 - val_loss: 1.5379 - val_accuracy: 0.3691\n",
      "Epoch 22/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 1.1634 - accuracy: 0.5264 - val_loss: 1.2368 - val_accuracy: 0.4698\n",
      "Epoch 23/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 1.1488 - accuracy: 0.5264 - val_loss: 1.1718 - val_accuracy: 0.5280\n",
      "Epoch 24/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 1.1087 - accuracy: 0.5408 - val_loss: 1.4145 - val_accuracy: 0.4228\n",
      "Epoch 25/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 1.1278 - accuracy: 0.5516 - val_loss: 1.3215 - val_accuracy: 0.4765\n",
      "Epoch 26/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 1.0444 - accuracy: 0.5863 - val_loss: 1.2343 - val_accuracy: 0.5078\n",
      "Epoch 27/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 1.0657 - accuracy: 0.5635 - val_loss: 1.2286 - val_accuracy: 0.5011\n",
      "Epoch 28/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 1.0255 - accuracy: 0.6019 - val_loss: 1.2952 - val_accuracy: 0.4720\n",
      "Epoch 29/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 1.1249 - accuracy: 0.5606 - val_loss: 1.3408 - val_accuracy: 0.4362\n",
      "Epoch 30/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 1.0124 - accuracy: 0.5857 - val_loss: 1.1923 - val_accuracy: 0.5324\n",
      "Epoch 31/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 1.0082 - accuracy: 0.5977 - val_loss: 1.2526 - val_accuracy: 0.5034\n",
      "Epoch 32/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 0.9692 - accuracy: 0.6229 - val_loss: 1.3237 - val_accuracy: 0.5056\n",
      "Epoch 33/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 0.9646 - accuracy: 0.6175 - val_loss: 1.5663 - val_accuracy: 0.4497\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 0.9889 - accuracy: 0.5947 - val_loss: 1.2767 - val_accuracy: 0.5235\n",
      "Epoch 35/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 1.0108 - accuracy: 0.5965 - val_loss: 1.4155 - val_accuracy: 0.5101\n",
      "Epoch 36/100\n",
      "1668/1668 [==============================] - 8s 5ms/sample - loss: 0.9780 - accuracy: 0.6199 - val_loss: 1.2645 - val_accuracy: 0.5101\n",
      "Epoch 37/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 0.9107 - accuracy: 0.6439 - val_loss: 1.1839 - val_accuracy: 0.5414\n",
      "Epoch 38/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 0.8610 - accuracy: 0.6427 - val_loss: 1.2422 - val_accuracy: 0.5481\n",
      "Epoch 39/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 0.8367 - accuracy: 0.6673 - val_loss: 1.4071 - val_accuracy: 0.5280\n",
      "Epoch 40/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 0.8676 - accuracy: 0.6607 - val_loss: 1.2684 - val_accuracy: 0.5615\n",
      "Epoch 41/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 0.8901 - accuracy: 0.6469 - val_loss: 1.2323 - val_accuracy: 0.5347\n",
      "Epoch 42/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 0.7885 - accuracy: 0.6924 - val_loss: 1.1791 - val_accuracy: 0.5660\n",
      "Epoch 43/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 0.7972 - accuracy: 0.6781 - val_loss: 1.1374 - val_accuracy: 0.5884\n",
      "Epoch 44/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 0.7989 - accuracy: 0.6888 - val_loss: 1.2376 - val_accuracy: 0.5436\n",
      "Epoch 45/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 0.7881 - accuracy: 0.6865 - val_loss: 1.2118 - val_accuracy: 0.5928\n",
      "Epoch 46/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 0.7498 - accuracy: 0.7014 - val_loss: 1.1308 - val_accuracy: 0.5996\n",
      "Epoch 47/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 0.7317 - accuracy: 0.7206 - val_loss: 1.1208 - val_accuracy: 0.5973\n",
      "Epoch 48/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 0.7329 - accuracy: 0.7158 - val_loss: 1.2203 - val_accuracy: 0.5593\n",
      "Epoch 49/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 0.7521 - accuracy: 0.7056 - val_loss: 1.1931 - val_accuracy: 0.5817\n",
      "Epoch 50/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 0.7445 - accuracy: 0.7206 - val_loss: 1.1367 - val_accuracy: 0.5996\n",
      "Epoch 51/100\n",
      "1668/1668 [==============================] - 9s 5ms/sample - loss: 0.6993 - accuracy: 0.7296 - val_loss: 1.1022 - val_accuracy: 0.6152\n",
      "Epoch 52/100\n",
      "1668/1668 [==============================] - 8s 5ms/sample - loss: 0.7080 - accuracy: 0.7272 - val_loss: 1.2180 - val_accuracy: 0.5906\n",
      "Epoch 53/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 0.7203 - accuracy: 0.7206 - val_loss: 1.3989 - val_accuracy: 0.5817\n",
      "Epoch 54/100\n",
      "1668/1668 [==============================] - 8s 5ms/sample - loss: 0.6708 - accuracy: 0.7350 - val_loss: 1.3752 - val_accuracy: 0.5459\n",
      "Epoch 55/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 0.6250 - accuracy: 0.7476 - val_loss: 1.1900 - val_accuracy: 0.5951\n",
      "Epoch 56/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 0.6525 - accuracy: 0.7506 - val_loss: 1.2590 - val_accuracy: 0.5817\n",
      "Epoch 57/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 0.6318 - accuracy: 0.7458 - val_loss: 1.1930 - val_accuracy: 0.5973\n",
      "Epoch 58/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 0.5723 - accuracy: 0.7806 - val_loss: 1.2215 - val_accuracy: 0.6040\n",
      "Epoch 59/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 0.6584 - accuracy: 0.7368 - val_loss: 1.2165 - val_accuracy: 0.5973\n",
      "Epoch 60/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 0.5818 - accuracy: 0.7710 - val_loss: 1.2116 - val_accuracy: 0.5973\n",
      "Epoch 61/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 0.5866 - accuracy: 0.7626 - val_loss: 1.2207 - val_accuracy: 0.5906\n",
      "Epoch 62/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 0.5714 - accuracy: 0.7806 - val_loss: 1.3676 - val_accuracy: 0.5369\n",
      "Epoch 63/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 0.5460 - accuracy: 0.7962 - val_loss: 1.2540 - val_accuracy: 0.6197\n",
      "Epoch 64/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 0.5072 - accuracy: 0.7992 - val_loss: 1.2717 - val_accuracy: 0.5951\n",
      "Epoch 65/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 0.5733 - accuracy: 0.7752 - val_loss: 1.2951 - val_accuracy: 0.5996\n",
      "Epoch 66/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 0.5277 - accuracy: 0.7992 - val_loss: 1.3371 - val_accuracy: 0.5906\n",
      "Epoch 67/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 0.5392 - accuracy: 0.7968 - val_loss: 1.3448 - val_accuracy: 0.5951\n",
      "Epoch 68/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 0.5044 - accuracy: 0.8034 - val_loss: 1.2747 - val_accuracy: 0.5861\n",
      "Epoch 69/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 0.4855 - accuracy: 0.8118 - val_loss: 1.3320 - val_accuracy: 0.5794\n",
      "Epoch 70/100\n",
      "1668/1668 [==============================] - 8s 5ms/sample - loss: 0.6001 - accuracy: 0.7770 - val_loss: 1.3036 - val_accuracy: 0.5928\n",
      "Epoch 71/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 0.5082 - accuracy: 0.8058 - val_loss: 1.3180 - val_accuracy: 0.5951\n",
      "Epoch 72/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 0.4777 - accuracy: 0.8165 - val_loss: 1.4713 - val_accuracy: 0.5682\n",
      "Epoch 73/100\n",
      "1668/1668 [==============================] - 8s 5ms/sample - loss: 0.4871 - accuracy: 0.8183 - val_loss: 1.3019 - val_accuracy: 0.6063\n",
      "Epoch 74/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 0.4637 - accuracy: 0.8231 - val_loss: 1.2209 - val_accuracy: 0.6219\n",
      "Epoch 75/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 0.4165 - accuracy: 0.8447 - val_loss: 1.3175 - val_accuracy: 0.6197\n",
      "Epoch 76/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 0.3852 - accuracy: 0.8561 - val_loss: 1.3613 - val_accuracy: 0.6152\n",
      "Epoch 77/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 0.4314 - accuracy: 0.8303 - val_loss: 1.3234 - val_accuracy: 0.6197\n",
      "Epoch 78/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 0.4038 - accuracy: 0.8525 - val_loss: 1.2952 - val_accuracy: 0.6242\n",
      "Epoch 79/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 0.4171 - accuracy: 0.8477 - val_loss: 1.2332 - val_accuracy: 0.6532\n",
      "Epoch 80/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 0.3808 - accuracy: 0.8609 - val_loss: 1.2462 - val_accuracy: 0.6398\n",
      "Epoch 81/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 0.3594 - accuracy: 0.8669 - val_loss: 1.3139 - val_accuracy: 0.6421\n",
      "Epoch 82/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 0.3782 - accuracy: 0.8567 - val_loss: 1.2321 - val_accuracy: 0.6286\n",
      "Epoch 83/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 0.4388 - accuracy: 0.8429 - val_loss: 1.3473 - val_accuracy: 0.6219\n",
      "Epoch 84/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 0.4646 - accuracy: 0.8261 - val_loss: 1.3172 - val_accuracy: 0.6286\n",
      "Epoch 85/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 0.4755 - accuracy: 0.8243 - val_loss: 1.3084 - val_accuracy: 0.6309\n",
      "Epoch 86/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 0.4443 - accuracy: 0.8231 - val_loss: 1.5085 - val_accuracy: 0.6130\n",
      "Epoch 87/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 0.3857 - accuracy: 0.8537 - val_loss: 1.4001 - val_accuracy: 0.6242\n",
      "Epoch 88/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 0.3824 - accuracy: 0.8669 - val_loss: 1.3725 - val_accuracy: 0.6353\n",
      "Epoch 89/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 0.3340 - accuracy: 0.8657 - val_loss: 1.3342 - val_accuracy: 0.6331\n",
      "Epoch 90/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 0.3484 - accuracy: 0.8687 - val_loss: 1.4667 - val_accuracy: 0.6309\n",
      "Epoch 91/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 0.3566 - accuracy: 0.8681 - val_loss: 1.3278 - val_accuracy: 0.6577\n",
      "Epoch 92/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 0.3353 - accuracy: 0.8717 - val_loss: 1.3895 - val_accuracy: 0.6376\n",
      "Epoch 93/100\n",
      "1668/1668 [==============================] - 8s 5ms/sample - loss: 0.4236 - accuracy: 0.8375 - val_loss: 1.3945 - val_accuracy: 0.6152\n",
      "Epoch 94/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 0.3282 - accuracy: 0.8735 - val_loss: 1.3380 - val_accuracy: 0.6242\n",
      "Epoch 95/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 0.3397 - accuracy: 0.8735 - val_loss: 1.3858 - val_accuracy: 0.6331\n",
      "Epoch 96/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 0.3510 - accuracy: 0.8675 - val_loss: 1.3943 - val_accuracy: 0.6063\n",
      "Epoch 97/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 0.3282 - accuracy: 0.8657 - val_loss: 1.5715 - val_accuracy: 0.6107\n",
      "Epoch 98/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 0.2990 - accuracy: 0.8897 - val_loss: 1.3493 - val_accuracy: 0.6286\n",
      "Epoch 99/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 0.3171 - accuracy: 0.8849 - val_loss: 1.3632 - val_accuracy: 0.6242\n",
      "Epoch 100/100\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 0.3078 - accuracy: 0.8933 - val_loss: 1.4046 - val_accuracy: 0.6242\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of the basic CNN model: 0.59142214\n"
     ]
    }
   ],
   "source": [
    "# Building the CNN model using sequential class\n",
    "basic_cnn_model = Sequential()\n",
    "\n",
    "# Conv. block 1\n",
    "basic_cnn_model.add(Conv2D(filters=25, kernel_size=(10,1), padding='same', activation='elu', input_shape=(1000,1,22)))\n",
    "basic_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "basic_cnn_model.add(BatchNormalization())\n",
    "basic_cnn_model.add(Dropout(0.5))\n",
    "\n",
    "# Conv. block 2\n",
    "basic_cnn_model.add(Conv2D(filters=50, kernel_size=(10,1), padding='same', activation='elu'))\n",
    "basic_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "basic_cnn_model.add(BatchNormalization())\n",
    "basic_cnn_model.add(Dropout(0.5))\n",
    "\n",
    "# Conv. block 3\n",
    "basic_cnn_model.add(Conv2D(filters=100, kernel_size=(10,1), padding='same', activation='elu'))\n",
    "basic_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "basic_cnn_model.add(BatchNormalization())\n",
    "basic_cnn_model.add(Dropout(0.5))\n",
    "\n",
    "# Conv. block 4\n",
    "basic_cnn_model.add(Conv2D(filters=200, kernel_size=(10,1), padding='same', activation='elu'))\n",
    "basic_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "basic_cnn_model.add(BatchNormalization())\n",
    "basic_cnn_model.add(Dropout(0.5))\n",
    "\n",
    "# Conv. block 5\n",
    "basic_cnn_model.add(Conv2D(filters=400, kernel_size=(10,1), padding='same', activation='elu'))\n",
    "basic_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "basic_cnn_model.add(BatchNormalization())\n",
    "basic_cnn_model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "# Output layer with Softmax activation\n",
    "basic_cnn_model.add(Flatten()) # Flattens the input\n",
    "basic_cnn_model.add(Dense(4, activation='softmax')) # Output FC layer with softmax activation\n",
    "\n",
    "\n",
    "# Printing the model summary\n",
    "basic_cnn_model.summary()\n",
    "\n",
    "# Model parameters\n",
    "learning_rate = 1e-3\n",
    "epochs = 100\n",
    "cnn_optimizer = tf.keras.optimizers.Adam(lr=learning_rate)\n",
    "\n",
    "\n",
    "# Compiling the model\n",
    "basic_cnn_model.compile(loss='categorical_crossentropy',\n",
    "                 optimizer=cnn_optimizer,\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "# Stops if val loss does not improve over 15 epochs\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=15)\n",
    "\n",
    "\n",
    "# Training and validating the model\n",
    "\n",
    "basic_cnn_model_results = basic_cnn_model.fit(x_train,\n",
    "             y_train,\n",
    "             batch_size=64,\n",
    "             epochs=epochs,\n",
    "             validation_data=(x_valid, y_valid), verbose=True)#, callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "# Plotting accuracy trajectory\n",
    "plt.plot(basic_cnn_model_results.history['accuracy'])\n",
    "plt.plot(basic_cnn_model_results.history['val_accuracy'])\n",
    "plt.title('Basic CNN model accuracy trajectory')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plotting loss trajectory\n",
    "plt.plot(basic_cnn_model_results.history['loss'],'o')\n",
    "plt.plot(basic_cnn_model_results.history['val_loss'],'o')\n",
    "plt.title('Basic CNN model loss trajectory')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "## Testing the basic CNN model\n",
    "\n",
    "cnn_score = basic_cnn_model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test accuracy of the basic CNN model:',cnn_score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN + LSTM Model All data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 1000, 1, 25)       5525      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 334, 1, 25)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 334, 1, 25)        100       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 334, 1, 25)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 334, 1, 50)        12550     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 112, 1, 50)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 112, 1, 50)        200       \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 112, 1, 50)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 112, 1, 100)       50100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 38, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 38, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 38, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 38, 1, 200)        200200    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 13, 1, 200)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 13, 1, 200)        800       \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 13, 1, 200)        0         \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 13, 1, 150)        210600    \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 13, 1, 150)        600       \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 13, 1, 150)        180600    \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 13, 1, 150)        600       \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1950)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4)                 7804      \n",
      "=================================================================\n",
      "Total params: 670,079\n",
      "Trainable params: 668,729\n",
      "Non-trainable params: 1,350\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "rnn_model=Sequential()\n",
    "\n",
    "# Conv. block 1\n",
    "rnn_model.add(Conv2D(filters=25, kernel_size=(10,1), padding='same', activation='elu', input_shape=(1000,1,22)))\n",
    "rnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "rnn_model.add(BatchNormalization())\n",
    "rnn_model.add(Dropout(0.5))\n",
    "\n",
    "# Conv. block 2\n",
    "rnn_model.add(Conv2D(filters=50, kernel_size=(10,1), padding='same', activation='elu'))\n",
    "rnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "rnn_model.add(BatchNormalization())\n",
    "rnn_model.add(Dropout(0.5))\n",
    "\n",
    "# Conv. block 3\n",
    "rnn_model.add(Conv2D(filters=100, kernel_size=(10,1), padding='same', activation='elu'))\n",
    "rnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "rnn_model.add(BatchNormalization())\n",
    "rnn_model.add(Dropout(0.5))\n",
    "\n",
    "# Conv. block 4\n",
    "rnn_model.add(Conv2D(filters=200, kernel_size=(10,1), padding='same', activation='elu'))\n",
    "rnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "rnn_model.add(BatchNormalization())\n",
    "rnn_model.add(Dropout(0.5))\n",
    "\n",
    "#rnn_model.add(LSTM(64,input_shape=(1000,22),activation='relu',return_sequences=True))\n",
    "\n",
    "#rnn_model.add(Dropout(0.2))\n",
    "\n",
    "#rnn_model.add(LSTM(64,activation='relu', return_sequences=True))\n",
    "\n",
    "#rnn_model.add(Dropout(0.2))\n",
    "\n",
    "rnn_model.add(TimeDistributed(LSTM(150,dropout=0.5, recurrent_dropout=0.1,return_sequences=True,activation='elu')))\n",
    "#rnn_model.add(Dropout(0.5))\n",
    "rnn_model.add(BatchNormalization())\n",
    "\n",
    "rnn_model.add(TimeDistributed(LSTM(150,dropout=0.5, recurrent_dropout=0.1,return_sequences=True,activation='elu')))\n",
    "#rnn_model.add(Dropout(0.5))\n",
    "rnn_model.add(BatchNormalization())\n",
    "\n",
    "rnn_model.add(Flatten()) # Flattens the input\n",
    "\n",
    "rnn_model.add(Dense(4,activation='softmax'))\n",
    "\n",
    "\n",
    "rnn_optimizer = Adam(lr=1e-2)\n",
    "\n",
    "\n",
    "rnn_model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "print(rnn_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape of training set after adding width info: (1668, 22, 1000, 1)\n",
    "# Shape of validation set after adding width info: (447, 22, 1000, 1)\n",
    "# Shape of test set after adding width info: (443, 22, 1000, 1)\n",
    "\n",
    "# x_train_rnn = x_train.reshape((1668,1000,22))\n",
    "# y_train_rnn = y_train\n",
    "\n",
    "# x_valid_rnn = x_valid.reshape((447,1000,22))\n",
    "# y_valid_rnn = y_valid\n",
    "\n",
    "# x_test_rnn = x_test.reshape((443,1000,22))\n",
    "# y_test_rnn = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1668 samples, validate on 447 samples\n",
      "Epoch 1/600\n",
      "1668/1668 [==============================] - 11s 7ms/sample - loss: 1.9370 - accuracy: 0.2542 - val_loss: 1.3965 - val_accuracy: 0.2931\n",
      "Epoch 2/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.8909 - accuracy: 0.2488 - val_loss: 1.3812 - val_accuracy: 0.2953\n",
      "Epoch 3/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.7551 - accuracy: 0.2668 - val_loss: 1.3762 - val_accuracy: 0.3154\n",
      "Epoch 4/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.7089 - accuracy: 0.2878 - val_loss: 1.3694 - val_accuracy: 0.3512\n",
      "Epoch 5/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.6601 - accuracy: 0.3082 - val_loss: 1.3667 - val_accuracy: 0.3356\n",
      "Epoch 6/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.7035 - accuracy: 0.2818 - val_loss: 1.3705 - val_accuracy: 0.3199\n",
      "Epoch 7/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.6131 - accuracy: 0.3213 - val_loss: 1.3584 - val_accuracy: 0.3647\n",
      "Epoch 8/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.6240 - accuracy: 0.2962 - val_loss: 1.3520 - val_accuracy: 0.3445\n",
      "Epoch 9/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.5578 - accuracy: 0.3195 - val_loss: 1.3534 - val_accuracy: 0.3378\n",
      "Epoch 10/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.5825 - accuracy: 0.3171 - val_loss: 1.3473 - val_accuracy: 0.3647\n",
      "Epoch 11/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.5902 - accuracy: 0.3082 - val_loss: 1.3475 - val_accuracy: 0.3423\n",
      "Epoch 12/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.5579 - accuracy: 0.3303 - val_loss: 1.3391 - val_accuracy: 0.3400\n",
      "Epoch 13/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.5349 - accuracy: 0.3255 - val_loss: 1.3333 - val_accuracy: 0.3691\n",
      "Epoch 14/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.5058 - accuracy: 0.3507 - val_loss: 1.3394 - val_accuracy: 0.3400\n",
      "Epoch 15/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.5030 - accuracy: 0.3351 - val_loss: 1.3402 - val_accuracy: 0.3311\n",
      "Epoch 16/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.5195 - accuracy: 0.3405 - val_loss: 1.3396 - val_accuracy: 0.3423\n",
      "Epoch 17/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.4621 - accuracy: 0.3669 - val_loss: 1.3365 - val_accuracy: 0.3244\n",
      "Epoch 18/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.4827 - accuracy: 0.3543 - val_loss: 1.3319 - val_accuracy: 0.3490\n",
      "Epoch 19/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.4621 - accuracy: 0.3525 - val_loss: 1.3417 - val_accuracy: 0.3423\n",
      "Epoch 20/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.4674 - accuracy: 0.3633 - val_loss: 1.3564 - val_accuracy: 0.3289\n",
      "Epoch 21/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.4573 - accuracy: 0.3549 - val_loss: 1.3333 - val_accuracy: 0.3400\n",
      "Epoch 22/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.4132 - accuracy: 0.3687 - val_loss: 1.3334 - val_accuracy: 0.3400\n",
      "Epoch 23/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.4343 - accuracy: 0.3603 - val_loss: 1.3249 - val_accuracy: 0.3468\n",
      "Epoch 24/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.4472 - accuracy: 0.3609 - val_loss: 1.3066 - val_accuracy: 0.3647\n",
      "Epoch 25/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.3975 - accuracy: 0.3717 - val_loss: 1.3115 - val_accuracy: 0.3848\n",
      "Epoch 26/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.4001 - accuracy: 0.3807 - val_loss: 1.3057 - val_accuracy: 0.3781\n",
      "Epoch 27/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.4077 - accuracy: 0.3717 - val_loss: 1.3226 - val_accuracy: 0.3400\n",
      "Epoch 28/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.4059 - accuracy: 0.3573 - val_loss: 1.2778 - val_accuracy: 0.3803\n",
      "Epoch 29/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.3962 - accuracy: 0.3639 - val_loss: 1.2877 - val_accuracy: 0.3826\n",
      "Epoch 30/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.3860 - accuracy: 0.3783 - val_loss: 1.2949 - val_accuracy: 0.3870\n",
      "Epoch 31/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.3943 - accuracy: 0.3807 - val_loss: 1.2787 - val_accuracy: 0.3647\n",
      "Epoch 32/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.3379 - accuracy: 0.3945 - val_loss: 1.2579 - val_accuracy: 0.3960\n",
      "Epoch 33/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.3489 - accuracy: 0.3873 - val_loss: 1.2606 - val_accuracy: 0.3803\n",
      "Epoch 34/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.3944 - accuracy: 0.3801 - val_loss: 1.3135 - val_accuracy: 0.3781\n",
      "Epoch 35/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.3487 - accuracy: 0.3921 - val_loss: 1.2744 - val_accuracy: 0.3781\n",
      "Epoch 36/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.3182 - accuracy: 0.3969 - val_loss: 1.2717 - val_accuracy: 0.3781\n",
      "Epoch 37/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.2991 - accuracy: 0.4137 - val_loss: 1.2881 - val_accuracy: 0.3826\n",
      "Epoch 38/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.3065 - accuracy: 0.4179 - val_loss: 1.2542 - val_accuracy: 0.3960\n",
      "Epoch 39/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.2991 - accuracy: 0.4245 - val_loss: 1.2427 - val_accuracy: 0.4161\n",
      "Epoch 40/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.2829 - accuracy: 0.4221 - val_loss: 1.2666 - val_accuracy: 0.4004\n",
      "Epoch 41/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.2672 - accuracy: 0.4239 - val_loss: 1.3336 - val_accuracy: 0.3736\n",
      "Epoch 42/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.3016 - accuracy: 0.4269 - val_loss: 1.2714 - val_accuracy: 0.3893\n",
      "Epoch 43/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.2829 - accuracy: 0.4341 - val_loss: 1.3289 - val_accuracy: 0.3781\n",
      "Epoch 44/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.2656 - accuracy: 0.4412 - val_loss: 1.2941 - val_accuracy: 0.3781\n",
      "Epoch 45/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.2846 - accuracy: 0.4269 - val_loss: 1.3031 - val_accuracy: 0.3848\n",
      "Epoch 46/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.3240 - accuracy: 0.4113 - val_loss: 1.2915 - val_accuracy: 0.3937\n",
      "Epoch 47/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.2486 - accuracy: 0.4436 - val_loss: 1.2373 - val_accuracy: 0.4206\n",
      "Epoch 48/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.3012 - accuracy: 0.4472 - val_loss: 1.2950 - val_accuracy: 0.3960\n",
      "Epoch 49/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.2605 - accuracy: 0.4329 - val_loss: 1.2767 - val_accuracy: 0.3781\n",
      "Epoch 50/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.2678 - accuracy: 0.4269 - val_loss: 1.2496 - val_accuracy: 0.4161\n",
      "Epoch 51/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.2469 - accuracy: 0.4490 - val_loss: 1.2180 - val_accuracy: 0.4273\n",
      "Epoch 52/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.2634 - accuracy: 0.4442 - val_loss: 1.2281 - val_accuracy: 0.4228\n",
      "Epoch 53/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.2231 - accuracy: 0.4436 - val_loss: 1.2630 - val_accuracy: 0.4139\n",
      "Epoch 54/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.2384 - accuracy: 0.4508 - val_loss: 1.2362 - val_accuracy: 0.4251\n",
      "Epoch 55/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.2154 - accuracy: 0.4724 - val_loss: 1.2311 - val_accuracy: 0.4072\n",
      "Epoch 56/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.2178 - accuracy: 0.4700 - val_loss: 1.2107 - val_accuracy: 0.4407\n",
      "Epoch 57/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.2444 - accuracy: 0.4430 - val_loss: 1.2566 - val_accuracy: 0.4228\n",
      "Epoch 58/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.2044 - accuracy: 0.4646 - val_loss: 1.3005 - val_accuracy: 0.4116\n",
      "Epoch 59/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.2441 - accuracy: 0.4478 - val_loss: 1.2504 - val_accuracy: 0.4295\n",
      "Epoch 60/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.2394 - accuracy: 0.4430 - val_loss: 1.2288 - val_accuracy: 0.4362\n",
      "Epoch 61/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.2194 - accuracy: 0.4628 - val_loss: 1.2049 - val_accuracy: 0.4653\n",
      "Epoch 62/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.2753 - accuracy: 0.4400 - val_loss: 1.3995 - val_accuracy: 0.4072\n",
      "Epoch 63/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.2954 - accuracy: 0.4305 - val_loss: 1.2868 - val_accuracy: 0.4027\n",
      "Epoch 64/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.2468 - accuracy: 0.4347 - val_loss: 1.2929 - val_accuracy: 0.4139\n",
      "Epoch 65/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.2285 - accuracy: 0.4412 - val_loss: 1.2531 - val_accuracy: 0.4183\n",
      "Epoch 66/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.2008 - accuracy: 0.4742 - val_loss: 1.2378 - val_accuracy: 0.4139\n",
      "Epoch 67/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.1889 - accuracy: 0.4820 - val_loss: 1.2768 - val_accuracy: 0.4161\n",
      "Epoch 68/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.2186 - accuracy: 0.4604 - val_loss: 1.2223 - val_accuracy: 0.4251\n",
      "Epoch 69/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.2083 - accuracy: 0.4670 - val_loss: 1.2175 - val_accuracy: 0.4407\n",
      "Epoch 70/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.1864 - accuracy: 0.4802 - val_loss: 1.2300 - val_accuracy: 0.4385\n",
      "Epoch 71/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.2052 - accuracy: 0.4628 - val_loss: 1.2231 - val_accuracy: 0.4318\n",
      "Epoch 72/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.2057 - accuracy: 0.4634 - val_loss: 1.2246 - val_accuracy: 0.4676\n",
      "Epoch 73/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.1998 - accuracy: 0.4664 - val_loss: 1.2364 - val_accuracy: 0.4474\n",
      "Epoch 74/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.1782 - accuracy: 0.4820 - val_loss: 1.2050 - val_accuracy: 0.4631\n",
      "Epoch 75/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.1884 - accuracy: 0.4892 - val_loss: 1.2415 - val_accuracy: 0.4497\n",
      "Epoch 76/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.1848 - accuracy: 0.4838 - val_loss: 1.2481 - val_accuracy: 0.4295\n",
      "Epoch 77/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.2092 - accuracy: 0.4598 - val_loss: 1.2310 - val_accuracy: 0.4497\n",
      "Epoch 78/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.1856 - accuracy: 0.4748 - val_loss: 1.2193 - val_accuracy: 0.4161\n",
      "Epoch 79/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.1960 - accuracy: 0.4598 - val_loss: 1.2374 - val_accuracy: 0.4564\n",
      "Epoch 80/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.2171 - accuracy: 0.4568 - val_loss: 1.2127 - val_accuracy: 0.4430\n",
      "Epoch 81/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.1543 - accuracy: 0.4940 - val_loss: 1.2020 - val_accuracy: 0.4362\n",
      "Epoch 82/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.1711 - accuracy: 0.4928 - val_loss: 1.1997 - val_accuracy: 0.4497\n",
      "Epoch 83/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.1592 - accuracy: 0.4964 - val_loss: 1.2142 - val_accuracy: 0.4407\n",
      "Epoch 84/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.1753 - accuracy: 0.4784 - val_loss: 1.2595 - val_accuracy: 0.4318\n",
      "Epoch 85/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.1395 - accuracy: 0.4958 - val_loss: 1.1898 - val_accuracy: 0.4631\n",
      "Epoch 86/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.1730 - accuracy: 0.4814 - val_loss: 1.2253 - val_accuracy: 0.4541\n",
      "Epoch 87/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.1532 - accuracy: 0.4994 - val_loss: 1.1976 - val_accuracy: 0.4273\n",
      "Epoch 88/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.1485 - accuracy: 0.4976 - val_loss: 1.2515 - val_accuracy: 0.4340\n",
      "Epoch 89/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.1285 - accuracy: 0.4988 - val_loss: 1.2103 - val_accuracy: 0.4519\n",
      "Epoch 90/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.1228 - accuracy: 0.5168 - val_loss: 1.2484 - val_accuracy: 0.4497\n",
      "Epoch 91/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.1500 - accuracy: 0.5030 - val_loss: 1.2098 - val_accuracy: 0.4519\n",
      "Epoch 92/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.1803 - accuracy: 0.4892 - val_loss: 1.2731 - val_accuracy: 0.4541\n",
      "Epoch 93/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.1778 - accuracy: 0.5006 - val_loss: 1.2722 - val_accuracy: 0.4362\n",
      "Epoch 94/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.1521 - accuracy: 0.4892 - val_loss: 1.2195 - val_accuracy: 0.4318\n",
      "Epoch 95/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.1145 - accuracy: 0.5072 - val_loss: 1.2937 - val_accuracy: 0.4318\n",
      "Epoch 96/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.1247 - accuracy: 0.4982 - val_loss: 1.2745 - val_accuracy: 0.4430\n",
      "Epoch 97/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.1519 - accuracy: 0.5042 - val_loss: 1.2521 - val_accuracy: 0.4452\n",
      "Epoch 98/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.1620 - accuracy: 0.4946 - val_loss: 1.3014 - val_accuracy: 0.4228\n",
      "Epoch 99/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.1652 - accuracy: 0.4964 - val_loss: 1.3030 - val_accuracy: 0.4228\n",
      "Epoch 100/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.1446 - accuracy: 0.5012 - val_loss: 1.2184 - val_accuracy: 0.4609\n",
      "Epoch 101/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.1199 - accuracy: 0.5216 - val_loss: 1.2580 - val_accuracy: 0.4631\n",
      "Epoch 102/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.0973 - accuracy: 0.5246 - val_loss: 1.2442 - val_accuracy: 0.4430\n",
      "Epoch 103/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.0951 - accuracy: 0.5222 - val_loss: 1.3740 - val_accuracy: 0.4094\n",
      "Epoch 104/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.1249 - accuracy: 0.5246 - val_loss: 1.2917 - val_accuracy: 0.4251\n",
      "Epoch 105/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.1735 - accuracy: 0.4940 - val_loss: 1.2273 - val_accuracy: 0.4519\n",
      "Epoch 106/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.1297 - accuracy: 0.5084 - val_loss: 1.2283 - val_accuracy: 0.4295\n",
      "Epoch 107/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.1269 - accuracy: 0.5126 - val_loss: 1.2159 - val_accuracy: 0.4609\n",
      "Epoch 108/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.1173 - accuracy: 0.5096 - val_loss: 1.2460 - val_accuracy: 0.4385\n",
      "Epoch 109/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.1149 - accuracy: 0.5162 - val_loss: 1.2568 - val_accuracy: 0.4407\n",
      "Epoch 110/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.1159 - accuracy: 0.5162 - val_loss: 1.2226 - val_accuracy: 0.4340\n",
      "Epoch 111/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.1215 - accuracy: 0.5174 - val_loss: 1.3089 - val_accuracy: 0.4273\n",
      "Epoch 112/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.0976 - accuracy: 0.5186 - val_loss: 1.2564 - val_accuracy: 0.4430\n",
      "Epoch 113/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.1005 - accuracy: 0.5150 - val_loss: 1.2436 - val_accuracy: 0.4385\n",
      "Epoch 114/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.0958 - accuracy: 0.5360 - val_loss: 1.2722 - val_accuracy: 0.4228\n",
      "Epoch 115/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.0734 - accuracy: 0.5384 - val_loss: 1.2609 - val_accuracy: 0.4139\n",
      "Epoch 116/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.1041 - accuracy: 0.5288 - val_loss: 1.2285 - val_accuracy: 0.4027\n",
      "Epoch 117/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.1142 - accuracy: 0.5138 - val_loss: 1.3267 - val_accuracy: 0.4116\n",
      "Epoch 118/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.1304 - accuracy: 0.5222 - val_loss: 1.2355 - val_accuracy: 0.4474\n",
      "Epoch 119/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.1018 - accuracy: 0.5216 - val_loss: 1.2834 - val_accuracy: 0.4228\n",
      "Epoch 120/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.1107 - accuracy: 0.5126 - val_loss: 1.2249 - val_accuracy: 0.4519\n",
      "Epoch 121/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.1189 - accuracy: 0.5114 - val_loss: 1.3439 - val_accuracy: 0.4273\n",
      "Epoch 122/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.1306 - accuracy: 0.5210 - val_loss: 1.2250 - val_accuracy: 0.4497\n",
      "Epoch 123/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.1346 - accuracy: 0.5126 - val_loss: 1.2562 - val_accuracy: 0.4474\n",
      "Epoch 124/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.1272 - accuracy: 0.5120 - val_loss: 1.2950 - val_accuracy: 0.4072\n",
      "Epoch 125/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.0844 - accuracy: 0.5240 - val_loss: 1.3281 - val_accuracy: 0.4251\n",
      "Epoch 126/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.0663 - accuracy: 0.5378 - val_loss: 1.2447 - val_accuracy: 0.4787\n",
      "Epoch 127/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.0741 - accuracy: 0.5408 - val_loss: 1.2807 - val_accuracy: 0.4318\n",
      "Epoch 128/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.0607 - accuracy: 0.5492 - val_loss: 1.3143 - val_accuracy: 0.4407\n",
      "Epoch 129/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.0739 - accuracy: 0.5492 - val_loss: 1.3469 - val_accuracy: 0.4139\n",
      "Epoch 130/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.0544 - accuracy: 0.5516 - val_loss: 1.3172 - val_accuracy: 0.4273\n",
      "Epoch 131/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.0525 - accuracy: 0.5492 - val_loss: 1.3041 - val_accuracy: 0.4430\n",
      "Epoch 132/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.0432 - accuracy: 0.5468 - val_loss: 1.2961 - val_accuracy: 0.4072\n",
      "Epoch 133/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.0418 - accuracy: 0.5600 - val_loss: 1.2868 - val_accuracy: 0.4049\n",
      "Epoch 134/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.0451 - accuracy: 0.5420 - val_loss: 1.2844 - val_accuracy: 0.4407\n",
      "Epoch 135/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.0691 - accuracy: 0.5414 - val_loss: 1.2949 - val_accuracy: 0.4340\n",
      "Epoch 136/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.0676 - accuracy: 0.5402 - val_loss: 1.3331 - val_accuracy: 0.4228\n",
      "Epoch 137/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.0761 - accuracy: 0.5336 - val_loss: 1.3830 - val_accuracy: 0.4251\n",
      "Epoch 138/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.0850 - accuracy: 0.5420 - val_loss: 1.2767 - val_accuracy: 0.4497\n",
      "Epoch 139/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.0474 - accuracy: 0.5737 - val_loss: 1.2812 - val_accuracy: 0.4653\n",
      "Epoch 140/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.0290 - accuracy: 0.5683 - val_loss: 1.2618 - val_accuracy: 0.4519\n",
      "Epoch 141/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.0426 - accuracy: 0.5743 - val_loss: 1.2955 - val_accuracy: 0.4474\n",
      "Epoch 142/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.0806 - accuracy: 0.5426 - val_loss: 1.2547 - val_accuracy: 0.4676\n",
      "Epoch 143/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.0458 - accuracy: 0.5659 - val_loss: 1.2458 - val_accuracy: 0.4877\n",
      "Epoch 144/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.0464 - accuracy: 0.5665 - val_loss: 1.2348 - val_accuracy: 0.4497\n",
      "Epoch 145/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.0378 - accuracy: 0.5528 - val_loss: 1.2515 - val_accuracy: 0.4765\n",
      "Epoch 146/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.0376 - accuracy: 0.5761 - val_loss: 1.2352 - val_accuracy: 0.4676\n",
      "Epoch 147/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.0289 - accuracy: 0.5624 - val_loss: 1.2672 - val_accuracy: 0.4631\n",
      "Epoch 148/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.0307 - accuracy: 0.5833 - val_loss: 1.3331 - val_accuracy: 0.4385\n",
      "Epoch 149/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.0271 - accuracy: 0.5671 - val_loss: 1.2449 - val_accuracy: 0.4787\n",
      "Epoch 150/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.0384 - accuracy: 0.5671 - val_loss: 1.2302 - val_accuracy: 0.4832\n",
      "Epoch 151/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.0152 - accuracy: 0.5737 - val_loss: 1.2883 - val_accuracy: 0.4877\n",
      "Epoch 152/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.0097 - accuracy: 0.5701 - val_loss: 1.2920 - val_accuracy: 0.4989\n",
      "Epoch 153/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.0023 - accuracy: 0.5773 - val_loss: 1.2279 - val_accuracy: 0.4922\n",
      "Epoch 154/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.0003 - accuracy: 0.5731 - val_loss: 1.2690 - val_accuracy: 0.4877\n",
      "Epoch 155/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.9728 - accuracy: 0.6025 - val_loss: 1.3098 - val_accuracy: 0.4474\n",
      "Epoch 156/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.9640 - accuracy: 0.6157 - val_loss: 1.2529 - val_accuracy: 0.4720\n",
      "Epoch 157/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.0137 - accuracy: 0.5779 - val_loss: 1.3714 - val_accuracy: 0.4497\n",
      "Epoch 158/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.0397 - accuracy: 0.5761 - val_loss: 1.3599 - val_accuracy: 0.4385\n",
      "Epoch 159/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.0101 - accuracy: 0.5815 - val_loss: 1.2874 - val_accuracy: 0.4452\n",
      "Epoch 160/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.9844 - accuracy: 0.5971 - val_loss: 1.2664 - val_accuracy: 0.4698\n",
      "Epoch 161/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.9799 - accuracy: 0.5989 - val_loss: 1.2457 - val_accuracy: 0.4698\n",
      "Epoch 162/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.9544 - accuracy: 0.6055 - val_loss: 1.2599 - val_accuracy: 0.4765\n",
      "Epoch 163/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.9496 - accuracy: 0.6115 - val_loss: 1.2452 - val_accuracy: 0.4698\n",
      "Epoch 164/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.9694 - accuracy: 0.5887 - val_loss: 1.2538 - val_accuracy: 0.4720\n",
      "Epoch 165/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.9536 - accuracy: 0.5941 - val_loss: 1.3016 - val_accuracy: 0.4676\n",
      "Epoch 166/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.9895 - accuracy: 0.5797 - val_loss: 1.3125 - val_accuracy: 0.4586\n",
      "Epoch 167/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.9356 - accuracy: 0.6151 - val_loss: 1.2450 - val_accuracy: 0.4944\n",
      "Epoch 168/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.9193 - accuracy: 0.6373 - val_loss: 1.3256 - val_accuracy: 0.4586\n",
      "Epoch 169/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.9546 - accuracy: 0.5959 - val_loss: 1.2951 - val_accuracy: 0.4519\n",
      "Epoch 170/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.9505 - accuracy: 0.6259 - val_loss: 1.2584 - val_accuracy: 0.5056\n",
      "Epoch 171/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.9578 - accuracy: 0.6139 - val_loss: 1.3514 - val_accuracy: 0.4474\n",
      "Epoch 172/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.9354 - accuracy: 0.6049 - val_loss: 1.2873 - val_accuracy: 0.4832\n",
      "Epoch 173/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.9250 - accuracy: 0.6283 - val_loss: 1.2750 - val_accuracy: 0.4765\n",
      "Epoch 174/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.9614 - accuracy: 0.5875 - val_loss: 1.3783 - val_accuracy: 0.4340\n",
      "Epoch 175/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.9128 - accuracy: 0.6169 - val_loss: 1.2999 - val_accuracy: 0.4720\n",
      "Epoch 176/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.9163 - accuracy: 0.6283 - val_loss: 1.2680 - val_accuracy: 0.4676\n",
      "Epoch 177/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.9063 - accuracy: 0.6355 - val_loss: 1.2580 - val_accuracy: 0.5034\n",
      "Epoch 178/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.9034 - accuracy: 0.6307 - val_loss: 1.2940 - val_accuracy: 0.4787\n",
      "Epoch 179/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.9192 - accuracy: 0.6331 - val_loss: 1.2581 - val_accuracy: 0.5056\n",
      "Epoch 180/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.8858 - accuracy: 0.6379 - val_loss: 1.2010 - val_accuracy: 0.4877\n",
      "Epoch 181/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.8919 - accuracy: 0.6499 - val_loss: 1.2933 - val_accuracy: 0.4810\n",
      "Epoch 182/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.8966 - accuracy: 0.6187 - val_loss: 1.2644 - val_accuracy: 0.5034\n",
      "Epoch 183/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.8935 - accuracy: 0.6325 - val_loss: 1.2718 - val_accuracy: 0.5123\n",
      "Epoch 184/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.9004 - accuracy: 0.6391 - val_loss: 1.2433 - val_accuracy: 0.5369\n",
      "Epoch 185/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.9159 - accuracy: 0.6223 - val_loss: 1.4636 - val_accuracy: 0.4832\n",
      "Epoch 186/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.9250 - accuracy: 0.6079 - val_loss: 1.3645 - val_accuracy: 0.4832\n",
      "Epoch 187/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.9332 - accuracy: 0.6169 - val_loss: 1.3423 - val_accuracy: 0.4855\n",
      "Epoch 188/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.9013 - accuracy: 0.6445 - val_loss: 1.1965 - val_accuracy: 0.5302\n",
      "Epoch 189/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.8988 - accuracy: 0.6343 - val_loss: 1.1934 - val_accuracy: 0.5034\n",
      "Epoch 190/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.8840 - accuracy: 0.6427 - val_loss: 1.2813 - val_accuracy: 0.4810\n",
      "Epoch 191/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.8582 - accuracy: 0.6511 - val_loss: 1.2631 - val_accuracy: 0.5056\n",
      "Epoch 192/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.8851 - accuracy: 0.6415 - val_loss: 1.2334 - val_accuracy: 0.5324\n",
      "Epoch 193/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.8830 - accuracy: 0.6397 - val_loss: 1.2043 - val_accuracy: 0.5257\n",
      "Epoch 194/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.8656 - accuracy: 0.6457 - val_loss: 1.2096 - val_accuracy: 0.5324\n",
      "Epoch 195/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.8459 - accuracy: 0.6589 - val_loss: 1.2240 - val_accuracy: 0.5235\n",
      "Epoch 196/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.8390 - accuracy: 0.6679 - val_loss: 1.2519 - val_accuracy: 0.5280\n",
      "Epoch 197/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.8830 - accuracy: 0.6409 - val_loss: 1.2945 - val_accuracy: 0.4899\n",
      "Epoch 198/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.8447 - accuracy: 0.6517 - val_loss: 1.3481 - val_accuracy: 0.4922\n",
      "Epoch 199/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.8828 - accuracy: 0.6463 - val_loss: 1.3307 - val_accuracy: 0.4810\n",
      "Epoch 200/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.8909 - accuracy: 0.6427 - val_loss: 1.3030 - val_accuracy: 0.5168\n",
      "Epoch 201/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.8215 - accuracy: 0.6703 - val_loss: 1.2625 - val_accuracy: 0.5168\n",
      "Epoch 202/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.8474 - accuracy: 0.6523 - val_loss: 1.2829 - val_accuracy: 0.5302\n",
      "Epoch 203/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.8141 - accuracy: 0.6643 - val_loss: 1.2479 - val_accuracy: 0.5257\n",
      "Epoch 204/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.8293 - accuracy: 0.6589 - val_loss: 1.2109 - val_accuracy: 0.5503\n",
      "Epoch 205/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.8132 - accuracy: 0.6727 - val_loss: 1.1994 - val_accuracy: 0.5391\n",
      "Epoch 206/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.8357 - accuracy: 0.6655 - val_loss: 1.2299 - val_accuracy: 0.5503\n",
      "Epoch 207/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.8798 - accuracy: 0.6367 - val_loss: 1.3433 - val_accuracy: 0.5324\n",
      "Epoch 208/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.8915 - accuracy: 0.6385 - val_loss: 1.3115 - val_accuracy: 0.5302\n",
      "Epoch 209/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.9076 - accuracy: 0.6211 - val_loss: 1.2431 - val_accuracy: 0.5302\n",
      "Epoch 210/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.8310 - accuracy: 0.6565 - val_loss: 1.2307 - val_accuracy: 0.5459\n",
      "Epoch 211/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.8457 - accuracy: 0.6535 - val_loss: 1.2045 - val_accuracy: 0.5302\n",
      "Epoch 212/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.8402 - accuracy: 0.6589 - val_loss: 1.1941 - val_accuracy: 0.5526\n",
      "Epoch 213/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.8156 - accuracy: 0.6589 - val_loss: 1.1626 - val_accuracy: 0.5638\n",
      "Epoch 214/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.8301 - accuracy: 0.6799 - val_loss: 1.2203 - val_accuracy: 0.5548\n",
      "Epoch 215/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.8574 - accuracy: 0.6613 - val_loss: 1.1796 - val_accuracy: 0.5570\n",
      "Epoch 216/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.8370 - accuracy: 0.6535 - val_loss: 1.2323 - val_accuracy: 0.5638\n",
      "Epoch 217/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.8146 - accuracy: 0.6787 - val_loss: 1.2012 - val_accuracy: 0.5660\n",
      "Epoch 218/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.8388 - accuracy: 0.6607 - val_loss: 1.2070 - val_accuracy: 0.5324\n",
      "Epoch 219/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.7756 - accuracy: 0.6906 - val_loss: 1.1856 - val_accuracy: 0.5548\n",
      "Epoch 220/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.7995 - accuracy: 0.6733 - val_loss: 1.1561 - val_accuracy: 0.5459\n",
      "Epoch 221/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.7763 - accuracy: 0.6817 - val_loss: 1.1909 - val_accuracy: 0.5391\n",
      "Epoch 222/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.8021 - accuracy: 0.6769 - val_loss: 1.1496 - val_accuracy: 0.5794\n",
      "Epoch 223/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.7697 - accuracy: 0.6882 - val_loss: 1.1631 - val_accuracy: 0.5660\n",
      "Epoch 224/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.7824 - accuracy: 0.6775 - val_loss: 1.1981 - val_accuracy: 0.5615\n",
      "Epoch 225/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.7811 - accuracy: 0.6871 - val_loss: 1.1697 - val_accuracy: 0.5772\n",
      "Epoch 226/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.7419 - accuracy: 0.7008 - val_loss: 1.2017 - val_accuracy: 0.5682\n",
      "Epoch 227/600\n",
      "1668/1668 [==============================] - 6s 4ms/sample - loss: 0.7535 - accuracy: 0.6990 - val_loss: 1.2236 - val_accuracy: 0.5459\n",
      "Epoch 228/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.7630 - accuracy: 0.7062 - val_loss: 1.2901 - val_accuracy: 0.5213\n",
      "Epoch 229/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.7578 - accuracy: 0.6966 - val_loss: 1.2896 - val_accuracy: 0.5503\n",
      "Epoch 230/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.7773 - accuracy: 0.6888 - val_loss: 1.3039 - val_accuracy: 0.5101\n",
      "Epoch 231/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.7278 - accuracy: 0.7050 - val_loss: 1.2532 - val_accuracy: 0.5414\n",
      "Epoch 232/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.7666 - accuracy: 0.7002 - val_loss: 1.2471 - val_accuracy: 0.5369\n",
      "Epoch 233/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.7646 - accuracy: 0.6966 - val_loss: 1.1844 - val_accuracy: 0.5503\n",
      "Epoch 234/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.7593 - accuracy: 0.7002 - val_loss: 1.1855 - val_accuracy: 0.5593\n",
      "Epoch 235/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.7460 - accuracy: 0.7032 - val_loss: 1.1578 - val_accuracy: 0.5727\n",
      "Epoch 236/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.7660 - accuracy: 0.6882 - val_loss: 1.1801 - val_accuracy: 0.5436\n",
      "Epoch 237/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.7497 - accuracy: 0.6930 - val_loss: 1.3062 - val_accuracy: 0.5459\n",
      "Epoch 238/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.7875 - accuracy: 0.6900 - val_loss: 1.1653 - val_accuracy: 0.5459\n",
      "Epoch 239/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.7363 - accuracy: 0.7002 - val_loss: 1.1701 - val_accuracy: 0.5705\n",
      "Epoch 240/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.7560 - accuracy: 0.6948 - val_loss: 1.1236 - val_accuracy: 0.5682\n",
      "Epoch 241/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.7410 - accuracy: 0.7134 - val_loss: 1.1919 - val_accuracy: 0.5481\n",
      "Epoch 242/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.7187 - accuracy: 0.7134 - val_loss: 1.1821 - val_accuracy: 0.5570\n",
      "Epoch 243/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.7449 - accuracy: 0.7080 - val_loss: 1.1793 - val_accuracy: 0.5884\n",
      "Epoch 244/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.7616 - accuracy: 0.6859 - val_loss: 1.1509 - val_accuracy: 0.5817\n",
      "Epoch 245/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.8147 - accuracy: 0.6853 - val_loss: 1.4197 - val_accuracy: 0.5213\n",
      "Epoch 246/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.7665 - accuracy: 0.6996 - val_loss: 1.2480 - val_accuracy: 0.5526\n",
      "Epoch 247/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.7229 - accuracy: 0.7062 - val_loss: 1.2206 - val_accuracy: 0.5884\n",
      "Epoch 248/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.7208 - accuracy: 0.7206 - val_loss: 1.2012 - val_accuracy: 0.5772\n",
      "Epoch 249/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.7262 - accuracy: 0.7122 - val_loss: 1.1957 - val_accuracy: 0.5794\n",
      "Epoch 250/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.7212 - accuracy: 0.7230 - val_loss: 1.1946 - val_accuracy: 0.5660\n",
      "Epoch 251/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.8398 - accuracy: 0.6757 - val_loss: 1.3438 - val_accuracy: 0.5257\n",
      "Epoch 252/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.7855 - accuracy: 0.6882 - val_loss: 1.1422 - val_accuracy: 0.5906\n",
      "Epoch 253/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.6985 - accuracy: 0.7206 - val_loss: 1.1979 - val_accuracy: 0.6018\n",
      "Epoch 254/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.7041 - accuracy: 0.7302 - val_loss: 1.1758 - val_accuracy: 0.6085\n",
      "Epoch 255/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.7037 - accuracy: 0.7206 - val_loss: 1.1326 - val_accuracy: 0.6107\n",
      "Epoch 256/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.7125 - accuracy: 0.7158 - val_loss: 1.1758 - val_accuracy: 0.5817\n",
      "Epoch 257/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.7176 - accuracy: 0.7098 - val_loss: 1.1420 - val_accuracy: 0.5861\n",
      "Epoch 258/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.7121 - accuracy: 0.7218 - val_loss: 1.1318 - val_accuracy: 0.5951\n",
      "Epoch 259/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.7330 - accuracy: 0.6996 - val_loss: 1.1320 - val_accuracy: 0.5884\n",
      "Epoch 260/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.7374 - accuracy: 0.7002 - val_loss: 1.2114 - val_accuracy: 0.5951\n",
      "Epoch 261/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.7117 - accuracy: 0.7122 - val_loss: 1.1582 - val_accuracy: 0.5772\n",
      "Epoch 262/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.7312 - accuracy: 0.7098 - val_loss: 1.1852 - val_accuracy: 0.5973\n",
      "Epoch 263/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.7386 - accuracy: 0.7008 - val_loss: 1.1695 - val_accuracy: 0.5973\n",
      "Epoch 264/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.7421 - accuracy: 0.7044 - val_loss: 1.1927 - val_accuracy: 0.6018\n",
      "Epoch 265/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.7246 - accuracy: 0.7134 - val_loss: 1.2037 - val_accuracy: 0.5749\n",
      "Epoch 266/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.7100 - accuracy: 0.7230 - val_loss: 1.2608 - val_accuracy: 0.5548\n",
      "Epoch 267/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.7053 - accuracy: 0.7146 - val_loss: 1.3044 - val_accuracy: 0.5459\n",
      "Epoch 268/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.7827 - accuracy: 0.6876 - val_loss: 1.2493 - val_accuracy: 0.5615\n",
      "Epoch 269/600\n",
      "1668/1668 [==============================] - 6s 3ms/sample - loss: 0.7145 - accuracy: 0.7206 - val_loss: 1.2115 - val_accuracy: 0.5660\n",
      "Epoch 270/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.7200 - accuracy: 0.7272 - val_loss: 1.2435 - val_accuracy: 0.5615\n",
      "Epoch 271/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.7131 - accuracy: 0.7164 - val_loss: 1.1814 - val_accuracy: 0.5928\n",
      "Epoch 272/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.6956 - accuracy: 0.7200 - val_loss: 1.1229 - val_accuracy: 0.6197\n",
      "Epoch 273/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.6945 - accuracy: 0.7338 - val_loss: 1.1663 - val_accuracy: 0.6130\n",
      "Epoch 274/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.7109 - accuracy: 0.7068 - val_loss: 1.1163 - val_accuracy: 0.6063\n",
      "Epoch 275/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.7100 - accuracy: 0.7194 - val_loss: 1.1292 - val_accuracy: 0.5996\n",
      "Epoch 276/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.6703 - accuracy: 0.7320 - val_loss: 1.1335 - val_accuracy: 0.6040\n",
      "Epoch 277/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.6567 - accuracy: 0.7464 - val_loss: 1.1538 - val_accuracy: 0.5861\n",
      "Epoch 278/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.7022 - accuracy: 0.7380 - val_loss: 1.1665 - val_accuracy: 0.5772\n",
      "Epoch 279/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.6802 - accuracy: 0.7332 - val_loss: 1.1676 - val_accuracy: 0.5906\n",
      "Epoch 280/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.7040 - accuracy: 0.7254 - val_loss: 1.1794 - val_accuracy: 0.5861\n",
      "Epoch 281/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.6574 - accuracy: 0.7470 - val_loss: 1.1229 - val_accuracy: 0.6085\n",
      "Epoch 282/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.6867 - accuracy: 0.7236 - val_loss: 1.1257 - val_accuracy: 0.6107\n",
      "Epoch 283/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.6978 - accuracy: 0.7260 - val_loss: 1.1611 - val_accuracy: 0.5928\n",
      "Epoch 284/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.6932 - accuracy: 0.7278 - val_loss: 1.2100 - val_accuracy: 0.5973\n",
      "Epoch 285/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.6920 - accuracy: 0.7242 - val_loss: 1.1330 - val_accuracy: 0.6085\n",
      "Epoch 286/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.7621 - accuracy: 0.6960 - val_loss: 1.2622 - val_accuracy: 0.5727\n",
      "Epoch 287/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.7127 - accuracy: 0.7194 - val_loss: 1.1834 - val_accuracy: 0.5772\n",
      "Epoch 288/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.6802 - accuracy: 0.7344 - val_loss: 1.2220 - val_accuracy: 0.5928\n",
      "Epoch 289/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.6462 - accuracy: 0.7542 - val_loss: 1.1421 - val_accuracy: 0.5996\n",
      "Epoch 290/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.6475 - accuracy: 0.7500 - val_loss: 1.2165 - val_accuracy: 0.6085\n",
      "Epoch 291/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.6433 - accuracy: 0.7482 - val_loss: 1.1405 - val_accuracy: 0.6219\n",
      "Epoch 292/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.6663 - accuracy: 0.7314 - val_loss: 1.1954 - val_accuracy: 0.5928\n",
      "Epoch 293/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.6275 - accuracy: 0.7572 - val_loss: 1.1249 - val_accuracy: 0.6331\n",
      "Epoch 294/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.6185 - accuracy: 0.7668 - val_loss: 1.1220 - val_accuracy: 0.6286\n",
      "Epoch 295/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.6338 - accuracy: 0.7590 - val_loss: 1.1821 - val_accuracy: 0.6018\n",
      "Epoch 296/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.6796 - accuracy: 0.7296 - val_loss: 1.2065 - val_accuracy: 0.5749\n",
      "Epoch 297/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.6661 - accuracy: 0.7296 - val_loss: 1.2102 - val_accuracy: 0.5839\n",
      "Epoch 298/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.6580 - accuracy: 0.7446 - val_loss: 1.2065 - val_accuracy: 0.6018\n",
      "Epoch 299/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.6422 - accuracy: 0.7428 - val_loss: 1.1838 - val_accuracy: 0.6063\n",
      "Epoch 300/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5992 - accuracy: 0.7632 - val_loss: 1.1627 - val_accuracy: 0.6152\n",
      "Epoch 301/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5966 - accuracy: 0.7668 - val_loss: 1.1470 - val_accuracy: 0.6130\n",
      "Epoch 302/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5944 - accuracy: 0.7770 - val_loss: 1.1485 - val_accuracy: 0.6130\n",
      "Epoch 303/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5794 - accuracy: 0.7632 - val_loss: 1.1506 - val_accuracy: 0.6040\n",
      "Epoch 304/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.6075 - accuracy: 0.7620 - val_loss: 1.1501 - val_accuracy: 0.6018\n",
      "Epoch 305/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.6109 - accuracy: 0.7584 - val_loss: 1.1907 - val_accuracy: 0.6040\n",
      "Epoch 306/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5706 - accuracy: 0.7818 - val_loss: 1.1307 - val_accuracy: 0.6040\n",
      "Epoch 307/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5654 - accuracy: 0.7800 - val_loss: 1.1728 - val_accuracy: 0.6085\n",
      "Epoch 308/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5706 - accuracy: 0.7752 - val_loss: 1.1457 - val_accuracy: 0.6040\n",
      "Epoch 309/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5802 - accuracy: 0.7746 - val_loss: 1.1810 - val_accuracy: 0.6219\n",
      "Epoch 310/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.6085 - accuracy: 0.7638 - val_loss: 1.1774 - val_accuracy: 0.6242\n",
      "Epoch 311/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.6055 - accuracy: 0.7614 - val_loss: 1.2215 - val_accuracy: 0.5906\n",
      "Epoch 312/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5626 - accuracy: 0.7866 - val_loss: 1.1309 - val_accuracy: 0.6376\n",
      "Epoch 313/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5597 - accuracy: 0.7806 - val_loss: 1.2038 - val_accuracy: 0.6130\n",
      "Epoch 314/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5845 - accuracy: 0.7704 - val_loss: 1.1768 - val_accuracy: 0.6130\n",
      "Epoch 315/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5860 - accuracy: 0.7650 - val_loss: 1.1679 - val_accuracy: 0.6309\n",
      "Epoch 316/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5778 - accuracy: 0.7836 - val_loss: 1.1869 - val_accuracy: 0.6107\n",
      "Epoch 317/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5685 - accuracy: 0.7716 - val_loss: 1.1270 - val_accuracy: 0.6353\n",
      "Epoch 318/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5725 - accuracy: 0.7758 - val_loss: 1.1169 - val_accuracy: 0.6309\n",
      "Epoch 319/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5571 - accuracy: 0.7800 - val_loss: 1.1327 - val_accuracy: 0.6376\n",
      "Epoch 320/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5741 - accuracy: 0.7746 - val_loss: 1.1380 - val_accuracy: 0.6219\n",
      "Epoch 321/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5763 - accuracy: 0.7710 - val_loss: 1.1122 - val_accuracy: 0.6331\n",
      "Epoch 322/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5872 - accuracy: 0.7698 - val_loss: 1.1726 - val_accuracy: 0.6130\n",
      "Epoch 323/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.6393 - accuracy: 0.7434 - val_loss: 1.2781 - val_accuracy: 0.5772\n",
      "Epoch 324/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.6335 - accuracy: 0.7476 - val_loss: 1.1541 - val_accuracy: 0.6174\n",
      "Epoch 325/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.6243 - accuracy: 0.7560 - val_loss: 1.2292 - val_accuracy: 0.6152\n",
      "Epoch 326/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5812 - accuracy: 0.7632 - val_loss: 1.1954 - val_accuracy: 0.5996\n",
      "Epoch 327/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5549 - accuracy: 0.7866 - val_loss: 1.1683 - val_accuracy: 0.6309\n",
      "Epoch 328/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.6203 - accuracy: 0.7524 - val_loss: 1.2720 - val_accuracy: 0.6040\n",
      "Epoch 329/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5830 - accuracy: 0.7680 - val_loss: 1.2048 - val_accuracy: 0.6085\n",
      "Epoch 330/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5640 - accuracy: 0.7896 - val_loss: 1.2584 - val_accuracy: 0.6174\n",
      "Epoch 331/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5584 - accuracy: 0.7860 - val_loss: 1.1877 - val_accuracy: 0.6040\n",
      "Epoch 332/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5243 - accuracy: 0.7992 - val_loss: 1.2092 - val_accuracy: 0.6107\n",
      "Epoch 333/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5756 - accuracy: 0.7794 - val_loss: 1.2436 - val_accuracy: 0.6130\n",
      "Epoch 334/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.6015 - accuracy: 0.7674 - val_loss: 1.1870 - val_accuracy: 0.5928\n",
      "Epoch 335/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.6020 - accuracy: 0.7680 - val_loss: 1.2461 - val_accuracy: 0.5861\n",
      "Epoch 336/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5950 - accuracy: 0.7758 - val_loss: 1.2064 - val_accuracy: 0.5951\n",
      "Epoch 337/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5715 - accuracy: 0.7878 - val_loss: 1.1628 - val_accuracy: 0.6264\n",
      "Epoch 338/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5755 - accuracy: 0.7740 - val_loss: 1.1802 - val_accuracy: 0.6510\n",
      "Epoch 339/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5647 - accuracy: 0.7758 - val_loss: 1.1774 - val_accuracy: 0.6398\n",
      "Epoch 340/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5712 - accuracy: 0.7704 - val_loss: 1.1629 - val_accuracy: 0.6421\n",
      "Epoch 341/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5804 - accuracy: 0.7734 - val_loss: 1.1023 - val_accuracy: 0.6398\n",
      "Epoch 342/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5622 - accuracy: 0.7872 - val_loss: 1.1255 - val_accuracy: 0.6443\n",
      "Epoch 343/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5720 - accuracy: 0.7614 - val_loss: 1.1294 - val_accuracy: 0.6264\n",
      "Epoch 344/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5548 - accuracy: 0.7902 - val_loss: 1.1371 - val_accuracy: 0.6286\n",
      "Epoch 345/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5645 - accuracy: 0.7734 - val_loss: 1.1005 - val_accuracy: 0.6309\n",
      "Epoch 346/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5464 - accuracy: 0.7938 - val_loss: 1.1164 - val_accuracy: 0.6331\n",
      "Epoch 347/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5396 - accuracy: 0.7944 - val_loss: 1.1543 - val_accuracy: 0.6309\n",
      "Epoch 348/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5518 - accuracy: 0.7872 - val_loss: 1.1672 - val_accuracy: 0.6264\n",
      "Epoch 349/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5584 - accuracy: 0.7848 - val_loss: 1.1524 - val_accuracy: 0.6219\n",
      "Epoch 350/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5363 - accuracy: 0.7896 - val_loss: 1.1638 - val_accuracy: 0.6242\n",
      "Epoch 351/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5577 - accuracy: 0.7866 - val_loss: 1.1647 - val_accuracy: 0.6219\n",
      "Epoch 352/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5570 - accuracy: 0.7776 - val_loss: 1.1486 - val_accuracy: 0.6443\n",
      "Epoch 353/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5275 - accuracy: 0.7932 - val_loss: 1.1247 - val_accuracy: 0.6353\n",
      "Epoch 354/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5252 - accuracy: 0.7986 - val_loss: 1.1167 - val_accuracy: 0.6286\n",
      "Epoch 355/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5174 - accuracy: 0.7938 - val_loss: 1.1908 - val_accuracy: 0.6219\n",
      "Epoch 356/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5263 - accuracy: 0.7962 - val_loss: 1.1662 - val_accuracy: 0.6242\n",
      "Epoch 357/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5268 - accuracy: 0.7884 - val_loss: 1.1534 - val_accuracy: 0.6286\n",
      "Epoch 358/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4944 - accuracy: 0.8124 - val_loss: 1.1792 - val_accuracy: 0.6286\n",
      "Epoch 359/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5112 - accuracy: 0.8064 - val_loss: 1.2093 - val_accuracy: 0.6197\n",
      "Epoch 360/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5282 - accuracy: 0.8016 - val_loss: 1.2137 - val_accuracy: 0.6085\n",
      "Epoch 361/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5402 - accuracy: 0.7968 - val_loss: 1.2015 - val_accuracy: 0.6107\n",
      "Epoch 362/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5185 - accuracy: 0.8052 - val_loss: 1.2053 - val_accuracy: 0.6107\n",
      "Epoch 363/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4888 - accuracy: 0.8106 - val_loss: 1.1754 - val_accuracy: 0.6264\n",
      "Epoch 364/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4796 - accuracy: 0.8129 - val_loss: 1.1911 - val_accuracy: 0.6286\n",
      "Epoch 365/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5740 - accuracy: 0.7890 - val_loss: 1.1514 - val_accuracy: 0.6286\n",
      "Epoch 366/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5220 - accuracy: 0.7920 - val_loss: 1.1462 - val_accuracy: 0.6286\n",
      "Epoch 367/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5154 - accuracy: 0.7884 - val_loss: 1.1651 - val_accuracy: 0.6331\n",
      "Epoch 368/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4960 - accuracy: 0.8070 - val_loss: 1.1422 - val_accuracy: 0.6353\n",
      "Epoch 369/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5505 - accuracy: 0.7854 - val_loss: 1.1391 - val_accuracy: 0.6532\n",
      "Epoch 370/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5477 - accuracy: 0.7872 - val_loss: 1.1320 - val_accuracy: 0.6353\n",
      "Epoch 371/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5100 - accuracy: 0.8028 - val_loss: 1.1598 - val_accuracy: 0.6443\n",
      "Epoch 372/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5117 - accuracy: 0.8028 - val_loss: 1.1242 - val_accuracy: 0.6443\n",
      "Epoch 373/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4817 - accuracy: 0.8261 - val_loss: 1.1525 - val_accuracy: 0.6331\n",
      "Epoch 374/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5053 - accuracy: 0.7968 - val_loss: 1.1345 - val_accuracy: 0.6286\n",
      "Epoch 375/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4902 - accuracy: 0.8070 - val_loss: 1.1469 - val_accuracy: 0.6219\n",
      "Epoch 376/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4575 - accuracy: 0.8303 - val_loss: 1.1643 - val_accuracy: 0.6174\n",
      "Epoch 377/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4514 - accuracy: 0.8327 - val_loss: 1.1622 - val_accuracy: 0.6242\n",
      "Epoch 378/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4991 - accuracy: 0.8094 - val_loss: 1.1851 - val_accuracy: 0.6219\n",
      "Epoch 379/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4806 - accuracy: 0.8100 - val_loss: 1.1915 - val_accuracy: 0.6242\n",
      "Epoch 380/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4742 - accuracy: 0.8219 - val_loss: 1.1815 - val_accuracy: 0.6107\n",
      "Epoch 381/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5289 - accuracy: 0.7998 - val_loss: 1.1485 - val_accuracy: 0.6242\n",
      "Epoch 382/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4916 - accuracy: 0.8058 - val_loss: 1.1539 - val_accuracy: 0.6331\n",
      "Epoch 383/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4969 - accuracy: 0.8135 - val_loss: 1.1573 - val_accuracy: 0.6219\n",
      "Epoch 384/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5150 - accuracy: 0.7950 - val_loss: 1.1775 - val_accuracy: 0.6376\n",
      "Epoch 385/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5011 - accuracy: 0.7986 - val_loss: 1.1710 - val_accuracy: 0.6286\n",
      "Epoch 386/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4714 - accuracy: 0.8243 - val_loss: 1.1404 - val_accuracy: 0.6443\n",
      "Epoch 387/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5112 - accuracy: 0.8076 - val_loss: 1.1318 - val_accuracy: 0.6622\n",
      "Epoch 388/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4953 - accuracy: 0.8135 - val_loss: 1.1391 - val_accuracy: 0.6242\n",
      "Epoch 389/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5138 - accuracy: 0.8106 - val_loss: 1.2591 - val_accuracy: 0.6018\n",
      "Epoch 390/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5124 - accuracy: 0.8010 - val_loss: 1.2002 - val_accuracy: 0.6197\n",
      "Epoch 391/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4910 - accuracy: 0.8076 - val_loss: 1.2177 - val_accuracy: 0.5996\n",
      "Epoch 392/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4619 - accuracy: 0.8273 - val_loss: 1.1564 - val_accuracy: 0.6309\n",
      "Epoch 393/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4874 - accuracy: 0.8064 - val_loss: 1.1928 - val_accuracy: 0.6398\n",
      "Epoch 394/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4730 - accuracy: 0.8225 - val_loss: 1.2923 - val_accuracy: 0.6107\n",
      "Epoch 395/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4819 - accuracy: 0.8135 - val_loss: 1.2398 - val_accuracy: 0.6174\n",
      "Epoch 396/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4848 - accuracy: 0.8201 - val_loss: 1.1997 - val_accuracy: 0.6398\n",
      "Epoch 397/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4532 - accuracy: 0.8333 - val_loss: 1.2270 - val_accuracy: 0.6219\n",
      "Epoch 398/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4558 - accuracy: 0.8255 - val_loss: 1.2061 - val_accuracy: 0.6421\n",
      "Epoch 399/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4799 - accuracy: 0.8076 - val_loss: 1.1937 - val_accuracy: 0.6555\n",
      "Epoch 400/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4680 - accuracy: 0.8189 - val_loss: 1.2155 - val_accuracy: 0.6465\n",
      "Epoch 401/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4379 - accuracy: 0.8285 - val_loss: 1.1648 - val_accuracy: 0.6532\n",
      "Epoch 402/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4557 - accuracy: 0.8279 - val_loss: 1.2146 - val_accuracy: 0.6353\n",
      "Epoch 403/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4977 - accuracy: 0.8153 - val_loss: 1.1861 - val_accuracy: 0.6398\n",
      "Epoch 404/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4494 - accuracy: 0.8303 - val_loss: 1.1948 - val_accuracy: 0.6353\n",
      "Epoch 405/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4389 - accuracy: 0.8339 - val_loss: 1.1838 - val_accuracy: 0.6443\n",
      "Epoch 406/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4721 - accuracy: 0.8207 - val_loss: 1.1472 - val_accuracy: 0.6465\n",
      "Epoch 407/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4311 - accuracy: 0.8321 - val_loss: 1.1379 - val_accuracy: 0.6555\n",
      "Epoch 408/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4497 - accuracy: 0.8267 - val_loss: 1.1762 - val_accuracy: 0.6353\n",
      "Epoch 409/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4701 - accuracy: 0.8225 - val_loss: 1.1947 - val_accuracy: 0.6353\n",
      "Epoch 410/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4668 - accuracy: 0.8213 - val_loss: 1.1972 - val_accuracy: 0.6152\n",
      "Epoch 411/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5052 - accuracy: 0.8052 - val_loss: 1.2536 - val_accuracy: 0.6286\n",
      "Epoch 412/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4804 - accuracy: 0.8243 - val_loss: 1.2378 - val_accuracy: 0.6331\n",
      "Epoch 413/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4926 - accuracy: 0.8153 - val_loss: 1.2064 - val_accuracy: 0.6443\n",
      "Epoch 414/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5170 - accuracy: 0.8100 - val_loss: 1.2021 - val_accuracy: 0.6421\n",
      "Epoch 415/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4929 - accuracy: 0.8046 - val_loss: 1.2462 - val_accuracy: 0.6130\n",
      "Epoch 416/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5071 - accuracy: 0.8064 - val_loss: 1.1879 - val_accuracy: 0.6309\n",
      "Epoch 417/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4720 - accuracy: 0.8213 - val_loss: 1.2469 - val_accuracy: 0.6398\n",
      "Epoch 418/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5176 - accuracy: 0.7944 - val_loss: 1.2513 - val_accuracy: 0.6309\n",
      "Epoch 419/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5118 - accuracy: 0.8106 - val_loss: 1.1935 - val_accuracy: 0.6465\n",
      "Epoch 420/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4804 - accuracy: 0.8100 - val_loss: 1.1783 - val_accuracy: 0.6510\n",
      "Epoch 421/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4852 - accuracy: 0.8112 - val_loss: 1.1452 - val_accuracy: 0.6331\n",
      "Epoch 422/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4459 - accuracy: 0.8285 - val_loss: 1.1673 - val_accuracy: 0.6488\n",
      "Epoch 423/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4490 - accuracy: 0.8207 - val_loss: 1.1461 - val_accuracy: 0.6398\n",
      "Epoch 424/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4543 - accuracy: 0.8303 - val_loss: 1.1260 - val_accuracy: 0.6532\n",
      "Epoch 425/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4650 - accuracy: 0.8255 - val_loss: 1.1854 - val_accuracy: 0.6264\n",
      "Epoch 426/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4125 - accuracy: 0.8441 - val_loss: 1.2135 - val_accuracy: 0.6376\n",
      "Epoch 427/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.5274 - accuracy: 0.8046 - val_loss: 1.1918 - val_accuracy: 0.6309\n",
      "Epoch 428/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4944 - accuracy: 0.8082 - val_loss: 1.1908 - val_accuracy: 0.6398\n",
      "Epoch 429/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4255 - accuracy: 0.8429 - val_loss: 1.2148 - val_accuracy: 0.6174\n",
      "Epoch 430/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4569 - accuracy: 0.8171 - val_loss: 1.1951 - val_accuracy: 0.6197\n",
      "Epoch 431/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4309 - accuracy: 0.8351 - val_loss: 1.2033 - val_accuracy: 0.6421\n",
      "Epoch 432/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4217 - accuracy: 0.8345 - val_loss: 1.1461 - val_accuracy: 0.6376\n",
      "Epoch 433/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4225 - accuracy: 0.8381 - val_loss: 1.1478 - val_accuracy: 0.6421\n",
      "Epoch 434/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4538 - accuracy: 0.8291 - val_loss: 1.0913 - val_accuracy: 0.6644\n",
      "Epoch 435/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4947 - accuracy: 0.8147 - val_loss: 1.1081 - val_accuracy: 0.6510\n",
      "Epoch 436/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4789 - accuracy: 0.8165 - val_loss: 1.1621 - val_accuracy: 0.6376\n",
      "Epoch 437/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4785 - accuracy: 0.8177 - val_loss: 1.1509 - val_accuracy: 0.6443\n",
      "Epoch 438/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4501 - accuracy: 0.8297 - val_loss: 1.2072 - val_accuracy: 0.6309\n",
      "Epoch 439/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4402 - accuracy: 0.8255 - val_loss: 1.1705 - val_accuracy: 0.6309\n",
      "Epoch 440/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4416 - accuracy: 0.8201 - val_loss: 1.1280 - val_accuracy: 0.6421\n",
      "Epoch 441/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4006 - accuracy: 0.8537 - val_loss: 1.1508 - val_accuracy: 0.6421\n",
      "Epoch 442/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3922 - accuracy: 0.8513 - val_loss: 1.1559 - val_accuracy: 0.6510\n",
      "Epoch 443/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4065 - accuracy: 0.8339 - val_loss: 1.1668 - val_accuracy: 0.6532\n",
      "Epoch 444/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4298 - accuracy: 0.8273 - val_loss: 1.1834 - val_accuracy: 0.6421\n",
      "Epoch 445/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4243 - accuracy: 0.8393 - val_loss: 1.1579 - val_accuracy: 0.6443\n",
      "Epoch 446/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3955 - accuracy: 0.8471 - val_loss: 1.1479 - val_accuracy: 0.6421\n",
      "Epoch 447/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4441 - accuracy: 0.8357 - val_loss: 1.2394 - val_accuracy: 0.6376\n",
      "Epoch 448/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4131 - accuracy: 0.8453 - val_loss: 1.1479 - val_accuracy: 0.6465\n",
      "Epoch 449/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4262 - accuracy: 0.8363 - val_loss: 1.2074 - val_accuracy: 0.6398\n",
      "Epoch 450/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3955 - accuracy: 0.8519 - val_loss: 1.1588 - val_accuracy: 0.6443\n",
      "Epoch 451/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3958 - accuracy: 0.8501 - val_loss: 1.2160 - val_accuracy: 0.6376\n",
      "Epoch 452/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4071 - accuracy: 0.8357 - val_loss: 1.1783 - val_accuracy: 0.6309\n",
      "Epoch 453/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4190 - accuracy: 0.8471 - val_loss: 1.2851 - val_accuracy: 0.6353\n",
      "Epoch 454/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4063 - accuracy: 0.8363 - val_loss: 1.1711 - val_accuracy: 0.6465\n",
      "Epoch 455/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3673 - accuracy: 0.8501 - val_loss: 1.1940 - val_accuracy: 0.6465\n",
      "Epoch 456/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4450 - accuracy: 0.8195 - val_loss: 1.2182 - val_accuracy: 0.6286\n",
      "Epoch 457/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4435 - accuracy: 0.8351 - val_loss: 1.2091 - val_accuracy: 0.6331\n",
      "Epoch 458/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4304 - accuracy: 0.8303 - val_loss: 1.2608 - val_accuracy: 0.6465\n",
      "Epoch 459/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4940 - accuracy: 0.8135 - val_loss: 1.3866 - val_accuracy: 0.6018\n",
      "Epoch 460/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4590 - accuracy: 0.8243 - val_loss: 1.3533 - val_accuracy: 0.6398\n",
      "Epoch 461/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4358 - accuracy: 0.8255 - val_loss: 1.3162 - val_accuracy: 0.6309\n",
      "Epoch 462/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3905 - accuracy: 0.8471 - val_loss: 1.2344 - val_accuracy: 0.6555\n",
      "Epoch 463/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3961 - accuracy: 0.8465 - val_loss: 1.2438 - val_accuracy: 0.6421\n",
      "Epoch 464/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4323 - accuracy: 0.8321 - val_loss: 1.2506 - val_accuracy: 0.6353\n",
      "Epoch 465/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3937 - accuracy: 0.8477 - val_loss: 1.2260 - val_accuracy: 0.6398\n",
      "Epoch 466/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3831 - accuracy: 0.8465 - val_loss: 1.2287 - val_accuracy: 0.6510\n",
      "Epoch 467/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3659 - accuracy: 0.8525 - val_loss: 1.1726 - val_accuracy: 0.6421\n",
      "Epoch 468/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4308 - accuracy: 0.8387 - val_loss: 1.1740 - val_accuracy: 0.6465\n",
      "Epoch 469/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4319 - accuracy: 0.8351 - val_loss: 1.2150 - val_accuracy: 0.6353\n",
      "Epoch 470/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4338 - accuracy: 0.8369 - val_loss: 1.2170 - val_accuracy: 0.6398\n",
      "Epoch 471/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4183 - accuracy: 0.8399 - val_loss: 1.2841 - val_accuracy: 0.6197\n",
      "Epoch 472/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4060 - accuracy: 0.8429 - val_loss: 1.2617 - val_accuracy: 0.6309\n",
      "Epoch 473/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4475 - accuracy: 0.8351 - val_loss: 1.2548 - val_accuracy: 0.6242\n",
      "Epoch 474/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3972 - accuracy: 0.8543 - val_loss: 1.2214 - val_accuracy: 0.6376\n",
      "Epoch 475/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4326 - accuracy: 0.8405 - val_loss: 1.2909 - val_accuracy: 0.6264\n",
      "Epoch 476/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4016 - accuracy: 0.8429 - val_loss: 1.2380 - val_accuracy: 0.6465\n",
      "Epoch 477/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3970 - accuracy: 0.8459 - val_loss: 1.2515 - val_accuracy: 0.6286\n",
      "Epoch 478/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3871 - accuracy: 0.8513 - val_loss: 1.2349 - val_accuracy: 0.6398\n",
      "Epoch 479/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3494 - accuracy: 0.8699 - val_loss: 1.2000 - val_accuracy: 0.6398\n",
      "Epoch 480/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3922 - accuracy: 0.8573 - val_loss: 1.2247 - val_accuracy: 0.6510\n",
      "Epoch 481/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3741 - accuracy: 0.8561 - val_loss: 1.2511 - val_accuracy: 0.6376\n",
      "Epoch 482/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3656 - accuracy: 0.8633 - val_loss: 1.2730 - val_accuracy: 0.6286\n",
      "Epoch 483/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4365 - accuracy: 0.8267 - val_loss: 1.2708 - val_accuracy: 0.6532\n",
      "Epoch 484/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3909 - accuracy: 0.8555 - val_loss: 1.2669 - val_accuracy: 0.6398\n",
      "Epoch 485/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3510 - accuracy: 0.8645 - val_loss: 1.2617 - val_accuracy: 0.6331\n",
      "Epoch 486/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4099 - accuracy: 0.8453 - val_loss: 1.3191 - val_accuracy: 0.6130\n",
      "Epoch 487/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3824 - accuracy: 0.8489 - val_loss: 1.2393 - val_accuracy: 0.6264\n",
      "Epoch 488/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3837 - accuracy: 0.8603 - val_loss: 1.2595 - val_accuracy: 0.6376\n",
      "Epoch 489/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4275 - accuracy: 0.8345 - val_loss: 1.3320 - val_accuracy: 0.6130\n",
      "Epoch 490/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4020 - accuracy: 0.8489 - val_loss: 1.2584 - val_accuracy: 0.6309\n",
      "Epoch 491/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3910 - accuracy: 0.8525 - val_loss: 1.2250 - val_accuracy: 0.6331\n",
      "Epoch 492/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4152 - accuracy: 0.8363 - val_loss: 1.2555 - val_accuracy: 0.6353\n",
      "Epoch 493/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3730 - accuracy: 0.8639 - val_loss: 1.3511 - val_accuracy: 0.6174\n",
      "Epoch 494/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3912 - accuracy: 0.8561 - val_loss: 1.2193 - val_accuracy: 0.6398\n",
      "Epoch 495/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4103 - accuracy: 0.8441 - val_loss: 1.2249 - val_accuracy: 0.6353\n",
      "Epoch 496/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3950 - accuracy: 0.8405 - val_loss: 1.2907 - val_accuracy: 0.6353\n",
      "Epoch 497/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3809 - accuracy: 0.8549 - val_loss: 1.2930 - val_accuracy: 0.6152\n",
      "Epoch 498/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3472 - accuracy: 0.8759 - val_loss: 1.2684 - val_accuracy: 0.6331\n",
      "Epoch 499/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3511 - accuracy: 0.8573 - val_loss: 1.2380 - val_accuracy: 0.6398\n",
      "Epoch 500/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3736 - accuracy: 0.8591 - val_loss: 1.2304 - val_accuracy: 0.6376\n",
      "Epoch 501/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3888 - accuracy: 0.8483 - val_loss: 1.2290 - val_accuracy: 0.6309\n",
      "Epoch 502/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3607 - accuracy: 0.8603 - val_loss: 1.2984 - val_accuracy: 0.6264\n",
      "Epoch 503/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3610 - accuracy: 0.8627 - val_loss: 1.2842 - val_accuracy: 0.6264\n",
      "Epoch 504/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4023 - accuracy: 0.8507 - val_loss: 1.2593 - val_accuracy: 0.6219\n",
      "Epoch 505/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3704 - accuracy: 0.8513 - val_loss: 1.2301 - val_accuracy: 0.6622\n",
      "Epoch 506/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3642 - accuracy: 0.8651 - val_loss: 1.2702 - val_accuracy: 0.6398\n",
      "Epoch 507/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3867 - accuracy: 0.8561 - val_loss: 1.2599 - val_accuracy: 0.6600\n",
      "Epoch 508/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3702 - accuracy: 0.8639 - val_loss: 1.3125 - val_accuracy: 0.6242\n",
      "Epoch 509/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3504 - accuracy: 0.8609 - val_loss: 1.2225 - val_accuracy: 0.6376\n",
      "Epoch 510/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4001 - accuracy: 0.8465 - val_loss: 1.2100 - val_accuracy: 0.6465\n",
      "Epoch 511/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3410 - accuracy: 0.8765 - val_loss: 1.2792 - val_accuracy: 0.6421\n",
      "Epoch 512/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4042 - accuracy: 0.8471 - val_loss: 1.2540 - val_accuracy: 0.6376\n",
      "Epoch 513/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4730 - accuracy: 0.8237 - val_loss: 1.3495 - val_accuracy: 0.6130\n",
      "Epoch 514/600\n",
      "1668/1668 [==============================] - 6s 3ms/sample - loss: 0.4398 - accuracy: 0.8267 - val_loss: 1.2476 - val_accuracy: 0.6353\n",
      "Epoch 515/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4326 - accuracy: 0.8345 - val_loss: 1.2274 - val_accuracy: 0.6398\n",
      "Epoch 516/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4070 - accuracy: 0.8525 - val_loss: 1.2669 - val_accuracy: 0.6264\n",
      "Epoch 517/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4279 - accuracy: 0.8405 - val_loss: 1.2792 - val_accuracy: 0.6353\n",
      "Epoch 518/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4158 - accuracy: 0.8435 - val_loss: 1.2227 - val_accuracy: 0.6398\n",
      "Epoch 519/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3877 - accuracy: 0.8477 - val_loss: 1.2493 - val_accuracy: 0.6443\n",
      "Epoch 520/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3626 - accuracy: 0.8693 - val_loss: 1.1985 - val_accuracy: 0.6510\n",
      "Epoch 521/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3947 - accuracy: 0.8459 - val_loss: 1.1810 - val_accuracy: 0.6532\n",
      "Epoch 522/600\n",
      "1668/1668 [==============================] - 6s 3ms/sample - loss: 0.3685 - accuracy: 0.8555 - val_loss: 1.2549 - val_accuracy: 0.6376\n",
      "Epoch 523/600\n",
      "1668/1668 [==============================] - 6s 4ms/sample - loss: 0.3855 - accuracy: 0.8537 - val_loss: 1.1958 - val_accuracy: 0.6510\n",
      "Epoch 524/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3881 - accuracy: 0.8537 - val_loss: 1.2067 - val_accuracy: 0.6421\n",
      "Epoch 525/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3732 - accuracy: 0.8585 - val_loss: 1.2495 - val_accuracy: 0.6264\n",
      "Epoch 526/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4356 - accuracy: 0.8381 - val_loss: 1.2959 - val_accuracy: 0.6421\n",
      "Epoch 527/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4221 - accuracy: 0.8405 - val_loss: 1.1831 - val_accuracy: 0.6465\n",
      "Epoch 528/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3794 - accuracy: 0.8525 - val_loss: 1.2366 - val_accuracy: 0.6465\n",
      "Epoch 529/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3830 - accuracy: 0.8453 - val_loss: 1.2144 - val_accuracy: 0.6421\n",
      "Epoch 530/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3409 - accuracy: 0.8651 - val_loss: 1.2211 - val_accuracy: 0.6421\n",
      "Epoch 531/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3789 - accuracy: 0.8525 - val_loss: 1.3067 - val_accuracy: 0.6107\n",
      "Epoch 532/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4032 - accuracy: 0.8513 - val_loss: 1.2273 - val_accuracy: 0.6510\n",
      "Epoch 533/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3706 - accuracy: 0.8639 - val_loss: 1.2639 - val_accuracy: 0.6510\n",
      "Epoch 534/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3881 - accuracy: 0.8495 - val_loss: 1.3243 - val_accuracy: 0.6174\n",
      "Epoch 535/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3544 - accuracy: 0.8717 - val_loss: 1.2629 - val_accuracy: 0.6465\n",
      "Epoch 536/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4235 - accuracy: 0.8393 - val_loss: 1.2494 - val_accuracy: 0.6376\n",
      "Epoch 537/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3819 - accuracy: 0.8537 - val_loss: 1.2873 - val_accuracy: 0.6264\n",
      "Epoch 538/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3412 - accuracy: 0.8693 - val_loss: 1.2080 - val_accuracy: 0.6376\n",
      "Epoch 539/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3542 - accuracy: 0.8609 - val_loss: 1.2715 - val_accuracy: 0.6510\n",
      "Epoch 540/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3403 - accuracy: 0.8639 - val_loss: 1.2257 - val_accuracy: 0.6353\n",
      "Epoch 541/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3879 - accuracy: 0.8573 - val_loss: 1.3079 - val_accuracy: 0.6398\n",
      "Epoch 542/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3913 - accuracy: 0.8537 - val_loss: 1.3203 - val_accuracy: 0.6376\n",
      "Epoch 543/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3679 - accuracy: 0.8639 - val_loss: 1.2851 - val_accuracy: 0.6331\n",
      "Epoch 544/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3523 - accuracy: 0.8627 - val_loss: 1.3087 - val_accuracy: 0.6264\n",
      "Epoch 545/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3687 - accuracy: 0.8609 - val_loss: 1.3195 - val_accuracy: 0.6197\n",
      "Epoch 546/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3724 - accuracy: 0.8639 - val_loss: 1.3333 - val_accuracy: 0.6398\n",
      "Epoch 547/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3898 - accuracy: 0.8549 - val_loss: 1.2865 - val_accuracy: 0.6264\n",
      "Epoch 548/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3905 - accuracy: 0.8543 - val_loss: 1.2879 - val_accuracy: 0.6398\n",
      "Epoch 549/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3576 - accuracy: 0.8573 - val_loss: 1.2643 - val_accuracy: 0.6264\n",
      "Epoch 550/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3446 - accuracy: 0.8735 - val_loss: 1.2587 - val_accuracy: 0.6286\n",
      "Epoch 551/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3124 - accuracy: 0.8813 - val_loss: 1.2590 - val_accuracy: 0.6398\n",
      "Epoch 552/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3666 - accuracy: 0.8633 - val_loss: 1.2483 - val_accuracy: 0.6286\n",
      "Epoch 553/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3517 - accuracy: 0.8633 - val_loss: 1.2696 - val_accuracy: 0.6421\n",
      "Epoch 554/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3591 - accuracy: 0.8627 - val_loss: 1.2181 - val_accuracy: 0.6242\n",
      "Epoch 555/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3683 - accuracy: 0.8633 - val_loss: 1.3076 - val_accuracy: 0.6242\n",
      "Epoch 556/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3712 - accuracy: 0.8531 - val_loss: 1.2522 - val_accuracy: 0.6309\n",
      "Epoch 557/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3726 - accuracy: 0.8507 - val_loss: 1.2713 - val_accuracy: 0.6309\n",
      "Epoch 558/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3425 - accuracy: 0.8735 - val_loss: 1.2891 - val_accuracy: 0.6443\n",
      "Epoch 559/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3587 - accuracy: 0.8645 - val_loss: 1.2714 - val_accuracy: 0.6264\n",
      "Epoch 560/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3300 - accuracy: 0.8741 - val_loss: 1.2684 - val_accuracy: 0.6331\n",
      "Epoch 561/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4150 - accuracy: 0.8309 - val_loss: 1.3288 - val_accuracy: 0.6398\n",
      "Epoch 562/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3882 - accuracy: 0.8453 - val_loss: 1.3092 - val_accuracy: 0.6264\n",
      "Epoch 563/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4017 - accuracy: 0.8477 - val_loss: 1.2641 - val_accuracy: 0.6465\n",
      "Epoch 564/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3889 - accuracy: 0.8573 - val_loss: 1.2749 - val_accuracy: 0.6264\n",
      "Epoch 565/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3290 - accuracy: 0.8777 - val_loss: 1.3277 - val_accuracy: 0.6219\n",
      "Epoch 566/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.4661 - accuracy: 0.8207 - val_loss: 1.2622 - val_accuracy: 0.6353\n",
      "Epoch 567/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3629 - accuracy: 0.8693 - val_loss: 1.3060 - val_accuracy: 0.6398\n",
      "Epoch 568/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3620 - accuracy: 0.8591 - val_loss: 1.2823 - val_accuracy: 0.6309\n",
      "Epoch 569/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3192 - accuracy: 0.8741 - val_loss: 1.2566 - val_accuracy: 0.6398\n",
      "Epoch 570/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3095 - accuracy: 0.8741 - val_loss: 1.2590 - val_accuracy: 0.6353\n",
      "Epoch 571/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3581 - accuracy: 0.8657 - val_loss: 1.2608 - val_accuracy: 0.6421\n",
      "Epoch 572/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3203 - accuracy: 0.8765 - val_loss: 1.2503 - val_accuracy: 0.6532\n",
      "Epoch 573/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3069 - accuracy: 0.8807 - val_loss: 1.2611 - val_accuracy: 0.6376\n",
      "Epoch 574/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.2941 - accuracy: 0.8879 - val_loss: 1.2947 - val_accuracy: 0.6376\n",
      "Epoch 575/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3059 - accuracy: 0.8837 - val_loss: 1.3229 - val_accuracy: 0.6421\n",
      "Epoch 576/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.2930 - accuracy: 0.8867 - val_loss: 1.3094 - val_accuracy: 0.6286\n",
      "Epoch 577/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3222 - accuracy: 0.8735 - val_loss: 1.2978 - val_accuracy: 0.6309\n",
      "Epoch 578/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.2921 - accuracy: 0.8891 - val_loss: 1.2944 - val_accuracy: 0.6264\n",
      "Epoch 579/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3267 - accuracy: 0.8735 - val_loss: 1.4185 - val_accuracy: 0.6197\n",
      "Epoch 580/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3330 - accuracy: 0.8771 - val_loss: 1.3267 - val_accuracy: 0.6174\n",
      "Epoch 581/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3227 - accuracy: 0.8687 - val_loss: 1.3866 - val_accuracy: 0.6152\n",
      "Epoch 582/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3407 - accuracy: 0.8699 - val_loss: 1.3432 - val_accuracy: 0.6040\n",
      "Epoch 583/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3426 - accuracy: 0.8651 - val_loss: 1.3074 - val_accuracy: 0.6376\n",
      "Epoch 584/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3555 - accuracy: 0.8651 - val_loss: 1.4393 - val_accuracy: 0.6264\n",
      "Epoch 585/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3593 - accuracy: 0.8657 - val_loss: 1.3516 - val_accuracy: 0.6376\n",
      "Epoch 586/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3461 - accuracy: 0.8807 - val_loss: 1.2959 - val_accuracy: 0.6398\n",
      "Epoch 587/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3730 - accuracy: 0.8579 - val_loss: 1.3530 - val_accuracy: 0.6331\n",
      "Epoch 588/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3651 - accuracy: 0.8579 - val_loss: 1.3313 - val_accuracy: 0.6309\n",
      "Epoch 589/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3772 - accuracy: 0.8591 - val_loss: 1.3764 - val_accuracy: 0.6398\n",
      "Epoch 590/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3558 - accuracy: 0.8675 - val_loss: 1.3592 - val_accuracy: 0.6174\n",
      "Epoch 591/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3200 - accuracy: 0.8831 - val_loss: 1.3992 - val_accuracy: 0.6331\n",
      "Epoch 592/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3463 - accuracy: 0.8675 - val_loss: 1.3492 - val_accuracy: 0.6398\n",
      "Epoch 593/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3221 - accuracy: 0.8783 - val_loss: 1.3607 - val_accuracy: 0.6174\n",
      "Epoch 594/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3239 - accuracy: 0.8657 - val_loss: 1.3168 - val_accuracy: 0.6242\n",
      "Epoch 595/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.2807 - accuracy: 0.8927 - val_loss: 1.3300 - val_accuracy: 0.6331\n",
      "Epoch 596/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3540 - accuracy: 0.8663 - val_loss: 1.3390 - val_accuracy: 0.6353\n",
      "Epoch 597/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3383 - accuracy: 0.8747 - val_loss: 1.3006 - val_accuracy: 0.6421\n",
      "Epoch 598/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.2985 - accuracy: 0.8819 - val_loss: 1.2886 - val_accuracy: 0.6353\n",
      "Epoch 599/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3223 - accuracy: 0.8735 - val_loss: 1.3392 - val_accuracy: 0.6174\n",
      "Epoch 600/600\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.3403 - accuracy: 0.8765 - val_loss: 1.3557 - val_accuracy: 0.6376\n"
     ]
    }
   ],
   "source": [
    "basic_rnn_model_results = rnn_model.fit(x_train, y_train,\n",
    "           batch_size=128,\n",
    "           epochs=600,\n",
    "           validation_data=(x_valid, y_valid), verbose=True)\n",
    "\n",
    "# print(history.history['loss'])\n",
    "# print(history.history['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'basic_rnn_model_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9900/369141706.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Plotting accuracy trajectory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbasic_rnn_model_results\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbasic_rnn_model_results\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Basic RNN model accuracy trajectory'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'basic_rnn_model_results' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting accuracy trajectory\n",
    "plt.plot(basic_rnn_model_results.history['accuracy'])\n",
    "plt.plot(basic_rnn_model_results.history['val_accuracy'])\n",
    "plt.title('Basic RNN model accuracy trajectory')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plotting loss trajectory\n",
    "plt.plot(basic_rnn_model_results.history['loss'],'o')\n",
    "plt.plot(basic_rnn_model_results.history['val_loss'],'o')\n",
    "plt.title('Basic CNN model loss trajectory')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of the basic CNN model: 0.489842\n"
     ]
    }
   ],
   "source": [
    "## Testing the basic RNN model\n",
    "\n",
    "rnn_score = rnn_model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test accuracy of the basic CNN model:',rnn_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN/ GRU Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_40 (GRU)                 (None, 1000, 50)          11100     \n",
      "_________________________________________________________________\n",
      "gru_41 (GRU)                 (None, 1000, 25)          5775      \n",
      "_________________________________________________________________\n",
      "gru_42 (GRU)                 (None, 1000, 25)          3900      \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 25000)             0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 20)                500020    \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 4)                 84        \n",
      "=================================================================\n",
      "Total params: 520,959\n",
      "Trainable params: 520,919\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "gru_model = Sequential()\n",
    "#1\n",
    "gru_model.add(GRU(50, return_sequences=True, stateful=False,\n",
    "         recurrent_dropout=0.6, dropout = 0.5, input_shape=(1000,22)))\n",
    "\n",
    "#2\n",
    "gru_model.add(GRU(25, return_sequences=True, stateful=False,\n",
    "          recurrent_dropout=0.6, dropout = 0.5))\n",
    "\n",
    "#3\n",
    "gru_model.add(GRU(25, return_sequences=True, stateful=False,\n",
    "          recurrent_dropout=0.6, dropout = 0.5))\n",
    "gru_model.add(Flatten())\n",
    "\n",
    "#4\n",
    "gru_model.add(Dense(20))\n",
    "gru_model.add(BatchNormalization(axis=-1))\n",
    "gru_model.add(Activation('relu'))\n",
    "gru_model.add(Dropout(0.5))\n",
    "\n",
    "#5\n",
    "gru_model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "gru_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#rnn_model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "print(gru_model.summary())\n",
    "\n",
    "# define early stopping callback\n",
    "#earlystop = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=70, mode='auto')\n",
    "\n",
    "\n",
    "#callbacks_list = [earlystop]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_gru = x_train.reshape((1668,1000,22))\n",
    "y_train_gru = y_train\n",
    "\n",
    "x_valid_gru = x_valid.reshape((447,1000,22))\n",
    "y_valid_gru = y_valid\n",
    "\n",
    "x_test_gru = x_test.reshape((443,1000,22))\n",
    "y_test_gru = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1668 samples, validate on 447 samples\n",
      "Epoch 1/50\n",
      "1668/1668 [==============================] - 102s 61ms/sample - loss: 1.7512 - accuracy: 0.2566 - val_loss: 1.5522 - val_accuracy: 0.2886\n",
      "Epoch 2/50\n",
      "1668/1668 [==============================] - 98s 59ms/sample - loss: 1.6106 - accuracy: 0.2740 - val_loss: 1.4770 - val_accuracy: 0.2975\n",
      "Epoch 3/50\n",
      "1668/1668 [==============================] - 98s 59ms/sample - loss: 1.5994 - accuracy: 0.2824 - val_loss: 1.4612 - val_accuracy: 0.2908\n",
      "Epoch 4/50\n",
      "1668/1668 [==============================] - 101s 60ms/sample - loss: 1.5477 - accuracy: 0.2866 - val_loss: 1.3547 - val_accuracy: 0.3557\n",
      "Epoch 5/50\n",
      "1668/1668 [==============================] - 102s 61ms/sample - loss: 1.5419 - accuracy: 0.2824 - val_loss: 1.3593 - val_accuracy: 0.3311\n",
      "Epoch 6/50\n",
      "1668/1668 [==============================] - 101s 61ms/sample - loss: 1.5385 - accuracy: 0.2830 - val_loss: 1.3739 - val_accuracy: 0.3289\n",
      "Epoch 7/50\n",
      "1668/1668 [==============================] - 100s 60ms/sample - loss: 1.4918 - accuracy: 0.2932 - val_loss: 1.3718 - val_accuracy: 0.3266\n",
      "Epoch 8/50\n",
      "1668/1668 [==============================] - 100s 60ms/sample - loss: 1.4699 - accuracy: 0.2854 - val_loss: 1.3610 - val_accuracy: 0.3400\n",
      "Epoch 9/50\n",
      "1668/1668 [==============================] - 100s 60ms/sample - loss: 1.4502 - accuracy: 0.3141 - val_loss: 1.3405 - val_accuracy: 0.3535\n",
      "Epoch 10/50\n",
      "1668/1668 [==============================] - 99s 59ms/sample - loss: 1.4590 - accuracy: 0.2992 - val_loss: 1.3521 - val_accuracy: 0.3535\n",
      "Epoch 11/50\n",
      "1668/1668 [==============================] - 99s 59ms/sample - loss: 1.4244 - accuracy: 0.3411 - val_loss: 1.3575 - val_accuracy: 0.3647\n",
      "Epoch 12/50\n",
      "1668/1668 [==============================] - 100s 60ms/sample - loss: 1.4219 - accuracy: 0.3261 - val_loss: 1.3906 - val_accuracy: 0.3512\n",
      "Epoch 13/50\n",
      "1668/1668 [==============================] - 100s 60ms/sample - loss: 1.4123 - accuracy: 0.3159 - val_loss: 1.3680 - val_accuracy: 0.3758\n",
      "Epoch 14/50\n",
      "1668/1668 [==============================] - 98s 59ms/sample - loss: 1.3925 - accuracy: 0.3345 - val_loss: 1.3732 - val_accuracy: 0.3937\n",
      "Epoch 15/50\n",
      "1668/1668 [==============================] - 99s 60ms/sample - loss: 1.3731 - accuracy: 0.3435 - val_loss: 1.3822 - val_accuracy: 0.3848\n",
      "Epoch 16/50\n",
      "1668/1668 [==============================] - 99s 59ms/sample - loss: 1.3564 - accuracy: 0.3603 - val_loss: 1.3678 - val_accuracy: 0.3736\n",
      "Epoch 17/50\n",
      "1668/1668 [==============================] - 99s 59ms/sample - loss: 1.3496 - accuracy: 0.3789 - val_loss: 1.3639 - val_accuracy: 0.3758\n",
      "Epoch 18/50\n",
      "1668/1668 [==============================] - 98s 59ms/sample - loss: 1.3162 - accuracy: 0.3915 - val_loss: 1.3657 - val_accuracy: 0.3647\n",
      "Epoch 19/50\n",
      "1668/1668 [==============================] - 98s 59ms/sample - loss: 1.3116 - accuracy: 0.3717 - val_loss: 1.3810 - val_accuracy: 0.3691\n",
      "Epoch 20/50\n",
      "1668/1668 [==============================] - 98s 59ms/sample - loss: 1.3158 - accuracy: 0.3747 - val_loss: 1.4068 - val_accuracy: 0.3758\n",
      "Epoch 21/50\n",
      "1668/1668 [==============================] - 99s 59ms/sample - loss: 1.3022 - accuracy: 0.3843 - val_loss: 1.3998 - val_accuracy: 0.3848\n",
      "Epoch 22/50\n",
      "1668/1668 [==============================] - 99s 59ms/sample - loss: 1.2683 - accuracy: 0.4005 - val_loss: 1.4141 - val_accuracy: 0.3803\n",
      "Epoch 23/50\n",
      "1668/1668 [==============================] - 99s 59ms/sample - loss: 1.2641 - accuracy: 0.4053 - val_loss: 1.4195 - val_accuracy: 0.3647\n",
      "Epoch 24/50\n",
      "1668/1668 [==============================] - 99s 59ms/sample - loss: 1.2612 - accuracy: 0.4131 - val_loss: 1.4076 - val_accuracy: 0.3982\n",
      "Epoch 25/50\n",
      "1668/1668 [==============================] - 99s 59ms/sample - loss: 1.2600 - accuracy: 0.4023 - val_loss: 1.4294 - val_accuracy: 0.3691\n",
      "Epoch 26/50\n",
      "1668/1668 [==============================] - 99s 59ms/sample - loss: 1.2548 - accuracy: 0.4233 - val_loss: 1.4296 - val_accuracy: 0.3736\n",
      "Epoch 27/50\n",
      "1668/1668 [==============================] - 99s 59ms/sample - loss: 1.2379 - accuracy: 0.4281 - val_loss: 1.3904 - val_accuracy: 0.4027\n",
      "Epoch 28/50\n",
      "1668/1668 [==============================] - 98s 59ms/sample - loss: 1.2359 - accuracy: 0.4287 - val_loss: 1.3932 - val_accuracy: 0.3803\n",
      "Epoch 29/50\n",
      "1668/1668 [==============================] - 98s 59ms/sample - loss: 1.2309 - accuracy: 0.4353 - val_loss: 1.3903 - val_accuracy: 0.4094\n",
      "Epoch 30/50\n",
      "1668/1668 [==============================] - 98s 59ms/sample - loss: 1.2112 - accuracy: 0.4496 - val_loss: 1.3893 - val_accuracy: 0.3870\n",
      "Epoch 31/50\n",
      "1668/1668 [==============================] - 100s 60ms/sample - loss: 1.2053 - accuracy: 0.4556 - val_loss: 1.3933 - val_accuracy: 0.3915\n",
      "Epoch 32/50\n",
      "1668/1668 [==============================] - 99s 59ms/sample - loss: 1.1813 - accuracy: 0.4658 - val_loss: 1.3831 - val_accuracy: 0.3915\n",
      "Epoch 33/50\n",
      "1668/1668 [==============================] - 98s 59ms/sample - loss: 1.1849 - accuracy: 0.4790 - val_loss: 1.3835 - val_accuracy: 0.3960\n",
      "Epoch 34/50\n",
      "1668/1668 [==============================] - 98s 59ms/sample - loss: 1.1903 - accuracy: 0.4538 - val_loss: 1.4020 - val_accuracy: 0.3915\n",
      "Epoch 35/50\n",
      "1668/1668 [==============================] - 100s 60ms/sample - loss: 1.1666 - accuracy: 0.4796 - val_loss: 1.4086 - val_accuracy: 0.3915\n",
      "Epoch 36/50\n",
      "1668/1668 [==============================] - 99s 59ms/sample - loss: 1.1754 - accuracy: 0.4622 - val_loss: 1.4115 - val_accuracy: 0.3937\n",
      "Epoch 37/50\n",
      "1668/1668 [==============================] - 99s 59ms/sample - loss: 1.1594 - accuracy: 0.4562 - val_loss: 1.4103 - val_accuracy: 0.3937\n",
      "Epoch 38/50\n",
      "1668/1668 [==============================] - 99s 59ms/sample - loss: 1.1573 - accuracy: 0.4754 - val_loss: 1.3921 - val_accuracy: 0.3982\n",
      "Epoch 39/50\n",
      "1668/1668 [==============================] - 99s 59ms/sample - loss: 1.1564 - accuracy: 0.4694 - val_loss: 1.3839 - val_accuracy: 0.3960\n",
      "Epoch 40/50\n",
      "1668/1668 [==============================] - 99s 59ms/sample - loss: 1.1270 - accuracy: 0.4964 - val_loss: 1.3835 - val_accuracy: 0.4004\n",
      "Epoch 41/50\n",
      "1668/1668 [==============================] - 99s 60ms/sample - loss: 1.1100 - accuracy: 0.5042 - val_loss: 1.3837 - val_accuracy: 0.4295\n",
      "Epoch 42/50\n",
      "1668/1668 [==============================] - 99s 60ms/sample - loss: 1.1299 - accuracy: 0.4964 - val_loss: 1.3827 - val_accuracy: 0.4027\n",
      "Epoch 43/50\n",
      "1668/1668 [==============================] - 100s 60ms/sample - loss: 1.1183 - accuracy: 0.5096 - val_loss: 1.3835 - val_accuracy: 0.4116\n",
      "Epoch 44/50\n",
      "1668/1668 [==============================] - 100s 60ms/sample - loss: 1.0985 - accuracy: 0.5030 - val_loss: 1.3890 - val_accuracy: 0.4004\n",
      "Epoch 45/50\n",
      "1668/1668 [==============================] - 100s 60ms/sample - loss: 1.1119 - accuracy: 0.5060 - val_loss: 1.3841 - val_accuracy: 0.4004\n",
      "Epoch 46/50\n",
      "1668/1668 [==============================] - 100s 60ms/sample - loss: 1.1018 - accuracy: 0.5048 - val_loss: 1.3997 - val_accuracy: 0.3915\n",
      "Epoch 47/50\n",
      "1668/1668 [==============================] - 100s 60ms/sample - loss: 1.0965 - accuracy: 0.5252 - val_loss: 1.3797 - val_accuracy: 0.3960\n",
      "Epoch 48/50\n",
      "1668/1668 [==============================] - 99s 59ms/sample - loss: 1.0849 - accuracy: 0.5126 - val_loss: 1.3895 - val_accuracy: 0.4027\n",
      "Epoch 49/50\n",
      "1668/1668 [==============================] - 99s 60ms/sample - loss: 1.0775 - accuracy: 0.5384 - val_loss: 1.4150 - val_accuracy: 0.4004\n",
      "Epoch 50/50\n",
      "1668/1668 [==============================] - 99s 59ms/sample - loss: 1.0729 - accuracy: 0.5348 - val_loss: 1.4162 - val_accuracy: 0.3915\n"
     ]
    }
   ],
   "source": [
    "history = gru_model.fit(x_train_gru, y_train_gru,\n",
    "                    batch_size=128, epochs=50, shuffle=True,\n",
    "                    validation_data=(x_valid_gru, y_valid_gru))#, callbacks=callbacks_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting accuracy trajectory\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Hybrid CNN-LSTM model accuracy trajectory')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plotting loss trajectory\n",
    "plt.plot(history.history['loss'],'o')\n",
    "plt.plot(history.history['val_loss'],'o')\n",
    "plt.title('Hybrid CNN-LSTM model loss trajectory')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of the hybrid CNN-LSTM model: 0.35214448\n"
     ]
    }
   ],
   "source": [
    "## Testing the hybrid CNN-LSTM model\n",
    "\n",
    "gru_score = gru_model.evaluate(x_test_gru, y_test_gru, verbose=0)\n",
    "print('Test accuracy of the hybrid CNN-LSTM model:',gru_score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function of Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model(time_period=1000):   \n",
    "    basic_cnn_model = Sequential()\n",
    "\n",
    "    # Conv. block 1\n",
    "    basic_cnn_model.add(Conv2D(filters=100, kernel_size=(10,1), padding='same', activation='elu', input_shape=(time_period,1,22)))\n",
    "    basic_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "    basic_cnn_model.add(BatchNormalization())\n",
    "    basic_cnn_model.add(Dropout(0.5))\n",
    "\n",
    "    # Conv. block 2\n",
    "    basic_cnn_model.add(Conv2D(filters=100, kernel_size=(10,1), padding='same', activation='elu'))\n",
    "    basic_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "    basic_cnn_model.add(BatchNormalization())\n",
    "    basic_cnn_model.add(Dropout(0.5))\n",
    "\n",
    "    # Conv. block 3\n",
    "    basic_cnn_model.add(Conv2D(filters=100, kernel_size=(10,1), padding='same', activation='elu'))\n",
    "    basic_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "    basic_cnn_model.add(BatchNormalization())\n",
    "    basic_cnn_model.add(Dropout(0.5))\n",
    "\n",
    "    # Conv. block 4\n",
    "    basic_cnn_model.add(Conv2D(filters=100, kernel_size=(10,1), padding='same', activation='elu'))\n",
    "    basic_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "    basic_cnn_model.add(BatchNormalization())\n",
    "    basic_cnn_model.add(Dropout(0.5))\n",
    "\n",
    "    # Output layer with Softmax activation\n",
    "    basic_cnn_model.add(Flatten()) # Flattens the input\n",
    "    basic_cnn_model.add(Dense(4, activation='softmax')) # Output FC layer with softmax activation\n",
    "\n",
    "\n",
    "    # Printing the model summary\n",
    "    basic_cnn_model.summary()\n",
    "\n",
    "    # Compiling the model\n",
    "    basic_cnn_model.compile(loss='categorical_crossentropy',\n",
    "                 optimizer='adam',\n",
    "                 metrics=['accuracy'])\n",
    "    \n",
    "    return basic_cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_data(time_period=1000):\n",
    "    # different period of time\n",
    "    x_train_time = x_train[:,:time_period,:,:]\n",
    "    y_train_time = y_train\n",
    "    x_valid_time = x_valid[:,:time_period,:,:]\n",
    "    y_valid_time = y_valid\n",
    "    x_test_time = x_test[:,:time_period,:,:]\n",
    "    y_test_time = y_test\n",
    "\n",
    "#     # preprocess data\n",
    "#     X_train_valid_cur = np.expand_dims(X_train_valid_cur, axis=3)\n",
    "#     X_test_cur = np.expand_dims(X_test_cur, axis=3)\n",
    "    \n",
    "    #lecun = lecun_uniform(seed=42)\n",
    "    \n",
    "    \n",
    "    model = cnn_model(time_period)\n",
    "    \n",
    "    model.fit(x_train_time, y_train_time, epochs=50, batch_size=64, validation_data=(x_valid_time, y_valid_time), shuffle=True, verbose=1)\n",
    "    \n",
    "    train_score = model.evaluate(x_train_time, y_train_time)\n",
    "    \n",
    "    test_score = model.evaluate(x_test_time, y_test_time)\n",
    "\n",
    "    print('train {:s}: {:.3f}%'.format(model.metrics_names[1], train_score[1]*100))\n",
    "    print('test {:s}: {:.3f}%'.format(model.metrics_names[1], test_score[1]*100))\n",
    "    #print(model.summary())\n",
    "    \n",
    "    return train_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_24 (Conv2D)           (None, 1000, 1, 25)       5525      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 334, 1, 25)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 334, 1, 25)        100       \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 334, 1, 25)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 334, 1, 50)        12550     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 112, 1, 50)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 112, 1, 50)        200       \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 112, 1, 50)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 112, 1, 100)       50100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 38, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 38, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 38, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 38, 1, 200)        200200    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 13, 1, 200)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 13, 1, 200)        800       \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 13, 1, 200)        0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 2600)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 4)                 10404     \n",
      "=================================================================\n",
      "Total params: 280,279\n",
      "Trainable params: 279,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "Train on 1668 samples, validate on 447 samples\n",
      "Epoch 1/50\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 2.3282 - accuracy: 0.2662 - val_loss: 1.5354 - val_accuracy: 0.3848\n",
      "Epoch 2/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 2.0931 - accuracy: 0.3177 - val_loss: 1.7283 - val_accuracy: 0.3468\n",
      "Epoch 3/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 1.9659 - accuracy: 0.3237 - val_loss: 1.4995 - val_accuracy: 0.3893\n",
      "Epoch 4/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 1.8630 - accuracy: 0.3513 - val_loss: 1.3533 - val_accuracy: 0.3870\n",
      "Epoch 5/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 1.7598 - accuracy: 0.3705 - val_loss: 1.5751 - val_accuracy: 0.3714\n",
      "Epoch 6/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 1.7684 - accuracy: 0.3681 - val_loss: 1.2796 - val_accuracy: 0.4430\n",
      "Epoch 7/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 1.5732 - accuracy: 0.4053 - val_loss: 1.2913 - val_accuracy: 0.4206\n",
      "Epoch 8/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 1.5738 - accuracy: 0.4191 - val_loss: 1.3464 - val_accuracy: 0.4027\n",
      "Epoch 9/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 1.4975 - accuracy: 0.4203 - val_loss: 1.4245 - val_accuracy: 0.4094\n",
      "Epoch 10/50\n",
      "1668/1668 [==============================] - 4s 3ms/sample - loss: 1.5315 - accuracy: 0.4269 - val_loss: 1.2623 - val_accuracy: 0.4787\n",
      "Epoch 11/50\n",
      "1668/1668 [==============================] - 4s 3ms/sample - loss: 1.3408 - accuracy: 0.4688 - val_loss: 1.2632 - val_accuracy: 0.4362\n",
      "Epoch 12/50\n",
      "1668/1668 [==============================] - 4s 3ms/sample - loss: 1.3572 - accuracy: 0.4616 - val_loss: 1.2987 - val_accuracy: 0.4251\n",
      "Epoch 13/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 1.3313 - accuracy: 0.4694 - val_loss: 1.7150 - val_accuracy: 0.3400\n",
      "Epoch 14/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 1.3093 - accuracy: 0.5006 - val_loss: 1.3010 - val_accuracy: 0.4653\n",
      "Epoch 15/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 1.2758 - accuracy: 0.4958 - val_loss: 1.2322 - val_accuracy: 0.4765\n",
      "Epoch 16/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 1.1979 - accuracy: 0.5186 - val_loss: 1.2607 - val_accuracy: 0.4653\n",
      "Epoch 17/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 1.2250 - accuracy: 0.5252 - val_loss: 1.2066 - val_accuracy: 0.4765\n",
      "Epoch 18/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 1.1891 - accuracy: 0.5228 - val_loss: 1.3213 - val_accuracy: 0.4564\n",
      "Epoch 19/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 1.1449 - accuracy: 0.5576 - val_loss: 1.3892 - val_accuracy: 0.4251\n",
      "Epoch 20/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 1.1488 - accuracy: 0.5420 - val_loss: 1.4284 - val_accuracy: 0.4206\n",
      "Epoch 21/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 1.1835 - accuracy: 0.5336 - val_loss: 1.3050 - val_accuracy: 0.4519\n",
      "Epoch 22/50\n",
      "1668/1668 [==============================] - 4s 3ms/sample - loss: 1.1389 - accuracy: 0.5552 - val_loss: 1.2243 - val_accuracy: 0.4720\n",
      "Epoch 23/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 1.1374 - accuracy: 0.5588 - val_loss: 1.3000 - val_accuracy: 0.4586\n",
      "Epoch 24/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 1.0810 - accuracy: 0.5809 - val_loss: 1.4041 - val_accuracy: 0.4564\n",
      "Epoch 25/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 1.1640 - accuracy: 0.5582 - val_loss: 1.2696 - val_accuracy: 0.4698\n",
      "Epoch 26/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 1.0641 - accuracy: 0.5821 - val_loss: 1.3663 - val_accuracy: 0.4676\n",
      "Epoch 27/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 1.0650 - accuracy: 0.5845 - val_loss: 1.2639 - val_accuracy: 0.4765\n",
      "Epoch 28/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 1.0927 - accuracy: 0.5827 - val_loss: 1.2028 - val_accuracy: 0.5481\n",
      "Epoch 29/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 1.0037 - accuracy: 0.6049 - val_loss: 1.1578 - val_accuracy: 0.5257\n",
      "Epoch 30/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 0.9991 - accuracy: 0.5989 - val_loss: 1.1792 - val_accuracy: 0.4989\n",
      "Epoch 31/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 0.9681 - accuracy: 0.6109 - val_loss: 1.1576 - val_accuracy: 0.5168\n",
      "Epoch 32/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 0.9915 - accuracy: 0.6013 - val_loss: 1.2107 - val_accuracy: 0.5056\n",
      "Epoch 33/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 0.9337 - accuracy: 0.6319 - val_loss: 0.9931 - val_accuracy: 0.5593\n",
      "Epoch 34/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 0.9291 - accuracy: 0.6367 - val_loss: 1.1831 - val_accuracy: 0.5145\n",
      "Epoch 35/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 0.9596 - accuracy: 0.6217 - val_loss: 1.1742 - val_accuracy: 0.4989\n",
      "Epoch 36/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 0.9490 - accuracy: 0.6049 - val_loss: 1.2380 - val_accuracy: 0.5235\n",
      "Epoch 37/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 0.9715 - accuracy: 0.6163 - val_loss: 1.1190 - val_accuracy: 0.5436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 0.8794 - accuracy: 0.6619 - val_loss: 1.0548 - val_accuracy: 0.5526\n",
      "Epoch 39/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 0.8485 - accuracy: 0.6715 - val_loss: 1.1397 - val_accuracy: 0.5235\n",
      "Epoch 40/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 0.8507 - accuracy: 0.6637 - val_loss: 1.2735 - val_accuracy: 0.5168\n",
      "Epoch 41/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 0.8580 - accuracy: 0.6613 - val_loss: 1.0906 - val_accuracy: 0.5794\n",
      "Epoch 42/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 0.8519 - accuracy: 0.6523 - val_loss: 1.0629 - val_accuracy: 0.5548\n",
      "Epoch 43/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 0.8570 - accuracy: 0.6763 - val_loss: 1.0569 - val_accuracy: 0.5727\n",
      "Epoch 44/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 0.8088 - accuracy: 0.6721 - val_loss: 1.0622 - val_accuracy: 0.5660\n",
      "Epoch 45/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 0.8356 - accuracy: 0.6721 - val_loss: 1.0733 - val_accuracy: 0.5638\n",
      "Epoch 46/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 0.8009 - accuracy: 0.6865 - val_loss: 0.9565 - val_accuracy: 0.5928\n",
      "Epoch 47/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 0.7990 - accuracy: 0.6823 - val_loss: 1.1079 - val_accuracy: 0.5593\n",
      "Epoch 48/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 0.8160 - accuracy: 0.6882 - val_loss: 1.0905 - val_accuracy: 0.5548\n",
      "Epoch 49/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 0.7700 - accuracy: 0.6978 - val_loss: 0.9941 - val_accuracy: 0.5682\n",
      "Epoch 50/50\n",
      "1668/1668 [==============================] - 4s 3ms/sample - loss: 0.7990 - accuracy: 0.6829 - val_loss: 1.0283 - val_accuracy: 0.5660\n",
      "1668/1668 [==============================] - 1s 578us/sample - loss: 0.4722 - accuracy: 0.8369\n",
      "443/443 [==============================] - 0s 583us/sample - loss: 1.0834 - accuracy: 0.5576\n",
      "train accuracy: 83.693%\n",
      "test accuracy: 55.756%\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_24 (Conv2D)           (None, 1000, 1, 25)       5525      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 334, 1, 25)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 334, 1, 25)        100       \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 334, 1, 25)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 334, 1, 50)        12550     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 112, 1, 50)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 112, 1, 50)        200       \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 112, 1, 50)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 112, 1, 100)       50100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 38, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 38, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 38, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 38, 1, 200)        200200    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 13, 1, 200)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 13, 1, 200)        800       \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 13, 1, 200)        0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 2600)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 4)                 10404     \n",
      "=================================================================\n",
      "Total params: 280,279\n",
      "Trainable params: 279,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "train_score, test_score = train_data(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================100===================\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_28 (Conv2D)           (None, 100, 1, 25)        5525      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 34, 1, 25)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 34, 1, 25)         100       \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 34, 1, 25)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 34, 1, 50)         12550     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 12, 1, 50)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 12, 1, 50)         200       \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 12, 1, 50)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 12, 1, 100)        50100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling (None, 4, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 4, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 4, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 4, 1, 200)         200200    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling (None, 2, 1, 200)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 2, 1, 200)         800       \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 2, 1, 200)         0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 4)                 1604      \n",
      "=================================================================\n",
      "Total params: 271,479\n",
      "Trainable params: 270,729\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "Train on 1668 samples, validate on 447 samples\n",
      "Epoch 1/50\n",
      "1668/1668 [==============================] - 2s 1ms/sample - loss: 2.2696 - accuracy: 0.2776 - val_loss: 1.6846 - val_accuracy: 0.2729\n",
      "Epoch 2/50\n",
      "1668/1668 [==============================] - 1s 396us/sample - loss: 2.1297 - accuracy: 0.2770 - val_loss: 1.4758 - val_accuracy: 0.3087\n",
      "Epoch 3/50\n",
      "1668/1668 [==============================] - 1s 398us/sample - loss: 1.9190 - accuracy: 0.3082 - val_loss: 1.4632 - val_accuracy: 0.3266\n",
      "Epoch 4/50\n",
      "1668/1668 [==============================] - 1s 420us/sample - loss: 1.8001 - accuracy: 0.3016 - val_loss: 1.4226 - val_accuracy: 0.3468\n",
      "Epoch 5/50\n",
      "1668/1668 [==============================] - 1s 462us/sample - loss: 1.7030 - accuracy: 0.3112 - val_loss: 1.4073 - val_accuracy: 0.3579\n",
      "Epoch 6/50\n",
      "1668/1668 [==============================] - 1s 408us/sample - loss: 1.6853 - accuracy: 0.3106 - val_loss: 1.4210 - val_accuracy: 0.2908\n",
      "Epoch 7/50\n",
      "1668/1668 [==============================] - 1s 416us/sample - loss: 1.6852 - accuracy: 0.3040 - val_loss: 1.3873 - val_accuracy: 0.3378\n",
      "Epoch 8/50\n",
      "1668/1668 [==============================] - 1s 431us/sample - loss: 1.6048 - accuracy: 0.3034 - val_loss: 1.3629 - val_accuracy: 0.3445\n",
      "Epoch 9/50\n",
      "1668/1668 [==============================] - 1s 393us/sample - loss: 1.5058 - accuracy: 0.3471 - val_loss: 1.3615 - val_accuracy: 0.3266\n",
      "Epoch 10/50\n",
      "1668/1668 [==============================] - 1s 387us/sample - loss: 1.5038 - accuracy: 0.3375 - val_loss: 1.4108 - val_accuracy: 0.3535\n",
      "Epoch 11/50\n",
      "1668/1668 [==============================] - 1s 386us/sample - loss: 1.4912 - accuracy: 0.3435 - val_loss: 1.3548 - val_accuracy: 0.3400\n",
      "Epoch 12/50\n",
      "1668/1668 [==============================] - 1s 396us/sample - loss: 1.4610 - accuracy: 0.3531 - val_loss: 1.3505 - val_accuracy: 0.3624\n",
      "Epoch 13/50\n",
      "1668/1668 [==============================] - 1s 385us/sample - loss: 1.4398 - accuracy: 0.3585 - val_loss: 1.3645 - val_accuracy: 0.3647\n",
      "Epoch 14/50\n",
      "1668/1668 [==============================] - 1s 395us/sample - loss: 1.4183 - accuracy: 0.3549 - val_loss: 1.3518 - val_accuracy: 0.3557\n",
      "Epoch 15/50\n",
      "1668/1668 [==============================] - 1s 390us/sample - loss: 1.3927 - accuracy: 0.3735 - val_loss: 1.3394 - val_accuracy: 0.3579\n",
      "Epoch 16/50\n",
      "1668/1668 [==============================] - 1s 404us/sample - loss: 1.4187 - accuracy: 0.3741 - val_loss: 1.3294 - val_accuracy: 0.3445\n",
      "Epoch 17/50\n",
      "1668/1668 [==============================] - 1s 399us/sample - loss: 1.3682 - accuracy: 0.3777 - val_loss: 1.3328 - val_accuracy: 0.3870\n",
      "Epoch 18/50\n",
      "1668/1668 [==============================] - 1s 384us/sample - loss: 1.3874 - accuracy: 0.3663 - val_loss: 1.3245 - val_accuracy: 0.3826\n",
      "Epoch 19/50\n",
      "1668/1668 [==============================] - 1s 405us/sample - loss: 1.3414 - accuracy: 0.3909 - val_loss: 1.3299 - val_accuracy: 0.3803\n",
      "Epoch 20/50\n",
      "1668/1668 [==============================] - 1s 406us/sample - loss: 1.3408 - accuracy: 0.3933 - val_loss: 1.3200 - val_accuracy: 0.3848\n",
      "Epoch 21/50\n",
      "1668/1668 [==============================] - 1s 392us/sample - loss: 1.3212 - accuracy: 0.3873 - val_loss: 1.3529 - val_accuracy: 0.3669\n",
      "Epoch 22/50\n",
      "1668/1668 [==============================] - 1s 389us/sample - loss: 1.3357 - accuracy: 0.3957 - val_loss: 1.3008 - val_accuracy: 0.3826\n",
      "Epoch 23/50\n",
      "1668/1668 [==============================] - 1s 404us/sample - loss: 1.2951 - accuracy: 0.4263 - val_loss: 1.3390 - val_accuracy: 0.3535\n",
      "Epoch 24/50\n",
      "1668/1668 [==============================] - 1s 384us/sample - loss: 1.3242 - accuracy: 0.3987 - val_loss: 1.3337 - val_accuracy: 0.3669\n",
      "Epoch 25/50\n",
      "1668/1668 [==============================] - 1s 393us/sample - loss: 1.2858 - accuracy: 0.4263 - val_loss: 1.3087 - val_accuracy: 0.3781\n",
      "Epoch 26/50\n",
      "1668/1668 [==============================] - 1s 398us/sample - loss: 1.3050 - accuracy: 0.3909 - val_loss: 1.3132 - val_accuracy: 0.3736\n",
      "Epoch 27/50\n",
      "1668/1668 [==============================] - 1s 387us/sample - loss: 1.2805 - accuracy: 0.4119 - val_loss: 1.3069 - val_accuracy: 0.3781\n",
      "Epoch 28/50\n",
      "1668/1668 [==============================] - 1s 402us/sample - loss: 1.2947 - accuracy: 0.3855 - val_loss: 1.3031 - val_accuracy: 0.3893\n",
      "Epoch 29/50\n",
      "1668/1668 [==============================] - 1s 422us/sample - loss: 1.2574 - accuracy: 0.4275 - val_loss: 1.2988 - val_accuracy: 0.3893\n",
      "Epoch 30/50\n",
      "1668/1668 [==============================] - 1s 422us/sample - loss: 1.2513 - accuracy: 0.4406 - val_loss: 1.2873 - val_accuracy: 0.4049\n",
      "Epoch 31/50\n",
      "1668/1668 [==============================] - 1s 399us/sample - loss: 1.2753 - accuracy: 0.4227 - val_loss: 1.2991 - val_accuracy: 0.3781\n",
      "Epoch 32/50\n",
      "1668/1668 [==============================] - 1s 399us/sample - loss: 1.2604 - accuracy: 0.4227 - val_loss: 1.3018 - val_accuracy: 0.3982\n",
      "Epoch 33/50\n",
      "1668/1668 [==============================] - 1s 401us/sample - loss: 1.2321 - accuracy: 0.4424 - val_loss: 1.2701 - val_accuracy: 0.4027\n",
      "Epoch 34/50\n",
      "1668/1668 [==============================] - 1s 402us/sample - loss: 1.2417 - accuracy: 0.4299 - val_loss: 1.2608 - val_accuracy: 0.4094\n",
      "Epoch 35/50\n",
      "1668/1668 [==============================] - 1s 399us/sample - loss: 1.2069 - accuracy: 0.4652 - val_loss: 1.2890 - val_accuracy: 0.3893\n",
      "Epoch 36/50\n",
      "1668/1668 [==============================] - 1s 395us/sample - loss: 1.2170 - accuracy: 0.4616 - val_loss: 1.2824 - val_accuracy: 0.3937\n",
      "Epoch 37/50\n",
      "1668/1668 [==============================] - 1s 395us/sample - loss: 1.2559 - accuracy: 0.4305 - val_loss: 1.2712 - val_accuracy: 0.3870\n",
      "Epoch 38/50\n",
      "1668/1668 [==============================] - 1s 389us/sample - loss: 1.2112 - accuracy: 0.4550 - val_loss: 1.2876 - val_accuracy: 0.3669\n",
      "Epoch 39/50\n",
      "1668/1668 [==============================] - 1s 385us/sample - loss: 1.2172 - accuracy: 0.4730 - val_loss: 1.2713 - val_accuracy: 0.3826\n",
      "Epoch 40/50\n",
      "1668/1668 [==============================] - 1s 392us/sample - loss: 1.2025 - accuracy: 0.4730 - val_loss: 1.2506 - val_accuracy: 0.3982\n",
      "Epoch 41/50\n",
      "1668/1668 [==============================] - 1s 403us/sample - loss: 1.1969 - accuracy: 0.4844 - val_loss: 1.2833 - val_accuracy: 0.4072\n",
      "Epoch 42/50\n",
      "1668/1668 [==============================] - 1s 389us/sample - loss: 1.1967 - accuracy: 0.4568 - val_loss: 1.2501 - val_accuracy: 0.4004\n",
      "Epoch 43/50\n",
      "1668/1668 [==============================] - 1s 392us/sample - loss: 1.2070 - accuracy: 0.4616 - val_loss: 1.2581 - val_accuracy: 0.4139\n",
      "Epoch 44/50\n",
      "1668/1668 [==============================] - 1s 422us/sample - loss: 1.1724 - accuracy: 0.4772 - val_loss: 1.2663 - val_accuracy: 0.4273\n",
      "Epoch 45/50\n",
      "1668/1668 [==============================] - 1s 408us/sample - loss: 1.1768 - accuracy: 0.4886 - val_loss: 1.2636 - val_accuracy: 0.4318\n",
      "Epoch 46/50\n",
      "1668/1668 [==============================] - 1s 397us/sample - loss: 1.1877 - accuracy: 0.4718 - val_loss: 1.2530 - val_accuracy: 0.4027\n",
      "Epoch 47/50\n",
      "1668/1668 [==============================] - 1s 404us/sample - loss: 1.1767 - accuracy: 0.4892 - val_loss: 1.3270 - val_accuracy: 0.4116\n",
      "Epoch 48/50\n",
      "1668/1668 [==============================] - 1s 412us/sample - loss: 1.1869 - accuracy: 0.4724 - val_loss: 1.2530 - val_accuracy: 0.4362\n",
      "Epoch 49/50\n",
      "1668/1668 [==============================] - 1s 411us/sample - loss: 1.1463 - accuracy: 0.4916 - val_loss: 1.2719 - val_accuracy: 0.4228\n",
      "Epoch 50/50\n",
      "1668/1668 [==============================] - 1s 408us/sample - loss: 1.1466 - accuracy: 0.5030 - val_loss: 1.2263 - val_accuracy: 0.4497\n",
      "1668/1668 [==============================] - 0s 145us/sample - loss: 1.0414 - accuracy: 0.5498\n",
      "443/443 [==============================] - 0s 151us/sample - loss: 1.1792 - accuracy: 0.4718\n",
      "train accuracy: 54.976%\n",
      "test accuracy: 47.178%\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_28 (Conv2D)           (None, 100, 1, 25)        5525      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 34, 1, 25)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 34, 1, 25)         100       \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 34, 1, 25)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 34, 1, 50)         12550     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 12, 1, 50)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 12, 1, 50)         200       \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 12, 1, 50)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 12, 1, 100)        50100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling (None, 4, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 4, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 4, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 4, 1, 200)         200200    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling (None, 2, 1, 200)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 2, 1, 200)         800       \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 2, 1, 200)         0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 4)                 1604      \n",
      "=================================================================\n",
      "Total params: 271,479\n",
      "Trainable params: 270,729\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "=================300===================\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_32 (Conv2D)           (None, 300, 1, 25)        5525      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_32 (MaxPooling (None, 100, 1, 25)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 100, 1, 25)        100       \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 100, 1, 25)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 100, 1, 50)        12550     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_33 (MaxPooling (None, 34, 1, 50)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 34, 1, 50)         200       \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 34, 1, 50)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 34, 1, 100)        50100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_34 (MaxPooling (None, 12, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 12, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 12, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 12, 1, 200)        200200    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_35 (MaxPooling (None, 4, 1, 200)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 4, 1, 200)         800       \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 4, 1, 200)         0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 4)                 3204      \n",
      "=================================================================\n",
      "Total params: 273,079\n",
      "Trainable params: 272,329\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "Train on 1668 samples, validate on 447 samples\n",
      "Epoch 1/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 2.3558 - accuracy: 0.2806 - val_loss: 2.5878 - val_accuracy: 0.3020\n",
      "Epoch 2/50\n",
      "1668/1668 [==============================] - 1s 883us/sample - loss: 2.0445 - accuracy: 0.3171 - val_loss: 1.7166 - val_accuracy: 0.3132\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1668/1668 [==============================] - 1s 877us/sample - loss: 1.9816 - accuracy: 0.3195 - val_loss: 1.7836 - val_accuracy: 0.2707\n",
      "Epoch 4/50\n",
      "1668/1668 [==============================] - 1s 831us/sample - loss: 1.8367 - accuracy: 0.3315 - val_loss: 1.6528 - val_accuracy: 0.3289\n",
      "Epoch 5/50\n",
      "1668/1668 [==============================] - 1s 836us/sample - loss: 1.8102 - accuracy: 0.3297 - val_loss: 1.4941 - val_accuracy: 0.3378\n",
      "Epoch 6/50\n",
      "1668/1668 [==============================] - 2s 1ms/sample - loss: 1.7047 - accuracy: 0.3555 - val_loss: 1.2982 - val_accuracy: 0.4027\n",
      "Epoch 7/50\n",
      "1668/1668 [==============================] - 1s 808us/sample - loss: 1.6063 - accuracy: 0.3519 - val_loss: 1.3509 - val_accuracy: 0.3714\n",
      "Epoch 8/50\n",
      "1668/1668 [==============================] - 1s 831us/sample - loss: 1.6042 - accuracy: 0.3441 - val_loss: 1.3363 - val_accuracy: 0.3624\n",
      "Epoch 9/50\n",
      "1668/1668 [==============================] - 1s 822us/sample - loss: 1.4613 - accuracy: 0.3885 - val_loss: 1.3114 - val_accuracy: 0.4072\n",
      "Epoch 10/50\n",
      "1668/1668 [==============================] - 1s 863us/sample - loss: 1.4826 - accuracy: 0.3867 - val_loss: 1.2978 - val_accuracy: 0.4027\n",
      "Epoch 11/50\n",
      "1668/1668 [==============================] - 1s 873us/sample - loss: 1.3970 - accuracy: 0.4161 - val_loss: 1.2998 - val_accuracy: 0.3826\n",
      "Epoch 12/50\n",
      "1668/1668 [==============================] - 1s 830us/sample - loss: 1.4422 - accuracy: 0.3825 - val_loss: 1.3972 - val_accuracy: 0.3289\n",
      "Epoch 13/50\n",
      "1668/1668 [==============================] - 1s 874us/sample - loss: 1.3821 - accuracy: 0.4035 - val_loss: 1.3212 - val_accuracy: 0.4116\n",
      "Epoch 14/50\n",
      "1668/1668 [==============================] - 1s 808us/sample - loss: 1.3676 - accuracy: 0.4095 - val_loss: 1.2983 - val_accuracy: 0.4072\n",
      "Epoch 15/50\n",
      "1668/1668 [==============================] - 1s 835us/sample - loss: 1.3524 - accuracy: 0.4197 - val_loss: 1.3548 - val_accuracy: 0.3602\n",
      "Epoch 16/50\n",
      "1668/1668 [==============================] - 1s 840us/sample - loss: 1.3486 - accuracy: 0.4287 - val_loss: 1.1956 - val_accuracy: 0.4698\n",
      "Epoch 17/50\n",
      "1668/1668 [==============================] - 1s 859us/sample - loss: 1.2568 - accuracy: 0.4526 - val_loss: 1.2635 - val_accuracy: 0.3647\n",
      "Epoch 18/50\n",
      "1668/1668 [==============================] - 1s 839us/sample - loss: 1.2713 - accuracy: 0.4394 - val_loss: 1.3008 - val_accuracy: 0.3714\n",
      "Epoch 19/50\n",
      "1668/1668 [==============================] - 1s 847us/sample - loss: 1.2107 - accuracy: 0.4868 - val_loss: 1.2572 - val_accuracy: 0.4116\n",
      "Epoch 20/50\n",
      "1668/1668 [==============================] - 1s 892us/sample - loss: 1.2392 - accuracy: 0.4622 - val_loss: 1.2533 - val_accuracy: 0.4318\n",
      "Epoch 21/50\n",
      "1668/1668 [==============================] - 1s 847us/sample - loss: 1.1967 - accuracy: 0.4958 - val_loss: 1.2045 - val_accuracy: 0.4832\n",
      "Epoch 22/50\n",
      "1668/1668 [==============================] - 1s 862us/sample - loss: 1.1731 - accuracy: 0.5018 - val_loss: 1.1941 - val_accuracy: 0.4586\n",
      "Epoch 23/50\n",
      "1668/1668 [==============================] - 1s 870us/sample - loss: 1.1741 - accuracy: 0.5156 - val_loss: 1.1631 - val_accuracy: 0.4698\n",
      "Epoch 24/50\n",
      "1668/1668 [==============================] - 2s 910us/sample - loss: 1.1490 - accuracy: 0.5180 - val_loss: 1.1256 - val_accuracy: 0.4989\n",
      "Epoch 25/50\n",
      "1668/1668 [==============================] - 1s 814us/sample - loss: 1.1335 - accuracy: 0.5240 - val_loss: 1.0986 - val_accuracy: 0.5369\n",
      "Epoch 26/50\n",
      "1668/1668 [==============================] - 1s 837us/sample - loss: 1.1185 - accuracy: 0.5282 - val_loss: 1.1388 - val_accuracy: 0.5168\n",
      "Epoch 27/50\n",
      "1668/1668 [==============================] - 1s 853us/sample - loss: 1.0770 - accuracy: 0.5576 - val_loss: 1.0735 - val_accuracy: 0.5481\n",
      "Epoch 28/50\n",
      "1668/1668 [==============================] - 1s 856us/sample - loss: 1.0973 - accuracy: 0.5372 - val_loss: 1.1230 - val_accuracy: 0.4922\n",
      "Epoch 29/50\n",
      "1668/1668 [==============================] - 1s 819us/sample - loss: 1.0507 - accuracy: 0.5624 - val_loss: 1.1749 - val_accuracy: 0.4966\n",
      "Epoch 30/50\n",
      "1668/1668 [==============================] - 1s 850us/sample - loss: 1.0174 - accuracy: 0.5821 - val_loss: 1.1767 - val_accuracy: 0.4832\n",
      "Epoch 31/50\n",
      "1668/1668 [==============================] - 1s 874us/sample - loss: 1.0660 - accuracy: 0.5522 - val_loss: 1.1739 - val_accuracy: 0.4989\n",
      "Epoch 32/50\n",
      "1668/1668 [==============================] - 1s 845us/sample - loss: 1.0276 - accuracy: 0.5857 - val_loss: 1.0988 - val_accuracy: 0.5190\n",
      "Epoch 33/50\n",
      "1668/1668 [==============================] - 1s 868us/sample - loss: 1.0200 - accuracy: 0.5665 - val_loss: 1.0905 - val_accuracy: 0.5257\n",
      "Epoch 34/50\n",
      "1668/1668 [==============================] - 2s 906us/sample - loss: 1.0114 - accuracy: 0.5719 - val_loss: 1.0897 - val_accuracy: 0.5235\n",
      "Epoch 35/50\n",
      "1668/1668 [==============================] - 1s 899us/sample - loss: 1.0053 - accuracy: 0.5767 - val_loss: 1.0862 - val_accuracy: 0.4966\n",
      "Epoch 36/50\n",
      "1668/1668 [==============================] - 1s 859us/sample - loss: 1.0160 - accuracy: 0.5785 - val_loss: 1.0353 - val_accuracy: 0.5660\n",
      "Epoch 37/50\n",
      "1668/1668 [==============================] - 1s 874us/sample - loss: 1.0378 - accuracy: 0.5683 - val_loss: 1.0606 - val_accuracy: 0.5190\n",
      "Epoch 38/50\n",
      "1668/1668 [==============================] - 1s 857us/sample - loss: 0.9903 - accuracy: 0.5947 - val_loss: 1.1188 - val_accuracy: 0.5257\n",
      "Epoch 39/50\n",
      "1668/1668 [==============================] - 1s 863us/sample - loss: 0.9946 - accuracy: 0.6043 - val_loss: 1.0683 - val_accuracy: 0.5638\n",
      "Epoch 40/50\n",
      "1668/1668 [==============================] - 1s 834us/sample - loss: 0.9633 - accuracy: 0.5953 - val_loss: 1.0293 - val_accuracy: 0.5436\n",
      "Epoch 41/50\n",
      "1668/1668 [==============================] - 1s 859us/sample - loss: 1.0175 - accuracy: 0.5911 - val_loss: 1.0199 - val_accuracy: 0.5526\n",
      "Epoch 42/50\n",
      "1668/1668 [==============================] - 1s 851us/sample - loss: 0.9701 - accuracy: 0.6037 - val_loss: 1.0108 - val_accuracy: 0.5727\n",
      "Epoch 43/50\n",
      "1668/1668 [==============================] - 1s 834us/sample - loss: 0.9255 - accuracy: 0.6181 - val_loss: 1.0232 - val_accuracy: 0.5794\n",
      "Epoch 44/50\n",
      "1668/1668 [==============================] - 1s 853us/sample - loss: 0.9192 - accuracy: 0.6283 - val_loss: 1.0227 - val_accuracy: 0.5526\n",
      "Epoch 45/50\n",
      "1668/1668 [==============================] - 2s 924us/sample - loss: 0.9287 - accuracy: 0.6247 - val_loss: 0.9797 - val_accuracy: 0.5973\n",
      "Epoch 46/50\n",
      "1668/1668 [==============================] - 2s 908us/sample - loss: 0.9156 - accuracy: 0.6367 - val_loss: 0.9712 - val_accuracy: 0.6107\n",
      "Epoch 47/50\n",
      "1668/1668 [==============================] - 1s 814us/sample - loss: 0.9158 - accuracy: 0.6181 - val_loss: 0.9781 - val_accuracy: 0.5817\n",
      "Epoch 48/50\n",
      "1668/1668 [==============================] - 1s 882us/sample - loss: 0.9272 - accuracy: 0.6229 - val_loss: 0.9845 - val_accuracy: 0.6152\n",
      "Epoch 49/50\n",
      "1668/1668 [==============================] - 1s 841us/sample - loss: 0.8713 - accuracy: 0.6445 - val_loss: 0.9932 - val_accuracy: 0.5682\n",
      "Epoch 50/50\n",
      "1668/1668 [==============================] - 1s 824us/sample - loss: 0.8813 - accuracy: 0.6511 - val_loss: 1.0177 - val_accuracy: 0.5548\n",
      "1668/1668 [==============================] - 0s 246us/sample - loss: 0.7067 - accuracy: 0.7320\n",
      "443/443 [==============================] - 0s 259us/sample - loss: 0.9670 - accuracy: 0.5824\n",
      "train accuracy: 73.201%\n",
      "test accuracy: 58.239%\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_32 (Conv2D)           (None, 300, 1, 25)        5525      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_32 (MaxPooling (None, 100, 1, 25)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 100, 1, 25)        100       \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 100, 1, 25)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 100, 1, 50)        12550     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_33 (MaxPooling (None, 34, 1, 50)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 34, 1, 50)         200       \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 34, 1, 50)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 34, 1, 100)        50100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_34 (MaxPooling (None, 12, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 12, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 12, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 12, 1, 200)        200200    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_35 (MaxPooling (None, 4, 1, 200)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 4, 1, 200)         800       \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 4, 1, 200)         0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 4)                 3204      \n",
      "=================================================================\n",
      "Total params: 273,079\n",
      "Trainable params: 272,329\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "=================500===================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_36 (Conv2D)           (None, 500, 1, 25)        5525      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_36 (MaxPooling (None, 167, 1, 25)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 167, 1, 25)        100       \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 167, 1, 25)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 167, 1, 50)        12550     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_37 (MaxPooling (None, 56, 1, 50)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 56, 1, 50)         200       \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 56, 1, 50)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 56, 1, 100)        50100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_38 (MaxPooling (None, 19, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 19, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 19, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 19, 1, 200)        200200    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_39 (MaxPooling (None, 7, 1, 200)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (None, 7, 1, 200)         800       \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 7, 1, 200)         0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 1400)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 4)                 5604      \n",
      "=================================================================\n",
      "Total params: 275,479\n",
      "Trainable params: 274,729\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "Train on 1668 samples, validate on 447 samples\n",
      "Epoch 1/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 2.2476 - accuracy: 0.3016 - val_loss: 2.1765 - val_accuracy: 0.3423\n",
      "Epoch 2/50\n",
      "1668/1668 [==============================] - 2s 1ms/sample - loss: 2.0116 - accuracy: 0.3094 - val_loss: 1.5626 - val_accuracy: 0.4206\n",
      "Epoch 3/50\n",
      "1668/1668 [==============================] - 2s 1ms/sample - loss: 1.8956 - accuracy: 0.3387 - val_loss: 1.4842 - val_accuracy: 0.4139\n",
      "Epoch 4/50\n",
      "1668/1668 [==============================] - 2s 1ms/sample - loss: 1.8173 - accuracy: 0.3495 - val_loss: 1.3134 - val_accuracy: 0.4273\n",
      "Epoch 5/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 1.6816 - accuracy: 0.3711 - val_loss: 1.2244 - val_accuracy: 0.4295\n",
      "Epoch 6/50\n",
      "1668/1668 [==============================] - 2s 1ms/sample - loss: 1.5130 - accuracy: 0.4185 - val_loss: 1.2481 - val_accuracy: 0.4072\n",
      "Epoch 7/50\n",
      "1668/1668 [==============================] - 2s 1ms/sample - loss: 1.4732 - accuracy: 0.4382 - val_loss: 1.3050 - val_accuracy: 0.4407\n",
      "Epoch 8/50\n",
      "1668/1668 [==============================] - 2s 1ms/sample - loss: 1.4582 - accuracy: 0.4365 - val_loss: 1.3010 - val_accuracy: 0.4206\n",
      "Epoch 9/50\n",
      "1668/1668 [==============================] - 2s 1ms/sample - loss: 1.4337 - accuracy: 0.4299 - val_loss: 1.3012 - val_accuracy: 0.3915\n",
      "Epoch 10/50\n",
      "1668/1668 [==============================] - 2s 1ms/sample - loss: 1.3612 - accuracy: 0.4514 - val_loss: 1.3306 - val_accuracy: 0.4295\n",
      "Epoch 11/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 1.3114 - accuracy: 0.4562 - val_loss: 1.3064 - val_accuracy: 0.4452\n",
      "Epoch 12/50\n",
      "1668/1668 [==============================] - 2s 1ms/sample - loss: 1.2859 - accuracy: 0.4952 - val_loss: 1.3197 - val_accuracy: 0.3736\n",
      "Epoch 13/50\n",
      "1668/1668 [==============================] - 2s 1ms/sample - loss: 1.2715 - accuracy: 0.4964 - val_loss: 1.2233 - val_accuracy: 0.4586\n",
      "Epoch 14/50\n",
      "1668/1668 [==============================] - 2s 1ms/sample - loss: 1.2437 - accuracy: 0.5024 - val_loss: 1.2358 - val_accuracy: 0.4318\n",
      "Epoch 15/50\n",
      "1668/1668 [==============================] - 2s 1ms/sample - loss: 1.2221 - accuracy: 0.5162 - val_loss: 1.1642 - val_accuracy: 0.4989\n",
      "Epoch 16/50\n",
      "1668/1668 [==============================] - 2s 1ms/sample - loss: 1.2546 - accuracy: 0.4844 - val_loss: 1.1834 - val_accuracy: 0.4698\n",
      "Epoch 17/50\n",
      "1668/1668 [==============================] - 2s 1ms/sample - loss: 1.2173 - accuracy: 0.5144 - val_loss: 1.2518 - val_accuracy: 0.4318\n",
      "Epoch 18/50\n",
      "1668/1668 [==============================] - 2s 1ms/sample - loss: 1.1766 - accuracy: 0.5288 - val_loss: 1.2630 - val_accuracy: 0.4452\n",
      "Epoch 19/50\n",
      "1668/1668 [==============================] - 2s 1ms/sample - loss: 1.1536 - accuracy: 0.5306 - val_loss: 1.1012 - val_accuracy: 0.5145\n",
      "Epoch 20/50\n",
      "1668/1668 [==============================] - 2s 1ms/sample - loss: 1.1523 - accuracy: 0.5288 - val_loss: 1.0666 - val_accuracy: 0.5369\n",
      "Epoch 21/50\n",
      "1668/1668 [==============================] - 2s 1ms/sample - loss: 1.0854 - accuracy: 0.5653 - val_loss: 1.0753 - val_accuracy: 0.5503\n",
      "Epoch 22/50\n",
      "1668/1668 [==============================] - 2s 1ms/sample - loss: 1.0668 - accuracy: 0.5731 - val_loss: 1.1392 - val_accuracy: 0.5034\n",
      "Epoch 23/50\n",
      "1668/1668 [==============================] - 2s 1ms/sample - loss: 1.0581 - accuracy: 0.5665 - val_loss: 1.2080 - val_accuracy: 0.4743\n",
      "Epoch 24/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 1.0728 - accuracy: 0.5713 - val_loss: 1.1852 - val_accuracy: 0.5078\n",
      "Epoch 25/50\n",
      "1668/1668 [==============================] - 2s 1ms/sample - loss: 1.0515 - accuracy: 0.5755 - val_loss: 1.0835 - val_accuracy: 0.5213\n",
      "Epoch 26/50\n",
      "1668/1668 [==============================] - 2s 1ms/sample - loss: 1.0445 - accuracy: 0.5803 - val_loss: 1.0648 - val_accuracy: 0.5503\n",
      "Epoch 27/50\n",
      "1668/1668 [==============================] - 2s 1ms/sample - loss: 1.0203 - accuracy: 0.5797 - val_loss: 1.0484 - val_accuracy: 0.5503\n",
      "Epoch 28/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 1.0072 - accuracy: 0.6031 - val_loss: 1.1294 - val_accuracy: 0.5145\n",
      "Epoch 29/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 0.9966 - accuracy: 0.5971 - val_loss: 1.0729 - val_accuracy: 0.5414\n",
      "Epoch 30/50\n",
      "1668/1668 [==============================] - 2s 1ms/sample - loss: 1.0210 - accuracy: 0.5911 - val_loss: 1.1390 - val_accuracy: 0.5347\n",
      "Epoch 31/50\n",
      "1668/1668 [==============================] - 2s 1ms/sample - loss: 1.0208 - accuracy: 0.5839 - val_loss: 1.0787 - val_accuracy: 0.5503\n",
      "Epoch 32/50\n",
      "1668/1668 [==============================] - 2s 1ms/sample - loss: 0.9580 - accuracy: 0.6145 - val_loss: 0.9693 - val_accuracy: 0.5772\n",
      "Epoch 33/50\n",
      "1668/1668 [==============================] - 2s 1ms/sample - loss: 0.9384 - accuracy: 0.6343 - val_loss: 1.1241 - val_accuracy: 0.5213\n",
      "Epoch 34/50\n",
      "1668/1668 [==============================] - 2s 1ms/sample - loss: 0.9974 - accuracy: 0.6031 - val_loss: 0.9666 - val_accuracy: 0.6063\n",
      "Epoch 35/50\n",
      "1668/1668 [==============================] - 2s 1ms/sample - loss: 0.9509 - accuracy: 0.6169 - val_loss: 1.0562 - val_accuracy: 0.5749\n",
      "Epoch 36/50\n",
      "1668/1668 [==============================] - 2s 1ms/sample - loss: 0.9549 - accuracy: 0.6235 - val_loss: 1.0202 - val_accuracy: 0.5906\n",
      "Epoch 37/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 0.9474 - accuracy: 0.6193 - val_loss: 1.0587 - val_accuracy: 0.5772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50\n",
      "1668/1668 [==============================] - 2s 1ms/sample - loss: 0.9054 - accuracy: 0.6259 - val_loss: 1.0103 - val_accuracy: 0.5884\n",
      "Epoch 39/50\n",
      "1668/1668 [==============================] - 2s 1ms/sample - loss: 0.9061 - accuracy: 0.6337 - val_loss: 0.9406 - val_accuracy: 0.5839\n",
      "Epoch 40/50\n",
      "1668/1668 [==============================] - 2s 1ms/sample - loss: 0.8880 - accuracy: 0.6307 - val_loss: 1.0223 - val_accuracy: 0.5548\n",
      "Epoch 41/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 0.8846 - accuracy: 0.6529 - val_loss: 0.9732 - val_accuracy: 0.5817\n",
      "Epoch 42/50\n",
      "1668/1668 [==============================] - 2s 1ms/sample - loss: 0.8928 - accuracy: 0.6361 - val_loss: 0.9329 - val_accuracy: 0.5861\n",
      "Epoch 43/50\n",
      "1668/1668 [==============================] - 2s 1ms/sample - loss: 0.8936 - accuracy: 0.6379 - val_loss: 0.9553 - val_accuracy: 0.5817\n",
      "Epoch 44/50\n",
      "1668/1668 [==============================] - 2s 1ms/sample - loss: 0.9270 - accuracy: 0.6151 - val_loss: 0.9180 - val_accuracy: 0.6063\n",
      "Epoch 45/50\n",
      "1668/1668 [==============================] - 2s 1ms/sample - loss: 0.8897 - accuracy: 0.6535 - val_loss: 0.9527 - val_accuracy: 0.5973\n",
      "Epoch 46/50\n",
      "1668/1668 [==============================] - 2s 1ms/sample - loss: 0.8717 - accuracy: 0.6475 - val_loss: 1.0173 - val_accuracy: 0.5906\n",
      "Epoch 47/50\n",
      "1668/1668 [==============================] - 2s 1ms/sample - loss: 0.8804 - accuracy: 0.6367 - val_loss: 0.9883 - val_accuracy: 0.5884\n",
      "Epoch 48/50\n",
      "1668/1668 [==============================] - 2s 1ms/sample - loss: 0.9059 - accuracy: 0.6625 - val_loss: 1.0168 - val_accuracy: 0.5794\n",
      "Epoch 49/50\n",
      "1668/1668 [==============================] - 2s 1ms/sample - loss: 0.8470 - accuracy: 0.6679 - val_loss: 0.9591 - val_accuracy: 0.6197\n",
      "Epoch 50/50\n",
      "1668/1668 [==============================] - 2s 1ms/sample - loss: 0.8059 - accuracy: 0.6859 - val_loss: 0.9432 - val_accuracy: 0.5973\n",
      "1668/1668 [==============================] - 1s 356us/sample - loss: 0.5655 - accuracy: 0.8189\n",
      "443/443 [==============================] - 0s 351us/sample - loss: 0.9449 - accuracy: 0.6253\n",
      "train accuracy: 81.894%\n",
      "test accuracy: 62.528%\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_36 (Conv2D)           (None, 500, 1, 25)        5525      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_36 (MaxPooling (None, 167, 1, 25)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 167, 1, 25)        100       \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 167, 1, 25)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 167, 1, 50)        12550     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_37 (MaxPooling (None, 56, 1, 50)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 56, 1, 50)         200       \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 56, 1, 50)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 56, 1, 100)        50100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_38 (MaxPooling (None, 19, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 19, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 19, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 19, 1, 200)        200200    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_39 (MaxPooling (None, 7, 1, 200)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (None, 7, 1, 200)         800       \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 7, 1, 200)         0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 1400)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 4)                 5604      \n",
      "=================================================================\n",
      "Total params: 275,479\n",
      "Trainable params: 274,729\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "=================700===================\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_40 (Conv2D)           (None, 700, 1, 25)        5525      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_40 (MaxPooling (None, 234, 1, 25)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 234, 1, 25)        100       \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 234, 1, 25)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 234, 1, 50)        12550     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_41 (MaxPooling (None, 78, 1, 50)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_41 (Batc (None, 78, 1, 50)         200       \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 78, 1, 50)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 78, 1, 100)        50100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_42 (MaxPooling (None, 26, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_42 (Batc (None, 26, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 26, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 26, 1, 200)        200200    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_43 (MaxPooling (None, 9, 1, 200)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_43 (Batc (None, 9, 1, 200)         800       \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 9, 1, 200)         0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 1800)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 4)                 7204      \n",
      "=================================================================\n",
      "Total params: 277,079\n",
      "Trainable params: 276,329\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "Train on 1668 samples, validate on 447 samples\n",
      "Epoch 1/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 2.3584 - accuracy: 0.2728 - val_loss: 1.4875 - val_accuracy: 0.3468\n",
      "Epoch 2/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 2.0645 - accuracy: 0.3195 - val_loss: 2.0193 - val_accuracy: 0.2975\n",
      "Epoch 3/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 1.8556 - accuracy: 0.3465 - val_loss: 1.7743 - val_accuracy: 0.3311\n",
      "Epoch 4/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 1.7898 - accuracy: 0.3363 - val_loss: 1.5837 - val_accuracy: 0.3535\n",
      "Epoch 5/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 1.7456 - accuracy: 0.3453 - val_loss: 1.5973 - val_accuracy: 0.3557\n",
      "Epoch 6/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 1.6813 - accuracy: 0.3657 - val_loss: 1.5295 - val_accuracy: 0.3579\n",
      "Epoch 7/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 1.6303 - accuracy: 0.3699 - val_loss: 1.4203 - val_accuracy: 0.3826\n",
      "Epoch 8/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 1.6094 - accuracy: 0.3699 - val_loss: 1.3625 - val_accuracy: 0.4161\n",
      "Epoch 9/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 1.5256 - accuracy: 0.3741 - val_loss: 1.2779 - val_accuracy: 0.4116\n",
      "Epoch 10/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 1.4520 - accuracy: 0.4119 - val_loss: 1.3837 - val_accuracy: 0.3065\n",
      "Epoch 11/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 1.4311 - accuracy: 0.4311 - val_loss: 1.3815 - val_accuracy: 0.3289\n",
      "Epoch 12/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 1.4208 - accuracy: 0.4365 - val_loss: 1.2903 - val_accuracy: 0.4161\n",
      "Epoch 13/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 1.3965 - accuracy: 0.4347 - val_loss: 1.4763 - val_accuracy: 0.3736\n",
      "Epoch 14/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 1.3178 - accuracy: 0.4730 - val_loss: 1.2448 - val_accuracy: 0.4609\n",
      "Epoch 15/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 1.3069 - accuracy: 0.4778 - val_loss: 1.2232 - val_accuracy: 0.4653\n",
      "Epoch 16/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 1.2741 - accuracy: 0.4856 - val_loss: 1.2938 - val_accuracy: 0.4318\n",
      "Epoch 17/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 1.2408 - accuracy: 0.4856 - val_loss: 1.1797 - val_accuracy: 0.5011\n",
      "Epoch 18/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 1.2205 - accuracy: 0.5018 - val_loss: 1.3528 - val_accuracy: 0.3758\n",
      "Epoch 19/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 1.1685 - accuracy: 0.5162 - val_loss: 1.2813 - val_accuracy: 0.4183\n",
      "Epoch 20/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 1.1588 - accuracy: 0.5216 - val_loss: 1.1224 - val_accuracy: 0.4877\n",
      "Epoch 21/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 1.2150 - accuracy: 0.4958 - val_loss: 1.1029 - val_accuracy: 0.5235\n",
      "Epoch 22/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 1.1364 - accuracy: 0.5498 - val_loss: 1.3387 - val_accuracy: 0.3982\n",
      "Epoch 23/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 1.1440 - accuracy: 0.5234 - val_loss: 1.1604 - val_accuracy: 0.4989\n",
      "Epoch 24/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 1.0857 - accuracy: 0.5731 - val_loss: 1.2341 - val_accuracy: 0.4586\n",
      "Epoch 25/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 1.1340 - accuracy: 0.5390 - val_loss: 1.1435 - val_accuracy: 0.5011\n",
      "Epoch 26/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 1.1081 - accuracy: 0.5558 - val_loss: 1.1427 - val_accuracy: 0.4810\n",
      "Epoch 27/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 1.0825 - accuracy: 0.5546 - val_loss: 1.1063 - val_accuracy: 0.5257\n",
      "Epoch 28/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 1.0441 - accuracy: 0.5713 - val_loss: 1.1725 - val_accuracy: 0.4855\n",
      "Epoch 29/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 1.0448 - accuracy: 0.5845 - val_loss: 1.3055 - val_accuracy: 0.4072\n",
      "Epoch 30/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 1.0103 - accuracy: 0.6091 - val_loss: 1.1402 - val_accuracy: 0.5145\n",
      "Epoch 31/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 1.0027 - accuracy: 0.5983 - val_loss: 1.0018 - val_accuracy: 0.5951\n",
      "Epoch 32/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 0.9940 - accuracy: 0.6097 - val_loss: 1.2255 - val_accuracy: 0.4787\n",
      "Epoch 33/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 0.9537 - accuracy: 0.6085 - val_loss: 1.0603 - val_accuracy: 0.5817\n",
      "Epoch 34/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 0.9783 - accuracy: 0.6067 - val_loss: 0.9994 - val_accuracy: 0.5794\n",
      "Epoch 35/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 0.9158 - accuracy: 0.6343 - val_loss: 1.0377 - val_accuracy: 0.5615\n",
      "Epoch 36/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 0.9344 - accuracy: 0.6259 - val_loss: 0.9976 - val_accuracy: 0.5794\n",
      "Epoch 37/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 0.8663 - accuracy: 0.6523 - val_loss: 0.9810 - val_accuracy: 0.6040\n",
      "Epoch 38/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 0.8603 - accuracy: 0.6547 - val_loss: 1.0791 - val_accuracy: 0.5481\n",
      "Epoch 39/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 0.8923 - accuracy: 0.6427 - val_loss: 1.1718 - val_accuracy: 0.5190\n",
      "Epoch 40/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 0.9156 - accuracy: 0.6271 - val_loss: 1.0067 - val_accuracy: 0.5906\n",
      "Epoch 41/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 0.8627 - accuracy: 0.6547 - val_loss: 0.9980 - val_accuracy: 0.5772\n",
      "Epoch 42/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 0.8768 - accuracy: 0.6481 - val_loss: 1.0821 - val_accuracy: 0.5682\n",
      "Epoch 43/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 0.9395 - accuracy: 0.6331 - val_loss: 1.2036 - val_accuracy: 0.4922\n",
      "Epoch 44/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 0.8564 - accuracy: 0.6649 - val_loss: 1.1110 - val_accuracy: 0.5503\n",
      "Epoch 45/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 0.8492 - accuracy: 0.6727 - val_loss: 1.1760 - val_accuracy: 0.5280\n",
      "Epoch 46/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 0.8148 - accuracy: 0.6757 - val_loss: 1.0548 - val_accuracy: 0.5548\n",
      "Epoch 47/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 0.8185 - accuracy: 0.6787 - val_loss: 1.3556 - val_accuracy: 0.4653\n",
      "Epoch 48/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 0.7649 - accuracy: 0.6936 - val_loss: 1.0662 - val_accuracy: 0.5570\n",
      "Epoch 49/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 0.7460 - accuracy: 0.7170 - val_loss: 0.8619 - val_accuracy: 0.6555\n",
      "Epoch 50/50\n",
      "1668/1668 [==============================] - 3s 2ms/sample - loss: 0.7821 - accuracy: 0.6871 - val_loss: 0.8899 - val_accuracy: 0.6353\n",
      "1668/1668 [==============================] - 1s 544us/sample - loss: 0.5304 - accuracy: 0.8201\n",
      "443/443 [==============================] - 0s 437us/sample - loss: 0.9583 - accuracy: 0.6230\n",
      "train accuracy: 82.014%\n",
      "test accuracy: 62.302%\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_40 (Conv2D)           (None, 700, 1, 25)        5525      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_40 (MaxPooling (None, 234, 1, 25)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 234, 1, 25)        100       \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 234, 1, 25)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 234, 1, 50)        12550     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_41 (MaxPooling (None, 78, 1, 50)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_41 (Batc (None, 78, 1, 50)         200       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 78, 1, 50)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 78, 1, 100)        50100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_42 (MaxPooling (None, 26, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_42 (Batc (None, 26, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 26, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 26, 1, 200)        200200    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_43 (MaxPooling (None, 9, 1, 200)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_43 (Batc (None, 9, 1, 200)         800       \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 9, 1, 200)         0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 1800)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 4)                 7204      \n",
      "=================================================================\n",
      "Total params: 277,079\n",
      "Trainable params: 276,329\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "=================900===================\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_44 (Conv2D)           (None, 900, 1, 25)        5525      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_44 (MaxPooling (None, 300, 1, 25)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_44 (Batc (None, 300, 1, 25)        100       \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 300, 1, 25)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 300, 1, 50)        12550     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_45 (MaxPooling (None, 100, 1, 50)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_45 (Batc (None, 100, 1, 50)        200       \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 100, 1, 50)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_46 (Conv2D)           (None, 100, 1, 100)       50100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_46 (MaxPooling (None, 34, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_46 (Batc (None, 34, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_46 (Dropout)         (None, 34, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 34, 1, 200)        200200    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_47 (MaxPooling (None, 12, 1, 200)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_47 (Batc (None, 12, 1, 200)        800       \n",
      "_________________________________________________________________\n",
      "dropout_47 (Dropout)         (None, 12, 1, 200)        0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 2400)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 4)                 9604      \n",
      "=================================================================\n",
      "Total params: 279,479\n",
      "Trainable params: 278,729\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "Train on 1668 samples, validate on 447 samples\n",
      "Epoch 1/50\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 2.2230 - accuracy: 0.2956 - val_loss: 2.4297 - val_accuracy: 0.2774\n",
      "Epoch 2/50\n",
      "1668/1668 [==============================] - 4s 3ms/sample - loss: 2.0222 - accuracy: 0.3351 - val_loss: 1.4917 - val_accuracy: 0.3669\n",
      "Epoch 3/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 1.9559 - accuracy: 0.3369 - val_loss: 1.4186 - val_accuracy: 0.3781\n",
      "Epoch 4/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 1.8172 - accuracy: 0.3579 - val_loss: 1.6647 - val_accuracy: 0.3378\n",
      "Epoch 5/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 1.8323 - accuracy: 0.3621 - val_loss: 1.5343 - val_accuracy: 0.3848\n",
      "Epoch 6/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 1.6596 - accuracy: 0.3789 - val_loss: 1.4060 - val_accuracy: 0.4027\n",
      "Epoch 7/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 1.6215 - accuracy: 0.3789 - val_loss: 1.5895 - val_accuracy: 0.3356\n",
      "Epoch 8/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 1.5914 - accuracy: 0.4131 - val_loss: 1.3267 - val_accuracy: 0.4183\n",
      "Epoch 9/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 1.5128 - accuracy: 0.4257 - val_loss: 1.3086 - val_accuracy: 0.4430\n",
      "Epoch 10/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 1.4724 - accuracy: 0.4329 - val_loss: 1.3746 - val_accuracy: 0.4228\n",
      "Epoch 11/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 1.4092 - accuracy: 0.4676 - val_loss: 1.3312 - val_accuracy: 0.4430\n",
      "Epoch 12/50\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.3295 - accuracy: 0.4826 - val_loss: 1.3424 - val_accuracy: 0.4072\n",
      "Epoch 13/50\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 1.3625 - accuracy: 0.4754 - val_loss: 1.4238 - val_accuracy: 0.4407\n",
      "Epoch 14/50\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 1.3113 - accuracy: 0.4862 - val_loss: 1.3105 - val_accuracy: 0.4362\n",
      "Epoch 15/50\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 1.2585 - accuracy: 0.5054 - val_loss: 1.2130 - val_accuracy: 0.4832\n",
      "Epoch 16/50\n",
      "1668/1668 [==============================] - 7s 4ms/sample - loss: 1.2373 - accuracy: 0.5180 - val_loss: 1.4106 - val_accuracy: 0.3937\n",
      "Epoch 17/50\n",
      "1668/1668 [==============================] - 6s 3ms/sample - loss: 1.2014 - accuracy: 0.5228 - val_loss: 1.2849 - val_accuracy: 0.4340\n",
      "Epoch 18/50\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.1991 - accuracy: 0.5156 - val_loss: 1.2315 - val_accuracy: 0.4922\n",
      "Epoch 19/50\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 1.1347 - accuracy: 0.5546 - val_loss: 1.3129 - val_accuracy: 0.4206\n",
      "Epoch 20/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 1.1024 - accuracy: 0.5516 - val_loss: 1.2959 - val_accuracy: 0.4564\n",
      "Epoch 21/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 1.1329 - accuracy: 0.5486 - val_loss: 1.1558 - val_accuracy: 0.4966\n",
      "Epoch 22/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 1.0440 - accuracy: 0.5743 - val_loss: 1.1304 - val_accuracy: 0.5257\n",
      "Epoch 23/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 1.0717 - accuracy: 0.5827 - val_loss: 1.3967 - val_accuracy: 0.4318\n",
      "Epoch 24/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 1.0795 - accuracy: 0.5689 - val_loss: 1.1943 - val_accuracy: 0.4877\n",
      "Epoch 25/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 1.0867 - accuracy: 0.5761 - val_loss: 1.0714 - val_accuracy: 0.5436\n",
      "Epoch 26/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 1.0527 - accuracy: 0.5803 - val_loss: 1.2630 - val_accuracy: 0.5101\n",
      "Epoch 27/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 1.0352 - accuracy: 0.5767 - val_loss: 1.2344 - val_accuracy: 0.4944\n",
      "Epoch 28/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 1.0391 - accuracy: 0.5995 - val_loss: 1.1266 - val_accuracy: 0.5280\n",
      "Epoch 29/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 1.0317 - accuracy: 0.5887 - val_loss: 1.1205 - val_accuracy: 0.5369\n",
      "Epoch 30/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 1.0650 - accuracy: 0.5791 - val_loss: 1.1887 - val_accuracy: 0.4966\n",
      "Epoch 31/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 0.9724 - accuracy: 0.6151 - val_loss: 1.1783 - val_accuracy: 0.5034\n",
      "Epoch 32/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 0.9624 - accuracy: 0.6301 - val_loss: 1.3295 - val_accuracy: 0.4631\n",
      "Epoch 33/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 0.9832 - accuracy: 0.6109 - val_loss: 1.1393 - val_accuracy: 0.5123\n",
      "Epoch 34/50\n",
      "1668/1668 [==============================] - 4s 3ms/sample - loss: 0.9593 - accuracy: 0.6235 - val_loss: 1.1394 - val_accuracy: 0.5369\n",
      "Epoch 35/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 1.0031 - accuracy: 0.6055 - val_loss: 1.0698 - val_accuracy: 0.5638\n",
      "Epoch 36/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 0.9586 - accuracy: 0.6121 - val_loss: 0.9892 - val_accuracy: 0.5906\n",
      "Epoch 37/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 0.9181 - accuracy: 0.6445 - val_loss: 1.0972 - val_accuracy: 0.5459\n",
      "Epoch 38/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 0.8783 - accuracy: 0.6529 - val_loss: 1.1514 - val_accuracy: 0.5145\n",
      "Epoch 39/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 0.8507 - accuracy: 0.6679 - val_loss: 1.1180 - val_accuracy: 0.5615\n",
      "Epoch 40/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 0.8269 - accuracy: 0.6751 - val_loss: 1.0905 - val_accuracy: 0.5570\n",
      "Epoch 41/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 0.8539 - accuracy: 0.6715 - val_loss: 1.1229 - val_accuracy: 0.5414\n",
      "Epoch 42/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 0.8199 - accuracy: 0.6841 - val_loss: 1.1907 - val_accuracy: 0.5324\n",
      "Epoch 43/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 0.7984 - accuracy: 0.6775 - val_loss: 1.0780 - val_accuracy: 0.5593\n",
      "Epoch 44/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 0.8422 - accuracy: 0.6733 - val_loss: 1.1660 - val_accuracy: 0.5324\n",
      "Epoch 45/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 0.8256 - accuracy: 0.6805 - val_loss: 1.1283 - val_accuracy: 0.5503\n",
      "Epoch 46/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 0.8078 - accuracy: 0.6888 - val_loss: 1.1669 - val_accuracy: 0.5369\n",
      "Epoch 47/50\n",
      "1668/1668 [==============================] - 4s 3ms/sample - loss: 0.8873 - accuracy: 0.6499 - val_loss: 1.1174 - val_accuracy: 0.5459\n",
      "Epoch 48/50\n",
      "1668/1668 [==============================] - 4s 2ms/sample - loss: 0.7788 - accuracy: 0.6912 - val_loss: 1.0508 - val_accuracy: 0.5839\n",
      "Epoch 49/50\n",
      "1668/1668 [==============================] - 4s 3ms/sample - loss: 0.7850 - accuracy: 0.6876 - val_loss: 1.1319 - val_accuracy: 0.5615\n",
      "Epoch 50/50\n",
      "1668/1668 [==============================] - 5s 3ms/sample - loss: 0.7990 - accuracy: 0.6882 - val_loss: 0.9954 - val_accuracy: 0.6107\n",
      "1668/1668 [==============================] - 2s 989us/sample - loss: 0.4665 - accuracy: 0.8369\n",
      "443/443 [==============================] - 0s 641us/sample - loss: 0.9940 - accuracy: 0.6275\n",
      "train accuracy: 83.693%\n",
      "test accuracy: 62.754%\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_44 (Conv2D)           (None, 900, 1, 25)        5525      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_44 (MaxPooling (None, 300, 1, 25)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_44 (Batc (None, 300, 1, 25)        100       \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 300, 1, 25)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 300, 1, 50)        12550     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_45 (MaxPooling (None, 100, 1, 50)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_45 (Batc (None, 100, 1, 50)        200       \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 100, 1, 50)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_46 (Conv2D)           (None, 100, 1, 100)       50100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_46 (MaxPooling (None, 34, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_46 (Batc (None, 34, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_46 (Dropout)         (None, 34, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 34, 1, 200)        200200    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_47 (MaxPooling (None, 12, 1, 200)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_47 (Batc (None, 12, 1, 200)        800       \n",
      "_________________________________________________________________\n",
      "dropout_47 (Dropout)         (None, 12, 1, 200)        0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 2400)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 4)                 9604      \n",
      "=================================================================\n",
      "Total params: 279,479\n",
      "Trainable params: 278,729\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train accuracies: \n",
      "[0.54976016, 0.7320144, 0.8189449, 0.8201439, 0.83693045]\n",
      "Test accuracies: \n",
      "[0.4717833, 0.58239275, 0.62528217, 0.6230248, 0.6275395]\n",
      "The best accuracy is 0.628.\n",
      "The corresponding time period is 300.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (19,) and (5,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23864/2629512722.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m# plot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_scores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'train accuracies'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_scores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'test accuracies'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda Python\\envs\\tf-gpu\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2787\u001b[0m     return gca().plot(\n\u001b[0;32m   2788\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[1;32m-> 2789\u001b[1;33m         is not None else {}), **kwargs)\n\u001b[0m\u001b[0;32m   2790\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2791\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda Python\\envs\\tf-gpu\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1664\u001b[0m         \"\"\"\n\u001b[0;32m   1665\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_alias_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1666\u001b[1;33m         \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1667\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1668\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda Python\\envs\\tf-gpu\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    223\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m                 \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 225\u001b[1;33m             \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda Python\\envs\\tf-gpu\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[1;34m(self, tup, kwargs)\u001b[0m\n\u001b[0;32m    389\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 391\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    392\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'plot'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda Python\\envs\\tf-gpu\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m    268\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m             raise ValueError(\"x and y must have same first dimension, but \"\n\u001b[1;32m--> 270\u001b[1;33m                              \"have shapes {} and {}\".format(x.shape, y.shape))\n\u001b[0m\u001b[0;32m    271\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (19,) and (5,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "for time in range(100, 1001, 200):\n",
    "    print(\"=================\" + str(time) + \"===================\")\n",
    "    train_score, test_score = train_data(time_period=time)\n",
    "    train_scores.append(train_score[1])\n",
    "    test_scores.append(test_score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracies: \n",
      "[0.54976016, 0.7320144, 0.8189449, 0.8201439, 0.83693045]\n",
      "Test accuracies: \n",
      "[0.4717833, 0.58239275, 0.62528217, 0.6230248, 0.6275395]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3dd3gVZfbA8e9JCCShJIROAgSQJh0DgiiiSFXAigVQXFfsZS37w44oruvaVldFdFERlCKKCCKIgLo2CIh0pCmEGkqAQELa+f0xk3AJCblAkkluzud58mT6nCn33Pe+M/OOqCrGGGMCV5DXARhjjClaluiNMSbAWaI3xpgAZ4neGGMCnCV6Y4wJcJbojTEmwFmid4nISBGZUITLXyUi3d1uEZH3RGS/iCwSkQtEZF0RrLO+iCSLSHBhL7s0K0v7pbRu65l8JkRkmIj8r4BpfhCR9qcX3ekRkQEiMqk415mtTCV6EblBROLdE3+HiMwWkfOLY92q2lJVF7q95wM9gRhV7aSq36tqszNdh4j8ISKX+Kxzi6pWUtXMM112PusTEdkkIquLYvlFpaj3S3ESkTHu+ZwsImkiku7TP7s4t1VEFopIqrvuPSLyqYjUOZ1lFdZnIi8i0h84pKq/+gxrKiJT3bgPiMhyEXlARIJFJFZEVERm5VrOBBEZ6XZ3d6d5I9c0/xORYe42zQBaiUibotiukykziV5EHgBeBZ4DagH1gTeBgR6E0wD4Q1UPe7DuwtQNqAk0EpGOxbliESlXnOsrKXJvt6re7ibySjjn9uTsflXt60GId7uxNAUigVdOdQHFcGxvBz70WV9j4BdgK9BaVSOAa4A4oLLPfJ1FpOtJlnsYuFFEYk8yzcfA8NML+/SViUQvIhHAKOAuVf1UVQ+rarqqfqGqD+czz1QR2el+u38nIi19xvUTkdUickhEtonIQ+7w6iIyU0SSRGSfiHwvIkHuuD9E5BIRuQV4F+jilnyedksDCT7Lr+eWhhJFZK+I/Mcd3lhE5rvD9ojIRBGJdMd9iPPl9YW73L/7lETKudPUFZEZbmwbRORWn3WOFJEpIjLe3a5VIhJXwK69Cfgc+NLt9t1/UeJUT20Xp4pqus+4gSKyTEQOishGEenju49yxTTB7c7elltEZAsw34/jFCYiL4nIn+74/7nDcu+XCBH5rzi/8raJyLPiVnWIyFki8q07/x4RmZzfzhDnp/kq9/gvFJEW7vARIvJJrmn/LSKv+bH+YeJUM7wiIvuAkQUck9wx5d7Whe7yf3TPky9EpJp7Lh0UkcXik6hEpLmIfO2eM+tEZJA/61XVfcA0oJW7nAoi8qKIbBGRXeL8Eglzx3UXkQQR+T8R2Qm8l8dnooUbe5K7jwf4jKvmntcHRWQR0Pgk+6M8cDHwrc/gp4EfVfUBVd3hxr9OVW9Q1SSf6V4Anj3JZicB7wNPnWSahcClJxlfNFQ14P+APkAGUO4k04wEJvj0/wXn27wCzi+BZT7jdgAXuN1VgQ5u9z+AMUCI+3cBIO64P4BL3O5hwP98ltcdSHC7g4HfcEpCFYFQ4Hx33Fk4VT4VgBrAd8CrPsvJWYfbHwto9nbjnNxvustsByQCPXy2PxXo58bwD+Dnk+yvcOCgO/1VwB6gvM/4WcBkd/+EABe6wzsBB9ztCAKigeb5xJ9zTHy2Zby7X8L8OE5v4Hywot1tOs+dLvd+mQ687S63JrAIuM0d9zHwmBtrzrHIY380xSnR9XS39+/ABqA8zi+4I0AVn2O8A+jsx/qH4Zy79wDlsrfbn3M4n3NgoRtXYyACWA38DlziLn888J47bUWcUu7N7rgO7nFumc/6FwJ/dbur43wZf+j2vwrMAKLc4/UF8A+f8z8D+Kd7fMI4/jMR4sb8qLs/LwYOAc3c8ZOAKW68rYBt+Hy+csXYEjica9hO4OaT7NfsfVjJXXb253gCMNL3MwzUxvlcZMf2P2CYz7Ki3GVVKdYcWJwr8+oPGAzsLGCaEz4kPuMi3YMT4fZvAW7LfbBwfjV8DpyVxzL+wL9E3wUnAef7peQz3+XAr3mtI9cJWg6oB2QClX3G/wN432f75/mMOxtIOcm6h2TH6X44k4Ar3HF1gCygah7zvQ28ks8yc8efc0x8tqXRSWLKOU44iTkFaJvHdL77pRZwFJ8EClwPLHC7xwNjca6nnOxYPAFM8ekPwkkK3d3+/wE3ut09gY1ud0HrHwZs8fM8z9lfeW2r278QeMxn/EvAbJ/+/rhflsC1wPd5HL+n8ln/QpwvtCR32yfiFEgE50uwsc+0XYDNPud/GhCaz2fiApxkHOQz/mN3e4OBdNzCgjvuOfJP9F3JlQvc+fucZL/6ni934haAyCPRu90v4FShZR/3YT7LCnGXVd+fY1pYf2Wi6gbYC1QXP+v+xLkA87xbrXAQJwGBU0oBpwTbD/jT/VnfxR3+L5ySx1xxLlKOOI1Y6wF/qmpGHnHVFJFJ7s/7gzgnWvUTlpC3usA+VT3kM+xPnNJutp0+3UeA0JPss5twEluGqh4FPuVY9U09d13785ivHrDRz5jzsjW7o4DjVB2nBF7QuhrgfPh2uNUCSTjJrKY7/u84iWqRW2Xwl3yWUxdnfwKgqllurNn79yOcBA5wg9vvz/qP2+ZCssunOyWP/ko+sZ2bHZcb22CcUmt+7lXVSFWNVtXBqpqIk+zDgSU+y/nKHZ4tUVVT81lmXWCru0+zZZ+7NXAS8NZc4/Kzn+Pr3cHJD/5eNH4HqCXOBd38/BPoLSJt8xiXve6kPMYVmbKS6H/CqZa43M/pb8C5SHsJTukw1h0uAKq6WFUH4nwYp+P8bERVD6nqg6raCKdk9ICI9DjFWLcC9fNJsP/AKQ20UdUqOKVq8Rl/sqZItwNRIuJ7ktfHKXmdEhGJwfn5PMStH98JXA30E5Hq7jZEiXv9IJet5F+HehgnIWTLK6H4buPJjtMenGOeb32tTzxHgepugopU1Sqq2hJAVXeq6q2qWhfnV9ybInJWHsvZjpMYnQBEBOdLLXv/TgW6u/vuCo4l+pOuP49tLk5bgW994opU5yLvHae4nD04XyAtfZYToc5F22wFnbv1xL3e5co+dxNxqn3q5RqXn/U4h8e3gDMPp/BWIFVNx6nTf4bjP3u+0+zFqap6Jo/RLXBuxDjoz/oKS5lI9Kp6AHgSeENELheRcBEJEZG+IvJCHrNUxvnw7cVJPM9ljxCR8iIyWEQi3IN+EKdKBBG5zL14Jz7DT/W2tkU49bfPi0hFEQmVY1f6KwPJQJJ7oua+kLwLaJTPPtgK/Aj8w11mG+AWnJ/Xp2ooTr1uM5y6/nY4ddQJwPXqXNCajZMUq7r7ups773+Bm0Wkh4gEiUi0iDR3xy0DrnOnj8P58jiZfI+TW/obB7wszkXoYBHpIiIVcu2XHcBc4CURqeLG1FhELgQQkWvc5AxOaVDJ+5hOAS51tysEeNCN7Ud3PYk4VRvv4VRZrPFn/R6bCTQVkaHuMQkRkY7iXmT2l3ss3gFeEZGaAO5x7+3nIn7BKQT83Y2hO05BapI6t41+Cox0P9dnk+vGgFyxpOMkdt/9+xRwnoj8S0Rqu/GdJc7tk3kVVj7Eqa7sc5KYX8a5JpR7X12I89koVmUi0QOo6svAA8DjOKWArcDdOCXy3Mbj/PzbhnOx6udc44cCf7jVBbfjlKwBmuCcRMk4vyLe1GP3zvsbZybOSXwWzrWABJy6UnBKEh1wLmbOwjnBff0DeNz9efxQHou/HqfUux34DKeu9etTic91E8627fT9w7kQnf0hG4pT97kW2A3c727fIpyLe6+42/Etx0rCT+CUwPe725pd6s1PQcfpIWAFsBjYh/OTOq9z/kaci3yr3XV/wrGf8h2BX0QkGedi4n2qujn3AlR1Hc558DpOCbY/0F9V03wm+wjn10fu7TrZ+j3jVvP1Aq7DOWd2cuyC6an6P5xqzZ/dz808nIKCP3GkAQOAvjj79k2c6x1r3Unuxqlu2olz18t7BSzybZzzM3v5G3GuGcQCq0TkAM4dQ/E4F31zx5OJ8+UQdZKYD+LU1eee5np3/cUq+44QY4wpM8R5cvYe9XloqhjW2R8Yqqp+3aJaqOu2RG+MMYGtzFTdGGNMWWWJ3hhjApwlemOMCXD+PkDUB/g3zlNo76rq87nG1wc+wHkyMRgYoapfitNmxhogu7nRn1X19pOtq3r16hobG3sKm2CMMWbJkiV7VLVGXuMKTPTiNK70Bs5j2wnAYhGZoaq+TdM+jvOU5FvufaxfcuzhlY2q2s7fYGNjY4mPj/d3cmOMMYCI5PtEsD9VN52ADaq6yb2fdRInNu2rQBW3OwLnnltjjDElgD+JPprj25FI4Pj2UcBpXGiIOM2KfonT0l62hiLyq9smzAV5rUBEhovzQpD4xMRE/6M3xhhTIH8SfV7tOeS++f56nFYQY3Aa+/rQbZdiB04rbe1xnkr9SESq5JoXVR2rqnGqGlejRp5VTMYYY06TPxdjEzi+waAYTqyauQW33QdV/UlEQnEaadqN094HqrpERDbitIlySpXw6enpJCQkkJqaX+N2prQIDQ0lJiaGkJAQr0MxpszwJ9EvBpqISEOcNkWuw2k10NcWoAfwvtvgUSiQKCI1cJqrzRSRRjhtwWw61SATEhKoXLkysbGxOO2FmdJIVdm7dy8JCQk0bNjQ63CMKTMKrLpx20W/G5iDc6vkFFVdJSKj5NjrvB4EbhWR33BeCDBMnbYVugHL3eGfALer84qxU5Kamkq1atUsyZdyIkK1atXsl5kxxcyv++hV9Uuci6y+w5706V6N8+aW3PNNw2kF7oxZkg8MdhyNKX5F/bZ1Y4wxecjKUvYcPsr2pFS27U9he1IKFSuU44ZzT/belNNjid4PSUlJfPTRR9x5552nPG+/fv346KOPiIzM6/0FpUt8fDzjx4/ntdde8zoUY0q8oxmZ7DzgJPFtSe7f/hS2H8j+n0paRtZx87SvH2mJ3itJSUm8+eabeSb6zMxMgoOD8533yy+/zHecl3JeGhzkf3NHcXFxxMXFFWFUxpQeB1LSc0ri25Kc/wnu/237U0hMPkruVuBrVq5AdNUwWkVH0LtlbaKrhlE3Isz5HxlGRFjR3I1mid4PI0aMYOPGjbRr146ePXty6aWX8vTTT1OnTh2WLVvG6tWrufzyy9m6dSupqancd999DB8+HDjWpENycjJ9+/bl/PPP58cffyQ6OprPP/+csLCw49b1xRdf8Oyzz5KWlka1atWYOHEitWrVIjk5mXvuuYf4+HhEhKeeeoqrrrqKr776ikcffZTMzEyqV6/ON998w8iRI6lUqRIPPeS8ZKpVq1bMnDkTgL59+3LRRRfx008/MX36dJ5//nkWL15MSkoKV199NU8//TQAixcv5r777uPw4cNUqFCBb775hiVLlvDiiy8yc+ZMDh8+zD333MOKFSvIyMhg5MiRDBw4kFWrVnHzzTeTlpZGVlYW06ZNo0mTJsV4tIw5c5lZSuKho2xLOkLC/hSneiXpyHHVLIeOZhw3T/lyQURHhhEdGUb3ZjWIjgynbmQo0VWdYbUjQqlQLv9CYVEqdYn+6S9WsXp74b5X9+y6VXiqf8t8xz///POsXLmSZcuWAbBw4UIWLVrEypUrc24THDduHFFRUaSkpNCxY0euuuoqqlWrdtxy1q9fz8cff8w777zDoEGDmDZtGkOGDDlumvPPP5+ff/4ZEeHdd9/lhRde4KWXXuKZZ54hIiKCFStWALB//34SExO59dZb+e6772jYsCH79hV8Q9O6det47733ePPNNwEYPXo0UVFRZGZm0qNHD5YvX07z5s259tprmTx5Mh07duTgwYMnfCGNHj2aiy++mHHjxpGUlESnTp245JJLGDNmDPfddx+DBw8mLS2NzMxTfWWuMUUvNT0zpxSeV9XKjqRUMrKOL45HhodQNyKM+tXC6dK4mpPU3ZJ4dGQY1SqWJyioZN5sUOoSfUnRqVOn4+4Ff+211/jss88A2Lp1K+vXrz8h0Tds2JB27Zz23c455xz++OOPE5abkJDAtddey44dO0hLS8tZx7x585g0aVLOdFWrVuWLL76gW7duOdNEReX7CsscDRo0oHPnzjn9U6ZMYezYsWRkZLBjxw5Wr16NiFCnTh06duwIQJUqJzzMzNy5c5kxYwYvvvgi4NwCu2XLFrp06cLo0aNJSEjgyiuvtNK8KXaqyv4j6U5VSq6qlexkvvdw2nHzBAnUruKUvjvUr0p0GzeBVw0jJjKMOpFhVKpQetNlqYv8ZCXv4lSxYsWc7oULFzJv3jx++uknwsPD6d69e573ileocOydysHBwaSkpJwwzT333MMDDzzAgAEDWLhwISNHjgSckzf3rYl5DQMoV64cWVnHLvL4xuIb9+bNm3nxxRdZvHgxVatWZdiwYaSmpua73NzrnjZtGs2aHf9+5xYtWnDuuecya9YsevfuzbvvvsvFF1980mUZcyoyMrPYeTD1uAub25JS3STuVK+kpB//SzIsJDin9N2ybgTRbpVKdv147SqhlAsO3NdzlLpE74XKlStz6NAJL4PPceDAAapWrUp4eDhr167l559/Pu11HThwgOhop824Dz74IGd4r169+M9//sOrr74KOFU3Xbp04a677mLz5s05VTdRUVHExsbm1MkvXbqUzZs357mugwcPUrFiRSIiIti1axezZ8+me/fuNG/enO3bt7N48WI6duzIoUOHTqi66d27N6+//jqvv/46IsKvv/5K+/bt2bRpE40aNeLee+9l06ZNLF++3BK9OSWHj2bkXNjMfbFz2/4Udh5MJVetCtUqlie6ahhNa1Wme7OaREc6ST3GTe5Vw0PK9DMcluj9UK1aNbp27UqrVq3o27cvl1566XHj+/Tpw5gxY2jTpg3NmjU7rmrkVI0cOZJrrrmG6OhoOnfunJOkH3/8ce666y5atWpFcHAwTz31FFdeeSVjx47lyiuvJCsri5o1a/L1119z1VVXMX78eNq1a0fHjh1p2rRpnutq27Yt7du3p2XLljRq1IiuXZ1n3sqXL8/kyZO55557SElJISwsjHnz5h037xNPPMH9999PmzZtUNWcL5fJkyczYcIEQkJCqF27Nk8++WReqzZllKqyJzntpPXjSUfSj5unXJBQJzKUuhFhdG5cjZjIY9Uq2fXjoSHeXOQsLURz3//jsbi4OM394pE1a9bQokULjyIyhc2OZ8Gc218hS5WsnP/HujXL+Z/pDj9u2qxc07rdmVknTpuZdWx8ls+yznhad737D6cfu1vFTei57x2vVKGcz4XNUKIjw907VZzuGpUrEFxCL3KWJCKyRFXzvP/ZSvTG+GFbUgovzVnH5r2HyVInETsJDjf5+STALN8k6ybkvKY9ISEfS94lrPx1RrLvHT+7bhV6nV0rpxRe1PeOm2Ms0RtzEumZWbz/wx+8Mu93VCEutirBQUKQCEHitN0TJDj9PsODRBD3f7AIQUG5phWfaYNyTZuz3GPj81pukEBwkBw/bU4cuacVgoM4YVpxl5F72vzWe+K2n3y9lUPLeXbvuDnGEr0x+Vi6ZT+PfrqCtTsPcUmLmowc0JKYquFeh2XMKbNEb0wuB46k8885a/l40RbqVAll7NBz6NWyttdhGXPaLNEb41JVpi/bxuhZa9h/JJ1bujbkbz2bUrEUPyhjDFiiNwaAjYnJPDF9JT9u3Eu7epF88JdWtKwb4XVYxhSKwH0UrBBlt155ul599VWOHDlSiBEVjzFjxjB+/HivwyhSqemZvPz17/R99XtWbDvAs5e34tM7zrMkbwKKJXo/BEKiz8jIKHiiXG6//XZuvPHGIoimZPh+fSJ9Xv2O175ZT7/WtZn/YHeGdG5QYhumMuZ0+ZXoRaSPiKwTkQ0iMiKP8fVFZIGI/Coiy0Wkn8+4R9z51olI78IMvrj4NlP88MMPA/Cvf/2Ljh070qZNG5566ikADh8+zKWXXkrbtm1p1aoVkydP5rXXXmP79u1cdNFFXHTRRScse9SoUXTs2JFWrVoxfPhwsh9g27BhA5dccglt27alQ4cObNy4EYAXXniB1q1b07ZtW0aMcA5F9+7dyX7IbM+ePcTGxgLw/vvvc80119C/f3969epFcnIyPXr0oEOHDrRu3ZrPP/88J47x48fTpk0b2rZty9ChQwHnKd3sRss2btxInz59OOecc7jgggtYu3YtAFOnTqVVq1a0bduWbt26Fep+Lyq7D6Vy78e/MvS/ixARJv71XF69rj01KlcoeGZjSqEC6+hFJBh4A+gJJACLRWSG+57YbI/jvDT8LRE5G+f9srFu93VAS6AuME9Emqrq6bddO3sE7Fxx2rPnqXZr6Pt8vqNzN1M8d+5c1q9fz6JFi1BVBgwYwHfffUdiYiJ169Zl1qxZgNNuTUREBC+//DILFiygevXqJyz77rvvzmkmYOjQocycOZP+/fszePBgRowYwRVXXEFqaipZWVnMnj2b6dOn88svvxAeHu5Xs8Q//fQTy5cvJyoqioyMDD777DOqVKnCnj176Ny5MwMGDGD16tWMHj2aH374gerVq+e53OHDhzNmzBiaNGnCL7/8wp133sn8+fMZNWoUc+bMITo6mqSkJL92t1cys5SPFm3hha/WcjQ9i/svacLtFza2x+dNwPPnYmwnYIOqbgIQkUnAQMA30SuQ3ZZtBLDd7R4ITFLVo8BmEdngLu+nQojdM3PnzmXu3Lm0b98egOTkZNavX88FF1zAQw89xP/93/9x2WWXccEFFxS4rAULFvDCCy9w5MgR9u3bR8uWLenevTvbtm3jiiuuACA0NBRwmiq++eabCQ937uX2p1ninj175kynqjz66KN89913BAUFsW3bNnbt2sX8+fO5+uqrc76Ici83OTmZH3/8kWuuuSZn2NGjRwHo2rUrw4YNY9CgQVx55ZUFxuOVldsO8Nj0lfy2NYmuZ1XjmYGtaFSjktdhGVMs/En00cBWn/4E4Nxc04wE5orIPUBF4BKfeX2bckxwhx1HRIYDwwHq1y/gfYknKXkXF1XlkUce4bbbbjth3JIlS/jyyy955JFH6NWr10kb9UpNTeXOO+8kPj6eevXqMXLkyJxmgvNbb0HNEuduHtm3WeKJEyeSmJjIkiVLCAkJITY21q9mibOysoiMjMz5ReNrzJgx/PLLL8yaNYt27dqxbNmyE9rh91Ly0Qxe+fp33vthM1EVy/Pv69oxoG3dMt2SoSl7/Kmjz+sTkTsTXQ+8r6oxQD/gQxEJ8nNeVHWsqsapalyNGjX8CKl45W6muHfv3owbN47k5GQAtm3bxu7du9m+fTvh4eEMGTKEhx56iKVLl+Y5f7bspFy9enWSk5P55JNPAOdFHzExMUyfPh1wSs9HjhyhV69ejBs3LufCbnYVS2xsLEuWLAHIWUZeDhw4QM2aNQkJCWHBggX8+eefAPTo0YMpU6awd+/e45abrUqVKjRs2JCpU6cCzhfOb7/9Bjh19+eeey6jRo2ievXqbN26lZJAVflq5Q4ueelbxv2wmes71eebB7ozsF20JXlT5vhTok8A6vn0x3CsaibbLUAfAFX9SURCgep+zlvi5W6m+F//+hdr1qyhS5cuAFSqVIkJEyawYcMGHn74YYKCgggJCeGtt94CnPrtvn37UqdOHRYsWJCz3MjISG699VZat25NbGxszhudAD788ENuu+02nnzySUJCQpg6dSp9+vRh2bJlxMXFUb58efr168dzzz3HQw89xKBBg/jwww9P2vb74MGD6d+/P3FxcbRr147mzZsD0LJlSx577DEuvPBCgoODad++Pe+///5x806cOJE77riDZ599lvT0dK677jratm3Lww8/zPr161FVevToQdu2bQtrt5+2rfuOMHLGKr5Zu5sWdarw5pAOdKhf1euwjPFMgc0Ui0g54HegB7ANWAzcoKqrfKaZDUxW1fdFpAXwDU4VzdnARzj18nXd4U1OdjHWmikOfEV1PNMzs3j3+838+5vfCRLhgZ5NGXZebEC/OciYbGfUTLGqZojI3cAcIBgYp6qrRGQUEK+qM4AHgXdE5G84VTPD1PkGWSUiU3Au3GYAd53RHTfG5CP+j3089tlK1u06RO+WtXiqf0vqRoYVPKMxZYBfTSCo6pc4t0z6DnvSp3s10DWfeUcDo88gRmPytf9wGv/8ai2TFm8lOjKMd2+M45Kza3kdljElSqlp68afF1abkq+w3mimqkxbuo3nvlzDgZR0buvWiPsuaUJ4+VJzShtTbErFpyI0NJS9e/dSrVo1S/almKqyd+/enOcCTteG3Yd47LOV/LJ5H+c0qMroK1rRvHaVgmc0powqFYk+JiaGhIQEEhMTvQ7FnKHQ0FBiYmJOa97U9Ez+M38Db3+3kfDy5Xj+ytYMiqtnbdMYU4BSkehDQkJo2LCh12EYD337eyJPTF/Jln1HuLJDNI/2a0H1StY2jTH+KBWJ3pRduw6mMmrmamYt30GjGhX56NZzOa/xiW0GGWPyZ4nelEiZWcqEn//kxTnrOJqZxYM9mzL8wkb2omljToMlelPirEg4wKOfrWDFtgNc0KQ6zwxsRWz1igXPaIzJkyV6U2IcSk3npbm/M/6nP6hWqQKvX9+ey9rUsTutjDlDluiN51SVL1fs5OkvVpGYfJQbOzfgwd7NqBIa4nVoxgQES/TGU1v2HuHJGStZuC6RlnWr8M6NcbStF+l1WMYEFEv0xhNpGVm88/0mXvtmPSHBQTzV/2yGdm5gDZAZUwQs0Zti98umvTw2fSUbdifTt1VtnurfktoRZ/a0rDEmf5boTbHZdziN575cwydLEoipGsa4YXFc3NwaIDOmqFmiN0UuK0v5ZEkCz81eQ3JqBnd2b8w9FzchrLzdE29McbBEb4rU77sO8dhnK1j8x346xlZl9BWtaVqrstdhGVOmWKI3RSIlLZPX5q/nne82UTm0HC9c3YarO8RYA2TGeMASvSl089fu4snPV5GwP4VrzonhkX4tiKpY3uuwjCmzLNGbQrPjQApPz1jNV6t2clbNSkwe3plzG1XzOixjyjy/En0rkyEAACAASURBVL2I9AH+jfPO2HdV9flc418BLnJ7w4GaqhrpjssEVrjjtqjqgMII3JQcGZlZfPDTn7w8dx0ZWcrDvZtx6wWNKF/O7ok3piQoMNGLSDDwBtATSAAWi8gM9z2xAKjq33ymvwdo77OIFFVtV3ghm5Jk2dYkHvtsBau2H6R7sxqMGtCK+tXCvQ7LGOPDnxJ9J2CDqm4CEJFJwEBgdT7TXw88VTjhmZLqYGo6L85Zx4c//0nNyhV4c3AH+raqbQ2QGVMC+ZPoo4GtPv0JwLl5TSgiDYCGwHyfwaEiEg9kAM+r6vQ85hsODAeoX7++f5EbT6gqXyzfwTMzV7M3+SjDzovlgZ5NqWwNkBlTYvmT6PMqomk+014HfKKqmT7D6qvqdhFpBMwXkRWquvG4hamOBcYCxMXF5bds47E/9hzmic9X8v36PbSJiWDcTR1pHRPhdVjGmAL4k+gTgHo+/THA9nymvQ64y3eAqm53/28SkYU49fcbT5zVlFRHMzJ5+9tN/GfBBsoHB/H0gJYM6dyAYLsn3phSwZ9EvxhoIiINgW04yfyG3BOJSDOgKvCTz7CqwBFVPSoi1YGuwAuFEbgpHj9u3MPj01eyKfEwl7WpwxOXnU2tKtYAmTGlSYGJXlUzRORuYA7O7ZXjVHWViIwC4lV1hjvp9cAkVfWtemkBvC0iWUAQTh19fhdxTQmyJ/koz81aw6e/bqN+VDjv39yR7s1qeh2WMeY0yPF52XtxcXEaHx/vdRhlVlaWMjl+K8/PXsuRtAxuv7Axd110FqEh1gCZMSWZiCxR1bi8xtmTsSbHmh0HeeyzFSzdksS5DaMYfUUrzqppDZAZU9pZojccScvg1Xnr+e//NhMRFsJL17Tlyg7Rdk+8MQHCEn0Z9/XqXYycsYptSSlc17Ee/9enOVWtATJjAool+jIqPTOL+ycvY9byHTSrVZlPbu9CXGyU12EZY4qAJfoy6oWv1jJr+Q4e6NmUO7o3JsReym1MwLJEXwZ9tXIH73y/mRu7NODeHk28DscYU8SsGFfGbEpM5qGpy2lbL5LHLm3hdTjGmGJgib4MOZKWwR0TlhISLLw5uAMVytm98caUBVZ1U0aoKo9/tpLfdx/ig5s7ER0Z5nVIxphiYiX6MuKjRVv49Ndt3N+jKd2a1vA6HGNMMbJEXwYsT0ji6RmrubBpDe65+CyvwzHGFDNL9AFu/+E07piwlBqVK/Dqte0IsqaFjSlzrI4+gGVlKX+bsozEQ0eZensXe+LVmDLKSvQB7D8LNrBwXSJP9D+btvUivQ7HGOMRS/QB6vv1ibwy73euaB/NkHPtPbzGlGWW6APQ9qQU7v34V5rUrMToK1pZK5TGlHGW6ANMWkYWd05cSnqm8taQcwgvb5dhjCnrLAsEmNGzVrNsaxJvDu5A4xqVvA7HGFMC+FWiF5E+IrJORDaIyIg8xr8iIsvcv99FJMln3E0ist79u6kwgzfHm/Hbdj746U9uOb8h/VrX8TocY0wJUWCJXkSCgTeAnkACsFhEZvi+5FtV/+Yz/T1Ae7c7CngKiAMUWOLOu79Qt8KwftchRkxbTlyDqozo29zrcIwxJYg/JfpOwAZV3aSqacAkYOBJpr8e+Njt7g18rar73OT+NdDnTAI2J0o+msHtE5YQXj6YNwZ3sLbljTHH8ScjRANbffoT3GEnEJEGQENg/qnMKyLDRSReROITExP9idu4VJUR05azec9hXru+PbWqhHodkjGmhPEn0ed1b57mM+11wCeqmnkq86rqWFWNU9W4GjWswa1T8f6PfzBz+Q4e6t2M8xpX9zocY0wJ5E+iTwDq+fTHANvzmfY6jlXbnOq85hQt+XM/o2et4ZIWtbi9W2OvwzHGlFD+JPrFQBMRaSgi5XGS+YzcE4lIM6Aq8JPP4DlALxGpKiJVgV7uMHOG9iQf5a6JS6kbGcZLg9paY2XGmHwVeNeNqmaIyN04CToYGKeqq0RkFBCvqtlJ/3pgkqqqz7z7ROQZnC8LgFGquq9wN6HsycxS7pv0K/uOpPHpHecRERbidUjGmBJMfPJyiRAXF6fx8fFeh1GivTR3Ha/P38ALV7VhUMd6Bc9gjAl4IrJEVePyGmf34ZUy89fu4vX5GxgUF2NJ3hjjF0v0pcjWfUf42+TfOLtOFUYNbOV1OMaYUsISfSmRmp7JHROXkKXKmCHnEBoS7HVIxphSwho1KyWe/mI1K7cd5J0b46hfLdzrcIwxpYiV6EuBT5Yk8PGiLdzRvTE9z67ldTjGmFLGEn0Jt2bHQR77bAVdGlXjwZ5NvQ7HGFMKWaIvwQ6mpnPHhCVEhIXw2vXtKWeNlRljToPV0ZdQqspDU35j6/4UJg3vTI3KFbwOyRhTSlkRsYR65/tNzF29i0f6NqdjbJTX4RhjSjFL9CXQL5v28s+v1tGvdW1uOb+h1+EYY0o5S/QlzO6Dqdz98a80iArnn1e1QcQaKzPGnBmroy9BMjKzuPvjX0lOzWDCLedSOdQaKzPGnDlL9CXIv+asY9HmfbxybVua1a7sdTjGmABhVTclxFcrd/L2d5sY0rk+V7SP8TocY0wAsURfAmzec5iHp/5G25gInrjsbK/DMcYEGEv0HktJy+SOCUsIDhbeGNyBCuWssTJjTOGyOnoPqSqPT1/Jul2HeG9YR2KqWmNlxpjCZyV6D01avJVpSxO49+ImdG9W0+twjDEByq9ELyJ9RGSdiGwQkRH5TDNIRFaLyCoR+chneKaILHP/TnipeFm1IuEAT81YxQVNqnNvjyZeh2OMCWAFVt2ISDDwBtATSAAWi8gMVV3tM00T4BGgq6ruFxHf4mmKqrYr5LhLtaQjadwxcQnVK5bn39e1JzjIHooyxhQdf0r0nYANqrpJVdOAScDAXNPcCryhqvsBVHV34YYZOLKylAem/Maug6m8OeQcoiqW9zokY0yA8yfRRwNbffoT3GG+mgJNReQHEflZRPr4jAsVkXh3+OV5rUBEhrvTxCcmJp7SBpQ2by7cwPy1u3nisrNpVy/S63CMMWWAP3fd5FWvoHkspwnQHYgBvheRVqqaBNRX1e0i0giYLyIrVHXjcQtTHQuMBYiLi8u97IDxv/V7ePnr3xnYri5DOzfwOhxjTBnhT4k+Aajn0x8DbM9jms9VNV1VNwPrcBI/qrrd/b8JWAi0P8OYS6UdB1K4d9KvNK5RiX9c2doaKzPGFBt/Ev1ioImINBSR8sB1QO67Z6YDFwGISHWcqpxNIlJVRCr4DO8KrKaMScvI4q6JSzmanslbQ84hvLw9vmCMKT4FZhxVzRCRu4E5QDAwTlVXicgoIF5VZ7jjeonIaiATeFhV94rIecDbIpKF86XyvO/dOmXFP2avYemWJN64oQNn1azkdTjGmDJGVEtWlXhcXJzGx8d7HUah+eK37dzz8a/8pWtDnuxv7dgYY4qGiCxR1bi8xtmTsUVow+5DjJi2nHMaVOWRfs29DscYU0ZZoi8ih49mcPuEpYSGBPPGDR0ICbZdbYzxhl0VLAKqyiOfrmBTYjIf3nIutSNCvQ7JGFOGWTGzCIz/6U9m/LadB3s1o+tZ1b0OxxhTxlmiL2RLt+zn2Vmr6dG8Jndc2NjrcIwxxqpuCtPe5KPcNXEptSNCeXlQO4KssTJjTH6yMiEjFTKOuv9TQYKhauE/NW+JvpBkZin3T17G3sNpfHrHeUSEh3gdkjGmIFmZkJ5yfLLNOAoZvsOO5pomj/EZqZCeemLiPq4/13Ky0k+MJ6Yj/HVeoW+mJfpC8u9v1vP9+j08f2VrWkVHeB2OKSyZGbDlJ1g3G9bPgSP7IKjcsb9gn+6g4OPH5QwLKWB8OQjOb5rs/oLGZy/jJOvIWc5JlpHzV4y1upkZBSROf5NvHsn1hOSbazlZGWcWe1AIhIRBuQpQLtT979MfGun8Dwn1GR/q8+czX0gYVCqaFxBZoi8EC9bt5rVv1nP1OTFc27FewTOYki31IGyY5yb3uZCaBMEVoGE3aHSRkxyyMpzSYE53eq5+d3x6GmQdcvozM04cn5V7mM+flyTozL4ssr8Ac6onTlKy1cwzizW4Qh5J0yeZhkflnVz9Tb75JfFyFZztLgUs0Z+hrfuO8LfJy2hRpwrPDGxljZWVVklb4fevYN2XsPl7J3GHV4Pml0Kzvk6Cr1CMzVeogmad+MWQmX5qXxa5x5/wZVMYy8jrCy7FiTWonJMQw6ufJLGeQfINrlC8vz5KKUv0Z+BoRiZ3fbSUzEzlrcEdCCtfOr7dDU4i3bHMKbWv+xJ2rnCGV2sCne+AZv2gXifvSmwizoW5oGCggjcxmIBhif4MjPpiNcsTDjB26DnEVq/odTimIBlHYfN3TmJf9xUc2u5UUdTrDD2fcUru1e39vSbwWKI/TZ8uTWDiL1u47cJG9GpZ2+twTH4O73Xq2dd9CRvnQ1oyhFSEsy6GZk9Ck15QsZrXURpTpCzRn4a1Ow/y6GcrOLdhFA/3auZ1OCa3PRvcUvts2PqzU9dduQ60GeRUycRe4NQFG1NGWKI/RYdS07ljwlKqhIbw+g3tKWeNlXkvKxMSFsPaWU5y37veGV6rNVzwEDTvB3XaOfXexpRBluhPgary8NTlbNl3hI9v7UzNylYq9MzRZNi0wEnsv38FR/Y6t/3Fng+dhkOzPhBZ3+sojSkRLNGfgv/+bzNfrdrJY/1a0KlhlNfhlD0Hd8Dvs53kvulbyDwKoRHQpLdzIfWsHk6/MeY4luj9tGjzPv4xey19Wtbmrxc09DqcskEVdq1yb4GcBdt/dYZHNoCOtzjJvX4X54lQY0y+/Er0ItIH+DfOO2PfVdXn85hmEDASUOA3Vb3BHX4T8Lg72bOq+kEhxF2sdh9K5e6PllI/KpwXrmljD0UVpYw0+PMHN7nPhgNbAIGYOOjxpHMxtUZzq2835hQUmOhFJBh4A+gJJACLRWSG70u+RaQJ8AjQVVX3i0hNd3gU8BQQh/MFsMSdd3/hb0rRyMjM4t6Pf+Vgajrjb+lElVArPRa6lP2wfp5zp8yGeXD0oPOoeeOL4MKHnaqZyrW8jtKYUsufEn0nYIOqbgIQkUnAQGC1zzS3Am9kJ3BV3e0O7w18rar73Hm/BvoAHxdO+EXvxbm/8/Omfbw8qC3Na1fxOpzAsW/zsSYH/vzReXS+Yg04e6BTam/UHcqHex2lMQHBn0QfDWz16U8Azs01TVMAEfkBp3pnpKp+lc+80acdbTGbu2onY77dyA3n1ufKDjFeh1O6ZWXB9qXH7m/f7ZYTarSA8+51knv0OdZuiTFFwJ9En1dlqOaxnCZAdyAG+F5EWvk5LyIyHBgOUL9+ybgl7s+9h3lw6m+0jo7gycvO9jqc0ik9BTYtPNbkwOHdTvstDc6D3v9wboGMauR1lMYEPH8SfQLg2/ZuDLA9j2l+VtV0YLOIrMNJ/Ak4yd933oW5V6CqY4GxAHFxcSd8ERS31PRMbp+wlCAR3hzcgdAQa6zMb8m74fc5Tql943yn7e/ylaHJJU6p/axLnGZjjTHFxp9EvxhoIiINgW3AdcANuaaZDlwPvC8i1XGqcjYBG4HnRKSqO10vnIu2JdqTn69kzY6DvDesI/WirJ74pFQhcd2xKpmExYBClRhoP8R5KrXB+VCuvNeRGlNmFZjoVTVDRO4G5uDUv49T1VUiMgqIV9UZ7rheIrIayAQeVtW9ACLyDM6XBcCo7AuzJdXkxVuYEp/AvRefxUXNi+ZtL6VeZobThszaL50Ev3+zM7xOO+j+iHN/e+3WdgukMSWEqHpeU3KcuLg4jY+P92TdK7cd4Mq3fuTchlG8f3Mngu3l3sekHoSN37hNDsxx37pUHhpe6CT2pn0gotRcZzcm4IjIElWNy2ucPRnrOnAknTsmLqFaxfK8em07S/KQ91uXwqKcxN6sLzS+GCpU9jpKY0wBLNEDWVnKg1OXsfNAKpNv60K1SmX0jT6qsOO3Y00OZL91KaoxdL7duZga08l5H6gxptSwTyzw1rcbmbdmNyP7n02H+lULniGQZBx1SuvZF1MPbQcE6neGnqOc5G5vXTKmVCvzif7HjXt4ae46+rety03nxXodTvFJ2Q9fPQprZrhvXQp3qmKaPQ5Ne0PF6l5HaIwpJGU60e88kMq9H/9KoxqVeP7K1mWnsbKdK2DyEDiwDdrdAM0vg4bd7K1LxgSoMpvo0zOzuPujpRxJy2TS8A5UrFBGdsXyKTDjXgiLhJu/hHqdvI7IGFPEykh2O9Hzs9cS/+d+Xr++PWfVLAN3jmSmw9zH4Zcx0KArXPM+VLLnBIwpC8pkop+1fAf//d9mhp0XS/+2db0Op+gd2glTh8GWn6DzXdDzaXtZhzFlSJlL9BsTk/n7J7/RoX4kj/Zr4XU4RW/LLzDlRqeN96v+C62v9joiY0wxK1OJ/khaBndMWEKFkGDeGNyB8uUCuElcVVj0Dsx5xHlJ9tBPoVZLr6MyxnigzCR6VeXRT1ewfncyH/7lXOpEhHkdUtFJOwIz/wbLJzlNE1zxtnPx1RhTJpWZRD/hly1MX7adB3s25fwmAXyP+L7NMHko7FoJ3R+Fbg/byzyMKePKRKJftjWJUV+s4qJmNbjrorO8DqforJ8H024BFAZPhSY9vY7IGFMCBHyi33c4jbsmLqVWlVBeubYdQYHYWFlWFnz/EiwY7dTDX/uhvbnJGJMjoBN9ZpZy/+RlJB46yrQ7ziMyPABffpF6AD69DX6fDW2uhctetZdqG2OOE9CJ/vX56/nu90Seu6I1rWMivA6n8O1a7TRlkPQn9P0XdLrVXvZhjDlBwCb6het28+9v1nNlh2iu71Sv4BlKm5XT4PO7nfbgb5oJDbp4HZExpoQKyES/LSmF+ycvo1mtyoy+PMAaK8vMgHlPwU//gXqdYdAHULm211EZY0owv+67E5E+IrJORDaIyIg8xg8TkUQRWeb+/dVnXKbP8BmFGXxejmZkcufEpWRmKm8NOYew8sFFvcrik7wbxg90knyn4XDTF5bkjTEFKrBELyLBwBtATyABWCwiM1R1da5JJ6vq3XksIkVV2515qP55duYaftuaxJgh59CwesXiWm3R27rYacogZT9cMRbaXut1RMaYUsKfEn0nYIOqblLVNGASMLBowzo903/dxoc//8nwbo3o0ypASrqqED8O3uvrNER2y1xL8saYU+JPoo8Gtvr0J7jDcrtKRJaLyCci4nv1M1RE4kXkZxG5/EyCPZk/9hzmkU9X0KlhFH/v3ayoVlO80lOcC64z/waNLoThC6FOG6+jMsaUMv5cjM3rSqbm6v8C+FhVj4rI7cAHwMXuuPqqul1EGgHzRWSFqm48bgUiw4HhAPXr1z+lDchWLyqcuy5qzKC4epQLDoBH/pO2OLdO7vgNuv0duo+AoAC63mCMKTb+ZMQEwLeEHgNs951AVfeq6lG39x3gHJ9x293/m4CFQPvcK1DVsaoap6pxNWrUOKUNyBYcJNx9cRNqVgmA1+FtnA9vX+i0W3P9JLj4MUvyxpjT5k+iXww0EZGGIlIeuA447u4ZEanj0zsAWOMOryoiFdzu6kBXIPdFXJNNFb5/GSZc5dxNM3whNOvrdVTGmFKuwKobVc0QkbuBOUAwME5VV4nIKCBeVWcA94rIACAD2AcMc2dvAbwtIlk4XyrP53G3jgFIPQjT74C1M6HVVTDgdSgfQHcNGWM8I6q5q9u9FRcXp/Hx8V6HUbwS18GkwbBvE/R6BjrfaU0ZGGNOiYgsUdW4vMYF5JOxpcrqz2H6nRASBjd+Dg0v8DoiY0yAsUTvlcwMmD8Kfvg3xHSEaz6AiLzuWjXGmDNjid4Lh/fAJzfD5u8g7i/Q53koV8HrqIwxAcoSfXHbtgQm3wiHE2HgG9B+iNcRGWMCnCX64rR0PMx6ECrVhlvmQN0THikwxphCZ4m+OGQchS8fhqUfQKPucNU4qFjN66iMMWWEJfqidiABJg+F7Uvh/Afg4sftKVdjTLGyRF+UNn8HU292SvTXToAW/b2OyBhTBlmiLwqq8OPrzpugqp0F106EGk29jsoYU0ZZoi9sRw85TQuvng4tBsDlbzrvdTXGGI9Yoi9Me9Y7TQvv+R16joLz7rWmDIwxnrNEX1jWzITPbody5WHoZ87dNcYYUwJYoj9TWZmwYDR8/5JzX/ygDyGyXsHzGWNMMbFEfyaO7INptzgvCulwI/T9F4QEwItPjDEBxRL96dq+DKYMhUM7of+/4ZxhXkdkjDF5skR/OpZ95LywO7wa3PwVxJxT8DzGGOMRS/SnIiMNvhoB8f+F2Avg6veg0um949YYY4qLJXp/HdwOU26ChEXObZM9noJg233GmJLPn5eDIyJ9RGSdiGwQkRF5jB8mIokissz9+6vPuJtEZL37d1NhBl9s/vgB3u4Gu1bBNe87r/uzJG+MKSUKzFYiEgy8AfQEEoDFIjIjj5d8T1bVu3PNGwU8BcQBCixx591fKNEXNVX4+S2Y+zhENYSbZkLN5l5HZYwxp8SfEn0nYIOqblLVNGASMNDP5fcGvlbVfW5y/xroc3qhFrO0wzDtrzDnEWjaB26db0neGFMq+ZPoo4GtPv0J7rDcrhKR5SLyiYhkPzHk77wly96N8O4lsHIaXPyE0/JkaITXURljzGnxJ9Hn1ViL5ur/AohV1TbAPOCDU5gXERkuIvEiEp+YmOhHSEVo3Vcw9iI4tAOGfALdHoIgvy5lGGNMieRPBksAfJ/pjwG2+06gqntV9ajb+w5wjr/zuvOPVdU4VY2rUcOj2xWzsmDBc/DxtVC1AQz/Fs66xJtYjDGmEPmT6BcDTUSkoYiUB64DZvhOICJ1fHoHAGvc7jlALxGpKiJVgV7usJIlZb+T4L/9J7S9AW6Z6yR7Y4wJAAXedaOqGSJyN06CDgbGqeoqERkFxKvqDOBeERkAZAD7gGHuvPtE5BmcLwuAUaq6rwi24/TtXOE0LXxgG1z6EsTdYk0LG2MCiqieUGXuqbi4OI2Pjy+elS2fAjPuhbBIGDQe6nUqnvUaY0whE5ElqhqX17iy+dRPZjrMeQwWvQ0NujpNGVSu5XVUxhhTJMpeoj+0E6YOgy0/Qec7nTdBBYd4HZUxxhSZspXot/zstFdz9CBc9V9ofbXXERljTJErG4leFRa94zzlGlEPhn4KtVp6HZUxxhSLwE/0aUectuOXT3KaMrjibefiqzHGlBGBnej3bYbJQ2HXSuj+KHR72J5yNcaUOYGb6Nd/7TRKhsINU6BpL68jMsYYTwReos/Kgu9fggWjnXr4az+EqEZeR2WMMZ4JrESfkgSf3Q6/z4bWg5yXdpcP9zoqY4zxVOAk+v1/woeXQ9IW6PsCdBpuTRkYYwyBlOgr1YTqTWHgm9Cgi9fRGGNMiRE4iT4kDG6Y7HUUxhhT4ti9hsYYE+As0RtjTICzRG+MMQHOEr0xxgQ4S/TGGBPgLNEbY0yAs0RvjDEBzhK9McYEuBL3cnARSQT+PINFVAf2FFI4hcniOjUW16mxuE5NIMbVQFVr5DWixCX6MyUi8fm9Cd1LFtepsbhOjcV1aspaXFZ1Y4wxAc4SvTHGBLhATPRjvQ4gHxbXqbG4To3FdWrKVFwBV0dvjDHmeIFYojfGGOPDEr0xxgS4UpXoRWSciOwWkZU+w6JE5GsRWe/+r+oOFxF5TUQ2iMhyEelQhHHVE5EFIrJGRFaJyH0lITYRCRWRRSLymxvX0+7whiLyixvXZBEp7w6v4PZvcMfHFkVcPvEFi8ivIjKzpMQlIn+IyAoRWSYi8e6wknCORYrIJyKy1j3Pungdl4g0c/dT9t9BEbnf67jcdf3NPedXisjH7mehJJxf97kxrRKR+91hRb+/VLXU/AHdgA7ASp9hLwAj3O4RwD/d7n7AbECAzsAvRRhXHaCD210Z+B042+vY3OVXcrtDgF/c9U0BrnOHjwHucLvvBMa43dcBk4v4eD4AfATMdPs9jwv4A6iea1hJOMc+AP7qdpcHIktCXD7xBQM7gQZexwVEA5uBMJ/zapjX5xfQClgJhOO83W8e0KQ49leRHvwi2lmxHJ/o1wF13O46wDq3+23g+rymK4YYPwd6lqTY3JNrKXAuzpN35dzhXYA5bvccoIvbXc6dTooonhjgG+BiYKZ7MpeEuP7gxETv6XEEqriJS0pSXLli6QX8UBLiwkn0W4Eo93yZCfT2+vwCrgHe9el/Avh7ceyvUlV1k49aqroDwP1f0x2efbCzJbjDipT7s689TunZ89jc6pFlwG7ga2AjkKSqGXmsOycud/wBoFpRxAW8inOSZ7n91UpIXArMFZElIjLcHeb1cWwEJALvuVVd74pIxRIQl6/rgI/dbk/jUtVtwIvAFmAHzvmyBO/Pr5VANxGpJiLhOCX2ehTD/gqERJ8fyWNYkd5LKiKVgGnA/ap68GST5jGsSGJT1UxVbYdTgu4EtDjJuoslLhG5DNitqkt8B3sdl6urqnYA+gJ3iUi3k0xbXHGVw6myfEtV2wOHcX7iex2XszKnrnsAMLWgSfMYVhTnV1VgINAQqAtUxDme+a27WOJS1TXAP3EKXF8BvwEZJ5ml0OIKhES/S0TqALj/d7vDE3C+LbPFANuLKggRCcFJ8hNV9dOSFBuAqiYBC3Hq+iJFpFwe686Jyx0fAewrgnC6AgNE5A9gEk71zaslIC5Udbv7fzfwGc6Xo9fHMQFIUNVf3P5PcBK/13Fl6wssVdVdbr/XcV0CbFbVRFVNBz4FzqNknF//VdUOqtrNXcd6imF/BUKinwHc5HbfhFM/nj38RvfKdWfgQPbPo8ImIgL8F1ijqi+XlNhEpIaIRLrdYTgfgDXAAuDqfOLKjvdqYL66lYOFSVUfUdUYVY3F+ck/X1UHex2XiFQUkcrZ3Tj1zivx+Diq6k5gq4g0cwf1AFZ7HZeP/t9skAAAAPVJREFU6zlWbZO9fi/j2gJ0FpFw97OZvb88Pb8ARKSm+78+cCXOfiv6/VXYFxyK8s/dKTuAdJxvu1tw6tK+wflm/AaIcqcV4A2cOukVQFwRxnU+zk+q5cAy96+f17EBbYBf3bhWAk+6wxsBi4ANOD+3K7jDQ93+De74RsVwTLtz7K4bT+Ny1/+b+7cKeMwdXhLOsXZAvHsspwNVS0hc4cBeIMJnWEmI62lgrXvefwhU8Pr8ctf1Pc6Xzm9Aj+LaX9YEgjHGBLhAqLoxxhhzEpbojTEmwFmiN8aYAGeJ3hhjApwlemOMCXCW6I0xJsBZojfGmAD3//0hkMrfJdEvAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Train accuracies: \")\n",
    "print(train_scores)\n",
    "print(\"Test accuracies: \")\n",
    "print(test_scores)\n",
    "\n",
    "# plot\n",
    "plt.plot(range(100, 1001, 200), train_scores, label='train accuracies')\n",
    "plt.plot(range(100, 1001, 200), test_scores, label='test accuracies')\n",
    "plt.legend()\n",
    "plt.title(\"Classification Accuracies over Time Period (CNN)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimized CNN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training/Valid data shape: (2115, 22, 1000)\n",
      "Test data shape: (443, 22, 1000)\n",
      "Training/Valid target shape: (2115,)\n",
      "Test target shape: (443,)\n",
      "Person train/valid shape: (2115, 1)\n",
      "Person test shape: (443, 1)\n"
     ]
    }
   ],
   "source": [
    "X_test = np.load(\"X_test.npy\")\n",
    "y_test = np.load(\"y_test.npy\")\n",
    "person_train_valid = np.load(\"person_train_valid.npy\")\n",
    "X_train_valid = np.load(\"X_train_valid.npy\")\n",
    "y_train_valid = np.load(\"y_train_valid.npy\")\n",
    "person_test = np.load(\"person_test.npy\")\n",
    "\n",
    "## Printing the shapes of the numpy arrays\n",
    "\n",
    "print ('Training/Valid data shape: {}'.format(X_train_valid.shape))\n",
    "print ('Test data shape: {}'.format(X_test.shape))\n",
    "print ('Training/Valid target shape: {}'.format(y_train_valid.shape))\n",
    "print ('Test target shape: {}'.format(y_test.shape))\n",
    "print ('Person train/valid shape: {}'.format(person_train_valid.shape))\n",
    "print ('Person test shape: {}'.format(person_test.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1ecb5af5ba8>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Adjusting the labels to {0,1,2,3}\n",
    "\n",
    "# Cue onset left - 0\n",
    "# Cue onset right - 1\n",
    "# Cue onset foot - 2\n",
    "# Cue onset tongue - 3\n",
    "\n",
    "y_train_valid -= 769\n",
    "y_test -= 769\n",
    "## Visualizing the data\n",
    "\n",
    "ch_data = X_train_valid[:,8,:]\n",
    "\n",
    "\n",
    "class_0_ind = np.where(y_train_valid == 0)\n",
    "ch_data_class_0 = ch_data[class_0_ind]\n",
    "avg_ch_data_class_0 = np.mean(ch_data_class_0,axis=0)\n",
    "\n",
    "\n",
    "class_1_ind = np.where(y_train_valid == 1)\n",
    "ch_data_class_1 = ch_data[class_1_ind]\n",
    "avg_ch_data_class_1 = np.mean(ch_data_class_1,axis=0)\n",
    "\n",
    "class_2_ind = np.where(y_train_valid == 2)\n",
    "ch_data_class_2 = ch_data[class_2_ind]\n",
    "avg_ch_data_class_2 = np.mean(ch_data_class_2,axis=0)\n",
    "\n",
    "class_3_ind = np.where(y_train_valid == 3)\n",
    "ch_data_class_3 = ch_data[class_3_ind]\n",
    "avg_ch_data_class_3 = np.mean(ch_data_class_3,axis=0)\n",
    "\n",
    "\n",
    "plt.plot(np.arange(1000),avg_ch_data_class_0)\n",
    "plt.plot(np.arange(1000),avg_ch_data_class_1)\n",
    "plt.plot(np.arange(1000),avg_ch_data_class_2)\n",
    "plt.plot(np.arange(1000),avg_ch_data_class_3)\n",
    "plt.axvline(x=500, label='line at t=500',c='cyan')\n",
    "\n",
    "plt.legend([\"Cue Onset left\", \"Cue Onset right\", \"Cue onset foot\", \"Cue onset tongue\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X after trimming: (2115, 22, 500)\n",
      "Shape of X after maxpooling: (2115, 22, 250)\n",
      "Shape of X after averaging+noise and concatenating: (4230, 22, 250)\n",
      "Shape of X after subsampling and concatenating: (8460, 22, 250)\n"
     ]
    }
   ],
   "source": [
    "def data_prep(X,y,sub_sample,average,noise):\n",
    "    \n",
    "    total_X = None\n",
    "    total_y = None\n",
    "    \n",
    "    # Trimming the data (sample,22,1000) -> (sample,22,500)\n",
    "    X = X[:,:,0:500]\n",
    "    print('Shape of X after trimming:',X.shape)\n",
    "    \n",
    "    # Maxpooling the data (sample,22,1000) -> (sample,22,500/sub_sample)\n",
    "    X_max = np.max(X.reshape(X.shape[0], X.shape[1], -1, sub_sample), axis=3)\n",
    "    \n",
    "    \n",
    "    total_X = X_max\n",
    "    total_y = y\n",
    "    print('Shape of X after maxpooling:',total_X.shape)\n",
    "    \n",
    "    # Averaging + noise \n",
    "    X_average = np.mean(X.reshape(X.shape[0], X.shape[1], -1, average),axis=3)\n",
    "    X_average = X_average + np.random.normal(0.0, 0.5, X_average.shape)\n",
    "    \n",
    "    total_X = np.vstack((total_X, X_average))\n",
    "    total_y = np.hstack((total_y, y))\n",
    "    print('Shape of X after averaging+noise and concatenating:',total_X.shape)\n",
    "    \n",
    "    # Subsampling\n",
    "    \n",
    "    for i in range(sub_sample):\n",
    "        \n",
    "        X_subsample = X[:, :, i::sub_sample] + \\\n",
    "                            (np.random.normal(0.0, 0.5, X[:, :,i::sub_sample].shape) if noise else 0.0)\n",
    "            \n",
    "        total_X = np.vstack((total_X, X_subsample))\n",
    "        total_y = np.hstack((total_y, y))\n",
    "        \n",
    "    \n",
    "    print('Shape of X after subsampling and concatenating:',total_X.shape)\n",
    "    return total_X,total_y\n",
    "\n",
    "\n",
    "X_train_valid_prep,y_train_valid_prep = data_prep(X_train_valid,y_train_valid,2,2,True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X after trimming: (2115, 22, 500)\n",
      "Shape of X after maxpooling: (2115, 22, 250)\n",
      "Shape of X after averaging+noise and concatenating: (4230, 22, 250)\n",
      "Shape of X after subsampling and concatenating: (8460, 22, 250)\n",
      "Shape of X after trimming: (443, 22, 500)\n",
      "Shape of X after maxpooling: (443, 22, 250)\n",
      "Shape of X after averaging+noise and concatenating: (886, 22, 250)\n",
      "Shape of X after subsampling and concatenating: (1772, 22, 250)\n",
      "(8460, 22, 250)\n",
      "(8460,)\n",
      "(1772, 22, 250)\n",
      "(1772,)\n",
      "Shape of training set: (6960, 22, 250)\n",
      "Shape of validation set: (1500, 22, 250)\n",
      "Shape of training labels: (6960,)\n",
      "Shape of validation labels: (1500,)\n",
      "Shape of training labels after categorical conversion: (6960, 4)\n",
      "Shape of validation labels after categorical conversion: (1500, 4)\n",
      "Shape of test labels after categorical conversion: (1772, 4)\n",
      "Shape of training set after adding width info: (6960, 22, 250, 1)\n",
      "Shape of validation set after adding width info: (1500, 22, 250, 1)\n",
      "Shape of test set after adding width info: (1772, 22, 250, 1)\n",
      "Shape of training set after dimension reshaping: (6960, 250, 1, 22)\n",
      "Shape of validation set after dimension reshaping: (1500, 250, 1, 22)\n",
      "Shape of test set after dimension reshaping: (1772, 250, 1, 22)\n"
     ]
    }
   ],
   "source": [
    "## Preprocessing the dataset\n",
    "\n",
    "X_train_valid_prep,y_train_valid_prep = data_prep(X_train_valid,y_train_valid,2,2,True)\n",
    "X_test_prep,y_test_prep = data_prep(X_test,y_test,2,2,True)\n",
    "\n",
    "print(X_train_valid_prep.shape)\n",
    "print(y_train_valid_prep.shape)\n",
    "print(X_test_prep.shape)\n",
    "print(y_test_prep.shape)\n",
    "\n",
    "\n",
    "\n",
    "## Random splitting and reshaping the data\n",
    "\n",
    "# First generating the training and validation indices using random splitting\n",
    "ind_valid = np.random.choice(8460, 1500, replace=False)\n",
    "ind_train = np.array(list(set(range(8460)).difference(set(ind_valid))))\n",
    "\n",
    "# Creating the training and validation sets using the generated indices\n",
    "(x_train, x_valid) = X_train_valid_prep[ind_train], X_train_valid_prep[ind_valid] \n",
    "(y_train, y_valid) = y_train_valid_prep[ind_train], y_train_valid_prep[ind_valid]\n",
    "print('Shape of training set:',x_train.shape)\n",
    "print('Shape of validation set:',x_valid.shape)\n",
    "print('Shape of training labels:',y_train.shape)\n",
    "print('Shape of validation labels:',y_valid.shape)\n",
    "\n",
    "\n",
    "# Converting the labels to categorical variables for multiclass classification\n",
    "y_train = to_categorical(y_train, 4)\n",
    "y_valid = to_categorical(y_valid, 4)\n",
    "y_test = to_categorical(y_test_prep, 4)\n",
    "print('Shape of training labels after categorical conversion:',y_train.shape)\n",
    "print('Shape of validation labels after categorical conversion:',y_valid.shape)\n",
    "print('Shape of test labels after categorical conversion:',y_test.shape)\n",
    "\n",
    "# Adding width of the segment to be 1\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
    "x_valid = x_valid.reshape(x_valid.shape[0], x_valid.shape[1], x_train.shape[2], 1)\n",
    "x_test = X_test_prep.reshape(X_test_prep.shape[0], X_test_prep.shape[1], X_test_prep.shape[2], 1)\n",
    "print('Shape of training set after adding width info:',x_train.shape)\n",
    "print('Shape of validation set after adding width info:',x_valid.shape)\n",
    "print('Shape of test set after adding width info:',x_test.shape)\n",
    "\n",
    "\n",
    "# Reshaping the training and validation dataset\n",
    "x_train = np.swapaxes(x_train, 1,3)\n",
    "x_train = np.swapaxes(x_train, 1,2)\n",
    "x_valid = np.swapaxes(x_valid, 1,3)\n",
    "x_valid = np.swapaxes(x_valid, 1,2)\n",
    "x_test = np.swapaxes(x_test, 1,3)\n",
    "x_test = np.swapaxes(x_test, 1,2)\n",
    "print('Shape of training set after dimension reshaping:',x_train.shape)\n",
    "print('Shape of validation set after dimension reshaping:',x_valid.shape)\n",
    "print('Shape of test set after dimension reshaping:',x_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_63\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_249 (Conv2D)          (None, 250, 1, 25)        5525      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_249 (MaxPoolin (None, 84, 1, 25)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_249 (Bat (None, 84, 1, 25)         100       \n",
      "_________________________________________________________________\n",
      "dropout_249 (Dropout)        (None, 84, 1, 25)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_250 (Conv2D)          (None, 84, 1, 50)         12550     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_250 (MaxPoolin (None, 28, 1, 50)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_250 (Bat (None, 28, 1, 50)         200       \n",
      "_________________________________________________________________\n",
      "dropout_250 (Dropout)        (None, 28, 1, 50)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_251 (Conv2D)          (None, 28, 1, 100)        50100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_251 (MaxPoolin (None, 10, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_251 (Bat (None, 10, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_251 (Dropout)        (None, 10, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "flatten_63 (Flatten)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 4)                 4004      \n",
      "=================================================================\n",
      "Total params: 72,879\n",
      "Trainable params: 72,529\n",
      "Non-trainable params: 350\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Building the CNN model using sequential class\n",
    "basic_cnn_model = Sequential()\n",
    "\n",
    "# Conv. block 1\n",
    "basic_cnn_model.add(Conv2D(filters=25, kernel_size=(10,1), padding='same', activation='elu', input_shape=(250,1,22)))\n",
    "basic_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same')) # Read the keras documentation\n",
    "basic_cnn_model.add(BatchNormalization())\n",
    "basic_cnn_model.add(Dropout(0.5))\n",
    "\n",
    "# Conv. block 2\n",
    "basic_cnn_model.add(Conv2D(filters=50, kernel_size=(10,1), padding='same', activation='elu'))\n",
    "basic_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "basic_cnn_model.add(BatchNormalization())\n",
    "basic_cnn_model.add(Dropout(0.5))\n",
    "\n",
    "# Conv. block 3\n",
    "basic_cnn_model.add(Conv2D(filters=100, kernel_size=(10,1), padding='same', activation='elu'))\n",
    "basic_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "basic_cnn_model.add(BatchNormalization())\n",
    "basic_cnn_model.add(Dropout(0.5))\n",
    "\n",
    "# # Conv. block 4\n",
    "# basic_cnn_model.add(Conv2D(filters=100, kernel_size=(10,1), padding='same', activation='elu'))\n",
    "# basic_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "# basic_cnn_model.add(BatchNormalization())\n",
    "# basic_cnn_model.add(Dropout(0.5))\n",
    "\n",
    "# Output layer with Softmax activation\n",
    "basic_cnn_model.add(Flatten()) # Flattens the input\n",
    "basic_cnn_model.add(Dense(4, activation='softmax')) # Output FC layer with softmax activation\n",
    "\n",
    "\n",
    "# Printing the model summary\n",
    "basic_cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "learning_rate = 1.5e-4\n",
    "epochs = 200\n",
    "cnn_optimizer = optimizers.Adam(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6960 samples, validate on 1500 samples\n",
      "Epoch 1/200\n",
      "6960/6960 [==============================] - 8s 1ms/sample - loss: 2.1866 - acc: 0.2790 - val_loss: 1.9333 - val_acc: 0.3187\n",
      "Epoch 2/200\n",
      "6960/6960 [==============================] - 1s 183us/sample - loss: 2.0443 - acc: 0.3116 - val_loss: 1.4743 - val_acc: 0.3680\n",
      "Epoch 3/200\n",
      "6960/6960 [==============================] - 1s 176us/sample - loss: 1.9366 - acc: 0.3267 - val_loss: 1.3857 - val_acc: 0.3760\n",
      "Epoch 4/200\n",
      "6960/6960 [==============================] - 1s 178us/sample - loss: 1.8918 - acc: 0.3333 - val_loss: 1.2833 - val_acc: 0.4227\n",
      "Epoch 5/200\n",
      "6960/6960 [==============================] - 1s 181us/sample - loss: 1.8352 - acc: 0.3319 - val_loss: 1.2447 - val_acc: 0.4307\n",
      "Epoch 6/200\n",
      "6960/6960 [==============================] - 1s 177us/sample - loss: 1.7522 - acc: 0.3562 - val_loss: 1.2196 - val_acc: 0.4547\n",
      "Epoch 7/200\n",
      "6960/6960 [==============================] - 1s 181us/sample - loss: 1.7327 - acc: 0.3575 - val_loss: 1.1895 - val_acc: 0.4673\n",
      "Epoch 8/200\n",
      "6960/6960 [==============================] - 1s 180us/sample - loss: 1.6548 - acc: 0.3687 - val_loss: 1.1719 - val_acc: 0.4887\n",
      "Epoch 9/200\n",
      "6960/6960 [==============================] - 1s 177us/sample - loss: 1.6125 - acc: 0.3881 - val_loss: 1.1390 - val_acc: 0.5140\n",
      "Epoch 10/200\n",
      "6960/6960 [==============================] - 1s 177us/sample - loss: 1.5458 - acc: 0.3957 - val_loss: 1.1322 - val_acc: 0.5173\n",
      "Epoch 11/200\n",
      "6960/6960 [==============================] - 1s 175us/sample - loss: 1.5154 - acc: 0.4170 - val_loss: 1.1114 - val_acc: 0.5420\n",
      "Epoch 12/200\n",
      "6960/6960 [==============================] - 1s 173us/sample - loss: 1.4837 - acc: 0.4253 - val_loss: 1.0772 - val_acc: 0.5520\n",
      "Epoch 13/200\n",
      "6960/6960 [==============================] - 1s 175us/sample - loss: 1.4260 - acc: 0.4430 - val_loss: 1.0805 - val_acc: 0.5467\n",
      "Epoch 14/200\n",
      "6960/6960 [==============================] - 1s 192us/sample - loss: 1.3919 - acc: 0.4435 - val_loss: 1.0642 - val_acc: 0.5587\n",
      "Epoch 15/200\n",
      "6960/6960 [==============================] - 1s 180us/sample - loss: 1.3612 - acc: 0.4614 - val_loss: 1.0267 - val_acc: 0.5827\n",
      "Epoch 16/200\n",
      "6960/6960 [==============================] - 1s 177us/sample - loss: 1.3322 - acc: 0.4743 - val_loss: 1.0351 - val_acc: 0.5747\n",
      "Epoch 17/200\n",
      "6960/6960 [==============================] - 1s 180us/sample - loss: 1.3110 - acc: 0.4853 - val_loss: 1.0056 - val_acc: 0.5980\n",
      "Epoch 18/200\n",
      "6960/6960 [==============================] - 1s 176us/sample - loss: 1.2761 - acc: 0.4907 - val_loss: 1.0018 - val_acc: 0.5907\n",
      "Epoch 19/200\n",
      "6960/6960 [==============================] - 1s 178us/sample - loss: 1.2660 - acc: 0.4945 - val_loss: 0.9726 - val_acc: 0.6133\n",
      "Epoch 20/200\n",
      "6960/6960 [==============================] - 1s 182us/sample - loss: 1.2440 - acc: 0.5011 - val_loss: 0.9594 - val_acc: 0.6160\n",
      "Epoch 21/200\n",
      "6960/6960 [==============================] - 1s 176us/sample - loss: 1.2126 - acc: 0.5065 - val_loss: 0.9526 - val_acc: 0.6167\n",
      "Epoch 22/200\n",
      "6960/6960 [==============================] - 1s 177us/sample - loss: 1.2000 - acc: 0.5147 - val_loss: 0.9520 - val_acc: 0.6187\n",
      "Epoch 23/200\n",
      "6960/6960 [==============================] - 1s 179us/sample - loss: 1.2033 - acc: 0.5164 - val_loss: 0.9411 - val_acc: 0.6160\n",
      "Epoch 24/200\n",
      "6960/6960 [==============================] - 1s 177us/sample - loss: 1.1605 - acc: 0.5339 - val_loss: 0.9216 - val_acc: 0.6427\n",
      "Epoch 25/200\n",
      "6960/6960 [==============================] - 1s 177us/sample - loss: 1.1486 - acc: 0.5389 - val_loss: 0.9144 - val_acc: 0.6427\n",
      "Epoch 26/200\n",
      "6960/6960 [==============================] - 1s 178us/sample - loss: 1.1446 - acc: 0.5339 - val_loss: 0.9050 - val_acc: 0.6527\n",
      "Epoch 27/200\n",
      "6960/6960 [==============================] - 1s 187us/sample - loss: 1.1282 - acc: 0.5417 - val_loss: 0.8943 - val_acc: 0.6587\n",
      "Epoch 28/200\n",
      "6960/6960 [==============================] - 1s 184us/sample - loss: 1.1191 - acc: 0.5398 - val_loss: 0.8874 - val_acc: 0.6607\n",
      "Epoch 29/200\n",
      "6960/6960 [==============================] - 1s 177us/sample - loss: 1.0774 - acc: 0.5487 - val_loss: 0.8793 - val_acc: 0.6640\n",
      "Epoch 30/200\n",
      "6960/6960 [==============================] - 1s 178us/sample - loss: 1.0791 - acc: 0.5618 - val_loss: 0.8711 - val_acc: 0.6573\n",
      "Epoch 31/200\n",
      "6960/6960 [==============================] - 1s 183us/sample - loss: 1.0885 - acc: 0.5573 - val_loss: 0.8731 - val_acc: 0.6627\n",
      "Epoch 32/200\n",
      "6960/6960 [==============================] - 1s 179us/sample - loss: 1.0548 - acc: 0.5685 - val_loss: 0.8559 - val_acc: 0.6713\n",
      "Epoch 33/200\n",
      "6960/6960 [==============================] - 1s 183us/sample - loss: 1.0396 - acc: 0.5756 - val_loss: 0.8434 - val_acc: 0.6867\n",
      "Epoch 34/200\n",
      "6960/6960 [==============================] - 1s 184us/sample - loss: 1.0348 - acc: 0.5777 - val_loss: 0.8452 - val_acc: 0.6740\n",
      "Epoch 35/200\n",
      "6960/6960 [==============================] - 1s 179us/sample - loss: 1.0219 - acc: 0.5841 - val_loss: 0.8321 - val_acc: 0.6833\n",
      "Epoch 36/200\n",
      "6960/6960 [==============================] - 1s 182us/sample - loss: 1.0006 - acc: 0.6024 - val_loss: 0.8326 - val_acc: 0.6847\n",
      "Epoch 37/200\n",
      "6960/6960 [==============================] - 1s 191us/sample - loss: 0.9885 - acc: 0.5894 - val_loss: 0.8220 - val_acc: 0.6860\n",
      "Epoch 38/200\n",
      "6960/6960 [==============================] - 1s 182us/sample - loss: 0.9836 - acc: 0.5983 - val_loss: 0.8085 - val_acc: 0.7013\n",
      "Epoch 39/200\n",
      "6960/6960 [==============================] - 1s 194us/sample - loss: 0.9782 - acc: 0.6047 - val_loss: 0.8093 - val_acc: 0.6940\n",
      "Epoch 40/200\n",
      "6960/6960 [==============================] - 1s 184us/sample - loss: 0.9550 - acc: 0.6138 - val_loss: 0.8021 - val_acc: 0.6933\n",
      "Epoch 41/200\n",
      "6960/6960 [==============================] - 1s 183us/sample - loss: 0.9510 - acc: 0.6119 - val_loss: 0.7869 - val_acc: 0.7173\n",
      "Epoch 42/200\n",
      "6960/6960 [==============================] - 1s 178us/sample - loss: 0.9594 - acc: 0.6198 - val_loss: 0.7897 - val_acc: 0.7140\n",
      "Epoch 43/200\n",
      "6960/6960 [==============================] - 1s 180us/sample - loss: 0.9440 - acc: 0.6142 - val_loss: 0.7867 - val_acc: 0.7073\n",
      "Epoch 44/200\n",
      "6960/6960 [==============================] - 1s 179us/sample - loss: 0.9210 - acc: 0.6269 - val_loss: 0.7656 - val_acc: 0.7300\n",
      "Epoch 45/200\n",
      "6960/6960 [==============================] - 1s 182us/sample - loss: 0.9198 - acc: 0.6326 - val_loss: 0.7754 - val_acc: 0.7080\n",
      "Epoch 46/200\n",
      "6960/6960 [==============================] - 1s 178us/sample - loss: 0.9427 - acc: 0.6187 - val_loss: 0.7735 - val_acc: 0.7160\n",
      "Epoch 47/200\n",
      "6960/6960 [==============================] - 1s 184us/sample - loss: 0.9133 - acc: 0.6349 - val_loss: 0.7703 - val_acc: 0.7133\n",
      "Epoch 48/200\n",
      "6960/6960 [==============================] - 1s 177us/sample - loss: 0.9098 - acc: 0.6341 - val_loss: 0.7515 - val_acc: 0.7280\n",
      "Epoch 49/200\n",
      "6960/6960 [==============================] - 1s 179us/sample - loss: 0.8973 - acc: 0.6493 - val_loss: 0.7542 - val_acc: 0.7200\n",
      "Epoch 50/200\n",
      "6960/6960 [==============================] - 1s 177us/sample - loss: 0.8862 - acc: 0.6427 - val_loss: 0.7484 - val_acc: 0.7247\n",
      "Epoch 51/200\n",
      "6960/6960 [==============================] - 1s 199us/sample - loss: 0.8799 - acc: 0.6424 - val_loss: 0.7487 - val_acc: 0.7167\n",
      "Epoch 52/200\n",
      "6960/6960 [==============================] - 1s 192us/sample - loss: 0.8849 - acc: 0.6438 - val_loss: 0.7369 - val_acc: 0.7327\n",
      "Epoch 53/200\n",
      "6960/6960 [==============================] - 1s 186us/sample - loss: 0.8565 - acc: 0.6582 - val_loss: 0.7341 - val_acc: 0.7267\n",
      "Epoch 54/200\n",
      "6960/6960 [==============================] - 1s 180us/sample - loss: 0.8644 - acc: 0.6566 - val_loss: 0.7297 - val_acc: 0.7260\n",
      "Epoch 55/200\n",
      "6960/6960 [==============================] - 1s 175us/sample - loss: 0.8628 - acc: 0.6557 - val_loss: 0.7352 - val_acc: 0.7147\n",
      "Epoch 56/200\n",
      "6960/6960 [==============================] - 1s 191us/sample - loss: 0.8557 - acc: 0.6662 - val_loss: 0.7266 - val_acc: 0.7313\n",
      "Epoch 57/200\n",
      "6960/6960 [==============================] - 1s 181us/sample - loss: 0.8472 - acc: 0.6609 - val_loss: 0.7221 - val_acc: 0.7300\n",
      "Epoch 58/200\n",
      "6960/6960 [==============================] - 1s 199us/sample - loss: 0.8486 - acc: 0.6603 - val_loss: 0.7085 - val_acc: 0.7387\n",
      "Epoch 59/200\n",
      "6960/6960 [==============================] - 1s 178us/sample - loss: 0.8289 - acc: 0.6716 - val_loss: 0.7082 - val_acc: 0.7360\n",
      "Epoch 60/200\n",
      "6960/6960 [==============================] - 1s 179us/sample - loss: 0.8232 - acc: 0.6704 - val_loss: 0.7134 - val_acc: 0.7273\n",
      "Epoch 61/200\n",
      "6960/6960 [==============================] - 1s 181us/sample - loss: 0.8136 - acc: 0.6700 - val_loss: 0.6997 - val_acc: 0.7393\n",
      "Epoch 62/200\n",
      "6960/6960 [==============================] - 1s 184us/sample - loss: 0.8171 - acc: 0.6759 - val_loss: 0.6926 - val_acc: 0.7440\n",
      "Epoch 63/200\n",
      "6960/6960 [==============================] - 1s 181us/sample - loss: 0.8292 - acc: 0.6671 - val_loss: 0.6966 - val_acc: 0.7400\n",
      "Epoch 64/200\n",
      "6960/6960 [==============================] - 1s 188us/sample - loss: 0.8079 - acc: 0.6761 - val_loss: 0.6856 - val_acc: 0.7487\n",
      "Epoch 65/200\n",
      "6960/6960 [==============================] - 1s 182us/sample - loss: 0.7962 - acc: 0.6884 - val_loss: 0.6896 - val_acc: 0.7393\n",
      "Epoch 66/200\n",
      "6960/6960 [==============================] - 1s 182us/sample - loss: 0.7871 - acc: 0.6846 - val_loss: 0.6794 - val_acc: 0.7547\n",
      "Epoch 67/200\n",
      "6960/6960 [==============================] - 1s 178us/sample - loss: 0.7933 - acc: 0.6869 - val_loss: 0.6874 - val_acc: 0.7333\n",
      "Epoch 68/200\n",
      "6960/6960 [==============================] - 1s 184us/sample - loss: 0.7923 - acc: 0.6851 - val_loss: 0.6725 - val_acc: 0.7553\n",
      "Epoch 69/200\n",
      "6960/6960 [==============================] - 1s 179us/sample - loss: 0.7758 - acc: 0.6917 - val_loss: 0.6760 - val_acc: 0.7460\n",
      "Epoch 70/200\n",
      "6960/6960 [==============================] - 1s 187us/sample - loss: 0.7896 - acc: 0.6898 - val_loss: 0.6720 - val_acc: 0.7487\n",
      "Epoch 71/200\n",
      "6960/6960 [==============================] - 1s 183us/sample - loss: 0.7865 - acc: 0.6892 - val_loss: 0.6699 - val_acc: 0.7480\n",
      "Epoch 72/200\n",
      "6960/6960 [==============================] - 1s 180us/sample - loss: 0.7662 - acc: 0.6924 - val_loss: 0.6649 - val_acc: 0.7420\n",
      "Epoch 73/200\n",
      "6960/6960 [==============================] - 1s 186us/sample - loss: 0.7680 - acc: 0.7026 - val_loss: 0.6600 - val_acc: 0.7547\n",
      "Epoch 74/200\n",
      "6960/6960 [==============================] - 1s 181us/sample - loss: 0.7665 - acc: 0.7014 - val_loss: 0.6560 - val_acc: 0.7613\n",
      "Epoch 75/200\n",
      "6960/6960 [==============================] - 1s 177us/sample - loss: 0.7429 - acc: 0.7093 - val_loss: 0.6622 - val_acc: 0.7480\n",
      "Epoch 76/200\n",
      "6960/6960 [==============================] - 1s 183us/sample - loss: 0.7543 - acc: 0.7006 - val_loss: 0.6480 - val_acc: 0.7573\n",
      "Epoch 77/200\n",
      "6960/6960 [==============================] - 1s 187us/sample - loss: 0.7408 - acc: 0.7095 - val_loss: 0.6542 - val_acc: 0.7500\n",
      "Epoch 78/200\n",
      "6960/6960 [==============================] - 1s 183us/sample - loss: 0.7550 - acc: 0.7029 - val_loss: 0.6462 - val_acc: 0.7573\n",
      "Epoch 79/200\n",
      "6960/6960 [==============================] - 1s 178us/sample - loss: 0.7437 - acc: 0.7052 - val_loss: 0.6393 - val_acc: 0.7680\n",
      "Epoch 80/200\n",
      "6960/6960 [==============================] - 1s 179us/sample - loss: 0.7583 - acc: 0.7006 - val_loss: 0.6490 - val_acc: 0.7573\n",
      "Epoch 81/200\n",
      "6960/6960 [==============================] - 1s 207us/sample - loss: 0.7300 - acc: 0.7106 - val_loss: 0.6430 - val_acc: 0.7540\n",
      "Epoch 82/200\n",
      "6960/6960 [==============================] - 1s 195us/sample - loss: 0.7257 - acc: 0.7114 - val_loss: 0.6417 - val_acc: 0.7533\n",
      "Epoch 83/200\n",
      "6960/6960 [==============================] - 1s 197us/sample - loss: 0.7275 - acc: 0.7165 - val_loss: 0.6388 - val_acc: 0.7473\n",
      "Epoch 84/200\n",
      "6960/6960 [==============================] - 1s 192us/sample - loss: 0.7175 - acc: 0.7182 - val_loss: 0.6252 - val_acc: 0.7660\n",
      "Epoch 85/200\n",
      "6960/6960 [==============================] - 1s 216us/sample - loss: 0.7148 - acc: 0.7217 - val_loss: 0.6201 - val_acc: 0.7720\n",
      "Epoch 86/200\n",
      "6960/6960 [==============================] - 1s 213us/sample - loss: 0.7229 - acc: 0.7187 - val_loss: 0.6338 - val_acc: 0.7553\n",
      "Epoch 87/200\n",
      "6960/6960 [==============================] - 1s 200us/sample - loss: 0.7236 - acc: 0.7204 - val_loss: 0.6299 - val_acc: 0.7627\n",
      "Epoch 88/200\n",
      "6960/6960 [==============================] - 1s 185us/sample - loss: 0.7126 - acc: 0.7216 - val_loss: 0.6115 - val_acc: 0.7693\n",
      "Epoch 89/200\n",
      "6960/6960 [==============================] - 1s 210us/sample - loss: 0.7102 - acc: 0.7210 - val_loss: 0.6149 - val_acc: 0.7727\n",
      "Epoch 90/200\n",
      "6960/6960 [==============================] - 1s 197us/sample - loss: 0.6896 - acc: 0.7293 - val_loss: 0.6251 - val_acc: 0.7553\n",
      "Epoch 91/200\n",
      "6960/6960 [==============================] - 1s 181us/sample - loss: 0.6943 - acc: 0.7315 - val_loss: 0.6011 - val_acc: 0.7760\n",
      "Epoch 92/200\n",
      "6960/6960 [==============================] - 1s 206us/sample - loss: 0.6998 - acc: 0.7260 - val_loss: 0.6121 - val_acc: 0.7600\n",
      "Epoch 93/200\n",
      "6960/6960 [==============================] - 1s 203us/sample - loss: 0.6999 - acc: 0.7208 - val_loss: 0.5971 - val_acc: 0.7733\n",
      "Epoch 94/200\n",
      "6960/6960 [==============================] - 1s 187us/sample - loss: 0.6832 - acc: 0.7343 - val_loss: 0.5929 - val_acc: 0.7820\n",
      "Epoch 95/200\n",
      "6960/6960 [==============================] - 1s 189us/sample - loss: 0.6844 - acc: 0.7333 - val_loss: 0.5877 - val_acc: 0.7787\n",
      "Epoch 96/200\n",
      "6960/6960 [==============================] - 1s 184us/sample - loss: 0.6906 - acc: 0.7296 - val_loss: 0.5830 - val_acc: 0.7820\n",
      "Epoch 97/200\n",
      "6960/6960 [==============================] - 1s 196us/sample - loss: 0.6877 - acc: 0.7371 - val_loss: 0.5823 - val_acc: 0.7833\n",
      "Epoch 98/200\n",
      "6960/6960 [==============================] - 2s 236us/sample - loss: 0.6756 - acc: 0.7371 - val_loss: 0.5933 - val_acc: 0.7727\n",
      "Epoch 99/200\n",
      "6960/6960 [==============================] - 1s 184us/sample - loss: 0.6740 - acc: 0.7351 - val_loss: 0.5654 - val_acc: 0.7900\n",
      "Epoch 100/200\n",
      "6960/6960 [==============================] - 2s 221us/sample - loss: 0.6690 - acc: 0.7394 - val_loss: 0.5778 - val_acc: 0.7753\n",
      "Epoch 101/200\n",
      "6960/6960 [==============================] - 2s 232us/sample - loss: 0.6800 - acc: 0.7338 - val_loss: 0.5694 - val_acc: 0.7893\n",
      "Epoch 102/200\n",
      "6960/6960 [==============================] - 1s 209us/sample - loss: 0.6689 - acc: 0.7395 - val_loss: 0.5644 - val_acc: 0.7900\n",
      "Epoch 103/200\n",
      "6960/6960 [==============================] - 2s 224us/sample - loss: 0.6602 - acc: 0.7405 - val_loss: 0.5767 - val_acc: 0.7747\n",
      "Epoch 104/200\n",
      "6960/6960 [==============================] - 1s 209us/sample - loss: 0.6620 - acc: 0.7431 - val_loss: 0.5710 - val_acc: 0.7780\n",
      "Epoch 105/200\n",
      "6960/6960 [==============================] - 1s 215us/sample - loss: 0.6614 - acc: 0.7388 - val_loss: 0.5607 - val_acc: 0.7913\n",
      "Epoch 106/200\n",
      "6960/6960 [==============================] - 2s 252us/sample - loss: 0.6438 - acc: 0.7464 - val_loss: 0.5569 - val_acc: 0.7913\n",
      "Epoch 107/200\n",
      "6960/6960 [==============================] - 2s 226us/sample - loss: 0.6467 - acc: 0.7460 - val_loss: 0.5562 - val_acc: 0.7887\n",
      "Epoch 108/200\n",
      "6960/6960 [==============================] - 1s 204us/sample - loss: 0.6536 - acc: 0.7489 - val_loss: 0.5584 - val_acc: 0.7860\n",
      "Epoch 109/200\n",
      "6960/6960 [==============================] - 1s 183us/sample - loss: 0.6422 - acc: 0.7486 - val_loss: 0.5541 - val_acc: 0.7887\n",
      "Epoch 110/200\n",
      "6960/6960 [==============================] - 1s 197us/sample - loss: 0.6413 - acc: 0.7503 - val_loss: 0.5630 - val_acc: 0.7847\n",
      "Epoch 111/200\n",
      "6960/6960 [==============================] - 1s 197us/sample - loss: 0.6395 - acc: 0.7506 - val_loss: 0.5530 - val_acc: 0.7853\n",
      "Epoch 112/200\n",
      "6960/6960 [==============================] - 1s 187us/sample - loss: 0.6398 - acc: 0.7471 - val_loss: 0.5492 - val_acc: 0.7887\n",
      "Epoch 113/200\n",
      "6960/6960 [==============================] - 1s 188us/sample - loss: 0.6245 - acc: 0.7591 - val_loss: 0.5393 - val_acc: 0.7953\n",
      "Epoch 114/200\n",
      "6960/6960 [==============================] - 1s 190us/sample - loss: 0.6257 - acc: 0.7580 - val_loss: 0.5420 - val_acc: 0.7900\n",
      "Epoch 115/200\n",
      "6960/6960 [==============================] - 1s 188us/sample - loss: 0.6241 - acc: 0.7537 - val_loss: 0.5389 - val_acc: 0.7940\n",
      "Epoch 116/200\n",
      "6960/6960 [==============================] - 1s 189us/sample - loss: 0.6263 - acc: 0.7562 - val_loss: 0.5327 - val_acc: 0.7967\n",
      "Epoch 117/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6960/6960 [==============================] - 1s 184us/sample - loss: 0.6133 - acc: 0.7651 - val_loss: 0.5266 - val_acc: 0.7973\n",
      "Epoch 118/200\n",
      "6960/6960 [==============================] - 1s 183us/sample - loss: 0.6158 - acc: 0.7606 - val_loss: 0.5196 - val_acc: 0.8027\n",
      "Epoch 119/200\n",
      "6960/6960 [==============================] - 1s 185us/sample - loss: 0.6252 - acc: 0.7609 - val_loss: 0.5210 - val_acc: 0.8013\n",
      "Epoch 120/200\n",
      "6960/6960 [==============================] - 1s 187us/sample - loss: 0.6125 - acc: 0.7654 - val_loss: 0.5103 - val_acc: 0.8073\n",
      "Epoch 121/200\n",
      "6960/6960 [==============================] - 1s 189us/sample - loss: 0.6100 - acc: 0.7598 - val_loss: 0.5011 - val_acc: 0.8113\n",
      "Epoch 122/200\n",
      "6960/6960 [==============================] - 1s 194us/sample - loss: 0.6115 - acc: 0.7678 - val_loss: 0.5105 - val_acc: 0.8060\n",
      "Epoch 123/200\n",
      "6960/6960 [==============================] - 1s 197us/sample - loss: 0.6071 - acc: 0.7609 - val_loss: 0.5062 - val_acc: 0.8087\n",
      "Epoch 124/200\n",
      "6960/6960 [==============================] - 1s 180us/sample - loss: 0.6053 - acc: 0.7645 - val_loss: 0.5060 - val_acc: 0.8107\n",
      "Epoch 125/200\n",
      "6960/6960 [==============================] - 1s 190us/sample - loss: 0.5917 - acc: 0.7698 - val_loss: 0.4977 - val_acc: 0.8147\n",
      "Epoch 126/200\n",
      "6960/6960 [==============================] - 1s 189us/sample - loss: 0.6076 - acc: 0.7592 - val_loss: 0.5012 - val_acc: 0.8067\n",
      "Epoch 127/200\n",
      "6960/6960 [==============================] - 1s 180us/sample - loss: 0.6077 - acc: 0.7661 - val_loss: 0.4958 - val_acc: 0.8113\n",
      "Epoch 128/200\n",
      "6960/6960 [==============================] - 1s 186us/sample - loss: 0.5811 - acc: 0.7789 - val_loss: 0.5008 - val_acc: 0.8067\n",
      "Epoch 129/200\n",
      "6960/6960 [==============================] - 1s 184us/sample - loss: 0.5883 - acc: 0.7726 - val_loss: 0.4980 - val_acc: 0.8087\n",
      "Epoch 130/200\n",
      "6960/6960 [==============================] - 1s 185us/sample - loss: 0.5965 - acc: 0.7667 - val_loss: 0.4829 - val_acc: 0.8193\n",
      "Epoch 131/200\n",
      "6960/6960 [==============================] - 1s 194us/sample - loss: 0.5827 - acc: 0.7740 - val_loss: 0.4807 - val_acc: 0.8187\n",
      "Epoch 132/200\n",
      "6960/6960 [==============================] - 1s 203us/sample - loss: 0.5737 - acc: 0.7820 - val_loss: 0.4910 - val_acc: 0.8133\n",
      "Epoch 133/200\n",
      "6960/6960 [==============================] - 1s 182us/sample - loss: 0.5796 - acc: 0.7730 - val_loss: 0.4640 - val_acc: 0.8260\n",
      "Epoch 134/200\n",
      "6960/6960 [==============================] - 1s 185us/sample - loss: 0.5838 - acc: 0.7713 - val_loss: 0.4882 - val_acc: 0.8107\n",
      "Epoch 135/200\n",
      "6960/6960 [==============================] - 1s 189us/sample - loss: 0.5901 - acc: 0.7724 - val_loss: 0.4754 - val_acc: 0.8173\n",
      "Epoch 136/200\n",
      "6960/6960 [==============================] - 1s 178us/sample - loss: 0.5767 - acc: 0.7792 - val_loss: 0.4742 - val_acc: 0.8147\n",
      "Epoch 137/200\n",
      "6960/6960 [==============================] - 1s 183us/sample - loss: 0.5687 - acc: 0.7796 - val_loss: 0.4760 - val_acc: 0.8207\n",
      "Epoch 138/200\n",
      "6960/6960 [==============================] - 1s 181us/sample - loss: 0.5692 - acc: 0.7772 - val_loss: 0.4869 - val_acc: 0.8167\n",
      "Epoch 139/200\n",
      "6960/6960 [==============================] - 1s 183us/sample - loss: 0.5675 - acc: 0.7819 - val_loss: 0.4565 - val_acc: 0.8287\n",
      "Epoch 140/200\n",
      "6960/6960 [==============================] - 1s 182us/sample - loss: 0.5553 - acc: 0.7848 - val_loss: 0.4613 - val_acc: 0.8227\n",
      "Epoch 141/200\n",
      "6960/6960 [==============================] - 1s 180us/sample - loss: 0.5778 - acc: 0.7704 - val_loss: 0.4630 - val_acc: 0.8253\n",
      "Epoch 142/200\n",
      "6960/6960 [==============================] - 1s 181us/sample - loss: 0.5674 - acc: 0.7779 - val_loss: 0.4513 - val_acc: 0.8360\n",
      "Epoch 143/200\n",
      "6960/6960 [==============================] - 1s 179us/sample - loss: 0.5652 - acc: 0.7793 - val_loss: 0.4567 - val_acc: 0.8280\n",
      "Epoch 144/200\n",
      "6960/6960 [==============================] - 1s 179us/sample - loss: 0.5482 - acc: 0.7865 - val_loss: 0.4544 - val_acc: 0.8280\n",
      "Epoch 145/200\n",
      "6960/6960 [==============================] - 1s 183us/sample - loss: 0.5585 - acc: 0.7823 - val_loss: 0.4403 - val_acc: 0.8353\n",
      "Epoch 146/200\n",
      "6960/6960 [==============================] - 1s 179us/sample - loss: 0.5481 - acc: 0.7898 - val_loss: 0.4356 - val_acc: 0.8340\n",
      "Epoch 147/200\n",
      "6960/6960 [==============================] - 1s 192us/sample - loss: 0.5515 - acc: 0.7881 - val_loss: 0.4550 - val_acc: 0.8280\n",
      "Epoch 148/200\n",
      "6960/6960 [==============================] - 1s 180us/sample - loss: 0.5381 - acc: 0.7875 - val_loss: 0.4410 - val_acc: 0.8293\n",
      "Epoch 149/200\n",
      "6960/6960 [==============================] - 1s 184us/sample - loss: 0.5401 - acc: 0.7958 - val_loss: 0.4292 - val_acc: 0.8373\n",
      "Epoch 150/200\n",
      "6960/6960 [==============================] - 1s 176us/sample - loss: 0.5633 - acc: 0.7829 - val_loss: 0.4290 - val_acc: 0.8360\n",
      "Epoch 151/200\n",
      "6960/6960 [==============================] - 1s 176us/sample - loss: 0.5467 - acc: 0.7846 - val_loss: 0.4318 - val_acc: 0.8320\n",
      "Epoch 152/200\n",
      "6960/6960 [==============================] - 1s 176us/sample - loss: 0.5483 - acc: 0.7872 - val_loss: 0.4195 - val_acc: 0.8447\n",
      "Epoch 153/200\n",
      "6960/6960 [==============================] - 1s 177us/sample - loss: 0.5207 - acc: 0.8026 - val_loss: 0.4242 - val_acc: 0.8380\n",
      "Epoch 154/200\n",
      "6960/6960 [==============================] - 1s 176us/sample - loss: 0.5293 - acc: 0.7987 - val_loss: 0.4308 - val_acc: 0.8373\n",
      "Epoch 155/200\n",
      "6960/6960 [==============================] - 1s 180us/sample - loss: 0.5322 - acc: 0.7902 - val_loss: 0.4254 - val_acc: 0.8373\n",
      "Epoch 156/200\n",
      "6960/6960 [==============================] - 1s 186us/sample - loss: 0.5334 - acc: 0.7884 - val_loss: 0.4175 - val_acc: 0.8333\n",
      "Epoch 157/200\n",
      "6960/6960 [==============================] - 1s 179us/sample - loss: 0.5378 - acc: 0.7934 - val_loss: 0.4079 - val_acc: 0.8480\n",
      "Epoch 158/200\n",
      "6960/6960 [==============================] - 1s 181us/sample - loss: 0.5331 - acc: 0.7961 - val_loss: 0.4014 - val_acc: 0.8460\n",
      "Epoch 159/200\n",
      "6960/6960 [==============================] - 1s 176us/sample - loss: 0.5299 - acc: 0.7973 - val_loss: 0.4038 - val_acc: 0.8520\n",
      "Epoch 160/200\n",
      "6960/6960 [==============================] - 1s 189us/sample - loss: 0.5312 - acc: 0.7961 - val_loss: 0.4020 - val_acc: 0.8493\n",
      "Epoch 161/200\n",
      "6960/6960 [==============================] - 1s 192us/sample - loss: 0.5250 - acc: 0.7957 - val_loss: 0.3984 - val_acc: 0.8587\n",
      "Epoch 162/200\n",
      "6960/6960 [==============================] - 1s 196us/sample - loss: 0.5126 - acc: 0.8046 - val_loss: 0.4040 - val_acc: 0.8447\n",
      "Epoch 163/200\n",
      "6960/6960 [==============================] - 1s 191us/sample - loss: 0.5157 - acc: 0.7967 - val_loss: 0.3857 - val_acc: 0.8673\n",
      "Epoch 164/200\n",
      "6960/6960 [==============================] - 1s 186us/sample - loss: 0.5244 - acc: 0.7993 - val_loss: 0.3843 - val_acc: 0.8580\n",
      "Epoch 165/200\n",
      "6960/6960 [==============================] - 1s 188us/sample - loss: 0.5222 - acc: 0.7940 - val_loss: 0.3847 - val_acc: 0.8607\n",
      "Epoch 166/200\n",
      "6960/6960 [==============================] - 1s 193us/sample - loss: 0.5191 - acc: 0.7983 - val_loss: 0.3853 - val_acc: 0.8580\n",
      "Epoch 167/200\n",
      "6960/6960 [==============================] - 1s 187us/sample - loss: 0.5088 - acc: 0.7974 - val_loss: 0.3884 - val_acc: 0.8527\n",
      "Epoch 168/200\n",
      "6960/6960 [==============================] - 1s 192us/sample - loss: 0.5095 - acc: 0.8040 - val_loss: 0.3854 - val_acc: 0.8567\n",
      "Epoch 169/200\n",
      "6960/6960 [==============================] - 1s 183us/sample - loss: 0.5106 - acc: 0.8057 - val_loss: 0.3829 - val_acc: 0.8560\n",
      "Epoch 170/200\n",
      "6960/6960 [==============================] - 1s 182us/sample - loss: 0.4936 - acc: 0.8085 - val_loss: 0.3993 - val_acc: 0.8473\n",
      "Epoch 171/200\n",
      "6960/6960 [==============================] - 1s 179us/sample - loss: 0.5024 - acc: 0.8075 - val_loss: 0.3827 - val_acc: 0.8553\n",
      "Epoch 172/200\n",
      "6960/6960 [==============================] - 1s 185us/sample - loss: 0.4907 - acc: 0.8105 - val_loss: 0.3799 - val_acc: 0.8613\n",
      "Epoch 173/200\n",
      "6960/6960 [==============================] - 1s 194us/sample - loss: 0.4891 - acc: 0.8040 - val_loss: 0.3759 - val_acc: 0.8600\n",
      "Epoch 174/200\n",
      "6960/6960 [==============================] - 1s 180us/sample - loss: 0.4938 - acc: 0.8093 - val_loss: 0.3659 - val_acc: 0.8687\n",
      "Epoch 175/200\n",
      "6960/6960 [==============================] - 1s 187us/sample - loss: 0.4953 - acc: 0.8099 - val_loss: 0.3723 - val_acc: 0.8600\n",
      "Epoch 176/200\n",
      "6960/6960 [==============================] - 1s 177us/sample - loss: 0.4993 - acc: 0.8118 - val_loss: 0.3759 - val_acc: 0.8613\n",
      "Epoch 177/200\n",
      "6960/6960 [==============================] - 1s 185us/sample - loss: 0.4915 - acc: 0.8053 - val_loss: 0.3626 - val_acc: 0.8653\n",
      "Epoch 178/200\n",
      "6960/6960 [==============================] - 1s 173us/sample - loss: 0.4945 - acc: 0.8101 - val_loss: 0.3526 - val_acc: 0.8733\n",
      "Epoch 179/200\n",
      "6960/6960 [==============================] - 1s 174us/sample - loss: 0.4981 - acc: 0.8116 - val_loss: 0.3538 - val_acc: 0.8713\n",
      "Epoch 180/200\n",
      "6960/6960 [==============================] - 1s 175us/sample - loss: 0.4938 - acc: 0.8096 - val_loss: 0.3631 - val_acc: 0.8620\n",
      "Epoch 181/200\n",
      "6960/6960 [==============================] - 1s 190us/sample - loss: 0.4850 - acc: 0.8114 - val_loss: 0.3616 - val_acc: 0.8593\n",
      "Epoch 182/200\n",
      "6960/6960 [==============================] - 1s 191us/sample - loss: 0.4904 - acc: 0.8060 - val_loss: 0.3534 - val_acc: 0.8707\n",
      "Epoch 183/200\n",
      "6960/6960 [==============================] - 1s 197us/sample - loss: 0.4858 - acc: 0.8109 - val_loss: 0.3628 - val_acc: 0.8653\n",
      "Epoch 184/200\n",
      "6960/6960 [==============================] - 1s 187us/sample - loss: 0.4846 - acc: 0.8147 - val_loss: 0.3372 - val_acc: 0.8820\n",
      "Epoch 185/200\n",
      "6960/6960 [==============================] - 1s 187us/sample - loss: 0.4736 - acc: 0.8205 - val_loss: 0.3384 - val_acc: 0.8747\n",
      "Epoch 186/200\n",
      "6960/6960 [==============================] - 1s 178us/sample - loss: 0.4802 - acc: 0.8149 - val_loss: 0.3394 - val_acc: 0.8800\n",
      "Epoch 187/200\n",
      "6960/6960 [==============================] - 1s 178us/sample - loss: 0.4720 - acc: 0.8207 - val_loss: 0.3303 - val_acc: 0.8873\n",
      "Epoch 188/200\n",
      "6960/6960 [==============================] - 1s 199us/sample - loss: 0.4716 - acc: 0.8164 - val_loss: 0.3355 - val_acc: 0.8787\n",
      "Epoch 189/200\n",
      "6960/6960 [==============================] - 1s 183us/sample - loss: 0.4710 - acc: 0.8213 - val_loss: 0.3399 - val_acc: 0.8787\n",
      "Epoch 190/200\n",
      "6960/6960 [==============================] - 1s 192us/sample - loss: 0.4807 - acc: 0.8184 - val_loss: 0.3365 - val_acc: 0.8800\n",
      "Epoch 191/200\n",
      "6960/6960 [==============================] - 1s 188us/sample - loss: 0.4552 - acc: 0.8292 - val_loss: 0.3269 - val_acc: 0.8847\n",
      "Epoch 192/200\n",
      "6960/6960 [==============================] - 1s 176us/sample - loss: 0.4696 - acc: 0.8228 - val_loss: 0.3370 - val_acc: 0.8820\n",
      "Epoch 193/200\n",
      "6960/6960 [==============================] - 1s 186us/sample - loss: 0.4679 - acc: 0.8218 - val_loss: 0.3272 - val_acc: 0.8880\n",
      "Epoch 194/200\n",
      "6960/6960 [==============================] - 1s 189us/sample - loss: 0.4640 - acc: 0.8218 - val_loss: 0.3256 - val_acc: 0.8853\n",
      "Epoch 195/200\n",
      "6960/6960 [==============================] - 1s 184us/sample - loss: 0.4531 - acc: 0.8228 - val_loss: 0.3224 - val_acc: 0.8933\n",
      "Epoch 196/200\n",
      "6960/6960 [==============================] - 1s 191us/sample - loss: 0.4637 - acc: 0.8233 - val_loss: 0.3290 - val_acc: 0.8840\n",
      "Epoch 197/200\n",
      "6960/6960 [==============================] - 1s 191us/sample - loss: 0.4636 - acc: 0.8170 - val_loss: 0.3172 - val_acc: 0.8913\n",
      "Epoch 198/200\n",
      "6960/6960 [==============================] - 1s 182us/sample - loss: 0.4524 - acc: 0.8296 - val_loss: 0.3148 - val_acc: 0.8967\n",
      "Epoch 199/200\n",
      "6960/6960 [==============================] - 1s 190us/sample - loss: 0.4467 - acc: 0.8295 - val_loss: 0.3291 - val_acc: 0.8833\n",
      "Epoch 200/200\n",
      "6960/6960 [==============================] - 1s 183us/sample - loss: 0.4570 - acc: 0.8188 - val_loss: 0.3177 - val_acc: 0.8893\n"
     ]
    }
   ],
   "source": [
    "# Compiling the model\n",
    "basic_cnn_model.compile(loss='categorical_crossentropy',\n",
    "                 optimizer=cnn_optimizer,\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "# Training and validating the model\n",
    "basic_cnn_model_results = basic_cnn_model.fit(x_train,\n",
    "             y_train,\n",
    "             batch_size=200,\n",
    "             epochs=epochs,\n",
    "             validation_data=(x_valid, y_valid), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de7xcdXnv8c83mw1sAiYBIoSEkKCcKJeQwBb1YBWkykUp0YMhiNaiNKVCEUo5BGuR0npEc6qFVpuizQErtwhJwIqCRZB6oZJgLlzlFiAJQsyNxGzIzs5z/lhrwmRYM3tmz3Xv+b5fr/3KzFpr1vxmzWSe+d2enyICMzOzQsOaXQAzM2tNDhBmZpbJAcLMzDI5QJiZWSYHCDMzy+QAYWZmmRwgrCqSfijpU80uRyuQdJ+kc8o8NiS9tdrztAJJfyDpiWaXw2rPAaJNSFohqUfSZknrJf1A0oHVnjciTo6I6wdQHkm6QNLDkn4vaaWk70k6It1/XfolekzeY94qKfLu3yfp1fzXIekPJa2o8mW1DUlXSPpuNeeIiP+KiEk1KEvRoGnN4QDRXk6NiD2BMcBLwD81sSxXA58DLgD2Bv4HsBD4UN4x64C/7+c8vwf+ph4FtB2BvOW/JyTt0uwyDEUt/8Zb7UXEq8CtwKG5bZI+JOnXkl6R9IKkK/L27S7pu5LWStog6UFJ+6X7dmoOkfSnkh6TtEnSo5KOKnx+SYcA5wFnRsRPIuK1iNgSETdExFV5h14PTJb0vhIv5xrgzHJ/eaa/Uj8r6cm0jH8n6S2Sfpm+9nmSdi14PU9JWifpDkkH5O37gKTHJW2U9M+ACp7r0+m1WC/pLkkHlVPGgnMMk/QFSc9JelnSdySNSPeVel/+RNIz6Wt8VtJZGec+Cfg8cEZas1yabr9P0pck/RzYAhws6ey89/UZSX+Wd57jJK3Mu3+ApNskrUmf+4K8fR2SPi/p6fRciyUdKOn+9JClaVnOKOP6h6TzJD0JPCnpG5L+oeA1fl/ShZVed0tFhP/a4A9YAfxhensPki/f7+TtPw44guRHw2SSGsa0dN+fAd9PH9cBHA28Kd13H3BOevtjwCrgHSRflm8FDsooy7nAc/2U9zqS2sMFwM/SbW9NPrI7jrkPOAf4GvDddNsfAitKnDeAO4A3AYcBrwH3AAcDI4BHgU+lx74f+B1wFLAbSY3r/nTfvsArwOlAJ3ARsC3vWkwDngLeDuwCfAH4RUE53lqkjPnX9NPpeQ4G9gTmA/9e6n0Bhqdlm5QeNwY4rMhzXZG7dgXP/3x6fXZJX9+HgLek7+v7SALHUXmfnZXp7WHAYuByYNe03M8AJ6b7LwGWA5PScx0J7JN1TUpd/7zjf0xSA+0CjgFWA8Py3qMtwH7N/v83WP9cg2gvCyVtIPny+AAwO7cjIu6LiOURsT0ilgE3kXwRAPQC+5D85+2LiMUR8UrG+c8BvhoRD0biqYh4LuO4fYAXyyzzvwLjJZ1c4pgvA6dKOqzMc34lIl6JiEeAh4G7I+KZiNgI/BCYmh53FjA3Ih6KiNeAy4B3S5oAnAI8GhG3RkQv8I/Ab/Oe48+AL0fEYxGxDfg/wJQB1CLOAr6Wlm9zWoYZaZNKqfdlO3C4pK6IeDF9rZW4LiIeiYhtEdEbET+IiKfT9/WnwN3AH2Q87h3A6Ii4MiK2RsQzwLeAGen+c4AvRMQT6bmWRsTaEq+92PXP+XJErIuInoj4FbAROCHdNwO4LyJeqvC1W8oBor1Mi4iRJL/Gzgd+Kml/AEnvlHRv2iywkeRX/r7p4/4duAu4WdJqSV+V1Jlx/gOBp8sox1qSX7X9Sr8Y/i79U5Fj1gD/DFxZzjlJakc5PRn390xvHwDsCHDpF/RaYGy674W8fZF/HzgIuDpt+tlA0p+i9LGV2KkM6e1dgP0o8r5ExO+BM0jewxeVDEh4W4XPm/9akHSypAfSpp4NJAFy34zHHQQckHvd6bGfT8sL5X9GoPT1zywnSc34E+ntT5BcIxsgB4g2lP7anA/0Ae9JN99I0vRyYESMAOaQfiGnvyD/NiIOBf4n8GHgjzNO/QJJM0R/7gHGSeous8j/j6T55yMljpkNHE/SzFIrq0m+8ACQNJzkF/sqkhpQ/ugp5d8nuRZ/FhEj8/66IuIX1ZQBGE/SlPVSqfclIu6KiA+QBOLHSX7FZymWzjl/tNhuwG3A/yVprhkJ3El2wH4BeLbgde8VEafk7S/nMwKlr3+x8n8XOE3SkSTNewvLfC7L4ADRhpQ4DRgFPJZu3gtYFxGvKhla+vG844+XdISkDpLmqV6S4FLo28BfSTo6fY63ZjWpRMSTwDeBm9IOzl3TDtcZkmZlHL+NpK380mKvKSI2AP8A/O+yLkJ5bgTOljQl/ZL8P8B/R8QK4AfAYZI+mjb3XADsn/fYOcBluWYvSSMkfWwAZbgJuEjSREl7pmW4JSK2FXtfJO0n6Y/SL9TXgM1kv1+Q1J4mqPRIpV1Jap1rgG1pc98Hixz7K+AVSZdK6ko7pQ+X9I50/7eBv5N0SPoZmSxpn7yyHJx3rlLXP1NErAQeJKk53BYRPSVel/XDAaK9fF/SZpIvky+RdMbm2qY/C1wpaRNJB+O8vMftTzLq6RWSgPJTkl9qO4mI76XnvRHYRPLrbe8iZbmApFnoG8AGkmaHj5B0uma5if77La6m+BdhxSLiHpIhtLelz/0W0rb0iPgdSaf8VSTNHocAP8977ALgKyTNP6+Q9HWU6kcpZi7Jl939wLPAq8BfpPuKvS/DgItJfoGvI+lL+myR838v/XetpIeyDoiITSTv1zxgPcmPhzuKHNsHnApMScv7O5KgMCI95Gvpee5Oy/1vJB3MkPwIuD5tmppe6vr343qSARduXqqSkqZTM7OBkfR+4NsRcXC/BzeApPeSBMoJEbG92eUZzFyDMLNqHU5SW2i6dPDE50gCloNDlTz70MwGTNLVwB8BTc/HJentwCJgKXB2k4szJLiJyczMMrmJyczMMtWtiUlJhs3vkIy02A5cGxFXFxxzFq8PXdwM/HlE5PLBrCAZCdMHbIuIfsfM77vvvjFhwoRavQQzsyFv8eLFv4uI0Vn76tkHsQ24OCIekrQXsFjSjyPi0bxjngXeFxHr07HV1wLvzNt/fDqcsCwTJkxg0aJFNSm8mVk7kJSVDgeoY4CIiBdJx61HxCZJj5FMkX8075j8WaUPAOPqVR4zM6tMQ/og0uRaU4H/LnHYZ0gSpeUEcLeSdMAz61c6MzPLUvdhrml6gNuAC4tkAEXS8SQB4j15m4+NiNWS3gz8WNLjEXF/xmNnAjMBxo8fX/Pym5m1q7oGiHTSym3ADWlyuKxjJpNMxT85P+1vRKxO/31Z0gKSXO9vCBARcS1J3wXd3d1vGLPb29vLypUrefXVV2vwilrX7rvvzrhx4+jszEqyamZWuXqOYhJJnpXHIuJrRY4ZT7IAyicj4jd524eTLPqxKb39QcpP5byTlStXstdeezFhwgSSIg09EcHatWtZuXIlEydObHZxzGyIqGcN4ljgk8BySUvSbZ8nSVdMRMwhSQq3D/DN9Ms7N5x1P2BBum0X4MaI+NFACvHqq6+WDA7rt2zlpY2vsrVvO7t2DGO/Ebszao9dM49tVZLYZ599WLNmTbOLYmZDSD1HMf2MIgu85B1zDskKU4XbnyFZirAmSgWHVet72J7OJt/at51V65PswIMxSJiZ1VJbz6R+aeOrO4JDzvYIXto4tPsrzMzK0dYBYmtfdrLHYtsHYsOGDXzzm9+s+HGnnHIKGzZsqFk5zMwq1dYBYteON778+554mXOuX8TEWT/g2Kt+wsJfr8p4ZPmKBYi+vtLr2tx5552MHDmyquc2M6tGW6f73m/E7jv1Qdz3xMt8496neW1bUoNYtaGHy+YvB2Da1ErXmk/MmjWLp59+milTptDZ2cmee+7JmDFjWLJkCY8++ijTpk3jhRde4NVXX+Vzn/scM2cmcwJzaUM2b97MySefzHve8x5+8YtfMHbsWG6//Xa6urr6eWYzs+q0dQ1i1B67MnZU146axHcfeH5HcMjp6e1j9l1PDPg5rrrqKt7ylrewZMkSZs+eza9+9Su+9KUv8eijScaRuXPnsnjxYhYtWsQ111zD2rVr33COJ598kvPOO49HHnmEkSNHcttttw24PGZm5WrrGgQkQSI3YmnNptcyj1m9oXbrnh9zzDE7zVW45pprWLBgAQAvvPACTz75JPvss89Oj5k4cSJTpkwB4Oijj2bFihU1K4+ZWTFtXYModMDI7GabYtsHYvjw4Ttu33ffffznf/4nv/zlL1m6dClTp07NnPG922677bjd0dHBtm3balYeM7NiHCDyXHLiJLo6O3ba1tXZwSUnThrwOffaay82bdqUuW/jxo2MGjWKPfbYg8cff5wHHnhgwM9jZlZrbd/ElC/XET37ridYvaGHA0Z2ccmJkwbcQQ2wzz77cOyxx3L44YfT1dXFfvvtt2PfSSedxJw5c5g8eTKTJk3iXe96V9WvwcysVobUmtTd3d1RuGDQY489xtvf/vYmlaix2um1mlltSFpcbMVONzGZmVkmBwgzM8vkAGFmZpncSc3QSPltZlZrbR8ghlLKbzOzWmr7Jian/DYzy9b2AaIRKb8rseeeezblec3MCrV9E9OuHcN2CgYjn1rI/ou+Sufm1TBiHJxwOUye3sQSmpk1R91qEJIOlHSvpMckPSLpcxnHSNI1kp6StEzSUXn7TpL0RLpvVr3Kud+I3RmWLtc58qmFjPuvWey6eRUiYOML8P0LYNm8AZ//0ksv3Wk9iCuuuIK//du/5YQTTuCoo47iiCOO4Pbbb6/6dZiZ1Vo9m5i2ARdHxNuBdwHnSTq04JiTgUPSv5nAvwBI6gC+ke4/FDgz47E1kZ/ye/9FX2VYX0Hm1t4euOfKAZ9/xowZ3HLLLTvuz5s3j7PPPpsFCxbw0EMPce+993LxxRczlGa0m9nQULcmpoh4EXgxvb1J0mPAWODRvMNOA74TybfjA5JGShoDTACeiohnACTdnB6b/9ia2ZHye/Pq7AM2rhzwuadOncrLL7/M6tWrWbNmDaNGjWLMmDFcdNFF3H///QwbNoxVq1bx0ksvsf/++w/4eczMaq0hfRCSJgBTgf8u2DUWeCHv/sp0W9b2dxY590yS2gfjx4+vrqAjxiXNSlnbq3D66adz66238tvf/pYZM2Zwww03sGbNGhYvXkxnZycTJkzITPNtZtZMdR/FJGlP4Dbgwoh4pXB3xkOixPY3boy4NiK6I6J79OjR1RX2hMuhs2Dth86uZHsVZsyYwc0338ytt97K6aefzsaNG3nzm99MZ2cn9957L88991xV5zczq4e61iAkdZIEhxsiYn7GISuBA/PujwNWA7sW2V5fudFK91yZNCvVaBTTYYcdxqZNmxg7dixjxozhrLPO4tRTT6W7u5spU6bwtre9rQaFNzOrrboFCEkC/g14LCK+VuSwO4Dz0z6GdwIbI+JFSWuAQyRNBFYBM4CP16usO5k8vS7DWpcvX77j9r777ssvf/nLzOM2b95c8+c2MxuIetYgjgU+CSyXtCTd9nlgPEBEzAHuBE4BngK2AGen+7ZJOh+4C+gA5kbEI3Up5ZZ1sOlF6NtKnzp5KUbxu+3DnZPJzNpePUcx/YzsvoT8YwI4r8i+O0kCSP1sWZd0SkcyUa4jetkv1rCNYEPfns7JZGZtrS1SbRSdY7DpxR3BIadDwf5aDwyunEyeR2FmtTbkA8Tuu+/O2rVrs79A+7ZmPqaTbTtuNysnUyUigrVr17L77rs3uyhmNoQM+VxM48aNY+XKlaxZs+aNO19ZB9u3vWHzNjp4KQ0oHYLHNnW94ZhWs/vuuzNuXHXzNczM8g35ANHZ2cnEiROzdy5bnuRa6n09vcaW2JVZvedwx/b3JI/vELNPP5JpU8c2orhmZi1jyDcxlTR5Opx6DYw4EBCr2Xen4ADQ2xfMvuuJ5pXRzKxJhnwNol958x6OnfWDzOnaqzf0ZGw1Mxva2rsGUeCAkdl9DcW2m5kNZQ4QeS45cRJdnR07bevq7OCSEyc1qURmZs3jJqY8uY7o2Xc9waoNPXRI9PT27eiDcEe1mbUT1yAKTJs6dkdNoi8d6rpqQw+XzV/Owl+vanLpzMwaxwEiw+y7nqCnt2+nbfk1CTOzduAAkaHYqCWPZjKzduIAkcGjmczMHCAyeTSTmZlHMWXKH820ekMPB4zs4pITJ3kUk5m1FQeIIqZNHeuAYGZtzU1MZmaWqZ5rUs8FPgy8HBGHZ+y/BDgrrxxvB0ZHxDpJK4BNQB+wLSK661XOUhb+epWbmcysbdWzBnEdcFKxnRExOyKmRMQU4DLgpxGxLu+Q49P9TQsOl81fzqoNPQSeLGdm7aduASIi7gfW9Xtg4kzgpnqVZSCKTZa7eN5SBwkzawtN74OQtAdJTeO2vM0B3C1psaSZ/Tx+pqRFkhZlrho3QMUmxfVFuCZhZm2h6QECOBX4eUHz0rERcRRwMnCepPcWe3BEXBsR3RHRPXr06JoVqtSkOKfdMLN20AoBYgYFzUsRsTr992VgAXBMowuVNVkun9NumNlQ19QAIWkE8D7g9rxtwyXtlbsNfBB4uNFlmzZ1LF/+6BF0SJn7nXbDzIa6eg5zvQk4DthX0krgi0AnQETMSQ/7CHB3RPw+76H7AQuUfDHvAtwYET+qVzlLyQ1pvWz+8p06rJ12w8zaQd0CREScWcYx15EMh83f9gxwZH1KVTmn3TCzduVUG2Vw2g0za0cOEGXyrGozazcOEGXIzarO9UPkZlWD16k2s6GrFYa5tjwvQWpm7cgBogxegtTM2pEDRBm8BKmZtSMHiDIUm1W9Zes252QysyHLAaIMuVnVI7s6d9q+fkuvE/eZ2ZDlAFGmaVPHMny3Nw76cme1mQ1VDhAVcGe1mbUTB4gKuLPazNqJA0QFsjqrnbjPzIYqz6SugBP3mVk7UUQ0uww1093dHYsWLWrIczk3k5kNBZIWR0R31j7XIAbAuZnMrB24D2IAnJvJzNqBA8QAFBvWusrDXc1sCHGAGIBiw1oFnlVtZkNG3QKEpLmSXpb0cJH9x0naKGlJ+nd53r6TJD0h6SlJs+pVxoG65MRJKGN7gJuZzGzIqGcN4jrgpH6O+a+ImJL+XQkgqQP4BnAycChwpqRD61jOik2bOpZiY79WbehxLcLMhoS6BYiIuB9YN4CHHgM8FRHPRMRW4GbgtJoWrtCyefD1w+GKkcm/y+b1+5CxJWZPO4GfmQ0Fze6DeLekpZJ+KOmwdNtY4IW8Y1am2zJJmilpkaRFa9asqbwEy+bB9y+AjS8Akfz7/Qv6DRLFUoCDRzSZ2dDQzADxEHBQRBwJ/BOwMN1erHk/U0RcGxHdEdE9evToyktxz5XQWzD6qLcn2V5CLgV4MU7gZ2aDXdMCRES8EhGb09t3Ap2S9iWpMRyYd+g4YHXdCrJxZWXb80ybOrZoU5MT+JnZYNe0ACFpf0lKbx+TlmUt8CBwiKSJknYFZgB31K0gI8ZVtr2AE/iZ2VBVt1Qbkm4CjgP2lbQS+CLQCRARc4DTgT+XtA3oAWZEkhhqm6TzgbuADmBuRDxSr3JywuVJn0N+M1NnV7K9DE7gZ2ZDVd0CRESc2c/+fwb+uci+O4E761GuN5g8Pfn3niuTZqUR45LgkNtehsIgkeugdpAws8HMyfogCQYVBIRCTt5nZkNRs4e5DglO3mdmQ5EDRA2USt7nCXNmNlg5QOQbwIxqKD2k1bOqzWywcoDIGeCMavCsajMbmhwgcgY4oxr6n1XtdSLMbDBygMipYkY1lJ5V7XUizGwwcoDIqXJGNXidCDMbWhwgck64PJlBna+CGdXgdSLMbGhxgMiZPB1OvQZGHAgo+ffUayqeQOd1IsxsqFCS/mho6O7ujkWLFjW1DIWzqguNHdnFz2e9v8GlMjPLJmlxRHRn7XOqjRrLpda48JYlmfs9osnMBgs3MdWBRzSZ2VDgAFEnHtFkZoNdWQFC0uckvUmJf5P0kKQP1rtwTTHAdBuFPKLJzAa7cmsQn46IV4APAqOBs4Gr6laqZqki3UaWUiOaLrplCV9YuHyABTUzq79yA0SuteQU4P9FxNK8bUNHFek2spTK0RTADQ8875qEmbWscgPEYkl3kwSIuyTtBWwv9QBJcyW9LOnhIvvPkrQs/fuFpCPz9q2QtFzSEkmNG7daZbqNQv3laHJ/hJm1snIDxGeAWcA7ImILydrSZ/fzmOuAk0rsfxZ4X0RMBv4OuLZg//ERMaXY+Ny6KJZWQ8Oq6oso1dTk/ggza1XlBoh3A09ExAZJnwC+AGws9YCIuB9YV2L/LyJifXr3AaD8pEf1kpVuAyD6quqLKDaiKcczrM2sFZUbIP4F2JI2A/1v4DngOzUsx2eAH+bdD+BuSYslzSz1QEkzJS2StGjNmjXVlSKXbkMZ/Qa9PfDDSwd02mlTx3LWu8YXDRJeM8LMWlG5AWJbJDk5TgOujoirgb1qUQBJx5MEiPxv32Mj4ijgZOA8Se8t9viIuDYiuiOie/To0dUXaPJ0iCLdKz3rBlyL+PtpR/D1M6YU3e8Z1mbWasoNEJskXQZ8EviBpA6SfoiqSJoMfBs4LSLW5rZHxOr035eBBcAx1T5XRUql+B7giCbovz9iwqwfMPXKu93cZGYtodwAcQbwGsl8iN8CY4HZ1TyxpPHAfOCTEfGbvO3D01FSSBpOMvcicyRU3ZRK8T3AEU05/fVHrN/SyyW3LnWQMLOmKytApEHhBmCEpA8Dr0ZEyT4ISTcBvwQmSVop6TOSzpV0bnrI5cA+wDcLhrPuB/xM0lLgV8APIuJHlb+0KkyeDl17Z++rYkQTlJ5hndPbF+6TMLOmKyubq6TpJDWG+0gmyP2TpEsi4tZij4mIM0udMyLOAc7J2P4McOQbH9FgJ38lGblUOHEu+mD+THj+Afjw1wZ06rEju/rtc1jtPgkza7Jym5j+mmQOxKci4o9J+gT+pn7FagGlRjQRsGhuVcNei82wzjmgRF+FmVkjlBsghqUdxjlrK3js4FVqRBMx4A7r3AzrkV3F+/m3bN3mfggza6qyVpSTNBuYDNyUbjoDWBYRA5sYUCd1WVHu64enyfuyCK7YUNXpF/56FVfc8QgbenqLHjNqj06+eOphOxYjMjOrlVIrypXbSX0JSSqMyST9A9e2WnComxMup2hewio7rCGpTSz54gdLDn/1yCYza4aym4ki4raI+MuIuCgiFtSzUC1l8nTo/jSZQSL6YP6fwlcmVh0o+uuU7u0LLp7nIGFmjVMyQEjaJOmVjL9Nkl5pVCGb7sNfg49eW6TDmmSGdRW5mqC8Tum+CK8jYWYNUzJARMReEfGmjL+9IuJNjSpkSyjZYU1VuZqgvJFN4HUkzKxxhv5IpFoqlYIDqsrVVM7IphyvI2FmjVDWKKbBoi6jmPLlliQtnDyXb8SBcFF1mUHKGdkEyYS71Rt6OGBkF5ecOMmjnMysYlWPYrJUbvJcsTQckAyJrbLTOjey6R/PmFIyb9OqDT1E+q/XlDCzWnOAqNTk6XDps6WDRM86uP28mgyBLbWOxE5P6TUlzKzGHCAG6uSvZK8+l9O3FRacW3WQyK0j0aH+w4TzN5lZLTlADFSuuamUKpcqzZk2dSzby+grGlFGB7eZWbkcIKoxeXrSKV1Kb09ViwzllDNPYkNPrxccMrOacYCo1gmXw7B+frlvfCHJ6VRFTeKSEyfROaz/Zqb1W3o9mc7MasIBolqTp8O0b5butIYkSFTR3DRt6lhmf+zIsudJfPeB512bMLOqeB5ELS2bBws/C9tLzF+owTwJgGOv+km/iw4BdHV28OWPHuE5EmaWqSnzICTNlfSypMxvQyWukfSUpGWSjsrbd5KkJ9J9s+pVxpqbPB1226v0MTVoboLyU3P09PZxxR2PVPVcZtae6tnEdB1wUon9JwOHpH8zgX8BkNQBfCPdfyhwpqRD61jO2upZ3/8xVTY3QWWpOTb09LqpycwqVrcAERH3A+tKHHIa8J1IPACMlDSGZDnTpyLimYjYCtycHjs49JevKacGo5tyM64/UcZkugtvWeI+CTOrSDM7qccC+Uu1rUy3Fds+OJxweekJdPmKrlRXmdxkuv5qE+u39DpQmFnZmhkgsn70Ront2SeRZkpaJGnRmjVrala4ActNoOtvfgQAqrovIidXmxi1R/9NTuu39Dp3k5n1q5kBYiWQ/y06DlhdYnumiLg2Irojonv06NF1KWjFJk9PRip99Fv91CaiJuk48n3x1MPK7ry+bP4yjr3qJ0yc9QOOveonDhhmtpNmBog7gD9ORzO9C9gYES8CDwKHSJooaVdgRnrs4FNObSK3bOkVI2oyuinXeV1O7qae3u07ZYT1BDszy7dLvU4s6SbgOGBfSSuBLwKdABExB7gTOAV4CtgCnJ3u2ybpfOAuoAOYGxGDd5zm5OnJ39cP77/PYeMLMH8mPP9AsszpAOXmPFzyvaX0bi9/nktutTqAex9f47UmzNqcJ8o1SjmLDe2gZA3sydOrespyFx7KePadOn082c5s6PKCQa0g19yk/vsHatU3keu4XnHVh8rqvM579p14rQmz9uQA0UiTp8NH5pA9UKtArm+iytXpcsrtvC5m1YYed2SbtRkHiEabPB26P01ZQQKS1enmz4T/+MuqnraSmdfFuCPbrL24D6JZls1LZlJXOlmua+9kNbsq+icW/noVs+96gtUbehjR1TmgPoqvnzHFfRJmQ0CpPggHiFawbF7S5xB95T+mBoEip9zMsIWGCbYHjPVIJ7NBy53UrS7XN1Fuig5Im55qM3+i3MWICuVG0K7a0OOZ2WZDkGsQrWTZPPjhpcmXf6U6u5JRUgOsUQx0SGyWUXt08sVTD3ONwmwQcBPTYPMffwmL5lIiBVW2rr3h0mdrUoRcP8VAmp5yHCjMWp8DxGBUTW2ihv0TkASLi+ctpa+Kz4r7KcxakwPEYFZNoICaBYuFv15VceqONxTFM7LNWo4DxFAx0KYnqNnw2Fr0U+Sanq62TaMAABFxSURBVIAdw22d88msORwghpKBzp+Aqjuy8w10aGwprmGYNZ6HuQ4lZa81kaG35/WhsVWm8LjkxElVpe7I0tPbxxV3DN7EvWZDTd3SfVud5WoBA+2f6FkHt5+387kqkPuVX9hEtOi5ddzwwPMDaQQDYENPL4f+zQ8B2NK7HfBoKLNmcRPTUFBtR3ZODTu0qx0iW0yHRF+ER0WZ1Yj7INpJrYKFOpLUHyMOhBMur2oCXrWjn4pxn4VZ9Rwg2tVXJlYfKABQkoF2gKvc1XKWdjFuhjIbGAeIdlXRKnb9ae4qd+Xo7BCzTz+SaVPHviFjrQQbtvR6OK1ZgaYFCEknAVeTrC397Yi4qmD/JcBZ6d1dgLcDoyNinaQVwCagD9hW7AXkc4DIsNOw2MLFRKvUQnMrcnJ9FKVeqZumzF7XlAAhqQP4DfABYCXwIHBmRDxa5PhTgYsi4v3p/RVAd0T8rtzndIAoQ01rFakaBIovLFxe1einSo0d2cXPZ72/Qc9m1rqaFSDeDVwRESem9y8DiIgvFzn+RuDeiPhWen8FDhD1Uc9aBYCGQWyvuIM7v1nogJFdHP+20dy2eBU9vRWsk1FJMcFNTtb2mhUgTgdOiohz0vufBN4ZEednHLsHSS3jrRGxLt32LLCe5NvrXyPi2iLPMxOYCTB+/Pijn3vuuXq8nKGtHrWKHarv4M7vS/j91m309tX+M7tHZzJn1HMvrN00K0B8DDixIEAcExF/kXHsGcAnIuLUvG0HRMRqSW8Gfgz8RUTcX+o5XYOowo5axUoYMQ4O+SAsvq6yVe7KVUWTVP4cizrUfTI5WNhQ1vJNTJIWAN+LiBuLnOsKYHNE/N9Sz+kAUWPL5sHCz8L2Og1PrUHfRT1yQmXp7BBnvONA7n18Das29HjCng0ZzQoQu5B0Up8ArCLppP54RDxScNwI4FngwIj4fbptODAsIjalt38MXBkRPyr1nA4QdVCriXf96do7+bdnfVKDKbPvYuGvV3HZ/OV166coR+cwsefuu3gYrQ1KzRzmegrwjyTDXOdGxJcknQsQEXPSY/6EpK9iRt7jDgYWpHd3AW6MiC/193wOEA1UTerxSpTR0V1szkPu9votvQ1rjsrJb5Yq7Hx3ALFW4olyVh/1Hg2VpYoRUvWezV1M4ZXxPAxrJQ4Q1liNapbKqaB5Kv/X/O6dw+hJRy01yzDB9vCSrNY8DhDWHM2oYcDrz1Vh81Su+QdoSm3DfRnWDA4Q1joa1XeRr3N48m/v75N/y2ymqmcm2nK5hmH15gBhraWaZVNrLp3IN/5dO88DSQNHYd/FqD06+dDkMXWd4d0fBwurJQcIa135E/S6RiXbGtV3UVL/gSM3YS83J6KrSX0a+bWM4982mnsfX+MRU1Y2BwgbfJrWf9GPzi449Zp+O8EbMXmvXJ4JbqU4QNjQ0SrNUwOcn9GMORmFcjWOkXll8szw9uUAYUNTYfPU1s3Qt7WxZagyr1SzZ4Fn8Wiq9uIAYe0hP2B07vH6qKVGGXFgkuTwybvf0GdRTFZfRv4v+1ZQOLHPM8OHFgcIa0+FGWpzX9YNnchXMCcDsstURKv0aQjo6hy2Ix164b6z3jWev592xI5tDiKDhwOEWZZmzMl4g/LXy2hGqvNK5fo3ipXPfRytxwHCrJisdTCW3linxZMq0LU3HPaRspqrWmnIbTlywSMrWLjm0XgOEGaVaIXO71LKTFQ4GGocOf1NQHTNo34cIMyqUVjL2PtgePZ+WuYrt4KRVFkjp1o9eOTkd5a7plE7DhBmtdYq8zHylRkoCr9cj3/b6KamDqkl566qnAOEWT3lBwt1pOt4t8Dv8gprFoW/yBc9t44bHng+81Xs0TkMIHNUUyvJNV3llorNf1c8wzzhAGHWaM2ek5GvczjsslvFy7lC/53GzVyIqZbauebRzCVHTwKuJlly9NsRcVXB/uOA20nWpAaYHxFXlvPYLA4Q1rKy5mRAYxdWKpS/0NKORImVB5GcrP6NXL8B0JKzxrMUG2U1VPs9mhIgJHUAvwE+AKwEHgTOjIhH8445DviriPhwpY/N4gBhQ0KrZLitYKhtTqkv0cLcVFu39bV8ExXA8F07+P3W/gNbYY6rwZKqpFkB4t3AFRFxYnr/MoCI+HLeMceRHSD6fWwWBwgb0loiw23Gan3FZqyXKWvNjS+eelhLzCCvpWKBo9k1k2YFiNOBkyLinPT+J4F3RsT5ecccB9xGUktYTRIsHinnsXnnmAnMBBg/fvzRzz33XF1ej1lLaonZ4AX6SYlerlLJDPN/rQ+Wmki5CnNf1VupALFLPZ83Y1vhp/gh4KCI2CzpFGAhcEiZj002RlwLXAtJDWLgxTUbhD78tbxFjVpk7YzeHpj/p7Dg3GREV5kT+wrlviAr/XX9hYXLi46+Ggx6evu48JYlXHjLkqanZm9qE1PGY1YA3SRBwk1MZgPVcjWLNHDlhgEPIPNtJbLSj4wtaNYZCqOvIOkj2bK1b8DNU81qYtqFpKP5BGAVSUfzxyPikbxj9gdeioiQdAxwK3AQycilko/N4gBhlqdVOrvLVaOmqUq16rocAzGQ5qmmNDFFxDZJ5wN3kXzhz037F85N988BTgf+XNI2oAeYEUnEynxsvcpqNiRNnp79ZZuVoDD3S76ZczZ6e5JmKWhokChsyupvhNXIFlodsFBPbx+z73qiZs1OnihnZjvLnBneJDsm+a1jp/6VKlbyK1elo4uKLTHbaAKevepD5R/vmdRmNmDL5sH3LyieAl3DIJo0iqgBgaJajV6bfOzILn4+6/1lH9+sUUxmNhTkvnxLzXXoL4jUS886mD8Tnn9g50WXqpybUUvTpo7tt+ZRqz4QAZecOKnq8+w4n2sQZlYTrbCORrHaTH8d4E0OKOXOQM9l3/2PpS++YQRW1tKv5XATk5k1Xqut1qcOOPpP0g75fuaMNGlEVSVqNQPbAcLMWkNWB3jn8OZmuy0lVyOp87yNZnKAMLPW1hJ5pio0CGoZ5XAntZm1tqw5G8X6BVpllnj+vA3YOXV7FWtwtBLXIMxs8Fk2r7lraVSqhWsbbmIys6GpMFDk+gyaPcGvmAbloqqoSA4QZtaWWqU5qlzFmqaKrUhYg6G5DhBm1r6yRk4VW/CoaxRse611R1XlDOsEaed5JgNsxnKAMDOrVLNmh1eja2+49NmKHlIqQAyrSaHMzIaaydOTX+QjDgSU/PvRbyV/XXs3u3TZetYlga1GXIMwMxuIwg7yXOJAyJvT0QQjDoSLHi77cM+DMDOrtWLrbeT2NauJauPKmp3KTUxmZvWQ1UTV/Zn0PkmHOSQjl2ppxLianco1CDOzeilVy8hXbHnY3Kircud1dHa9PgS2BhwgzMyarZJA0sCUHnUNEJJOAq4mWVf62xFxVcH+s4BL07ubgT+PiKXpvhXAJqAP2FasE8XMrG2UG0hqpG4BQlIH8A3gA8BK4EFJd0TEo3mHPQu8LyLWSzoZuBZ4Z97+4yPid/Uqo5mZFVfPTupjgKci4pmI2ArcDJyWf0BE/CIi1qd3HwBq17tiZmZVqWeAGAvkDwRemW4r5jPAD/PuB3C3pMWSZhZ7kKSZkhZJWrRmzZqqCmxmZq+rZx+EMrZlzsqTdDxJgHhP3uZjI2K1pDcDP5b0eETc/4YTRlxL0jRFd3f30Jn1Z2bWZPWsQawEDsy7Pw5YXXiQpMnAt4HTImJtbntErE7/fRlYQNJkZWZmDVK3VBuSdgF+A5wArAIeBD4eEY/kHTMe+AnwxxHxi7ztw4FhEbEpvf1j4MqI+FE/z7kGeG6ARd4XaMUOcZercq1aNperMi5X5QZStoMiYnTWjro1MUXENknnA3eRDHOdGxGPSDo33T8HuBzYB/imJHh9OOt+wIJ02y7Ajf0Fh/ScmS+yHJIWteJQWpercq1aNperMi5X5WpdtrrOg4iIO4E7C7bNybt9DnBOxuOeAY6sZ9nMzKw052IyM7NMDhCvu7bZBSjC5apcq5bN5aqMy1W5mpZtSK0HYWZmteMahJmZZXKAMDOzTG0fICSdJOkJSU9JmtXEchwo6V5Jj0l6RNLn0u1XSFolaUn6d0qTyrdC0vK0DIvSbXtL+rGkJ9N/RzW4TJPyrssSSa9IurAZ10zSXEkvS3o4b1vR6yPpsvQz94SkE5tQttmSHpe0TNICSSPT7RMk9eRduznFz1yXchV97xp1zYqU65a8Mq2QtCTd3sjrVew7on6fs4ho2z+S+RlPAwcDuwJLgUObVJYxwFHp7b1IJhkeClwB/FULXKsVwL4F274KzEpvzwK+0uT38rfAQc24ZsB7gaOAh/u7Pun7uhTYDZiYfgY7Gly2DwK7pLe/kle2CfnHNeGaZb53jbxmWeUq2P8PwOVNuF7FviPq9jlr9xpEvxlnGyUiXoyIh9Lbm4DHKJ3csBWcBlyf3r4emNbEspwAPB0RA51JX5VI8oStK9hc7PqcBtwcEa9FxLPAU9QxlUxW2SLi7ojYlt5tSiblItesmIZds1LlUjJ7dzpwUz2eu5QS3xF1+5y1e4CoNONsQ0iaAEwF/jvddH7aFDC30c04ebKy6+4XES9C8uEF3tyksgHMYOf/tK1wzYpdn1b73H2anTMpT5T0a0k/lfQHTShP1nvXKtfsD4CXIuLJvG0Nv14F3xF1+5y1e4AoO+Nso0jaE7gNuDAiXgH+BXgLMAV4kaR62wzHRsRRwMnAeZLe26RyvIGkXYE/Ar6XbmqVa1ZMy3zuJP01sA24Id30IjA+IqYCfwncKOlNDSxSsfeuVa7Zmez8Q6Th1yvjO6LooRnbKrpm7R4gyso42yiSOkne+BsiYj5ARLwUEX0RsR34Fk3KahvZ2XVfkjQmLfsY4OVmlI0kaD0UES+lZWyJa0bx69MSnztJnwI+DJwVaaN12hyxNr29mKTd+n80qkwl3rumXzMlCUg/CtyS29bo65X1HUEdP2ftHiAeBA6RNDH9FToDuKMZBUnbNv8NeCwivpa3fUzeYR8BHi58bAPKNlzSXrnbJB2cD5Ncq0+lh30KuL3RZUvt9KuuFa5Zqtj1uQOYIWk3SROBQ4BfNbJgStaLvxT4o4jYkrd9tJLlgpF0cFq2ZxpYrmLvXdOvGfCHwOMRsTK3oZHXq9h3BPX8nDWi972V/4BTSEYDPA38dRPL8R6S6t8yYEn6dwrw78DydPsdwJgmlO1gktEQS4FHcteJJBPvPcCT6b97N6FsewBrgRF52xp+zUgC1ItAL8kvt8+Uuj7AX6efuSeAk5tQtqdI2qdzn7U56bH/K32PlwIPAac2uFxF37tGXbOscqXbrwPOLTi2kder2HdE3T5nTrVhZmaZ2r2JyczMinCAMDOzTA4QZmaWyQHCzMwyOUCYmVkmBwizFiDpOEn/0exymOVzgDAzs0wOEGYVkPQJSb9Kc///q6QOSZsl/YOkhyTdI2l0euwUSQ/o9TUXRqXb3yrpPyUtTR/zlvT0e0q6Vck6DTekM2fNmsYBwqxMkt4OnEGSuHAK0AecBQwnyQV1FPBT4IvpQ74DXBoRk0lmB+e23wB8IyKOBP4nyaxdSLJzXkiSx/9g4Ni6vyizEnZpdgHMBpETgKOBB9Mf910kidG283oCt+8C8yWNAEZGxE/T7dcD30tzWo2NiAUAEfEqQHq+X0Wa5yddsWwC8LP6vyyzbA4QZuUTcH1EXLbTRulvCo4rlb+mVLPRa3m3+/D/T2syNzGZle8e4HRJb4YdawEfRPL/6PT0mI8DP4uIjcD6vAVkPgn8NJL8/SslTUvPsZukPRr6KszK5F8oZmWKiEclfYFkZb1hJNk+zwN+DxwmaTGwkaSfApLUy3PSAPAMcHa6/ZPAv0q6Mj3Hxxr4MszK5myuZlWStDki9mx2OcxqzU1MZmaWyTUIMzPL5BqEmZllcoAwM7NMDhBmZpbJAcLMzDI5QJiZWab/D6qVQo8+DYJPAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting accuracy trajectory\n",
    "plt.plot(basic_cnn_model_results.history['acc'])\n",
    "plt.plot(basic_cnn_model_results.history['val_acc'])\n",
    "plt.title('Basic CNN model accuracy trajectory')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plotting loss trajectory\n",
    "plt.plot(basic_cnn_model_results.history['loss'],'o')\n",
    "plt.plot(basic_cnn_model_results.history['val_loss'],'o')\n",
    "plt.title('Basic CNN model loss trajectory')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of the basic CNN model: 0.73419863\n"
     ]
    }
   ],
   "source": [
    "## Testing the basic CNN model\n",
    "\n",
    "cnn_score = basic_cnn_model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test accuracy of the basic CNN model:',cnn_score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimized CNN+LSTM models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_75\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_295 (Conv2D)          (None, 250, 1, 100)       22100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_295 (MaxPoolin (None, 84, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_295 (Bat (None, 84, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_295 (Dropout)        (None, 84, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_296 (Conv2D)          (None, 84, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_296 (MaxPoolin (None, 28, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_296 (Bat (None, 28, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_296 (Dropout)        (None, 28, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_297 (Conv2D)          (None, 28, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_297 (MaxPoolin (None, 10, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_297 (Bat (None, 10, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_297 (Dropout)        (None, 10, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "flatten_75 (Flatten)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 100)               100100    \n",
      "_________________________________________________________________\n",
      "reshape_3 (Reshape)          (None, 100, 1)            0         \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 100, 100)          40800     \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 70)                47880     \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 4)                 284       \n",
      "=================================================================\n",
      "Total params: 412,564\n",
      "Trainable params: 411,964\n",
      "Non-trainable params: 600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Building the CNN model using sequential class\n",
    "hybrid_cnn_lstm_model = Sequential()\n",
    "\n",
    "# Conv. block 1\n",
    "hybrid_cnn_lstm_model.add(Conv2D(filters=100, kernel_size=(10,1), padding='same', activation='elu', input_shape=(250,1,22)))\n",
    "hybrid_cnn_lstm_model.add(MaxPooling2D(pool_size=(3,1), padding='same')) # Read the keras documentation\n",
    "hybrid_cnn_lstm_model.add(BatchNormalization())\n",
    "hybrid_cnn_lstm_model.add(Dropout(0.5))\n",
    "\n",
    "# Conv. block 2\n",
    "hybrid_cnn_lstm_model.add(Conv2D(filters=100, kernel_size=(10,1), padding='same', activation='elu'))\n",
    "hybrid_cnn_lstm_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "hybrid_cnn_lstm_model.add(BatchNormalization())\n",
    "hybrid_cnn_lstm_model.add(Dropout(0.5))\n",
    "\n",
    "# Conv. block 3\n",
    "hybrid_cnn_lstm_model.add(Conv2D(filters=100, kernel_size=(10,1), padding='same', activation='elu'))\n",
    "hybrid_cnn_lstm_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "hybrid_cnn_lstm_model.add(BatchNormalization())\n",
    "hybrid_cnn_lstm_model.add(Dropout(0.5))\n",
    "\n",
    "# Conv. block 4\n",
    "#hybrid_cnn_lstm_model.add(Conv2D(filters=100, kernel_size=(10,1), padding='same', activation='elu'))\n",
    "#hybrid_cnn_lstm_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "#hybrid_cnn_lstm_model.add(BatchNormalization())\n",
    "#hybrid_cnn_lstm_model.add(Dropout(0.5))\n",
    "\n",
    "# FC+LSTM layers\n",
    "hybrid_cnn_lstm_model.add(Flatten()) # Adding a flattening operation to the output of CNN block\n",
    "hybrid_cnn_lstm_model.add(Dense((100))) # FC layer with 100 units\n",
    "hybrid_cnn_lstm_model.add(Reshape((100,1))) # Reshape my output of FC layer so that it's compatible\n",
    "hybrid_cnn_lstm_model.add(LSTM(100, dropout=0.6, recurrent_dropout=0.1, input_shape=(100,1), return_sequences=True))\n",
    "\n",
    "hybrid_cnn_lstm_model.add(LSTM(70, dropout=0.6, recurrent_dropout=0.1, return_sequences=False))\n",
    "# Output layer with Softmax activation \n",
    "hybrid_cnn_lstm_model.add(Dense(4, activation='softmax')) # Output FC layer with softmax activation\n",
    "\n",
    "\n",
    "# Printing the model summary\n",
    "hybrid_cnn_lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "learning_rate = 2e-3\n",
    "epochs = 50\n",
    "hybrid_cnn_lstm_optimizer = optimizers.Adam(lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6960 samples, validate on 1500 samples\n",
      "Epoch 1/50\n",
      "6960/6960 [==============================] - 36s 5ms/sample - loss: 1.3733 - acc: 0.2784 - val_loss: 1.3287 - val_acc: 0.3673\n",
      "Epoch 2/50\n",
      "6960/6960 [==============================] - 24s 3ms/sample - loss: 1.3014 - acc: 0.3710 - val_loss: 1.2688 - val_acc: 0.4253\n",
      "Epoch 3/50\n",
      "6960/6960 [==============================] - 24s 4ms/sample - loss: 1.2286 - acc: 0.4274 - val_loss: 1.2039 - val_acc: 0.4653\n",
      "Epoch 4/50\n",
      "6960/6960 [==============================] - 28s 4ms/sample - loss: 1.1545 - acc: 0.4704 - val_loss: 1.0380 - val_acc: 0.5467\n",
      "Epoch 5/50\n",
      "6960/6960 [==============================] - 30s 4ms/sample - loss: 1.1111 - acc: 0.4927 - val_loss: 1.0549 - val_acc: 0.5247\n",
      "Epoch 6/50\n",
      "6960/6960 [==============================] - 26s 4ms/sample - loss: 1.0598 - acc: 0.5279 - val_loss: 0.9550 - val_acc: 0.5913\n",
      "Epoch 7/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 1.0302 - acc: 0.5395 - val_loss: 0.9327 - val_acc: 0.5927\n",
      "Epoch 8/50\n",
      "6960/6960 [==============================] - 26s 4ms/sample - loss: 1.0067 - acc: 0.5520 - val_loss: 0.8959 - val_acc: 0.6087\n",
      "Epoch 9/50\n",
      "6960/6960 [==============================] - 26s 4ms/sample - loss: 0.9692 - acc: 0.5800 - val_loss: 0.8205 - val_acc: 0.6707\n",
      "Epoch 10/50\n",
      "6960/6960 [==============================] - 25s 4ms/sample - loss: 0.9602 - acc: 0.5807 - val_loss: 0.7796 - val_acc: 0.7020\n",
      "Epoch 11/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 0.8870 - acc: 0.6195 - val_loss: 0.7040 - val_acc: 0.7413\n",
      "Epoch 12/50\n",
      "6960/6960 [==============================] - 29s 4ms/sample - loss: 0.8576 - acc: 0.6420 - val_loss: 0.6128 - val_acc: 0.7633\n",
      "Epoch 13/50\n",
      "6960/6960 [==============================] - 25s 4ms/sample - loss: 0.8120 - acc: 0.6611 - val_loss: 0.6150 - val_acc: 0.7740\n",
      "Epoch 14/50\n",
      "6960/6960 [==============================] - 25s 4ms/sample - loss: 0.7860 - acc: 0.6751 - val_loss: 0.5625 - val_acc: 0.8007\n",
      "Epoch 15/50\n",
      "6960/6960 [==============================] - 26s 4ms/sample - loss: 0.7587 - acc: 0.6832 - val_loss: 0.4975 - val_acc: 0.8473\n",
      "Epoch 16/50\n",
      "6960/6960 [==============================] - 26s 4ms/sample - loss: 0.7427 - acc: 0.6888 - val_loss: 0.5053 - val_acc: 0.8273\n",
      "Epoch 17/50\n",
      "6960/6960 [==============================] - 25s 4ms/sample - loss: 0.6775 - acc: 0.7178 - val_loss: 0.4229 - val_acc: 0.8500\n",
      "Epoch 18/50\n",
      "6960/6960 [==============================] - 24s 3ms/sample - loss: 0.6675 - acc: 0.7195 - val_loss: 0.3753 - val_acc: 0.8700\n",
      "Epoch 19/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 0.6343 - acc: 0.7336 - val_loss: 0.3342 - val_acc: 0.8960\n",
      "Epoch 20/50\n",
      "6960/6960 [==============================] - 24s 3ms/sample - loss: 0.6310 - acc: 0.7353 - val_loss: 0.3123 - val_acc: 0.8940\n",
      "Epoch 21/50\n",
      "6960/6960 [==============================] - 26s 4ms/sample - loss: 0.6053 - acc: 0.7555 - val_loss: 0.3464 - val_acc: 0.8680\n",
      "Epoch 22/50\n",
      "6960/6960 [==============================] - 25s 4ms/sample - loss: 0.5997 - acc: 0.7526 - val_loss: 0.2903 - val_acc: 0.9107\n",
      "Epoch 23/50\n",
      "6960/6960 [==============================] - 26s 4ms/sample - loss: 0.5690 - acc: 0.7614 - val_loss: 0.2570 - val_acc: 0.9220\n",
      "Epoch 24/50\n",
      "6960/6960 [==============================] - 26s 4ms/sample - loss: 0.5486 - acc: 0.7701 - val_loss: 0.2717 - val_acc: 0.9293\n",
      "Epoch 25/50\n",
      "6960/6960 [==============================] - 25s 4ms/sample - loss: 0.5188 - acc: 0.7802 - val_loss: 0.2342 - val_acc: 0.9280\n",
      "Epoch 26/50\n",
      "6960/6960 [==============================] - 26s 4ms/sample - loss: 0.5083 - acc: 0.7833 - val_loss: 0.2038 - val_acc: 0.9393\n",
      "Epoch 27/50\n",
      "6960/6960 [==============================] - 28s 4ms/sample - loss: 0.5104 - acc: 0.7846 - val_loss: 0.2379 - val_acc: 0.9340\n",
      "Epoch 28/50\n",
      "6960/6960 [==============================] - 25s 4ms/sample - loss: 0.4761 - acc: 0.7973 - val_loss: 0.1632 - val_acc: 0.9533\n",
      "Epoch 29/50\n",
      "6960/6960 [==============================] - 25s 4ms/sample - loss: 0.4828 - acc: 0.7955 - val_loss: 0.2289 - val_acc: 0.9180\n",
      "Epoch 30/50\n",
      "6960/6960 [==============================] - 25s 4ms/sample - loss: 0.4642 - acc: 0.7999 - val_loss: 0.1975 - val_acc: 0.9540\n",
      "Epoch 31/50\n",
      "6960/6960 [==============================] - 24s 3ms/sample - loss: 0.4579 - acc: 0.8070 - val_loss: 0.1688 - val_acc: 0.9653\n",
      "Epoch 32/50\n",
      "6960/6960 [==============================] - 25s 4ms/sample - loss: 0.4476 - acc: 0.8116 - val_loss: 0.1633 - val_acc: 0.9473\n",
      "Epoch 33/50\n",
      "6960/6960 [==============================] - 24s 3ms/sample - loss: 0.4767 - acc: 0.7976 - val_loss: 0.1406 - val_acc: 0.9653\n",
      "Epoch 34/50\n",
      "6960/6960 [==============================] - 25s 4ms/sample - loss: 0.4382 - acc: 0.8073 - val_loss: 0.1254 - val_acc: 0.9687\n",
      "Epoch 35/50\n",
      "6960/6960 [==============================] - 26s 4ms/sample - loss: 0.4397 - acc: 0.8131 - val_loss: 0.1390 - val_acc: 0.9627\n",
      "Epoch 36/50\n",
      "6960/6960 [==============================] - 28s 4ms/sample - loss: 0.4236 - acc: 0.8231 - val_loss: 0.1026 - val_acc: 0.9707\n",
      "Epoch 37/50\n",
      "6960/6960 [==============================] - 24s 3ms/sample - loss: 0.4162 - acc: 0.8172 - val_loss: 0.1054 - val_acc: 0.9700\n",
      "Epoch 38/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 0.4161 - acc: 0.8224 - val_loss: 0.1160 - val_acc: 0.9767\n",
      "Epoch 39/50\n",
      "6960/6960 [==============================] - 21s 3ms/sample - loss: 0.3996 - acc: 0.8247 - val_loss: 0.0949 - val_acc: 0.9780\n",
      "Epoch 40/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 0.3828 - acc: 0.8280 - val_loss: 0.0932 - val_acc: 0.9767\n",
      "Epoch 41/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 0.3834 - acc: 0.8269 - val_loss: 0.0870 - val_acc: 0.9860\n",
      "Epoch 42/50\n",
      "6960/6960 [==============================] - 25s 4ms/sample - loss: 0.3753 - acc: 0.8341 - val_loss: 0.0767 - val_acc: 0.9807\n",
      "Epoch 43/50\n",
      "6960/6960 [==============================] - 25s 4ms/sample - loss: 0.3874 - acc: 0.8289 - val_loss: 0.0877 - val_acc: 0.9740\n",
      "Epoch 44/50\n",
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 0.3772 - acc: 0.8296 - val_loss: 0.0804 - val_acc: 0.9833\n",
      "Epoch 45/50\n",
      "6960/6960 [==============================] - 24s 3ms/sample - loss: 0.3689 - acc: 0.8358 - val_loss: 0.0703 - val_acc: 0.9833\n",
      "Epoch 46/50\n",
      "6960/6960 [==============================] - 25s 4ms/sample - loss: 0.3860 - acc: 0.8249 - val_loss: 0.0857 - val_acc: 0.9767\n",
      "Epoch 47/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 0.3636 - acc: 0.8395 - val_loss: 0.0679 - val_acc: 0.9867\n",
      "Epoch 48/50\n",
      "6960/6960 [==============================] - 24s 4ms/sample - loss: 0.3554 - acc: 0.8427 - val_loss: 0.0779 - val_acc: 0.9827\n",
      "Epoch 49/50\n",
      "6960/6960 [==============================] - 24s 3ms/sample - loss: 0.3525 - acc: 0.8431 - val_loss: 0.0726 - val_acc: 0.9840\n",
      "Epoch 50/50\n",
      "6960/6960 [==============================] - 26s 4ms/sample - loss: 0.3581 - acc: 0.8374 - val_loss: 0.0638 - val_acc: 0.9893\n"
     ]
    }
   ],
   "source": [
    "hybrid_cnn_lstm_model.compile(loss='categorical_crossentropy',\n",
    "                 optimizer=hybrid_cnn_lstm_optimizer,\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "# Training and validating the model\n",
    "hybrid_cnn_lstm_model_results = hybrid_cnn_lstm_model.fit(x_train,\n",
    "             y_train,\n",
    "             batch_size=200,\n",
    "             epochs=epochs,\n",
    "             validation_data=(x_valid, y_valid), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting accuracy trajectory\n",
    "plt.plot(hybrid_cnn_lstm_model_results.history['acc'])\n",
    "plt.plot(hybrid_cnn_lstm_model_results.history['val_acc'])\n",
    "plt.title('Hybrid CNN-LSTM model accuracy trajectory')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plotting loss trajectory\n",
    "plt.plot(hybrid_cnn_lstm_model_results.history['loss'],'o')\n",
    "plt.plot(hybrid_cnn_lstm_model_results.history['val_loss'],'o')\n",
    "plt.title('Hybrid CNN-LSTM model loss trajectory')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of the hybrid CNN-LSTM model: 0.6839729\n"
     ]
    }
   ],
   "source": [
    "## Testing the hybrid CNN-LSTM model\n",
    "\n",
    "hybrid_cnn_lstm_score = hybrid_cnn_lstm_model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test accuracy of the hybrid CNN-LSTM model:',hybrid_cnn_lstm_score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function of Time - Optimized CNN (with preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model(time_period=1000):   \n",
    "    time_period = min(time_period, 250)\n",
    "    \n",
    "    # Building the CNN model using sequential class\n",
    "    basic_cnn_model = Sequential()\n",
    "    \n",
    "    # Conv. block 1\n",
    "    basic_cnn_model.add(Conv2D(filters=100, kernel_size=(10,1), padding='same', activation='elu', input_shape=(time_period,1,22)))\n",
    "    basic_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same')) # Read the keras documentation\n",
    "    basic_cnn_model.add(BatchNormalization())\n",
    "    basic_cnn_model.add(Dropout(0.5))\n",
    "\n",
    "    # Conv. block 2\n",
    "    basic_cnn_model.add(Conv2D(filters=100, kernel_size=(10,1), padding='same', activation='elu'))\n",
    "    basic_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "    basic_cnn_model.add(BatchNormalization())\n",
    "    basic_cnn_model.add(Dropout(0.5))\n",
    "\n",
    "    # Conv. block 3\n",
    "    basic_cnn_model.add(Conv2D(filters=100, kernel_size=(10,1), padding='same', activation='elu'))\n",
    "    basic_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "    basic_cnn_model.add(BatchNormalization())\n",
    "    basic_cnn_model.add(Dropout(0.5))\n",
    "\n",
    "    # Conv. block 4\n",
    "    basic_cnn_model.add(Conv2D(filters=100, kernel_size=(10,1), padding='same', activation='elu'))\n",
    "    basic_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "    basic_cnn_model.add(BatchNormalization())\n",
    "    basic_cnn_model.add(Dropout(0.5))\n",
    "\n",
    "    # Output layer with Softmax activation\n",
    "    basic_cnn_model.add(Flatten()) # Flattens the input\n",
    "    basic_cnn_model.add(Dense(4, activation='softmax')) # Output FC layer with softmax activation\n",
    "    \n",
    "    cnn_optimizer = optimizers.Adam(learning_rate)\n",
    "    \n",
    "    basic_cnn_model.compile(loss='categorical_crossentropy',\n",
    "                     optimizer=cnn_optimizer,\n",
    "                     metrics=['accuracy'])\n",
    "\n",
    "    # Printing the model summary\n",
    "    basic_cnn_model.summary()\n",
    "    \n",
    "    return basic_cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "learning_rate = 1.5e-3\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_data(time_period=1000):\n",
    "    # different period of time\n",
    "    x_train_time = x_train[:,:time_period,:,:]\n",
    "    y_train_time = y_train\n",
    "    x_valid_time = x_valid[:,:time_period,:,:]\n",
    "    y_valid_time = y_valid\n",
    "    x_test_time = x_test[:,:time_period,:,:]\n",
    "    y_test_time = y_test\n",
    "    \n",
    "    \n",
    "    model = cnn_model(time_period)\n",
    "\n",
    "    # Training and validating the model\n",
    "    cnn_model_results = model.fit(x_train_time,\n",
    "                 y_train_time,\n",
    "                 batch_size=200,\n",
    "                 epochs=epochs,\n",
    "                 validation_data=(x_valid_time, y_valid_time), verbose=True)\n",
    "    \n",
    "    train_score = model.evaluate(x_train_time, y_train_time)\n",
    "    \n",
    "    test_score = model.evaluate(x_test_time, y_test_time)\n",
    "\n",
    "    print('train {:s}: {:.3f}%'.format(model.metrics_names[1], train_score[1]*100))\n",
    "    print('test {:s}: {:.3f}%'.format(model.metrics_names[1], test_score[1]*100))\n",
    "    #print(model.summary())\n",
    "    \n",
    "    return train_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================25===================\n",
      "Model: \"sequential_64\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_252 (Conv2D)          (None, 25, 1, 100)        22100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_252 (MaxPoolin (None, 9, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_252 (Bat (None, 9, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_252 (Dropout)        (None, 9, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_253 (Conv2D)          (None, 9, 1, 100)         100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_253 (MaxPoolin (None, 3, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_253 (Bat (None, 3, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_253 (Dropout)        (None, 3, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_254 (Conv2D)          (None, 3, 1, 100)         100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_254 (MaxPoolin (None, 1, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_254 (Bat (None, 1, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_254 (Dropout)        (None, 1, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_255 (Conv2D)          (None, 1, 1, 100)         100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_255 (MaxPoolin (None, 1, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_255 (Bat (None, 1, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_255 (Dropout)        (None, 1, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_64 (Flatten)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 4)                 404       \n",
      "=================================================================\n",
      "Total params: 324,404\n",
      "Trainable params: 323,604\n",
      "Non-trainable params: 800\n",
      "_________________________________________________________________\n",
      "Train on 6960 samples, validate on 1500 samples\n",
      "Epoch 1/50\n",
      "6960/6960 [==============================] - 9s 1ms/sample - loss: 1.9951 - acc: 0.2741 - val_loss: 1.4723 - val_acc: 0.2787\n",
      "Epoch 2/50\n",
      "6960/6960 [==============================] - 1s 127us/sample - loss: 1.7384 - acc: 0.2843 - val_loss: 1.4377 - val_acc: 0.2840\n",
      "Epoch 3/50\n",
      "6960/6960 [==============================] - 1s 136us/sample - loss: 1.6085 - acc: 0.2835 - val_loss: 1.3614 - val_acc: 0.3500\n",
      "Epoch 4/50\n",
      "6960/6960 [==============================] - 1s 132us/sample - loss: 1.5156 - acc: 0.3079 - val_loss: 1.3393 - val_acc: 0.3520\n",
      "Epoch 5/50\n",
      "6960/6960 [==============================] - 1s 127us/sample - loss: 1.4417 - acc: 0.3205 - val_loss: 1.3098 - val_acc: 0.3687\n",
      "Epoch 6/50\n",
      "6960/6960 [==============================] - 1s 126us/sample - loss: 1.3966 - acc: 0.3249 - val_loss: 1.2986 - val_acc: 0.3773\n",
      "Epoch 7/50\n",
      "6960/6960 [==============================] - 1s 123us/sample - loss: 1.3576 - acc: 0.3445 - val_loss: 1.2806 - val_acc: 0.4080\n",
      "Epoch 8/50\n",
      "6960/6960 [==============================] - 1s 123us/sample - loss: 1.3247 - acc: 0.3694 - val_loss: 1.2658 - val_acc: 0.3987\n",
      "Epoch 9/50\n",
      "6960/6960 [==============================] - 1s 132us/sample - loss: 1.2966 - acc: 0.3818 - val_loss: 1.2579 - val_acc: 0.4033\n",
      "Epoch 10/50\n",
      "6960/6960 [==============================] - 1s 122us/sample - loss: 1.2834 - acc: 0.4004 - val_loss: 1.2420 - val_acc: 0.4033\n",
      "Epoch 11/50\n",
      "6960/6960 [==============================] - 1s 124us/sample - loss: 1.2579 - acc: 0.4170 - val_loss: 1.2389 - val_acc: 0.4153\n",
      "Epoch 12/50\n",
      "6960/6960 [==============================] - 1s 121us/sample - loss: 1.2508 - acc: 0.4270 - val_loss: 1.2149 - val_acc: 0.4247\n",
      "Epoch 13/50\n",
      "6960/6960 [==============================] - 1s 125us/sample - loss: 1.2296 - acc: 0.4348 - val_loss: 1.1966 - val_acc: 0.4447\n",
      "Epoch 14/50\n",
      "6960/6960 [==============================] - 1s 122us/sample - loss: 1.2089 - acc: 0.4504 - val_loss: 1.1898 - val_acc: 0.4547\n",
      "Epoch 15/50\n",
      "6960/6960 [==============================] - 1s 123us/sample - loss: 1.2004 - acc: 0.4580 - val_loss: 1.1636 - val_acc: 0.4633\n",
      "Epoch 16/50\n",
      "6960/6960 [==============================] - 1s 123us/sample - loss: 1.1768 - acc: 0.4716 - val_loss: 1.1413 - val_acc: 0.4687\n",
      "Epoch 17/50\n",
      "6960/6960 [==============================] - 1s 122us/sample - loss: 1.1713 - acc: 0.4700 - val_loss: 1.1248 - val_acc: 0.4833\n",
      "Epoch 18/50\n",
      "6960/6960 [==============================] - 1s 125us/sample - loss: 1.1516 - acc: 0.4921 - val_loss: 1.0983 - val_acc: 0.5073\n",
      "Epoch 19/50\n",
      "6960/6960 [==============================] - 1s 125us/sample - loss: 1.1368 - acc: 0.4977 - val_loss: 1.0971 - val_acc: 0.5053\n",
      "Epoch 20/50\n",
      "6960/6960 [==============================] - 1s 122us/sample - loss: 1.1230 - acc: 0.5066 - val_loss: 1.0517 - val_acc: 0.5527\n",
      "Epoch 21/50\n",
      "6960/6960 [==============================] - 1s 126us/sample - loss: 1.1046 - acc: 0.5270 - val_loss: 1.0501 - val_acc: 0.5553\n",
      "Epoch 22/50\n",
      "6960/6960 [==============================] - 1s 137us/sample - loss: 1.0839 - acc: 0.5361 - val_loss: 1.0155 - val_acc: 0.5747\n",
      "Epoch 23/50\n",
      "6960/6960 [==============================] - 1s 137us/sample - loss: 1.0743 - acc: 0.5351 - val_loss: 0.9843 - val_acc: 0.6047\n",
      "Epoch 24/50\n",
      "6960/6960 [==============================] - 1s 132us/sample - loss: 1.0608 - acc: 0.5464 - val_loss: 0.9920 - val_acc: 0.5760\n",
      "Epoch 25/50\n",
      "6960/6960 [==============================] - 1s 124us/sample - loss: 1.0423 - acc: 0.5616 - val_loss: 0.9615 - val_acc: 0.5947\n",
      "Epoch 26/50\n",
      "6960/6960 [==============================] - 1s 139us/sample - loss: 1.0246 - acc: 0.5659 - val_loss: 0.9627 - val_acc: 0.6033\n",
      "Epoch 27/50\n",
      "6960/6960 [==============================] - 1s 132us/sample - loss: 1.0157 - acc: 0.5714 - val_loss: 0.8917 - val_acc: 0.6420\n",
      "Epoch 28/50\n",
      "6960/6960 [==============================] - 1s 130us/sample - loss: 1.0017 - acc: 0.5832 - val_loss: 0.9058 - val_acc: 0.6200\n",
      "Epoch 29/50\n",
      "6960/6960 [==============================] - 1s 130us/sample - loss: 0.9731 - acc: 0.5943 - val_loss: 0.8781 - val_acc: 0.6493\n",
      "Epoch 30/50\n",
      "6960/6960 [==============================] - 1s 131us/sample - loss: 0.9621 - acc: 0.5984 - val_loss: 0.8794 - val_acc: 0.6393\n",
      "Epoch 31/50\n",
      "6960/6960 [==============================] - 1s 132us/sample - loss: 0.9638 - acc: 0.6039 - val_loss: 0.8313 - val_acc: 0.6813\n",
      "Epoch 32/50\n",
      "6960/6960 [==============================] - 1s 128us/sample - loss: 0.9496 - acc: 0.6073 - val_loss: 0.8305 - val_acc: 0.6673\n",
      "Epoch 33/50\n",
      "6960/6960 [==============================] - 1s 133us/sample - loss: 0.9323 - acc: 0.6046 - val_loss: 0.7959 - val_acc: 0.6987\n",
      "Epoch 34/50\n",
      "6960/6960 [==============================] - 1s 132us/sample - loss: 0.8939 - acc: 0.6369 - val_loss: 0.7838 - val_acc: 0.6920\n",
      "Epoch 35/50\n",
      "6960/6960 [==============================] - 1s 130us/sample - loss: 0.9094 - acc: 0.6264 - val_loss: 0.7610 - val_acc: 0.7020\n",
      "Epoch 36/50\n",
      "6960/6960 [==============================] - 1s 124us/sample - loss: 0.8779 - acc: 0.6471 - val_loss: 0.7452 - val_acc: 0.7187\n",
      "Epoch 37/50\n",
      "6960/6960 [==============================] - 1s 126us/sample - loss: 0.8573 - acc: 0.6523 - val_loss: 0.7661 - val_acc: 0.7053\n",
      "Epoch 38/50\n",
      "6960/6960 [==============================] - 1s 172us/sample - loss: 0.8456 - acc: 0.6555 - val_loss: 0.6919 - val_acc: 0.7387\n",
      "Epoch 39/50\n",
      "6960/6960 [==============================] - 1s 148us/sample - loss: 0.8412 - acc: 0.6625 - val_loss: 0.7064 - val_acc: 0.7340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50\n",
      "6960/6960 [==============================] - 1s 149us/sample - loss: 0.8210 - acc: 0.6599 - val_loss: 0.6925 - val_acc: 0.7327\n",
      "Epoch 41/50\n",
      "6960/6960 [==============================] - 1s 131us/sample - loss: 0.8139 - acc: 0.6789 - val_loss: 0.6610 - val_acc: 0.7593\n",
      "Epoch 42/50\n",
      "6960/6960 [==============================] - 1s 124us/sample - loss: 0.8041 - acc: 0.6776 - val_loss: 0.6400 - val_acc: 0.7693\n",
      "Epoch 43/50\n",
      "6960/6960 [==============================] - 1s 127us/sample - loss: 0.7953 - acc: 0.6779 - val_loss: 0.6201 - val_acc: 0.7720\n",
      "Epoch 44/50\n",
      "6960/6960 [==============================] - 1s 133us/sample - loss: 0.7704 - acc: 0.6944 - val_loss: 0.6044 - val_acc: 0.7827\n",
      "Epoch 45/50\n",
      "6960/6960 [==============================] - 1s 134us/sample - loss: 0.7951 - acc: 0.6848 - val_loss: 0.6218 - val_acc: 0.7693\n",
      "Epoch 46/50\n",
      "6960/6960 [==============================] - 1s 130us/sample - loss: 0.7616 - acc: 0.6968 - val_loss: 0.5825 - val_acc: 0.7907\n",
      "Epoch 47/50\n",
      "6960/6960 [==============================] - 1s 126us/sample - loss: 0.7562 - acc: 0.6970 - val_loss: 0.5725 - val_acc: 0.7913\n",
      "Epoch 48/50\n",
      "6960/6960 [==============================] - 1s 133us/sample - loss: 0.7382 - acc: 0.7111 - val_loss: 0.5950 - val_acc: 0.7733\n",
      "Epoch 49/50\n",
      "6960/6960 [==============================] - ETA: 0s - loss: 0.7232 - acc: 0.714 - 1s 126us/sample - loss: 0.7238 - acc: 0.7145 - val_loss: 0.5456 - val_acc: 0.8067\n",
      "Epoch 50/50\n",
      "6960/6960 [==============================] - 1s 128us/sample - loss: 0.7084 - acc: 0.7175 - val_loss: 0.5407 - val_acc: 0.8007\n",
      "6960/6960 [==============================] - 2s 328us/sample - loss: 0.2962 - acc: 0.9230\n",
      "1772/1772 [==============================] - 1s 333us/sample - loss: 1.7202 - acc: 0.3883\n",
      "train acc: 92.299%\n",
      "test acc: 38.826%\n",
      "=================50===================\n",
      "Model: \"sequential_65\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_256 (Conv2D)          (None, 50, 1, 100)        22100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_256 (MaxPoolin (None, 17, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_256 (Bat (None, 17, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_256 (Dropout)        (None, 17, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_257 (Conv2D)          (None, 17, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_257 (MaxPoolin (None, 6, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_257 (Bat (None, 6, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_257 (Dropout)        (None, 6, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_258 (Conv2D)          (None, 6, 1, 100)         100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_258 (MaxPoolin (None, 2, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_258 (Bat (None, 2, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_258 (Dropout)        (None, 2, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_259 (Conv2D)          (None, 2, 1, 100)         100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_259 (MaxPoolin (None, 1, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_259 (Bat (None, 1, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_259 (Dropout)        (None, 1, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_65 (Flatten)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 4)                 404       \n",
      "=================================================================\n",
      "Total params: 324,404\n",
      "Trainable params: 323,604\n",
      "Non-trainable params: 800\n",
      "_________________________________________________________________\n",
      "Train on 6960 samples, validate on 1500 samples\n",
      "Epoch 1/50\n",
      "6960/6960 [==============================] - 9s 1ms/sample - loss: 2.0630 - acc: 0.2694 - val_loss: 2.1993 - val_acc: 0.2840\n",
      "Epoch 2/50\n",
      "6960/6960 [==============================] - 1s 136us/sample - loss: 1.7062 - acc: 0.2884 - val_loss: 1.6280 - val_acc: 0.2933\n",
      "Epoch 3/50\n",
      "6960/6960 [==============================] - 1s 130us/sample - loss: 1.5752 - acc: 0.2943 - val_loss: 1.3645 - val_acc: 0.3633\n",
      "Epoch 4/50\n",
      "6960/6960 [==============================] - 1s 130us/sample - loss: 1.4740 - acc: 0.3276 - val_loss: 1.2769 - val_acc: 0.4133\n",
      "Epoch 5/50\n",
      "6960/6960 [==============================] - 1s 137us/sample - loss: 1.4010 - acc: 0.3510 - val_loss: 1.2511 - val_acc: 0.4147\n",
      "Epoch 6/50\n",
      "6960/6960 [==============================] - 1s 131us/sample - loss: 1.3494 - acc: 0.3777 - val_loss: 1.2130 - val_acc: 0.4527\n",
      "Epoch 7/50\n",
      "6960/6960 [==============================] - 1s 136us/sample - loss: 1.3174 - acc: 0.3999 - val_loss: 1.1913 - val_acc: 0.4807\n",
      "Epoch 8/50\n",
      "6960/6960 [==============================] - 1s 133us/sample - loss: 1.2734 - acc: 0.4220 - val_loss: 1.1728 - val_acc: 0.4827\n",
      "Epoch 9/50\n",
      "6960/6960 [==============================] - 1s 134us/sample - loss: 1.2416 - acc: 0.4415 - val_loss: 1.1487 - val_acc: 0.5180\n",
      "Epoch 10/50\n",
      "6960/6960 [==============================] - 1s 131us/sample - loss: 1.2103 - acc: 0.4612 - val_loss: 1.1436 - val_acc: 0.4953\n",
      "Epoch 11/50\n",
      "6960/6960 [==============================] - 1s 130us/sample - loss: 1.1840 - acc: 0.4703 - val_loss: 1.1181 - val_acc: 0.5227\n",
      "Epoch 12/50\n",
      "6960/6960 [==============================] - 1s 137us/sample - loss: 1.1565 - acc: 0.4954 - val_loss: 1.0741 - val_acc: 0.5360\n",
      "Epoch 13/50\n",
      "6960/6960 [==============================] - 1s 131us/sample - loss: 1.1311 - acc: 0.5082 - val_loss: 1.0554 - val_acc: 0.5473\n",
      "Epoch 14/50\n",
      "6960/6960 [==============================] - 1s 142us/sample - loss: 1.0923 - acc: 0.5300 - val_loss: 1.0375 - val_acc: 0.5567\n",
      "Epoch 15/50\n",
      "6960/6960 [==============================] - 1s 136us/sample - loss: 1.0921 - acc: 0.5295 - val_loss: 0.9971 - val_acc: 0.5580\n",
      "Epoch 16/50\n",
      "6960/6960 [==============================] - 1s 136us/sample - loss: 1.0533 - acc: 0.5494 - val_loss: 0.9513 - val_acc: 0.5940\n",
      "Epoch 17/50\n",
      "6960/6960 [==============================] - 1s 134us/sample - loss: 1.0315 - acc: 0.5628 - val_loss: 0.8992 - val_acc: 0.6213\n",
      "Epoch 18/50\n",
      "6960/6960 [==============================] - 1s 133us/sample - loss: 1.0086 - acc: 0.5717 - val_loss: 0.8721 - val_acc: 0.6427\n",
      "Epoch 19/50\n",
      "6960/6960 [==============================] - 1s 137us/sample - loss: 0.9753 - acc: 0.5881 - val_loss: 0.8271 - val_acc: 0.6613\n",
      "Epoch 20/50\n",
      "6960/6960 [==============================] - 1s 132us/sample - loss: 0.9426 - acc: 0.6046 - val_loss: 0.8131 - val_acc: 0.6567\n",
      "Epoch 21/50\n",
      "6960/6960 [==============================] - 1s 134us/sample - loss: 0.9264 - acc: 0.6184 - val_loss: 0.7912 - val_acc: 0.6647\n",
      "Epoch 22/50\n",
      "6960/6960 [==============================] - 1s 139us/sample - loss: 0.9274 - acc: 0.6170 - val_loss: 0.7514 - val_acc: 0.7067\n",
      "Epoch 23/50\n",
      "6960/6960 [==============================] - 1s 134us/sample - loss: 0.8826 - acc: 0.6323 - val_loss: 0.7383 - val_acc: 0.7107\n",
      "Epoch 24/50\n",
      "6960/6960 [==============================] - 1s 138us/sample - loss: 0.8671 - acc: 0.6478 - val_loss: 0.7276 - val_acc: 0.6980\n",
      "Epoch 25/50\n",
      "6960/6960 [==============================] - 1s 134us/sample - loss: 0.8340 - acc: 0.6588 - val_loss: 0.6591 - val_acc: 0.7433\n",
      "Epoch 26/50\n",
      "6960/6960 [==============================] - 1s 131us/sample - loss: 0.7978 - acc: 0.6772 - val_loss: 0.6142 - val_acc: 0.7653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50\n",
      "6960/6960 [==============================] - 1s 133us/sample - loss: 0.8044 - acc: 0.6790 - val_loss: 0.6277 - val_acc: 0.7553\n",
      "Epoch 28/50\n",
      "6960/6960 [==============================] - 1s 133us/sample - loss: 0.7744 - acc: 0.6912 - val_loss: 0.5979 - val_acc: 0.7620\n",
      "Epoch 29/50\n",
      "6960/6960 [==============================] - 1s 133us/sample - loss: 0.7560 - acc: 0.7009 - val_loss: 0.5523 - val_acc: 0.8053\n",
      "Epoch 30/50\n",
      "6960/6960 [==============================] - 1s 133us/sample - loss: 0.7480 - acc: 0.7000 - val_loss: 0.5790 - val_acc: 0.7767\n",
      "Epoch 31/50\n",
      "6960/6960 [==============================] - 1s 138us/sample - loss: 0.7232 - acc: 0.7151 - val_loss: 0.5153 - val_acc: 0.8093\n",
      "Epoch 32/50\n",
      "6960/6960 [==============================] - 1s 137us/sample - loss: 0.7053 - acc: 0.7191 - val_loss: 0.4995 - val_acc: 0.8267\n",
      "Epoch 33/50\n",
      "6960/6960 [==============================] - 1s 134us/sample - loss: 0.6753 - acc: 0.7343 - val_loss: 0.4803 - val_acc: 0.8153\n",
      "Epoch 34/50\n",
      "6960/6960 [==============================] - 1s 137us/sample - loss: 0.6504 - acc: 0.7445 - val_loss: 0.4869 - val_acc: 0.8113\n",
      "Epoch 35/50\n",
      "6960/6960 [==============================] - 1s 152us/sample - loss: 0.6556 - acc: 0.7389 - val_loss: 0.4306 - val_acc: 0.8500\n",
      "Epoch 36/50\n",
      "6960/6960 [==============================] - 1s 133us/sample - loss: 0.6389 - acc: 0.7496 - val_loss: 0.4226 - val_acc: 0.8453\n",
      "Epoch 37/50\n",
      "6960/6960 [==============================] - 1s 134us/sample - loss: 0.6239 - acc: 0.7481 - val_loss: 0.3892 - val_acc: 0.8693\n",
      "Epoch 38/50\n",
      "6960/6960 [==============================] - 1s 135us/sample - loss: 0.5924 - acc: 0.7675 - val_loss: 0.3708 - val_acc: 0.8687\n",
      "Epoch 39/50\n",
      "6960/6960 [==============================] - 1s 134us/sample - loss: 0.5964 - acc: 0.7624 - val_loss: 0.3660 - val_acc: 0.8693\n",
      "Epoch 40/50\n",
      "6960/6960 [==============================] - 1s 132us/sample - loss: 0.5904 - acc: 0.7684 - val_loss: 0.3587 - val_acc: 0.8780\n",
      "Epoch 41/50\n",
      "6960/6960 [==============================] - 1s 131us/sample - loss: 0.5749 - acc: 0.7753 - val_loss: 0.3261 - val_acc: 0.9027\n",
      "Epoch 42/50\n",
      "6960/6960 [==============================] - 1s 134us/sample - loss: 0.5594 - acc: 0.7882 - val_loss: 0.3261 - val_acc: 0.8880\n",
      "Epoch 43/50\n",
      "6960/6960 [==============================] - 1s 136us/sample - loss: 0.5466 - acc: 0.7849 - val_loss: 0.2994 - val_acc: 0.8987\n",
      "Epoch 44/50\n",
      "6960/6960 [==============================] - 1s 131us/sample - loss: 0.5212 - acc: 0.7999 - val_loss: 0.3110 - val_acc: 0.8953\n",
      "Epoch 45/50\n",
      "6960/6960 [==============================] - 1s 137us/sample - loss: 0.5277 - acc: 0.8033 - val_loss: 0.2760 - val_acc: 0.9100\n",
      "Epoch 46/50\n",
      "6960/6960 [==============================] - 1s 135us/sample - loss: 0.5330 - acc: 0.7961 - val_loss: 0.2724 - val_acc: 0.9080\n",
      "Epoch 47/50\n",
      "6960/6960 [==============================] - 1s 148us/sample - loss: 0.5137 - acc: 0.8047 - val_loss: 0.2625 - val_acc: 0.9073\n",
      "Epoch 48/50\n",
      "6960/6960 [==============================] - 1s 144us/sample - loss: 0.4938 - acc: 0.8111 - val_loss: 0.2452 - val_acc: 0.9293\n",
      "Epoch 49/50\n",
      "6960/6960 [==============================] - 1s 134us/sample - loss: 0.4984 - acc: 0.8069 - val_loss: 0.2570 - val_acc: 0.9133\n",
      "Epoch 50/50\n",
      "6960/6960 [==============================] - 1s 133us/sample - loss: 0.4921 - acc: 0.8095 - val_loss: 0.2358 - val_acc: 0.9247\n",
      "6960/6960 [==============================] - 3s 373us/sample - loss: 0.0989 - acc: 0.9836\n",
      "1772/1772 [==============================] - 1s 380us/sample - loss: 1.4016 - acc: 0.5248\n",
      "train acc: 98.362%\n",
      "test acc: 52.483%\n",
      "=================75===================\n",
      "Model: \"sequential_66\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_260 (Conv2D)          (None, 75, 1, 100)        22100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_260 (MaxPoolin (None, 25, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_260 (Bat (None, 25, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_260 (Dropout)        (None, 25, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_261 (Conv2D)          (None, 25, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_261 (MaxPoolin (None, 9, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_261 (Bat (None, 9, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_261 (Dropout)        (None, 9, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_262 (Conv2D)          (None, 9, 1, 100)         100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_262 (MaxPoolin (None, 3, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_262 (Bat (None, 3, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_262 (Dropout)        (None, 3, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_263 (Conv2D)          (None, 3, 1, 100)         100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_263 (MaxPoolin (None, 1, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_263 (Bat (None, 1, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_263 (Dropout)        (None, 1, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_66 (Flatten)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 4)                 404       \n",
      "=================================================================\n",
      "Total params: 324,404\n",
      "Trainable params: 323,604\n",
      "Non-trainable params: 800\n",
      "_________________________________________________________________\n",
      "Train on 6960 samples, validate on 1500 samples\n",
      "Epoch 1/50\n",
      "6960/6960 [==============================] - 9s 1ms/sample - loss: 1.9957 - acc: 0.2774 - val_loss: 3.6306 - val_acc: 0.2500\n",
      "Epoch 2/50\n",
      "6960/6960 [==============================] - 1s 147us/sample - loss: 1.7048 - acc: 0.2892 - val_loss: 1.6942 - val_acc: 0.2753\n",
      "Epoch 3/50\n",
      "6960/6960 [==============================] - 1s 140us/sample - loss: 1.5644 - acc: 0.3079 - val_loss: 1.4696 - val_acc: 0.3213\n",
      "Epoch 4/50\n",
      "6960/6960 [==============================] - 1s 144us/sample - loss: 1.4617 - acc: 0.3276 - val_loss: 1.2817 - val_acc: 0.4060\n",
      "Epoch 5/50\n",
      "6960/6960 [==============================] - 1s 154us/sample - loss: 1.3975 - acc: 0.3524 - val_loss: 1.2248 - val_acc: 0.4533\n",
      "Epoch 6/50\n",
      "6960/6960 [==============================] - 1s 150us/sample - loss: 1.3294 - acc: 0.3807 - val_loss: 1.1979 - val_acc: 0.4747\n",
      "Epoch 7/50\n",
      "6960/6960 [==============================] - 1s 144us/sample - loss: 1.3002 - acc: 0.4009 - val_loss: 1.1725 - val_acc: 0.5200\n",
      "Epoch 8/50\n",
      "6960/6960 [==============================] - 1s 144us/sample - loss: 1.2497 - acc: 0.4300 - val_loss: 1.1366 - val_acc: 0.5133\n",
      "Epoch 9/50\n",
      "6960/6960 [==============================] - 1s 144us/sample - loss: 1.2197 - acc: 0.4506 - val_loss: 1.1205 - val_acc: 0.5240\n",
      "Epoch 10/50\n",
      "6960/6960 [==============================] - 1s 141us/sample - loss: 1.1885 - acc: 0.4726 - val_loss: 1.1039 - val_acc: 0.5267\n",
      "Epoch 11/50\n",
      "6960/6960 [==============================] - 1s 144us/sample - loss: 1.1522 - acc: 0.4943 - val_loss: 1.0429 - val_acc: 0.5647\n",
      "Epoch 12/50\n",
      "6960/6960 [==============================] - 1s 142us/sample - loss: 1.1163 - acc: 0.5195 - val_loss: 1.0038 - val_acc: 0.5973\n",
      "Epoch 13/50\n",
      "6960/6960 [==============================] - 1s 143us/sample - loss: 1.0933 - acc: 0.5287 - val_loss: 0.9777 - val_acc: 0.5880\n",
      "Epoch 14/50\n",
      "6960/6960 [==============================] - 1s 155us/sample - loss: 1.0757 - acc: 0.5444 - val_loss: 0.9485 - val_acc: 0.6200\n",
      "Epoch 15/50\n",
      "6960/6960 [==============================] - 1s 142us/sample - loss: 1.0403 - acc: 0.5634 - val_loss: 0.9157 - val_acc: 0.6253\n",
      "Epoch 16/50\n",
      "6960/6960 [==============================] - 1s 141us/sample - loss: 1.0031 - acc: 0.5773 - val_loss: 0.8732 - val_acc: 0.6460\n",
      "Epoch 17/50\n",
      "6960/6960 [==============================] - 1s 141us/sample - loss: 0.9797 - acc: 0.5958 - val_loss: 0.8380 - val_acc: 0.6827\n",
      "Epoch 18/50\n",
      "6960/6960 [==============================] - 1s 141us/sample - loss: 0.9664 - acc: 0.6014 - val_loss: 0.8440 - val_acc: 0.6547\n",
      "Epoch 19/50\n",
      "6960/6960 [==============================] - 1s 142us/sample - loss: 0.9328 - acc: 0.6085 - val_loss: 0.7667 - val_acc: 0.7047\n",
      "Epoch 20/50\n",
      "6960/6960 [==============================] - 1s 141us/sample - loss: 0.9152 - acc: 0.6194 - val_loss: 0.7442 - val_acc: 0.7007\n",
      "Epoch 21/50\n",
      "6960/6960 [==============================] - 1s 147us/sample - loss: 0.8747 - acc: 0.6434 - val_loss: 0.7274 - val_acc: 0.7153\n",
      "Epoch 22/50\n",
      "6960/6960 [==============================] - 1s 149us/sample - loss: 0.8598 - acc: 0.6556 - val_loss: 0.6640 - val_acc: 0.7487\n",
      "Epoch 23/50\n",
      "6960/6960 [==============================] - 1s 142us/sample - loss: 0.8316 - acc: 0.6648 - val_loss: 0.6201 - val_acc: 0.7693\n",
      "Epoch 24/50\n",
      "6960/6960 [==============================] - 1s 141us/sample - loss: 0.8019 - acc: 0.6789 - val_loss: 0.5909 - val_acc: 0.7913\n",
      "Epoch 25/50\n",
      "6960/6960 [==============================] - 1s 142us/sample - loss: 0.7788 - acc: 0.6865 - val_loss: 0.5677 - val_acc: 0.8007\n",
      "Epoch 26/50\n",
      "6960/6960 [==============================] - 1s 142us/sample - loss: 0.7685 - acc: 0.7020 - val_loss: 0.5491 - val_acc: 0.7947\n",
      "Epoch 27/50\n",
      "6960/6960 [==============================] - 1s 141us/sample - loss: 0.7448 - acc: 0.7066 - val_loss: 0.5346 - val_acc: 0.7987\n",
      "Epoch 28/50\n",
      "6960/6960 [==============================] - 1s 146us/sample - loss: 0.7056 - acc: 0.7230 - val_loss: 0.5057 - val_acc: 0.8020\n",
      "Epoch 29/50\n",
      "6960/6960 [==============================] - 1s 143us/sample - loss: 0.7003 - acc: 0.7243 - val_loss: 0.4619 - val_acc: 0.8347\n",
      "Epoch 30/50\n",
      "6960/6960 [==============================] - 1s 142us/sample - loss: 0.6712 - acc: 0.7384 - val_loss: 0.4657 - val_acc: 0.8213\n",
      "Epoch 31/50\n",
      "6960/6960 [==============================] - 1s 144us/sample - loss: 0.6616 - acc: 0.7434 - val_loss: 0.4319 - val_acc: 0.8367\n",
      "Epoch 32/50\n",
      "6960/6960 [==============================] - 1s 140us/sample - loss: 0.6479 - acc: 0.7493 - val_loss: 0.4027 - val_acc: 0.8533\n",
      "Epoch 33/50\n",
      "6960/6960 [==============================] - 1s 143us/sample - loss: 0.6170 - acc: 0.7649 - val_loss: 0.3803 - val_acc: 0.8660\n",
      "Epoch 34/50\n",
      "6960/6960 [==============================] - 1s 143us/sample - loss: 0.5965 - acc: 0.7634 - val_loss: 0.3873 - val_acc: 0.8540\n",
      "Epoch 35/50\n",
      "6960/6960 [==============================] - 1s 145us/sample - loss: 0.5882 - acc: 0.7693 - val_loss: 0.3367 - val_acc: 0.8873\n",
      "Epoch 36/50\n",
      "6960/6960 [==============================] - 1s 142us/sample - loss: 0.5619 - acc: 0.7815 - val_loss: 0.3002 - val_acc: 0.9020\n",
      "Epoch 37/50\n",
      "6960/6960 [==============================] - 1s 148us/sample - loss: 0.5671 - acc: 0.7779 - val_loss: 0.3144 - val_acc: 0.8987\n",
      "Epoch 38/50\n",
      "6960/6960 [==============================] - 1s 147us/sample - loss: 0.5471 - acc: 0.7911 - val_loss: 0.2628 - val_acc: 0.9180\n",
      "Epoch 39/50\n",
      "6960/6960 [==============================] - 1s 146us/sample - loss: 0.5342 - acc: 0.7971 - val_loss: 0.2548 - val_acc: 0.9080\n",
      "Epoch 40/50\n",
      "6960/6960 [==============================] - 1s 142us/sample - loss: 0.5021 - acc: 0.8065 - val_loss: 0.2646 - val_acc: 0.9080\n",
      "Epoch 41/50\n",
      "6960/6960 [==============================] - 1s 143us/sample - loss: 0.4959 - acc: 0.8108 - val_loss: 0.2474 - val_acc: 0.9227\n",
      "Epoch 42/50\n",
      "6960/6960 [==============================] - 1s 144us/sample - loss: 0.4961 - acc: 0.8105 - val_loss: 0.2740 - val_acc: 0.9080\n",
      "Epoch 43/50\n",
      "6960/6960 [==============================] - 1s 142us/sample - loss: 0.4834 - acc: 0.8144 - val_loss: 0.2575 - val_acc: 0.9127\n",
      "Epoch 44/50\n",
      "6960/6960 [==============================] - 1s 141us/sample - loss: 0.4816 - acc: 0.8171 - val_loss: 0.2159 - val_acc: 0.9300\n",
      "Epoch 45/50\n",
      "6960/6960 [==============================] - 1s 141us/sample - loss: 0.4680 - acc: 0.8221 - val_loss: 0.2055 - val_acc: 0.9380\n",
      "Epoch 46/50\n",
      "6960/6960 [==============================] - 1s 150us/sample - loss: 0.4568 - acc: 0.8264 - val_loss: 0.1785 - val_acc: 0.9480\n",
      "Epoch 47/50\n",
      "6960/6960 [==============================] - 1s 143us/sample - loss: 0.4403 - acc: 0.8292 - val_loss: 0.1857 - val_acc: 0.9440\n",
      "Epoch 48/50\n",
      "6960/6960 [==============================] - 1s 145us/sample - loss: 0.4362 - acc: 0.8326 - val_loss: 0.2024 - val_acc: 0.9347\n",
      "Epoch 49/50\n",
      "6960/6960 [==============================] - 1s 144us/sample - loss: 0.4500 - acc: 0.8353 - val_loss: 0.1648 - val_acc: 0.9527\n",
      "Epoch 50/50\n",
      "6960/6960 [==============================] - 1s 142us/sample - loss: 0.4211 - acc: 0.8450 - val_loss: 0.1560 - val_acc: 0.9520\n",
      "6960/6960 [==============================] - 3s 389us/sample - loss: 0.0626 - acc: 0.9909\n",
      "1772/1772 [==============================] - 1s 474us/sample - loss: 1.2894 - acc: 0.5942\n",
      "train acc: 99.095%\n",
      "test acc: 59.424%\n",
      "=================100===================\n",
      "Model: \"sequential_67\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_264 (Conv2D)          (None, 100, 1, 100)       22100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_264 (MaxPoolin (None, 34, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_264 (Bat (None, 34, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_264 (Dropout)        (None, 34, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_265 (Conv2D)          (None, 34, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_265 (MaxPoolin (None, 12, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_265 (Bat (None, 12, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_265 (Dropout)        (None, 12, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_266 (Conv2D)          (None, 12, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_266 (MaxPoolin (None, 4, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_266 (Bat (None, 4, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_266 (Dropout)        (None, 4, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_267 (Conv2D)          (None, 4, 1, 100)         100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_267 (MaxPoolin (None, 2, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_267 (Bat (None, 2, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_267 (Dropout)        (None, 2, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_67 (Flatten)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 4)                 804       \n",
      "=================================================================\n",
      "Total params: 324,804\n",
      "Trainable params: 324,004\n",
      "Non-trainable params: 800\n",
      "_________________________________________________________________\n",
      "Train on 6960 samples, validate on 1500 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6960/6960 [==============================] - 10s 1ms/sample - loss: 1.9950 - acc: 0.2891 - val_loss: 2.1358 - val_acc: 0.3353\n",
      "Epoch 2/50\n",
      "6960/6960 [==============================] - 1s 168us/sample - loss: 1.6372 - acc: 0.3162 - val_loss: 1.6983 - val_acc: 0.3133\n",
      "Epoch 3/50\n",
      "6960/6960 [==============================] - 1s 166us/sample - loss: 1.4961 - acc: 0.3236 - val_loss: 1.4002 - val_acc: 0.3847\n",
      "Epoch 4/50\n",
      "6960/6960 [==============================] - 1s 157us/sample - loss: 1.3703 - acc: 0.3759 - val_loss: 1.1735 - val_acc: 0.4813\n",
      "Epoch 5/50\n",
      "6960/6960 [==============================] - 1s 166us/sample - loss: 1.2787 - acc: 0.4300 - val_loss: 1.0998 - val_acc: 0.5393\n",
      "Epoch 6/50\n",
      "6960/6960 [==============================] - 1s 163us/sample - loss: 1.2099 - acc: 0.4632 - val_loss: 1.0856 - val_acc: 0.5513\n",
      "Epoch 7/50\n",
      "6960/6960 [==============================] - 1s 163us/sample - loss: 1.1685 - acc: 0.4816 - val_loss: 1.1029 - val_acc: 0.5253\n",
      "Epoch 8/50\n",
      "6960/6960 [==============================] - 1s 173us/sample - loss: 1.1363 - acc: 0.5047 - val_loss: 0.9928 - val_acc: 0.5913\n",
      "Epoch 9/50\n",
      "6960/6960 [==============================] - 1s 159us/sample - loss: 1.0816 - acc: 0.5394 - val_loss: 0.9721 - val_acc: 0.5967\n",
      "Epoch 10/50\n",
      "6960/6960 [==============================] - 1s 164us/sample - loss: 1.0605 - acc: 0.5461 - val_loss: 0.9097 - val_acc: 0.6340\n",
      "Epoch 11/50\n",
      "6960/6960 [==============================] - 1s 166us/sample - loss: 1.0066 - acc: 0.5802 - val_loss: 0.9809 - val_acc: 0.5653\n",
      "Epoch 12/50\n",
      "6960/6960 [==============================] - 1s 166us/sample - loss: 0.9883 - acc: 0.5845 - val_loss: 0.8652 - val_acc: 0.6393\n",
      "Epoch 13/50\n",
      "6960/6960 [==============================] - 1s 162us/sample - loss: 0.9390 - acc: 0.6115 - val_loss: 0.8071 - val_acc: 0.6687\n",
      "Epoch 14/50\n",
      "6960/6960 [==============================] - 1s 165us/sample - loss: 0.9386 - acc: 0.6093 - val_loss: 0.8571 - val_acc: 0.6513\n",
      "Epoch 15/50\n",
      "6960/6960 [==============================] - 1s 167us/sample - loss: 0.9086 - acc: 0.6280 - val_loss: 0.7090 - val_acc: 0.7160\n",
      "Epoch 16/50\n",
      "6960/6960 [==============================] - 1s 163us/sample - loss: 0.8692 - acc: 0.6420 - val_loss: 0.7036 - val_acc: 0.7187\n",
      "Epoch 17/50\n",
      "6960/6960 [==============================] - 1s 162us/sample - loss: 0.8405 - acc: 0.6647 - val_loss: 0.6525 - val_acc: 0.7527\n",
      "Epoch 18/50\n",
      "6960/6960 [==============================] - 1s 162us/sample - loss: 0.8165 - acc: 0.6695 - val_loss: 0.5996 - val_acc: 0.7680\n",
      "Epoch 19/50\n",
      "6960/6960 [==============================] - 1s 158us/sample - loss: 0.7810 - acc: 0.6852 - val_loss: 0.5641 - val_acc: 0.7873\n",
      "Epoch 20/50\n",
      "6960/6960 [==============================] - 1s 160us/sample - loss: 0.7470 - acc: 0.7070 - val_loss: 0.5296 - val_acc: 0.8080\n",
      "Epoch 21/50\n",
      "6960/6960 [==============================] - 1s 163us/sample - loss: 0.7275 - acc: 0.7099 - val_loss: 0.5388 - val_acc: 0.7900\n",
      "Epoch 22/50\n",
      "6960/6960 [==============================] - 1s 180us/sample - loss: 0.7215 - acc: 0.7121 - val_loss: 0.4907 - val_acc: 0.8053\n",
      "Epoch 23/50\n",
      "6960/6960 [==============================] - 1s 170us/sample - loss: 0.6847 - acc: 0.7312 - val_loss: 0.4661 - val_acc: 0.8260\n",
      "Epoch 24/50\n",
      "6960/6960 [==============================] - 1s 177us/sample - loss: 0.6698 - acc: 0.7359 - val_loss: 0.4214 - val_acc: 0.8467\n",
      "Epoch 25/50\n",
      "6960/6960 [==============================] - 1s 176us/sample - loss: 0.6195 - acc: 0.7566 - val_loss: 0.4084 - val_acc: 0.8500\n",
      "Epoch 26/50\n",
      "6960/6960 [==============================] - 1s 166us/sample - loss: 0.6048 - acc: 0.7578 - val_loss: 0.3681 - val_acc: 0.8627\n",
      "Epoch 27/50\n",
      "6960/6960 [==============================] - ETA: 0s - loss: 0.5920 - acc: 0.771 - 1s 165us/sample - loss: 0.5867 - acc: 0.7730 - val_loss: 0.3358 - val_acc: 0.8873\n",
      "Epoch 28/50\n",
      "6960/6960 [==============================] - 1s 166us/sample - loss: 0.5763 - acc: 0.7690 - val_loss: 0.3520 - val_acc: 0.8740\n",
      "Epoch 29/50\n",
      "6960/6960 [==============================] - 1s 165us/sample - loss: 0.5535 - acc: 0.7838 - val_loss: 0.2929 - val_acc: 0.9073\n",
      "Epoch 30/50\n",
      "6960/6960 [==============================] - 1s 165us/sample - loss: 0.5421 - acc: 0.7894 - val_loss: 0.2880 - val_acc: 0.9040\n",
      "Epoch 31/50\n",
      "6960/6960 [==============================] - 1s 166us/sample - loss: 0.5244 - acc: 0.7943 - val_loss: 0.2539 - val_acc: 0.9227\n",
      "Epoch 32/50\n",
      "6960/6960 [==============================] - 1s 167us/sample - loss: 0.4974 - acc: 0.8079 - val_loss: 0.2418 - val_acc: 0.9233\n",
      "Epoch 33/50\n",
      "6960/6960 [==============================] - 1s 163us/sample - loss: 0.4766 - acc: 0.8182 - val_loss: 0.2398 - val_acc: 0.9247\n",
      "Epoch 34/50\n",
      "6960/6960 [==============================] - 1s 165us/sample - loss: 0.4716 - acc: 0.8151 - val_loss: 0.2085 - val_acc: 0.9347\n",
      "Epoch 35/50\n",
      "6960/6960 [==============================] - 1s 168us/sample - loss: 0.4325 - acc: 0.8310 - val_loss: 0.1939 - val_acc: 0.9340\n",
      "Epoch 36/50\n",
      "6960/6960 [==============================] - 1s 199us/sample - loss: 0.4262 - acc: 0.8381 - val_loss: 0.1988 - val_acc: 0.9387\n",
      "Epoch 37/50\n",
      "6960/6960 [==============================] - 1s 177us/sample - loss: 0.4235 - acc: 0.8385 - val_loss: 0.1609 - val_acc: 0.9520\n",
      "Epoch 38/50\n",
      "6960/6960 [==============================] - 1s 162us/sample - loss: 0.4048 - acc: 0.8422 - val_loss: 0.1673 - val_acc: 0.9460\n",
      "Epoch 39/50\n",
      "6960/6960 [==============================] - 1s 165us/sample - loss: 0.4077 - acc: 0.8443 - val_loss: 0.1468 - val_acc: 0.9553\n",
      "Epoch 40/50\n",
      "6960/6960 [==============================] - 1s 163us/sample - loss: 0.3927 - acc: 0.8550 - val_loss: 0.1464 - val_acc: 0.9540\n",
      "Epoch 41/50\n",
      "6960/6960 [==============================] - 1s 163us/sample - loss: 0.3884 - acc: 0.8542 - val_loss: 0.1382 - val_acc: 0.9547\n",
      "Epoch 42/50\n",
      "6960/6960 [==============================] - 1s 159us/sample - loss: 0.3872 - acc: 0.8543 - val_loss: 0.1428 - val_acc: 0.9620\n",
      "Epoch 43/50\n",
      "6960/6960 [==============================] - 1s 164us/sample - loss: 0.3744 - acc: 0.8591 - val_loss: 0.1237 - val_acc: 0.9633\n",
      "Epoch 44/50\n",
      "6960/6960 [==============================] - 1s 158us/sample - loss: 0.3531 - acc: 0.8616 - val_loss: 0.1359 - val_acc: 0.9513\n",
      "Epoch 45/50\n",
      "6960/6960 [==============================] - 1s 163us/sample - loss: 0.3546 - acc: 0.8652 - val_loss: 0.1253 - val_acc: 0.9613\n",
      "Epoch 46/50\n",
      "6960/6960 [==============================] - 1s 157us/sample - loss: 0.3404 - acc: 0.8707 - val_loss: 0.1351 - val_acc: 0.9540\n",
      "Epoch 47/50\n",
      "6960/6960 [==============================] - 1s 169us/sample - loss: 0.3519 - acc: 0.8652 - val_loss: 0.1140 - val_acc: 0.9667\n",
      "Epoch 48/50\n",
      "6960/6960 [==============================] - 1s 163us/sample - loss: 0.3446 - acc: 0.8688 - val_loss: 0.0948 - val_acc: 0.9760\n",
      "Epoch 49/50\n",
      "6960/6960 [==============================] - 1s 170us/sample - loss: 0.3389 - acc: 0.8756 - val_loss: 0.1046 - val_acc: 0.9740\n",
      "Epoch 50/50\n",
      "6960/6960 [==============================] - 1s 160us/sample - loss: 0.3146 - acc: 0.8807 - val_loss: 0.0940 - val_acc: 0.9747\n",
      "6960/6960 [==============================] - 3s 400us/sample - loss: 0.0378 - acc: 0.9947\n",
      "1772/1772 [==============================] - 1s 414us/sample - loss: 1.1195 - acc: 0.6445\n",
      "train acc: 99.468%\n",
      "test acc: 64.447%\n",
      "=================125===================\n",
      "Model: \"sequential_68\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_268 (Conv2D)          (None, 125, 1, 100)       22100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_268 (MaxPoolin (None, 42, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_268 (Bat (None, 42, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_268 (Dropout)        (None, 42, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_269 (Conv2D)          (None, 42, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_269 (MaxPoolin (None, 14, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_269 (Bat (None, 14, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_269 (Dropout)        (None, 14, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_270 (Conv2D)          (None, 14, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_270 (MaxPoolin (None, 5, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_270 (Bat (None, 5, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_270 (Dropout)        (None, 5, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_271 (Conv2D)          (None, 5, 1, 100)         100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_271 (MaxPoolin (None, 2, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_271 (Bat (None, 2, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_271 (Dropout)        (None, 2, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_68 (Flatten)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 4)                 804       \n",
      "=================================================================\n",
      "Total params: 324,804\n",
      "Trainable params: 324,004\n",
      "Non-trainable params: 800\n",
      "_________________________________________________________________\n",
      "Train on 6960 samples, validate on 1500 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "6960/6960 [==============================] - 10s 1ms/sample - loss: 2.0110 - acc: 0.2918 - val_loss: 5.2624 - val_acc: 0.2527\n",
      "Epoch 2/50\n",
      "6960/6960 [==============================] - 1s 181us/sample - loss: 1.6468 - acc: 0.3207 - val_loss: 1.6907 - val_acc: 0.3367\n",
      "Epoch 3/50\n",
      "6960/6960 [==============================] - 1s 179us/sample - loss: 1.4583 - acc: 0.3717 - val_loss: 1.1928 - val_acc: 0.4593\n",
      "Epoch 4/50\n",
      "6960/6960 [==============================] - 1s 183us/sample - loss: 1.3177 - acc: 0.4180 - val_loss: 1.1016 - val_acc: 0.5127\n",
      "Epoch 5/50\n",
      "6960/6960 [==============================] - 1s 182us/sample - loss: 1.2019 - acc: 0.4718 - val_loss: 1.0377 - val_acc: 0.5540\n",
      "Epoch 6/50\n",
      "6960/6960 [==============================] - 1s 177us/sample - loss: 1.1394 - acc: 0.5063 - val_loss: 0.9585 - val_acc: 0.6047\n",
      "Epoch 7/50\n",
      "6960/6960 [==============================] - 1s 185us/sample - loss: 1.0907 - acc: 0.5366 - val_loss: 0.9332 - val_acc: 0.6200\n",
      "Epoch 8/50\n",
      "6960/6960 [==============================] - 1s 190us/sample - loss: 1.0370 - acc: 0.5625 - val_loss: 0.9273 - val_acc: 0.6227\n",
      "Epoch 9/50\n",
      "6960/6960 [==============================] - 1s 178us/sample - loss: 0.9810 - acc: 0.5953 - val_loss: 0.8469 - val_acc: 0.6600\n",
      "Epoch 10/50\n",
      "6960/6960 [==============================] - 1s 179us/sample - loss: 0.9612 - acc: 0.6045 - val_loss: 0.7836 - val_acc: 0.6913\n",
      "Epoch 11/50\n",
      "6960/6960 [==============================] - 1s 181us/sample - loss: 0.9221 - acc: 0.6138 - val_loss: 0.7860 - val_acc: 0.6887\n",
      "Epoch 12/50\n",
      "6960/6960 [==============================] - 1s 184us/sample - loss: 0.8763 - acc: 0.6405 - val_loss: 0.7356 - val_acc: 0.7133\n",
      "Epoch 13/50\n",
      "6960/6960 [==============================] - ETA: 0s - loss: 0.8523 - acc: 0.644 - 1s 184us/sample - loss: 0.8490 - acc: 0.6468 - val_loss: 0.6669 - val_acc: 0.7367\n",
      "Epoch 14/50\n",
      "6960/6960 [==============================] - 1s 185us/sample - loss: 0.8044 - acc: 0.6681 - val_loss: 0.6686 - val_acc: 0.7107\n",
      "Epoch 15/50\n",
      "6960/6960 [==============================] - 1s 176us/sample - loss: 0.7974 - acc: 0.6772 - val_loss: 0.5877 - val_acc: 0.7793\n",
      "Epoch 16/50\n",
      "6960/6960 [==============================] - 1s 180us/sample - loss: 0.7468 - acc: 0.6996 - val_loss: 0.5456 - val_acc: 0.7947\n",
      "Epoch 17/50\n",
      "6960/6960 [==============================] - 1s 180us/sample - loss: 0.7191 - acc: 0.7111 - val_loss: 0.4984 - val_acc: 0.8007\n",
      "Epoch 18/50\n",
      "6960/6960 [==============================] - 1s 178us/sample - loss: 0.7014 - acc: 0.7211 - val_loss: 0.4816 - val_acc: 0.8273\n",
      "Epoch 19/50\n",
      "6960/6960 [==============================] - 1s 179us/sample - loss: 0.6692 - acc: 0.7326 - val_loss: 0.4580 - val_acc: 0.8300\n",
      "Epoch 20/50\n",
      "6960/6960 [==============================] - 1s 178us/sample - loss: 0.6348 - acc: 0.7490 - val_loss: 0.3946 - val_acc: 0.8593\n",
      "Epoch 21/50\n",
      "6960/6960 [==============================] - 1s 183us/sample - loss: 0.6180 - acc: 0.7519 - val_loss: 0.3807 - val_acc: 0.8553\n",
      "Epoch 22/50\n",
      "6960/6960 [==============================] - 1s 179us/sample - loss: 0.6069 - acc: 0.7636 - val_loss: 0.3898 - val_acc: 0.8480\n",
      "Epoch 23/50\n",
      "6960/6960 [==============================] - 1s 180us/sample - loss: 0.5642 - acc: 0.7819 - val_loss: 0.3456 - val_acc: 0.8800\n",
      "Epoch 24/50\n",
      "6960/6960 [==============================] - 1s 178us/sample - loss: 0.5631 - acc: 0.7836 - val_loss: 0.3540 - val_acc: 0.8740\n",
      "Epoch 25/50\n",
      "6960/6960 [==============================] - 1s 178us/sample - loss: 0.5468 - acc: 0.7882 - val_loss: 0.3237 - val_acc: 0.8733\n",
      "Epoch 26/50\n",
      "6960/6960 [==============================] - 1s 187us/sample - loss: 0.5095 - acc: 0.8019 - val_loss: 0.2869 - val_acc: 0.8967\n",
      "Epoch 27/50\n",
      "6960/6960 [==============================] - 1s 180us/sample - loss: 0.4937 - acc: 0.8122 - val_loss: 0.2642 - val_acc: 0.9047\n",
      "Epoch 28/50\n",
      "6960/6960 [==============================] - 1s 179us/sample - loss: 0.4645 - acc: 0.8198 - val_loss: 0.2582 - val_acc: 0.9200\n",
      "Epoch 29/50\n",
      "6960/6960 [==============================] - 1s 177us/sample - loss: 0.4706 - acc: 0.8178 - val_loss: 0.2523 - val_acc: 0.9013\n",
      "Epoch 30/50\n",
      "6960/6960 [==============================] - 1s 185us/sample - loss: 0.4365 - acc: 0.8361 - val_loss: 0.2162 - val_acc: 0.9333\n",
      "Epoch 31/50\n",
      "6960/6960 [==============================] - 1s 180us/sample - loss: 0.4082 - acc: 0.8451 - val_loss: 0.1793 - val_acc: 0.9447\n",
      "Epoch 32/50\n",
      "6960/6960 [==============================] - 1s 183us/sample - loss: 0.4151 - acc: 0.8404 - val_loss: 0.1808 - val_acc: 0.9400\n",
      "Epoch 33/50\n",
      "6960/6960 [==============================] - 1s 181us/sample - loss: 0.4114 - acc: 0.8424 - val_loss: 0.1539 - val_acc: 0.9560\n",
      "Epoch 34/50\n",
      "6960/6960 [==============================] - 1s 180us/sample - loss: 0.3835 - acc: 0.8537 - val_loss: 0.1620 - val_acc: 0.9447\n",
      "Epoch 35/50\n",
      "6960/6960 [==============================] - 1s 183us/sample - loss: 0.3774 - acc: 0.8588 - val_loss: 0.1594 - val_acc: 0.9527\n",
      "Epoch 36/50\n",
      "6960/6960 [==============================] - 1s 179us/sample - loss: 0.3704 - acc: 0.8596 - val_loss: 0.1481 - val_acc: 0.9533\n",
      "Epoch 37/50\n",
      "6960/6960 [==============================] - 1s 180us/sample - loss: 0.3632 - acc: 0.8606 - val_loss: 0.1230 - val_acc: 0.9640\n",
      "Epoch 38/50\n",
      "6960/6960 [==============================] - 1s 188us/sample - loss: 0.3337 - acc: 0.8753 - val_loss: 0.1340 - val_acc: 0.9633\n",
      "Epoch 39/50\n",
      "6960/6960 [==============================] - 1s 188us/sample - loss: 0.3468 - acc: 0.8671 - val_loss: 0.1023 - val_acc: 0.9733\n",
      "Epoch 40/50\n",
      "6960/6960 [==============================] - 1s 187us/sample - loss: 0.3324 - acc: 0.8726 - val_loss: 0.1113 - val_acc: 0.9707\n",
      "Epoch 41/50\n",
      "6960/6960 [==============================] - 1s 182us/sample - loss: 0.3310 - acc: 0.8746 - val_loss: 0.0916 - val_acc: 0.9793\n",
      "Epoch 42/50\n",
      "6960/6960 [==============================] - 1s 181us/sample - loss: 0.3078 - acc: 0.8819 - val_loss: 0.0882 - val_acc: 0.9767\n",
      "Epoch 43/50\n",
      "6960/6960 [==============================] - 1s 178us/sample - loss: 0.3173 - acc: 0.8802 - val_loss: 0.0800 - val_acc: 0.9780\n",
      "Epoch 44/50\n",
      "6960/6960 [==============================] - 1s 183us/sample - loss: 0.2961 - acc: 0.8845 - val_loss: 0.0681 - val_acc: 0.9833\n",
      "Epoch 45/50\n",
      "6960/6960 [==============================] - 1s 180us/sample - loss: 0.2885 - acc: 0.8881 - val_loss: 0.0702 - val_acc: 0.9820\n",
      "Epoch 46/50\n",
      "6960/6960 [==============================] - 1s 178us/sample - loss: 0.2886 - acc: 0.8932 - val_loss: 0.0662 - val_acc: 0.9853\n",
      "Epoch 47/50\n",
      "6960/6960 [==============================] - 1s 181us/sample - loss: 0.2853 - acc: 0.8947 - val_loss: 0.0754 - val_acc: 0.9847\n",
      "Epoch 48/50\n",
      "6960/6960 [==============================] - 1s 187us/sample - loss: 0.2829 - acc: 0.8925 - val_loss: 0.0686 - val_acc: 0.9827\n",
      "Epoch 49/50\n",
      "6960/6960 [==============================] - 1s 182us/sample - loss: 0.2703 - acc: 0.8953 - val_loss: 0.0534 - val_acc: 0.9887\n",
      "Epoch 50/50\n",
      "6960/6960 [==============================] - 1s 177us/sample - loss: 0.2693 - acc: 0.8997 - val_loss: 0.0429 - val_acc: 0.9947\n",
      "6960/6960 [==============================] - 3s 426us/sample - loss: 0.0151 - acc: 0.9997\n",
      "1772/1772 [==============================] - 1s 412us/sample - loss: 0.9860 - acc: 0.6744\n",
      "train acc: 99.971%\n",
      "test acc: 67.438%\n",
      "=================150===================\n",
      "Model: \"sequential_69\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_272 (Conv2D)          (None, 150, 1, 100)       22100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_272 (MaxPoolin (None, 50, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_272 (Bat (None, 50, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_272 (Dropout)        (None, 50, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_273 (Conv2D)          (None, 50, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_273 (MaxPoolin (None, 17, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_273 (Bat (None, 17, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_273 (Dropout)        (None, 17, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_274 (Conv2D)          (None, 17, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_274 (MaxPoolin (None, 6, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_274 (Bat (None, 6, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_274 (Dropout)        (None, 6, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_275 (Conv2D)          (None, 6, 1, 100)         100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_275 (MaxPoolin (None, 2, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_275 (Bat (None, 2, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_275 (Dropout)        (None, 2, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_69 (Flatten)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 4)                 804       \n",
      "=================================================================\n",
      "Total params: 324,804\n",
      "Trainable params: 324,004\n",
      "Non-trainable params: 800\n",
      "_________________________________________________________________\n",
      "Train on 6960 samples, validate on 1500 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "6960/6960 [==============================] - 9s 1ms/sample - loss: 2.0574 - acc: 0.2838 - val_loss: 3.3743 - val_acc: 0.3273\n",
      "Epoch 2/50\n",
      "6960/6960 [==============================] - 1s 203us/sample - loss: 1.6581 - acc: 0.3158 - val_loss: 2.0264 - val_acc: 0.3293\n",
      "Epoch 3/50\n",
      "6960/6960 [==============================] - 1s 200us/sample - loss: 1.4621 - acc: 0.3665 - val_loss: 1.2464 - val_acc: 0.4720\n",
      "Epoch 4/50\n",
      "6960/6960 [==============================] - 1s 204us/sample - loss: 1.2876 - acc: 0.4325 - val_loss: 1.0936 - val_acc: 0.5333\n",
      "Epoch 5/50\n",
      "6960/6960 [==============================] - 1s 199us/sample - loss: 1.2178 - acc: 0.4721 - val_loss: 1.0276 - val_acc: 0.5647\n",
      "Epoch 6/50\n",
      "6960/6960 [==============================] - 1s 206us/sample - loss: 1.1238 - acc: 0.5122 - val_loss: 0.9712 - val_acc: 0.5967\n",
      "Epoch 7/50\n",
      "6960/6960 [==============================] - 1s 202us/sample - loss: 1.0698 - acc: 0.5455 - val_loss: 0.9307 - val_acc: 0.6307\n",
      "Epoch 8/50\n",
      "6960/6960 [==============================] - 1s 199us/sample - loss: 1.0165 - acc: 0.5796 - val_loss: 0.9125 - val_acc: 0.6373\n",
      "Epoch 9/50\n",
      "6960/6960 [==============================] - 1s 204us/sample - loss: 0.9757 - acc: 0.5908 - val_loss: 0.8373 - val_acc: 0.6587\n",
      "Epoch 10/50\n",
      "6960/6960 [==============================] - 1s 201us/sample - loss: 0.9323 - acc: 0.6141 - val_loss: 0.7842 - val_acc: 0.6787\n",
      "Epoch 11/50\n",
      "6960/6960 [==============================] - 1s 201us/sample - loss: 0.8969 - acc: 0.6339 - val_loss: 0.7543 - val_acc: 0.7093\n",
      "Epoch 12/50\n",
      "6960/6960 [==============================] - 1s 198us/sample - loss: 0.8660 - acc: 0.6445 - val_loss: 0.6790 - val_acc: 0.7447\n",
      "Epoch 13/50\n",
      "6960/6960 [==============================] - 1s 213us/sample - loss: 0.8276 - acc: 0.6674 - val_loss: 0.6950 - val_acc: 0.7227\n",
      "Epoch 14/50\n",
      "6960/6960 [==============================] - 1s 199us/sample - loss: 0.7959 - acc: 0.6878 - val_loss: 0.6019 - val_acc: 0.7767\n",
      "Epoch 15/50\n",
      "6960/6960 [==============================] - 1s 208us/sample - loss: 0.7633 - acc: 0.6938 - val_loss: 0.5649 - val_acc: 0.8007\n",
      "Epoch 16/50\n",
      "6960/6960 [==============================] - 1s 200us/sample - loss: 0.7411 - acc: 0.6997 - val_loss: 0.5535 - val_acc: 0.8013\n",
      "Epoch 17/50\n",
      "6960/6960 [==============================] - 2s 216us/sample - loss: 0.7183 - acc: 0.7128 - val_loss: 0.5028 - val_acc: 0.8267\n",
      "Epoch 18/50\n",
      "6960/6960 [==============================] - 1s 214us/sample - loss: 0.6722 - acc: 0.7312 - val_loss: 0.4947 - val_acc: 0.8153\n",
      "Epoch 19/50\n",
      "6960/6960 [==============================] - 1s 199us/sample - loss: 0.6667 - acc: 0.7382 - val_loss: 0.4366 - val_acc: 0.8453\n",
      "Epoch 20/50\n",
      "6960/6960 [==============================] - 1s 201us/sample - loss: 0.6330 - acc: 0.7560 - val_loss: 0.4533 - val_acc: 0.8327\n",
      "Epoch 21/50\n",
      "6960/6960 [==============================] - 1s 199us/sample - loss: 0.5999 - acc: 0.7649 - val_loss: 0.4266 - val_acc: 0.8400\n",
      "Epoch 22/50\n",
      "6960/6960 [==============================] - 1s 199us/sample - loss: 0.5857 - acc: 0.7698 - val_loss: 0.3590 - val_acc: 0.8767\n",
      "Epoch 23/50\n",
      "6960/6960 [==============================] - 1s 207us/sample - loss: 0.5678 - acc: 0.7807 - val_loss: 0.3376 - val_acc: 0.8767\n",
      "Epoch 24/50\n",
      "6960/6960 [==============================] - 1s 215us/sample - loss: 0.5428 - acc: 0.7881 - val_loss: 0.3092 - val_acc: 0.8960\n",
      "Epoch 25/50\n",
      "6960/6960 [==============================] - 1s 211us/sample - loss: 0.5241 - acc: 0.7947 - val_loss: 0.2895 - val_acc: 0.9020\n",
      "Epoch 26/50\n",
      "6960/6960 [==============================] - 1s 198us/sample - loss: 0.5075 - acc: 0.8030 - val_loss: 0.3032 - val_acc: 0.9000\n",
      "Epoch 27/50\n",
      "6960/6960 [==============================] - 1s 208us/sample - loss: 0.4920 - acc: 0.8079 - val_loss: 0.2889 - val_acc: 0.8960\n",
      "Epoch 28/50\n",
      "6960/6960 [==============================] - 1s 203us/sample - loss: 0.4622 - acc: 0.8236 - val_loss: 0.2539 - val_acc: 0.9080\n",
      "Epoch 29/50\n",
      "6960/6960 [==============================] - 1s 204us/sample - loss: 0.4699 - acc: 0.8148 - val_loss: 0.2318 - val_acc: 0.9193\n",
      "Epoch 30/50\n",
      "6960/6960 [==============================] - 1s 203us/sample - loss: 0.4287 - acc: 0.8382 - val_loss: 0.2312 - val_acc: 0.9127\n",
      "Epoch 31/50\n",
      "6960/6960 [==============================] - 1s 199us/sample - loss: 0.4211 - acc: 0.8401 - val_loss: 0.1916 - val_acc: 0.9373\n",
      "Epoch 32/50\n",
      "6960/6960 [==============================] - 1s 200us/sample - loss: 0.4230 - acc: 0.8378 - val_loss: 0.1823 - val_acc: 0.9493\n",
      "Epoch 33/50\n",
      "6960/6960 [==============================] - 1s 201us/sample - loss: 0.4009 - acc: 0.8513 - val_loss: 0.1772 - val_acc: 0.9427\n",
      "Epoch 34/50\n",
      "6960/6960 [==============================] - 1s 201us/sample - loss: 0.3597 - acc: 0.8616 - val_loss: 0.1651 - val_acc: 0.9433\n",
      "Epoch 35/50\n",
      "6960/6960 [==============================] - 1s 207us/sample - loss: 0.3554 - acc: 0.8647 - val_loss: 0.1379 - val_acc: 0.9520\n",
      "Epoch 36/50\n",
      "6960/6960 [==============================] - 1s 204us/sample - loss: 0.3604 - acc: 0.8638 - val_loss: 0.1300 - val_acc: 0.9633\n",
      "Epoch 37/50\n",
      "6960/6960 [==============================] - 1s 203us/sample - loss: 0.3542 - acc: 0.8717 - val_loss: 0.1398 - val_acc: 0.9527\n",
      "Epoch 38/50\n",
      "6960/6960 [==============================] - 1s 202us/sample - loss: 0.3516 - acc: 0.8649 - val_loss: 0.1067 - val_acc: 0.9720\n",
      "Epoch 39/50\n",
      "6960/6960 [==============================] - 1s 200us/sample - loss: 0.3153 - acc: 0.8828 - val_loss: 0.1090 - val_acc: 0.9707\n",
      "Epoch 40/50\n",
      "6960/6960 [==============================] - 2s 223us/sample - loss: 0.3215 - acc: 0.8807 - val_loss: 0.0945 - val_acc: 0.9673\n",
      "Epoch 41/50\n",
      "6960/6960 [==============================] - 1s 204us/sample - loss: 0.2985 - acc: 0.8897 - val_loss: 0.1064 - val_acc: 0.9713\n",
      "Epoch 42/50\n",
      "6960/6960 [==============================] - 1s 198us/sample - loss: 0.2829 - acc: 0.8950 - val_loss: 0.0856 - val_acc: 0.9753\n",
      "Epoch 43/50\n",
      "6960/6960 [==============================] - 1s 202us/sample - loss: 0.2926 - acc: 0.8931 - val_loss: 0.0876 - val_acc: 0.9793\n",
      "Epoch 44/50\n",
      "6960/6960 [==============================] - 1s 201us/sample - loss: 0.2762 - acc: 0.8977 - val_loss: 0.0719 - val_acc: 0.9793\n",
      "Epoch 45/50\n",
      "6960/6960 [==============================] - 1s 201us/sample - loss: 0.2899 - acc: 0.8941 - val_loss: 0.0713 - val_acc: 0.9787\n",
      "Epoch 46/50\n",
      "6960/6960 [==============================] - 1s 203us/sample - loss: 0.2876 - acc: 0.8915 - val_loss: 0.0760 - val_acc: 0.9753\n",
      "Epoch 47/50\n",
      "6960/6960 [==============================] - 1s 206us/sample - loss: 0.2672 - acc: 0.8997 - val_loss: 0.0730 - val_acc: 0.9800\n",
      "Epoch 48/50\n",
      "6960/6960 [==============================] - 1s 202us/sample - loss: 0.2575 - acc: 0.9073 - val_loss: 0.0733 - val_acc: 0.9793\n",
      "Epoch 49/50\n",
      "6960/6960 [==============================] - 1s 200us/sample - loss: 0.2596 - acc: 0.9033 - val_loss: 0.0586 - val_acc: 0.9847\n",
      "Epoch 50/50\n",
      "6960/6960 [==============================] - 1s 204us/sample - loss: 0.2506 - acc: 0.9093 - val_loss: 0.0469 - val_acc: 0.9880\n",
      "6960/6960 [==============================] - 3s 431us/sample - loss: 0.0134 - acc: 0.9996\n",
      "1772/1772 [==============================] - 1s 409us/sample - loss: 1.0184 - acc: 0.6981\n",
      "train acc: 99.957%\n",
      "test acc: 69.808%\n",
      "=================175===================\n",
      "Model: \"sequential_70\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_276 (Conv2D)          (None, 175, 1, 100)       22100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_276 (MaxPoolin (None, 59, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_276 (Bat (None, 59, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_276 (Dropout)        (None, 59, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_277 (Conv2D)          (None, 59, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_277 (MaxPoolin (None, 20, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_277 (Bat (None, 20, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_277 (Dropout)        (None, 20, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_278 (Conv2D)          (None, 20, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_278 (MaxPoolin (None, 7, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_278 (Bat (None, 7, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_278 (Dropout)        (None, 7, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_279 (Conv2D)          (None, 7, 1, 100)         100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_279 (MaxPoolin (None, 3, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_279 (Bat (None, 3, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_279 (Dropout)        (None, 3, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_70 (Flatten)         (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 4)                 1204      \n",
      "=================================================================\n",
      "Total params: 325,204\n",
      "Trainable params: 324,404\n",
      "Non-trainable params: 800\n",
      "_________________________________________________________________\n",
      "Train on 6960 samples, validate on 1500 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "6960/6960 [==============================] - 10s 1ms/sample - loss: 1.9882 - acc: 0.2953 - val_loss: 2.5464 - val_acc: 0.3180\n",
      "Epoch 2/50\n",
      "6960/6960 [==============================] - 2s 223us/sample - loss: 1.5814 - acc: 0.3408 - val_loss: 1.8870 - val_acc: 0.3773\n",
      "Epoch 3/50\n",
      "6960/6960 [==============================] - 2s 227us/sample - loss: 1.4207 - acc: 0.3818 - val_loss: 1.1831 - val_acc: 0.4753\n",
      "Epoch 4/50\n",
      "6960/6960 [==============================] - 2s 224us/sample - loss: 1.2787 - acc: 0.4420 - val_loss: 1.0193 - val_acc: 0.5840\n",
      "Epoch 5/50\n",
      "6960/6960 [==============================] - 2s 226us/sample - loss: 1.1583 - acc: 0.5000 - val_loss: 1.0259 - val_acc: 0.5840\n",
      "Epoch 6/50\n",
      "6960/6960 [==============================] - 2s 218us/sample - loss: 1.0928 - acc: 0.5391 - val_loss: 0.9142 - val_acc: 0.6220\n",
      "Epoch 7/50\n",
      "6960/6960 [==============================] - 2s 221us/sample - loss: 1.0268 - acc: 0.5731 - val_loss: 0.8389 - val_acc: 0.6900\n",
      "Epoch 8/50\n",
      "6960/6960 [==============================] - 2s 222us/sample - loss: 0.9589 - acc: 0.6027 - val_loss: 0.8003 - val_acc: 0.6860\n",
      "Epoch 9/50\n",
      "6960/6960 [==============================] - 2s 220us/sample - loss: 0.9226 - acc: 0.6204 - val_loss: 0.7454 - val_acc: 0.7287\n",
      "Epoch 10/50\n",
      "6960/6960 [==============================] - 2s 216us/sample - loss: 0.8867 - acc: 0.6401 - val_loss: 0.6930 - val_acc: 0.7553\n",
      "Epoch 11/50\n",
      "6960/6960 [==============================] - 2s 221us/sample - loss: 0.8323 - acc: 0.6641 - val_loss: 0.6606 - val_acc: 0.7607\n",
      "Epoch 12/50\n",
      "6960/6960 [==============================] - 2s 218us/sample - loss: 0.7918 - acc: 0.6871 - val_loss: 0.6080 - val_acc: 0.7653\n",
      "Epoch 13/50\n",
      "6960/6960 [==============================] - 2s 218us/sample - loss: 0.7653 - acc: 0.6891 - val_loss: 0.5956 - val_acc: 0.7827\n",
      "Epoch 14/50\n",
      "6960/6960 [==============================] - 2s 220us/sample - loss: 0.7171 - acc: 0.7085 - val_loss: 0.5529 - val_acc: 0.7853\n",
      "Epoch 15/50\n",
      "6960/6960 [==============================] - 2s 229us/sample - loss: 0.6855 - acc: 0.7332 - val_loss: 0.5016 - val_acc: 0.8033\n",
      "Epoch 16/50\n",
      "6960/6960 [==============================] - 2s 221us/sample - loss: 0.6654 - acc: 0.7404 - val_loss: 0.4539 - val_acc: 0.8473\n",
      "Epoch 17/50\n",
      "6960/6960 [==============================] - 2s 218us/sample - loss: 0.6261 - acc: 0.7497 - val_loss: 0.4561 - val_acc: 0.8293\n",
      "Epoch 18/50\n",
      "6960/6960 [==============================] - 2s 221us/sample - loss: 0.6040 - acc: 0.7612 - val_loss: 0.4585 - val_acc: 0.8267\n",
      "Epoch 19/50\n",
      "6960/6960 [==============================] - 2s 219us/sample - loss: 0.5903 - acc: 0.7710 - val_loss: 0.4423 - val_acc: 0.8400\n",
      "Epoch 20/50\n",
      "6960/6960 [==============================] - 2s 218us/sample - loss: 0.5574 - acc: 0.7816 - val_loss: 0.3450 - val_acc: 0.8880\n",
      "Epoch 21/50\n",
      "6960/6960 [==============================] - 2s 219us/sample - loss: 0.5270 - acc: 0.7957 - val_loss: 0.3324 - val_acc: 0.8860\n",
      "Epoch 22/50\n",
      "6960/6960 [==============================] - 2s 228us/sample - loss: 0.5219 - acc: 0.7991 - val_loss: 0.2909 - val_acc: 0.9053\n",
      "Epoch 23/50\n",
      "6960/6960 [==============================] - 2s 217us/sample - loss: 0.4934 - acc: 0.8078 - val_loss: 0.2634 - val_acc: 0.9107\n",
      "Epoch 24/50\n",
      "6960/6960 [==============================] - 2s 222us/sample - loss: 0.4575 - acc: 0.8247 - val_loss: 0.2784 - val_acc: 0.9100\n",
      "Epoch 25/50\n",
      "6960/6960 [==============================] - 2s 226us/sample - loss: 0.4424 - acc: 0.8280 - val_loss: 0.2193 - val_acc: 0.9380\n",
      "Epoch 26/50\n",
      "6960/6960 [==============================] - 2s 224us/sample - loss: 0.4205 - acc: 0.8408 - val_loss: 0.2033 - val_acc: 0.9360\n",
      "Epoch 27/50\n",
      "6960/6960 [==============================] - 2s 222us/sample - loss: 0.4209 - acc: 0.8371 - val_loss: 0.1935 - val_acc: 0.9360\n",
      "Epoch 28/50\n",
      "6960/6960 [==============================] - 2s 222us/sample - loss: 0.4066 - acc: 0.8453 - val_loss: 0.1892 - val_acc: 0.9413\n",
      "Epoch 29/50\n",
      "6960/6960 [==============================] - 2s 218us/sample - loss: 0.3853 - acc: 0.8510 - val_loss: 0.1822 - val_acc: 0.9473\n",
      "Epoch 30/50\n",
      "6960/6960 [==============================] - 2s 219us/sample - loss: 0.3780 - acc: 0.8546 - val_loss: 0.1590 - val_acc: 0.9507\n",
      "Epoch 31/50\n",
      "6960/6960 [==============================] - 2s 222us/sample - loss: 0.3533 - acc: 0.8677 - val_loss: 0.1288 - val_acc: 0.9613\n",
      "Epoch 32/50\n",
      "6960/6960 [==============================] - 2s 223us/sample - loss: 0.3444 - acc: 0.8695 - val_loss: 0.1199 - val_acc: 0.9653\n",
      "Epoch 33/50\n",
      "6960/6960 [==============================] - 2s 218us/sample - loss: 0.3381 - acc: 0.8707 - val_loss: 0.1470 - val_acc: 0.9533\n",
      "Epoch 34/50\n",
      "6960/6960 [==============================] - 2s 218us/sample - loss: 0.3231 - acc: 0.8792 - val_loss: 0.1021 - val_acc: 0.9753\n",
      "Epoch 35/50\n",
      "6960/6960 [==============================] - 2s 222us/sample - loss: 0.3198 - acc: 0.8805 - val_loss: 0.1074 - val_acc: 0.9733\n",
      "Epoch 36/50\n",
      "6960/6960 [==============================] - 2s 239us/sample - loss: 0.3021 - acc: 0.8872 - val_loss: 0.0952 - val_acc: 0.9800\n",
      "Epoch 37/50\n",
      "6960/6960 [==============================] - 2s 220us/sample - loss: 0.2868 - acc: 0.8925 - val_loss: 0.0878 - val_acc: 0.9787\n",
      "Epoch 38/50\n",
      "6960/6960 [==============================] - 2s 220us/sample - loss: 0.2715 - acc: 0.8989 - val_loss: 0.0871 - val_acc: 0.9767\n",
      "Epoch 39/50\n",
      "6960/6960 [==============================] - 2s 220us/sample - loss: 0.2864 - acc: 0.8943 - val_loss: 0.0838 - val_acc: 0.9807\n",
      "Epoch 40/50\n",
      "6960/6960 [==============================] - 2s 224us/sample - loss: 0.2733 - acc: 0.8935 - val_loss: 0.0687 - val_acc: 0.9807\n",
      "Epoch 41/50\n",
      "6960/6960 [==============================] - 2s 224us/sample - loss: 0.2710 - acc: 0.8996 - val_loss: 0.0607 - val_acc: 0.9860\n",
      "Epoch 42/50\n",
      "6960/6960 [==============================] - 2s 222us/sample - loss: 0.2619 - acc: 0.8980 - val_loss: 0.0584 - val_acc: 0.9860\n",
      "Epoch 43/50\n",
      "6960/6960 [==============================] - 2s 225us/sample - loss: 0.2516 - acc: 0.9072 - val_loss: 0.0465 - val_acc: 0.9913\n",
      "Epoch 44/50\n",
      "6960/6960 [==============================] - 2s 230us/sample - loss: 0.2543 - acc: 0.9039 - val_loss: 0.0822 - val_acc: 0.9753\n",
      "Epoch 45/50\n",
      "6960/6960 [==============================] - 2s 237us/sample - loss: 0.2419 - acc: 0.9158 - val_loss: 0.0439 - val_acc: 0.9900\n",
      "Epoch 46/50\n",
      "6960/6960 [==============================] - 2s 232us/sample - loss: 0.2382 - acc: 0.9124 - val_loss: 0.0458 - val_acc: 0.9893\n",
      "Epoch 47/50\n",
      "6960/6960 [==============================] - 2s 223us/sample - loss: 0.2297 - acc: 0.9155 - val_loss: 0.0423 - val_acc: 0.9900\n",
      "Epoch 48/50\n",
      "6960/6960 [==============================] - 2s 225us/sample - loss: 0.2214 - acc: 0.9158 - val_loss: 0.0457 - val_acc: 0.9900\n",
      "Epoch 49/50\n",
      "6960/6960 [==============================] - 2s 226us/sample - loss: 0.2087 - acc: 0.9263 - val_loss: 0.0381 - val_acc: 0.9933\n",
      "Epoch 50/50\n",
      "6960/6960 [==============================] - 2s 228us/sample - loss: 0.1919 - acc: 0.9267 - val_loss: 0.0351 - val_acc: 0.9927\n",
      "6960/6960 [==============================] - 3s 483us/sample - loss: 0.0116 - acc: 0.9987\n",
      "1772/1772 [==============================] - 1s 437us/sample - loss: 1.1362 - acc: 0.6919\n",
      "train acc: 99.871%\n",
      "test acc: 69.187%\n",
      "=================200===================\n",
      "Model: \"sequential_71\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_280 (Conv2D)          (None, 200, 1, 100)       22100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_280 (MaxPoolin (None, 67, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_280 (Bat (None, 67, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_280 (Dropout)        (None, 67, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_281 (Conv2D)          (None, 67, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_281 (MaxPoolin (None, 23, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_281 (Bat (None, 23, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_281 (Dropout)        (None, 23, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_282 (Conv2D)          (None, 23, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_282 (MaxPoolin (None, 8, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_282 (Bat (None, 8, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_282 (Dropout)        (None, 8, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_283 (Conv2D)          (None, 8, 1, 100)         100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_283 (MaxPoolin (None, 3, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_283 (Bat (None, 3, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_283 (Dropout)        (None, 3, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_71 (Flatten)         (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 4)                 1204      \n",
      "=================================================================\n",
      "Total params: 325,204\n",
      "Trainable params: 324,404\n",
      "Non-trainable params: 800\n",
      "_________________________________________________________________\n",
      "Train on 6960 samples, validate on 1500 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "6960/6960 [==============================] - 11s 2ms/sample - loss: 1.9357 - acc: 0.3116 - val_loss: 4.0915 - val_acc: 0.3680\n",
      "Epoch 2/50\n",
      "6960/6960 [==============================] - 2s 253us/sample - loss: 1.5985 - acc: 0.3435 - val_loss: 2.1639 - val_acc: 0.3900\n",
      "Epoch 3/50\n",
      "6960/6960 [==============================] - 2s 244us/sample - loss: 1.3728 - acc: 0.4039 - val_loss: 1.2113 - val_acc: 0.5120\n",
      "Epoch 4/50\n",
      "6960/6960 [==============================] - 2s 243us/sample - loss: 1.2301 - acc: 0.4688 - val_loss: 1.0794 - val_acc: 0.5460\n",
      "Epoch 5/50\n",
      "6960/6960 [==============================] - 2s 240us/sample - loss: 1.1478 - acc: 0.5083 - val_loss: 0.9750 - val_acc: 0.6040\n",
      "Epoch 6/50\n",
      "6960/6960 [==============================] - 2s 259us/sample - loss: 1.0765 - acc: 0.5468 - val_loss: 0.9486 - val_acc: 0.6107\n",
      "Epoch 7/50\n",
      "6960/6960 [==============================] - 2s 252us/sample - loss: 1.0051 - acc: 0.5816 - val_loss: 0.8316 - val_acc: 0.6720\n",
      "Epoch 8/50\n",
      "6960/6960 [==============================] - 2s 256us/sample - loss: 0.9566 - acc: 0.6029 - val_loss: 0.8273 - val_acc: 0.6533\n",
      "Epoch 9/50\n",
      "6960/6960 [==============================] - 2s 245us/sample - loss: 0.8972 - acc: 0.6386 - val_loss: 0.7441 - val_acc: 0.7100\n",
      "Epoch 10/50\n",
      "6960/6960 [==============================] - 2s 241us/sample - loss: 0.8563 - acc: 0.6529 - val_loss: 0.7040 - val_acc: 0.7340\n",
      "Epoch 11/50\n",
      "6960/6960 [==============================] - 2s 242us/sample - loss: 0.8153 - acc: 0.6744 - val_loss: 0.6941 - val_acc: 0.7327\n",
      "Epoch 12/50\n",
      "6960/6960 [==============================] - 2s 241us/sample - loss: 0.7886 - acc: 0.6859 - val_loss: 0.5904 - val_acc: 0.7827\n",
      "Epoch 13/50\n",
      "6960/6960 [==============================] - 2s 245us/sample - loss: 0.7511 - acc: 0.7001 - val_loss: 0.5486 - val_acc: 0.8007\n",
      "Epoch 14/50\n",
      "6960/6960 [==============================] - 2s 243us/sample - loss: 0.7202 - acc: 0.7144 - val_loss: 0.5046 - val_acc: 0.8213\n",
      "Epoch 15/50\n",
      "6960/6960 [==============================] - 2s 242us/sample - loss: 0.6934 - acc: 0.7226 - val_loss: 0.4559 - val_acc: 0.8413\n",
      "Epoch 16/50\n",
      "6960/6960 [==============================] - 2s 244us/sample - loss: 0.6419 - acc: 0.7451 - val_loss: 0.4443 - val_acc: 0.8547\n",
      "Epoch 17/50\n",
      "6960/6960 [==============================] - 2s 254us/sample - loss: 0.6173 - acc: 0.7659 - val_loss: 0.4109 - val_acc: 0.8540\n",
      "Epoch 18/50\n",
      "6960/6960 [==============================] - 2s 257us/sample - loss: 0.5823 - acc: 0.7759 - val_loss: 0.3861 - val_acc: 0.8640\n",
      "Epoch 19/50\n",
      "6960/6960 [==============================] - 2s 247us/sample - loss: 0.5625 - acc: 0.7853 - val_loss: 0.3542 - val_acc: 0.8760\n",
      "Epoch 20/50\n",
      "6960/6960 [==============================] - 2s 243us/sample - loss: 0.5440 - acc: 0.7871 - val_loss: 0.3378 - val_acc: 0.8820\n",
      "Epoch 21/50\n",
      "6960/6960 [==============================] - 2s 244us/sample - loss: 0.5257 - acc: 0.8000 - val_loss: 0.2876 - val_acc: 0.9133\n",
      "Epoch 22/50\n",
      "6960/6960 [==============================] - 2s 246us/sample - loss: 0.4765 - acc: 0.8188 - val_loss: 0.2542 - val_acc: 0.9253\n",
      "Epoch 23/50\n",
      "6960/6960 [==============================] - 2s 254us/sample - loss: 0.4638 - acc: 0.8259 - val_loss: 0.2463 - val_acc: 0.9327\n",
      "Epoch 24/50\n",
      "6960/6960 [==============================] - 2s 239us/sample - loss: 0.4525 - acc: 0.8323 - val_loss: 0.2144 - val_acc: 0.9440\n",
      "Epoch 25/50\n",
      "6960/6960 [==============================] - 2s 248us/sample - loss: 0.4208 - acc: 0.8435 - val_loss: 0.2159 - val_acc: 0.9400\n",
      "Epoch 26/50\n",
      "6960/6960 [==============================] - 2s 248us/sample - loss: 0.4198 - acc: 0.8389 - val_loss: 0.1899 - val_acc: 0.9453\n",
      "Epoch 27/50\n",
      "6960/6960 [==============================] - 2s 244us/sample - loss: 0.3937 - acc: 0.8503 - val_loss: 0.1711 - val_acc: 0.9520\n",
      "Epoch 28/50\n",
      "6960/6960 [==============================] - 2s 246us/sample - loss: 0.3762 - acc: 0.8619 - val_loss: 0.1746 - val_acc: 0.9447\n",
      "Epoch 29/50\n",
      "6960/6960 [==============================] - 2s 245us/sample - loss: 0.3873 - acc: 0.8534 - val_loss: 0.1525 - val_acc: 0.9593\n",
      "Epoch 30/50\n",
      "6960/6960 [==============================] - 2s 246us/sample - loss: 0.3560 - acc: 0.8648 - val_loss: 0.1280 - val_acc: 0.9687\n",
      "Epoch 31/50\n",
      "6960/6960 [==============================] - 2s 241us/sample - loss: 0.3483 - acc: 0.8685 - val_loss: 0.1167 - val_acc: 0.9720\n",
      "Epoch 32/50\n",
      "6960/6960 [==============================] - 2s 254us/sample - loss: 0.3452 - acc: 0.8707 - val_loss: 0.1145 - val_acc: 0.9707\n",
      "Epoch 33/50\n",
      "6960/6960 [==============================] - 2s 244us/sample - loss: 0.3201 - acc: 0.8774 - val_loss: 0.1056 - val_acc: 0.9753\n",
      "Epoch 34/50\n",
      "6960/6960 [==============================] - 2s 247us/sample - loss: 0.3268 - acc: 0.8774 - val_loss: 0.1180 - val_acc: 0.9687\n",
      "Epoch 35/50\n",
      "6960/6960 [==============================] - 2s 247us/sample - loss: 0.3086 - acc: 0.8866 - val_loss: 0.0891 - val_acc: 0.9793\n",
      "Epoch 36/50\n",
      "6960/6960 [==============================] - 2s 248us/sample - loss: 0.2918 - acc: 0.8889 - val_loss: 0.0864 - val_acc: 0.9787\n",
      "Epoch 37/50\n",
      "6960/6960 [==============================] - 2s 243us/sample - loss: 0.2992 - acc: 0.8885 - val_loss: 0.0749 - val_acc: 0.9827\n",
      "Epoch 38/50\n",
      "6960/6960 [==============================] - 2s 255us/sample - loss: 0.2891 - acc: 0.8932 - val_loss: 0.0732 - val_acc: 0.9840\n",
      "Epoch 39/50\n",
      "6960/6960 [==============================] - 2s 240us/sample - loss: 0.2623 - acc: 0.9060 - val_loss: 0.0608 - val_acc: 0.9887\n",
      "Epoch 40/50\n",
      "6960/6960 [==============================] - 2s 246us/sample - loss: 0.2709 - acc: 0.9037 - val_loss: 0.0640 - val_acc: 0.9860\n",
      "Epoch 41/50\n",
      "6960/6960 [==============================] - 2s 258us/sample - loss: 0.2556 - acc: 0.9091 - val_loss: 0.0827 - val_acc: 0.9760\n",
      "Epoch 42/50\n",
      "6960/6960 [==============================] - 2s 272us/sample - loss: 0.2600 - acc: 0.9056 - val_loss: 0.0621 - val_acc: 0.9853\n",
      "Epoch 43/50\n",
      "6960/6960 [==============================] - 2s 251us/sample - loss: 0.2486 - acc: 0.9052 - val_loss: 0.0664 - val_acc: 0.9773\n",
      "Epoch 44/50\n",
      "6960/6960 [==============================] - 2s 246us/sample - loss: 0.2325 - acc: 0.9141 - val_loss: 0.0487 - val_acc: 0.9893\n",
      "Epoch 45/50\n",
      "6960/6960 [==============================] - 2s 250us/sample - loss: 0.2265 - acc: 0.9158 - val_loss: 0.0600 - val_acc: 0.9807\n",
      "Epoch 46/50\n",
      "6960/6960 [==============================] - 2s 249us/sample - loss: 0.2150 - acc: 0.9201 - val_loss: 0.0399 - val_acc: 0.9893\n",
      "Epoch 47/50\n",
      "6960/6960 [==============================] - 2s 245us/sample - loss: 0.2259 - acc: 0.9187 - val_loss: 0.0489 - val_acc: 0.9827\n",
      "Epoch 48/50\n",
      "6960/6960 [==============================] - 2s 250us/sample - loss: 0.2101 - acc: 0.9236 - val_loss: 0.0443 - val_acc: 0.9893\n",
      "Epoch 49/50\n",
      "6960/6960 [==============================] - 2s 245us/sample - loss: 0.2160 - acc: 0.9210 - val_loss: 0.0342 - val_acc: 0.9940\n",
      "Epoch 50/50\n",
      "6960/6960 [==============================] - 2s 250us/sample - loss: 0.2062 - acc: 0.9223 - val_loss: 0.0492 - val_acc: 0.9873\n",
      "6960/6960 [==============================] - 3s 465us/sample - loss: 0.0154 - acc: 0.9983\n",
      "1772/1772 [==============================] - 1s 533us/sample - loss: 1.0127 - acc: 0.7020\n",
      "train acc: 99.828%\n",
      "test acc: 70.203%\n",
      "=================225===================\n",
      "Model: \"sequential_72\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_284 (Conv2D)          (None, 225, 1, 100)       22100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_284 (MaxPoolin (None, 75, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_284 (Bat (None, 75, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_284 (Dropout)        (None, 75, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_285 (Conv2D)          (None, 75, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_285 (MaxPoolin (None, 25, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_285 (Bat (None, 25, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_285 (Dropout)        (None, 25, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_286 (Conv2D)          (None, 25, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_286 (MaxPoolin (None, 9, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_286 (Bat (None, 9, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_286 (Dropout)        (None, 9, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_287 (Conv2D)          (None, 9, 1, 100)         100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_287 (MaxPoolin (None, 3, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_287 (Bat (None, 3, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_287 (Dropout)        (None, 3, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_72 (Flatten)         (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 4)                 1204      \n",
      "=================================================================\n",
      "Total params: 325,204\n",
      "Trainable params: 324,404\n",
      "Non-trainable params: 800\n",
      "_________________________________________________________________\n",
      "Train on 6960 samples, validate on 1500 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "6960/6960 [==============================] - 11s 2ms/sample - loss: 1.9915 - acc: 0.3126 - val_loss: 3.4654 - val_acc: 0.3353\n",
      "Epoch 2/50\n",
      "6960/6960 [==============================] - 2s 274us/sample - loss: 1.5734 - acc: 0.3506 - val_loss: 1.6883 - val_acc: 0.3927\n",
      "Epoch 3/50\n",
      "6960/6960 [==============================] - 2s 265us/sample - loss: 1.3647 - acc: 0.4164 - val_loss: 1.1924 - val_acc: 0.5227\n",
      "Epoch 4/50\n",
      "6960/6960 [==============================] - 2s 264us/sample - loss: 1.2191 - acc: 0.4830 - val_loss: 1.1014 - val_acc: 0.5440\n",
      "Epoch 5/50\n",
      "6960/6960 [==============================] - 2s 274us/sample - loss: 1.1164 - acc: 0.5259 - val_loss: 0.9982 - val_acc: 0.5873\n",
      "Epoch 6/50\n",
      "6960/6960 [==============================] - 2s 280us/sample - loss: 1.0485 - acc: 0.5624 - val_loss: 0.8875 - val_acc: 0.6473\n",
      "Epoch 7/50\n",
      "6960/6960 [==============================] - 2s 280us/sample - loss: 0.9895 - acc: 0.5875 - val_loss: 0.8424 - val_acc: 0.6673\n",
      "Epoch 8/50\n",
      "6960/6960 [==============================] - 2s 285us/sample - loss: 0.9474 - acc: 0.6047 - val_loss: 0.7854 - val_acc: 0.7000\n",
      "Epoch 9/50\n",
      "6960/6960 [==============================] - 2s 274us/sample - loss: 0.8979 - acc: 0.6315 - val_loss: 0.7483 - val_acc: 0.7000\n",
      "Epoch 10/50\n",
      "6960/6960 [==============================] - 2s 266us/sample - loss: 0.8527 - acc: 0.6522 - val_loss: 0.7179 - val_acc: 0.7207\n",
      "Epoch 11/50\n",
      "6960/6960 [==============================] - 2s 263us/sample - loss: 0.8207 - acc: 0.6695 - val_loss: 0.6335 - val_acc: 0.7567\n",
      "Epoch 12/50\n",
      "6960/6960 [==============================] - 2s 266us/sample - loss: 0.7696 - acc: 0.6958 - val_loss: 0.5841 - val_acc: 0.7873\n",
      "Epoch 13/50\n",
      "6960/6960 [==============================] - 2s 274us/sample - loss: 0.7400 - acc: 0.7059 - val_loss: 0.5444 - val_acc: 0.7960\n",
      "Epoch 14/50\n",
      "6960/6960 [==============================] - 2s 289us/sample - loss: 0.6838 - acc: 0.7342 - val_loss: 0.5350 - val_acc: 0.7920\n",
      "Epoch 15/50\n",
      "6960/6960 [==============================] - 2s 292us/sample - loss: 0.6632 - acc: 0.7470 - val_loss: 0.5381 - val_acc: 0.7913\n",
      "Epoch 16/50\n",
      "6960/6960 [==============================] - 2s 270us/sample - loss: 0.6421 - acc: 0.7490 - val_loss: 0.4748 - val_acc: 0.8247\n",
      "Epoch 17/50\n",
      "6960/6960 [==============================] - 2s 282us/sample - loss: 0.6215 - acc: 0.7582 - val_loss: 0.4008 - val_acc: 0.8653\n",
      "Epoch 18/50\n",
      "6960/6960 [==============================] - 2s 283us/sample - loss: 0.5640 - acc: 0.7830 - val_loss: 0.3822 - val_acc: 0.8700\n",
      "Epoch 19/50\n",
      "6960/6960 [==============================] - 2s 268us/sample - loss: 0.5596 - acc: 0.7876 - val_loss: 0.3306 - val_acc: 0.8833\n",
      "Epoch 20/50\n",
      "6960/6960 [==============================] - 2s 270us/sample - loss: 0.5361 - acc: 0.7981 - val_loss: 0.2914 - val_acc: 0.9100\n",
      "Epoch 21/50\n",
      "6960/6960 [==============================] - 2s 269us/sample - loss: 0.4900 - acc: 0.8148 - val_loss: 0.3037 - val_acc: 0.8927\n",
      "Epoch 22/50\n",
      "6960/6960 [==============================] - 2s 275us/sample - loss: 0.4876 - acc: 0.8136 - val_loss: 0.2959 - val_acc: 0.8987\n",
      "Epoch 23/50\n",
      "6960/6960 [==============================] - 2s 276us/sample - loss: 0.4500 - acc: 0.8293 - val_loss: 0.2612 - val_acc: 0.9220\n",
      "Epoch 24/50\n",
      "6960/6960 [==============================] - 2s 269us/sample - loss: 0.4467 - acc: 0.8312 - val_loss: 0.2370 - val_acc: 0.9267\n",
      "Epoch 25/50\n",
      "6960/6960 [==============================] - 2s 273us/sample - loss: 0.4147 - acc: 0.8494 - val_loss: 0.1904 - val_acc: 0.9507\n",
      "Epoch 26/50\n",
      "6960/6960 [==============================] - 2s 275us/sample - loss: 0.3959 - acc: 0.8510 - val_loss: 0.1883 - val_acc: 0.9547\n",
      "Epoch 27/50\n",
      "6960/6960 [==============================] - 2s 285us/sample - loss: 0.3734 - acc: 0.8591 - val_loss: 0.1938 - val_acc: 0.9427\n",
      "Epoch 28/50\n",
      "6960/6960 [==============================] - 2s 274us/sample - loss: 0.3720 - acc: 0.8583 - val_loss: 0.1550 - val_acc: 0.9547\n",
      "Epoch 29/50\n",
      "6960/6960 [==============================] - 2s 270us/sample - loss: 0.3624 - acc: 0.8618 - val_loss: 0.1571 - val_acc: 0.9580\n",
      "Epoch 30/50\n",
      "6960/6960 [==============================] - 2s 277us/sample - loss: 0.3546 - acc: 0.8647 - val_loss: 0.1307 - val_acc: 0.9633\n",
      "Epoch 31/50\n",
      "6960/6960 [==============================] - 2s 279us/sample - loss: 0.3274 - acc: 0.8764 - val_loss: 0.1259 - val_acc: 0.9693\n",
      "Epoch 32/50\n",
      "6960/6960 [==============================] - 2s 281us/sample - loss: 0.3060 - acc: 0.8918 - val_loss: 0.1207 - val_acc: 0.9620\n",
      "Epoch 33/50\n",
      "6960/6960 [==============================] - 2s 278us/sample - loss: 0.3143 - acc: 0.8853 - val_loss: 0.0939 - val_acc: 0.9800\n",
      "Epoch 34/50\n",
      "6960/6960 [==============================] - 2s 282us/sample - loss: 0.2877 - acc: 0.8920 - val_loss: 0.0876 - val_acc: 0.9767\n",
      "Epoch 35/50\n",
      "6960/6960 [==============================] - 2s 285us/sample - loss: 0.2847 - acc: 0.8908 - val_loss: 0.1133 - val_acc: 0.9693\n",
      "Epoch 36/50\n",
      "6960/6960 [==============================] - 2s 292us/sample - loss: 0.3077 - acc: 0.8843 - val_loss: 0.1138 - val_acc: 0.9660\n",
      "Epoch 37/50\n",
      "6960/6960 [==============================] - 2s 286us/sample - loss: 0.2837 - acc: 0.8947 - val_loss: 0.0966 - val_acc: 0.9700\n",
      "Epoch 38/50\n",
      "6960/6960 [==============================] - 2s 286us/sample - loss: 0.2639 - acc: 0.9033 - val_loss: 0.0712 - val_acc: 0.9827\n",
      "Epoch 39/50\n",
      "6960/6960 [==============================] - 2s 300us/sample - loss: 0.2545 - acc: 0.9023 - val_loss: 0.0604 - val_acc: 0.9867\n",
      "Epoch 40/50\n",
      "6960/6960 [==============================] - 2s 289us/sample - loss: 0.2425 - acc: 0.9106 - val_loss: 0.0539 - val_acc: 0.9880\n",
      "Epoch 41/50\n",
      "6960/6960 [==============================] - 2s 277us/sample - loss: 0.2326 - acc: 0.9154 - val_loss: 0.0581 - val_acc: 0.9860\n",
      "Epoch 42/50\n",
      "6960/6960 [==============================] - 2s 275us/sample - loss: 0.2282 - acc: 0.9167 - val_loss: 0.0601 - val_acc: 0.9853\n",
      "Epoch 43/50\n",
      "6960/6960 [==============================] - 2s 272us/sample - loss: 0.2243 - acc: 0.9144 - val_loss: 0.0423 - val_acc: 0.9920\n",
      "Epoch 44/50\n",
      "6960/6960 [==============================] - 2s 282us/sample - loss: 0.1993 - acc: 0.9243 - val_loss: 0.0549 - val_acc: 0.9867\n",
      "Epoch 45/50\n",
      "6960/6960 [==============================] - 2s 276us/sample - loss: 0.2118 - acc: 0.9214 - val_loss: 0.0404 - val_acc: 0.9900\n",
      "Epoch 46/50\n",
      "6960/6960 [==============================] - 2s 281us/sample - loss: 0.2084 - acc: 0.9182 - val_loss: 0.0370 - val_acc: 0.9920\n",
      "Epoch 47/50\n",
      "6960/6960 [==============================] - 2s 285us/sample - loss: 0.2150 - acc: 0.9200 - val_loss: 0.0323 - val_acc: 0.9927\n",
      "Epoch 48/50\n",
      "6960/6960 [==============================] - 2s 279us/sample - loss: 0.2009 - acc: 0.9259 - val_loss: 0.0369 - val_acc: 0.9913\n",
      "Epoch 49/50\n",
      "6960/6960 [==============================] - 2s 291us/sample - loss: 0.1917 - acc: 0.9274 - val_loss: 0.0267 - val_acc: 0.9940\n",
      "Epoch 50/50\n",
      "6960/6960 [==============================] - 2s 274us/sample - loss: 0.1940 - acc: 0.9256 - val_loss: 0.0291 - val_acc: 0.9947\n",
      "6960/6960 [==============================] - 4s 513us/sample - loss: 0.0090 - acc: 0.9993\n",
      "1772/1772 [==============================] - 1s 496us/sample - loss: 1.0359 - acc: 0.6998\n",
      "train acc: 99.928%\n",
      "test acc: 69.977%\n",
      "=================250===================\n",
      "Model: \"sequential_73\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_288 (Conv2D)          (None, 250, 1, 100)       22100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_288 (MaxPoolin (None, 84, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_288 (Bat (None, 84, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_288 (Dropout)        (None, 84, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_289 (Conv2D)          (None, 84, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_289 (MaxPoolin (None, 28, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_289 (Bat (None, 28, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_289 (Dropout)        (None, 28, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_290 (Conv2D)          (None, 28, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_290 (MaxPoolin (None, 10, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_290 (Bat (None, 10, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_290 (Dropout)        (None, 10, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_291 (Conv2D)          (None, 10, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_291 (MaxPoolin (None, 4, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_291 (Bat (None, 4, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_291 (Dropout)        (None, 4, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_73 (Flatten)         (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 4)                 1604      \n",
      "=================================================================\n",
      "Total params: 325,604\n",
      "Trainable params: 324,804\n",
      "Non-trainable params: 800\n",
      "_________________________________________________________________\n",
      "Train on 6960 samples, validate on 1500 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "6960/6960 [==============================] - 11s 2ms/sample - loss: 1.9250 - acc: 0.3109 - val_loss: 3.9406 - val_acc: 0.3653\n",
      "Epoch 2/50\n",
      "6960/6960 [==============================] - 2s 292us/sample - loss: 1.5309 - acc: 0.3615 - val_loss: 1.8074 - val_acc: 0.4300\n",
      "Epoch 3/50\n",
      "6960/6960 [==============================] - 2s 297us/sample - loss: 1.3296 - acc: 0.4346 - val_loss: 1.1558 - val_acc: 0.5353\n",
      "Epoch 4/50\n",
      "6960/6960 [==============================] - 2s 301us/sample - loss: 1.2034 - acc: 0.4846 - val_loss: 1.0337 - val_acc: 0.5867\n",
      "Epoch 5/50\n",
      "6960/6960 [==============================] - 2s 296us/sample - loss: 1.1070 - acc: 0.5361 - val_loss: 0.9013 - val_acc: 0.6547\n",
      "Epoch 6/50\n",
      "6960/6960 [==============================] - 2s 308us/sample - loss: 1.0307 - acc: 0.5638 - val_loss: 0.8719 - val_acc: 0.6547\n",
      "Epoch 7/50\n",
      "6960/6960 [==============================] - 2s 288us/sample - loss: 0.9618 - acc: 0.6017 - val_loss: 0.8002 - val_acc: 0.6993\n",
      "Epoch 8/50\n",
      "6960/6960 [==============================] - 2s 293us/sample - loss: 0.9297 - acc: 0.6198 - val_loss: 0.7525 - val_acc: 0.7040\n",
      "Epoch 9/50\n",
      "6960/6960 [==============================] - 2s 299us/sample - loss: 0.8678 - acc: 0.6540 - val_loss: 0.7051 - val_acc: 0.7320\n",
      "Epoch 10/50\n",
      "6960/6960 [==============================] - 2s 294us/sample - loss: 0.8090 - acc: 0.6740 - val_loss: 0.6729 - val_acc: 0.7433\n",
      "Epoch 11/50\n",
      "6960/6960 [==============================] - 2s 297us/sample - loss: 0.7914 - acc: 0.6809 - val_loss: 0.6215 - val_acc: 0.7667\n",
      "Epoch 12/50\n",
      "6960/6960 [==============================] - 2s 301us/sample - loss: 0.7606 - acc: 0.6958 - val_loss: 0.5491 - val_acc: 0.7973\n",
      "Epoch 13/50\n",
      "6960/6960 [==============================] - 2s 299us/sample - loss: 0.6978 - acc: 0.7302 - val_loss: 0.5333 - val_acc: 0.7900\n",
      "Epoch 14/50\n",
      "6960/6960 [==============================] - 2s 308us/sample - loss: 0.6780 - acc: 0.7376 - val_loss: 0.4666 - val_acc: 0.8333\n",
      "Epoch 15/50\n",
      "6960/6960 [==============================] - 2s 299us/sample - loss: 0.6332 - acc: 0.7576 - val_loss: 0.4315 - val_acc: 0.8513\n",
      "Epoch 16/50\n",
      "6960/6960 [==============================] - 2s 301us/sample - loss: 0.6217 - acc: 0.7537 - val_loss: 0.4024 - val_acc: 0.8687\n",
      "Epoch 17/50\n",
      "6960/6960 [==============================] - 2s 305us/sample - loss: 0.5653 - acc: 0.7807 - val_loss: 0.3828 - val_acc: 0.8680\n",
      "Epoch 18/50\n",
      "6960/6960 [==============================] - 2s 293us/sample - loss: 0.5563 - acc: 0.7861 - val_loss: 0.3400 - val_acc: 0.8880\n",
      "Epoch 19/50\n",
      "6960/6960 [==============================] - 2s 294us/sample - loss: 0.5180 - acc: 0.8020 - val_loss: 0.3115 - val_acc: 0.9033\n",
      "Epoch 20/50\n",
      "6960/6960 [==============================] - 2s 296us/sample - loss: 0.5167 - acc: 0.7999 - val_loss: 0.2874 - val_acc: 0.9093\n",
      "Epoch 21/50\n",
      "6960/6960 [==============================] - 2s 311us/sample - loss: 0.5007 - acc: 0.8121 - val_loss: 0.2570 - val_acc: 0.9160\n",
      "Epoch 22/50\n",
      "6960/6960 [==============================] - 2s 318us/sample - loss: 0.4541 - acc: 0.8266 - val_loss: 0.2409 - val_acc: 0.9153\n",
      "Epoch 23/50\n",
      "6960/6960 [==============================] - 2s 318us/sample - loss: 0.4511 - acc: 0.8283 - val_loss: 0.1988 - val_acc: 0.9447\n",
      "Epoch 24/50\n",
      "6960/6960 [==============================] - 2s 310us/sample - loss: 0.4083 - acc: 0.8435 - val_loss: 0.1908 - val_acc: 0.9513\n",
      "Epoch 25/50\n",
      "6960/6960 [==============================] - 2s 314us/sample - loss: 0.4131 - acc: 0.8466 - val_loss: 0.2131 - val_acc: 0.9320\n",
      "Epoch 26/50\n",
      "6960/6960 [==============================] - 2s 303us/sample - loss: 0.3981 - acc: 0.8534 - val_loss: 0.1633 - val_acc: 0.9600\n",
      "Epoch 27/50\n",
      "6960/6960 [==============================] - 2s 306us/sample - loss: 0.3701 - acc: 0.8596 - val_loss: 0.1577 - val_acc: 0.9553\n",
      "Epoch 28/50\n",
      "6960/6960 [==============================] - 2s 301us/sample - loss: 0.3511 - acc: 0.8665 - val_loss: 0.1139 - val_acc: 0.9767\n",
      "Epoch 29/50\n",
      "6960/6960 [==============================] - 2s 305us/sample - loss: 0.3325 - acc: 0.8726 - val_loss: 0.1291 - val_acc: 0.9667\n",
      "Epoch 30/50\n",
      "6960/6960 [==============================] - 2s 313us/sample - loss: 0.3401 - acc: 0.8708 - val_loss: 0.1271 - val_acc: 0.9673\n",
      "Epoch 31/50\n",
      "6960/6960 [==============================] - 2s 308us/sample - loss: 0.3227 - acc: 0.8799 - val_loss: 0.1014 - val_acc: 0.9753\n",
      "Epoch 32/50\n",
      "6960/6960 [==============================] - 2s 308us/sample - loss: 0.3113 - acc: 0.8843 - val_loss: 0.0868 - val_acc: 0.9853\n",
      "Epoch 33/50\n",
      "6960/6960 [==============================] - 2s 308us/sample - loss: 0.2978 - acc: 0.8898 - val_loss: 0.0880 - val_acc: 0.9787\n",
      "Epoch 34/50\n",
      "6960/6960 [==============================] - 2s 312us/sample - loss: 0.2931 - acc: 0.8856 - val_loss: 0.0794 - val_acc: 0.9827\n",
      "Epoch 35/50\n",
      "6960/6960 [==============================] - 2s 316us/sample - loss: 0.2850 - acc: 0.8950 - val_loss: 0.0743 - val_acc: 0.9880\n",
      "Epoch 36/50\n",
      "6960/6960 [==============================] - 2s 312us/sample - loss: 0.2660 - acc: 0.9014 - val_loss: 0.0605 - val_acc: 0.9913\n",
      "Epoch 37/50\n",
      "6960/6960 [==============================] - 2s 302us/sample - loss: 0.2439 - acc: 0.9079 - val_loss: 0.0653 - val_acc: 0.9893\n",
      "Epoch 38/50\n",
      "6960/6960 [==============================] - 2s 305us/sample - loss: 0.2440 - acc: 0.9101 - val_loss: 0.0570 - val_acc: 0.9873\n",
      "Epoch 39/50\n",
      "6960/6960 [==============================] - 2s 307us/sample - loss: 0.2480 - acc: 0.9109 - val_loss: 0.0509 - val_acc: 0.9913\n",
      "Epoch 40/50\n",
      "6960/6960 [==============================] - 2s 295us/sample - loss: 0.2410 - acc: 0.9115 - val_loss: 0.0447 - val_acc: 0.9927\n",
      "Epoch 41/50\n",
      "6960/6960 [==============================] - 2s 302us/sample - loss: 0.2386 - acc: 0.9103 - val_loss: 0.0466 - val_acc: 0.9920\n",
      "Epoch 42/50\n",
      "6960/6960 [==============================] - 2s 302us/sample - loss: 0.2335 - acc: 0.9122 - val_loss: 0.0386 - val_acc: 0.9913\n",
      "Epoch 43/50\n",
      "6960/6960 [==============================] - 2s 302us/sample - loss: 0.2302 - acc: 0.9159 - val_loss: 0.0389 - val_acc: 0.9920\n",
      "Epoch 44/50\n",
      "6960/6960 [==============================] - 2s 305us/sample - loss: 0.2135 - acc: 0.9224 - val_loss: 0.0625 - val_acc: 0.9787\n",
      "Epoch 45/50\n",
      "6960/6960 [==============================] - 2s 298us/sample - loss: 0.2161 - acc: 0.9217 - val_loss: 0.0292 - val_acc: 0.9960\n",
      "Epoch 46/50\n",
      "6960/6960 [==============================] - 2s 299us/sample - loss: 0.2024 - acc: 0.9272 - val_loss: 0.0259 - val_acc: 0.9953\n",
      "Epoch 47/50\n",
      "6960/6960 [==============================] - 2s 294us/sample - loss: 0.2001 - acc: 0.9260 - val_loss: 0.0282 - val_acc: 0.9947\n",
      "Epoch 48/50\n",
      "6960/6960 [==============================] - 2s 308us/sample - loss: 0.1922 - acc: 0.9295 - val_loss: 0.0270 - val_acc: 0.9940\n",
      "Epoch 49/50\n",
      "6960/6960 [==============================] - 2s 300us/sample - loss: 0.2037 - acc: 0.9233 - val_loss: 0.0259 - val_acc: 0.9967\n",
      "Epoch 50/50\n",
      "6960/6960 [==============================] - 2s 329us/sample - loss: 0.2073 - acc: 0.9227 - val_loss: 0.0282 - val_acc: 0.9953\n",
      "6960/6960 [==============================] - 4s 518us/sample - loss: 0.0092 - acc: 0.9996\n",
      "1772/1772 [==============================] - 1s 490us/sample - loss: 1.0378 - acc: 0.7246\n",
      "train acc: 99.957%\n",
      "test acc: 72.460%\n"
     ]
    }
   ],
   "source": [
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "for time in range(25, 251, 25):\n",
    "    print(\"=================\" + str(time) + \"===================\")\n",
    "    train_score, test_score = train_data(time_period=time)\n",
    "    train_scores.append(train_score[1])\n",
    "    test_scores.append(test_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracies: \n",
      "[0.92298853, 0.9836207, 0.99094826, 0.9946839, 0.99971265, 0.99956894, 0.9987069, 0.9982759, 0.9992816, 0.99956894]\n",
      "Test accuracies: \n",
      "[0.38826185, 0.5248307, 0.59424376, 0.6444695, 0.6743792, 0.69808125, 0.6918736, 0.7020316, 0.69977427, 0.72460496]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXgUVfbw8e/JTggkQNgDBBVlk0UDioiiiIIbroj7NiKjoDP+cEQdFVRmGETHcVwQHVzQV8SdTUUURWUNyiIospOwGZYEQvbkvn/cSlJpOp0GknTSOZ/n6ae7696uOnW7+vTtW9VVYoxBKaVU7RcS6ACUUkpVDk3oSikVJDShK6VUkNCErpRSQUITulJKBQlN6EopFSTqXEIXkbEi8k4Vzn+tiPR3HouIvCEiB0RkmYj0E5H1VbDMtiKSKSKhlT3v2kxEbhSReYGOozqIyOcicmug4zgax/N5EJHbROSHCur8KCI9jy26YyMil4vI9OpcpltQJnQRuUFEkp0kt8vZ2M+ujmUbY7oYY751np4NDAQSjDG9jTHfG2NOOd5liMhWEbnAtcztxpgYY0zh8c67nOWJiGwWkXVVMf+qYox51xhzYaDjqAxORyHTuRWKSI7r+SPGmMHGmLeqIY7bnOVnishBEVkpIpcey7wq6/PgjYhcBhwyxvzsmnayiHwgIntFJENEVovIAyISKiKJImJEZI7HfN4RkbHO4/5OnZc86vwgIrc56zQT6Coi3apivSoSdAldRB4Angf+ATQH2gIvA0MCEE47YKsx5nAAll2ZzgGaASeISK/qXLCIhFXn8moKz19bTkchxhgTA3wPjCx+boz5RzWHt9iJIw74HzBDRBofzQyq4X0dAUxzLe9EYCmQApxqjIkFrgWSgAau150pIn19zPcwcIuIJPqo8x4w/NjCPk7GmKC5AbFAJnCtjzpjgXdczz8AdgMZwEKgi6vsYmAdcAjYAYx2pscDs4F0YD/2AxbilG0FLgDuBHKAQiemcUB/INU1/zbAx0AasA940Zl+IvCNM20v8C4Q55RNA4qAbGe+fwMSAQOEOXVaATOd2DYCd3ms/wzgbWe91gJJFbTrVCeGj4tjdJV1Ab5ylrUHeMSZHgo8AmxylrPCWd8ysTp1vwX+5Dy+DfgR+Lczz6d9tUcF7Xgb8IOrXkdXrOuBoRW9117aIgT4O7AN+MNpx1in7AtsonXXXwVc5cfy3wReAeZik8YFPt6Pkvbyow3Tgc3AWc70FCfuW12vjQQmAdud93AyUK+cZXu2aX3n/UzyNR+cbR94CPt5m8aRn4dOznqkY7fLy11lTbDb9EFgGfCUOw6PGCOwn48E17R3gDk+2jTRWY+HgAUerxvrsQ7/Bd5w1fkBuM31vC+wpbrznzEm6BL6IKAAV7LwUmcsZRP6Hdhv6Ehsz36lq2wX0M953Ag4zXn8T2djDXdu/QBxyrYWfxi9bPwlGzA24a1yPnT1gSjgbKfsJOxQTSTQFPtF87xrPiXL8NgYixP6d9hfJVFAD2yiG+Ba/xxsAgt11mWJj/aKdj5EFwNXYxNqhFPWwGmj/3OW1QA4wyl7EFgDnAII0B37oSwTq1P3W8omowJgFBAG1PPVHhW0Y0n7O2UpwO3OfE9z1qWLr/faS3vcgf2SPAGIwX6RTHPKbgF+dNXtjE1OkX4s/01sp6Iv9ksjysd7UtJeFbTh7U77PI1Nsi85sVyI/eKKceo/j02WjZ33cBbwz3KW7W7TMOB+Z16xvuaD3fYLgH85MdSj7Och3GnXR7AJ+Xxnvqc45dOxHZH6QFfsl255Cb0LcNhj2m7gdh9tmojdLmOceRd/hr0l9BbYz0RxbJ4JvbEzr4bVngOre4FVujJwI7C7gjpjcSV0j7I4540o7nFtB+72fGOAJ4HPgJO8zGMr/iX0PthEW+6Xj+t1VwA/e1uGx8YYhu2tFgINXOX/BN50rf98V1lnINvHsm8qjtP5IKYDVzpl17vj8njdemCIl+klsbqmfUvZZLTd3/bw1Y6UTT7XAd97lL8KPOHrvfYyz6+Be1zPTwHynfZpgO1dt3PKxgNT/Vz+m8Dbfm7nJe3low03uMpOddq8uWvaPuyXvTgxn+gq60M5PUxKvyzSsV9IS7C/SH3OB7vt5+H6oqLs56EfNumGuMrfw26voU4bd3SV/YPyE3pfPPKA8/pBPtq0ZLsE7sHp5OAloTuPJwLvO489E3q4M6+2/ryflXkLtjH0fUC8v+Nzzs6QCSKySUQOYhMl2CEVsD3Si4FtIvKdiPRxpj+D7U3Mc3YWjjmGWNsA24wxBV7iaiYi00VkhxPXO66YKtIK2G+MOeSatg1o7Xq+2/U4C4jy0Wa3AjOMMQXGmFxsj/RW1zpsKud1vsoqkuJ+UkF7lNuOHtoBZ4hIevEN2wFo4ZSX9157aoVtz2LbsEmgudPmc4BhTtkw7PCQP8s/Yr2P0x7X42wAY4zntBjsL55oYIUrri+c6eVZYoyJM8bEG2PONMbM93M+acaYnHLm2QpIMcYUuaYVb7dNsW2c4lFWngOUHRcHmxta+niN22tAc2fHann+BVwkIt29lBUvO93P5VWaYEvoi7HDCVf4Wf8G7M7SC7A/GROd6QJgjFlujBmC3SH4KfYnH8aYQ8aY/zPGnABcBjwgIgOOMtYUoG05ifSf2G/4bsaYhthesrjKjY/57gQai4h7g26L/Rl5VEQkAfvT9yYR2S0iu4FrgItFJN5ZhxPLeXl5ZcU7iKNd01p41PFcP1/t4asdPeP5zklExbcYY8yfofz32oud2ORcrC22x1qcLN8Drne+EOoBC/xZfjnrXR32YpN7F1dcscbu9Kzs+VS03bYREXdOKt5u07Bt3MajrDwbsAdnuTsx87Ff2hUyxuRj93k9RdnPnbvOPuwQ01NeijthD4Y46M/yKlNQJXRjTAbwOPCSiFwhItEiEi4ig0VkopeXNABysd/e0difcQCISIRzHHOs8wYfxA5lICKXishJIiKu6Ud7yOAy7LjtBBGpLyJRrr3rDbA7PNOdjfJBj9fuwY7hemuDFGAR8E9nnt2wO2jf9Va/AjcDv2OHFXo4t5Ox44jXY3cMtxCRv4hIpIg0EJEznNe+DjwlIh2cwx67iUgTY0wa9kN6k/ML6Q7K/1Io5qs9fLWj22zgZBG52dkmwkWkl4h08vVee/Ee8FcRaS8iMdht5n3XL4S52IT/pDO9uMdZ7vIrWPcq5cT3GvBvEWkGICKtReSiap7PUuyX/d+ctumP7SxNN/Zw3I+Bsc5nujOlvxK9xZKPTeDnuiY/AZwlIs+ISAsnvpPEHpYY52U207BDjIN8xPwcdmez53t4LvC5j9dVmaBK6ADGmOeAB7BHIqRhe0Yjsb0uT29jf7rtwB7hsMSj/GZgq/MzfwS2ZwjQAbvBZGJ/FbxsSo899zfOQuwGexJ2/DYVO84KtndwGnYn2Rzsxuz2T+Dvzk/b0V5mfz3218ZO4BPsOO1XRxOf41bsuu1237A7hG91hhgGOuuxG9szOs957XPYXu48bIL8H7bHCnAXNinvw+7AWlRBHOW2RwXtiKveIezOwGHYdtlN6Q46KP+99jQV+2FfCGzB/iIc5VpO8bDUBcD/O4rlB9JD2CHEJc76z8d+iVfbfIwxecDlwGBsb/9l4BZjzG9OlZHYIaLd2P0Nb1Qwy1ex72nx/Ddhx/QTgbUikgF8BCRjd756xlOI/RIo93BMpwc+0Uud653lV7viIzOUUiqoiP0n6Sjj+nNRNSzzMuBmY8zQ6lpmmeVrQldKqeAQdEMuSilVV2lCV0qpIKEJXSmlgkTATnwUHx9vEhMTA7V4pZSqlVasWLHXGOP1j18BS+iJiYkkJycHavFKKVUriUi5/5LVIRellAoSmtCVUipIaEJXSqkgoQldKaWChCZ0pZQKEhUmdBGZKiJ/iMgv5ZSLiLwgIhvFXnT1tMoPUymlVEX86aG/ie9TSA7Gnn2wA/bCqK8cf1hKKaWOVoXHoRtjForvK1wPwV46y2BPmxknIi2NMbsqKUalyC8s4nBuAYfzCsnKLSAzt4CsvEJnWgGHcwvJcu7LnHBOSq9P4L5SQfFkcU11VfVa1z4+8noHZV9X+iQ0BEJEEBFCxD4OEZznQmhI6ePicimp57s8NKRs3dL5li0XnHv345KYS+dRPK24TvF6iZcy56Ue8ytbj5JllrZZkTEUFRmKTNnHhSWPnedF9nJqdrpT17PMPR/nuXGel1dWWGQwOJfdLH6TDBQ/M6b0ChzGmV68KZniic7jkumueRW/3r39lb6+7Lx6tInjzBOaHLEtHa/K+GNRa8peGirVmXZEQheR4dhePG3b+rrgiKrNCosMh/MKyMotdJJtacItk4iLk7CTiA87ZbaOM82ZT15hUcULdhQnJD2RqKqpRpx7Yo1N6N4u0eT1o2SMmQJMAUhKStKPWzUqKCwip6CInPxC52Yf5xYUkp3nTC8onW7L7OPsPM+yInILbJ1s17yy82wCzsn3P/lGhYdQPyKM6MhQ6keEUT8yjAZRYbSMjSI6Ioz6kaFER4QR49zXjwylfmSYfU2E8zgyjPrO43rhoYSEeL1qWIniHpQ74Rsv5UdOd9c/ch541HX3LI0p22t09zxL6+I8NxT6KC/y6IH6KjdOeXGvsrin6O5JmpK6lO3BHlG/7HOMKZ3ufuwx7+K2cv+asL8g7C+JEHH/KrG9fju9orKy8wrxLAuBUDlyOcVKf4mU/q4q+YUBZX6N2DvXrxdKf3mIe16uXye+6oWFVM3xKJWR0FMpe62/BOwVWdRxKigs4mBOAelZeaRn55ORlU96dp5zn096Vj4Z2fkcyilwErOXxOsk6vzCY/v+DBGICg+1t7AQoiJCiQoLJSo8hKjwUBpEhdvHYaElSdmdeKMjQomJDPNIzjaBR4eHEhZa/QdalXzAys37vr8QlKqpKiOhzwRGish04AwgQ8fPy8otKCxJwhlOIk7Pyit9nJ1Xkpzdzw/l+L6QfcOoMOKiI4iJDCtJsA3rlSZYz+Rbcl9SFlKarMuUlT4ODxWv48ZKqZqnwoQuIu8B/YF4EUnFXmcvHMAYMxl7UdyLsdcSzAJur6pga5L0rDyWbN7HgazSJJyR5T1BZ+eXf/3o0BAhtl44cfXCiY0OJz4mgpOaxdhp0XZ6XHQEsa7HcfXCaVgvnNAKhhaUUnWLP0e5XF9BuQHurbSIariCwiL+37LtPPfV76Rn5ZdMjwgNsQk4Opy4ehG0aRzNqcVJOTrClaAjiIsOL3keExmmPWClVKUI2Olza6MfN+5l3Ky1/L4nkz4nNOGBC08moVE94upFEBUeoolZKRVQmtD9sH1fFuPnruPLtXto07gek286nYu6NNcErpSqUTSh+3A4t4CXv93Ia99vIVSEBy86hTvPbk9UeGigQ1NKqSNoQveiqMjw6codTPj8N/44lMuVPVvz0KCOtIiNCnRoSilVLk3oHlampDNu1lp+3p5O94RYXrnpdE5v1yjQYSmlVIU0oTv+OJjDxC/X8+GKVOJjInnmmm5cfVpChf86VEqpmqLOJ/TcgkKm/rCVF7/ZQF5hEXefewIjzzuJBlHhgQ5NKaWOSp1N6MYY5v/6B0/PWce2fVlc0Kk5j17Sifbx9QMdmlJKHZM6mdA37DnEk7PX8f2GvZzULIa37ujNuSc3DXRYSil1XOpUQs/Iyuff839n2pJtREeE8vilnbm5TzvCA3CCKKWUqmx1IqEXFhneW7adZ+etJyM7n+t7t+WBgSfTJCYy0KEppVSlCfqEvnjTPsbNWstvuw/Ru31jnrisM11axQY6LKWUqnRBm9BT9mfxz89/Ze6a3bSOq8dLN5zGxae20L/rK6WCVtAl9Ky8AiZ/u4lXF25GBB4YeDLDzzlB/66vlAp6QZPQjTHMXLWTCZ//xq6MHC7v3ooxgzvSKq5eoENTSqlqERQJfU1qBuNmrSV52wG6tGrIC9f3pFdi40CHpZRS1apWJ/S0Q7lM+nI9M1ak0KR+BP+6+lSuOb2NXslHKVUn1cqEnldQxFuLtvLC1xvIzi/kT2e3Z9SADjTUv+srpeqwWpfQk7fu528frmbz3sOcd0pT/n5pZ05sGhPosJRSKuBqXUKPDAslJER447ZenNexWaDDUUqpGqPWJfRTE2KZ95dz9LS2SinloVaexESTuVJKHalWJnSllFJH8iuhi8ggEVkvIhtFZIyX8kYi8omIrBaRZSLStfJDVUop5UuFCV1EQoGXgMFAZ+B6EensUe0RYKUxphtwC/Cfyg5UKaWUb/700HsDG40xm40xecB0YIhHnc7A1wDGmN+ARBFpXqmRKqWU8smfhN4aSHE9T3Wmua0CrgIQkd5AOyDBc0YiMlxEkkUkOS0t7dgiVkop5ZU/Cd3bISXG4/kEoJGIrARGAT8DBUe8yJgpxpgkY0xS06Z6yTellKpM/hyHngq0cT1PAHa6KxhjDgK3A4g94fgW56aUUqqa+NNDXw50EJH2IhIBDANmuiuISJxTBvAnYKGT5JVSSlWTCnvoxpgCERkJfAmEAlONMWtFZIRTPhnoBLwtIoXAOuDOKoxZKaWUF3799d8YMxeY6zFtsuvxYqBD5YamlFLqaOg/RZVSKkhoQldKqSChCV0ppYKEJnSllAoSmtCVUipIaEJXSqkgoQldKaWChCZ0pZQKEprQlVIqSGhCV0qpIKEJXSmlgoQmdKWUChKa0JVSKkhoQldKqSChCV0ppYKEJnSllAoSmtCVUipIaEJXSqkgoQldKaWChCZ0pZQKEprQlVIqSGhCV0qpIKEJXSmlgoQmdKWUChJ+JXQRGSQi60Vko4iM8VIeKyKzRGSViKwVkdsrP1SllFK+VJjQRSQUeAkYDHQGrheRzh7V7gXWGWO6A/2BZ0UkopJjVUop5YM/PfTewEZjzGZjTB4wHRjiUccADUREgBhgP1BQqZEqpZTyyZ+E3hpIcT1Pdaa5vQh0AnYCa4D7jTFFnjMSkeEikiwiyWlpaccYslJKKW/8SejiZZrxeH4RsBJoBfQAXhSRhke8yJgpxpgkY0xS06ZNjzpYpZRS5fMnoacCbVzPE7A9cbfbgY+NtRHYAnSsnBCVUkr5w5+EvhzoICLtnR2dw4CZHnW2AwMARKQ5cAqwuTIDVUop5VtYRRWMMQUiMhL4EggFphpj1orICKd8MvAU8KaIrMEO0TxkjNlbhXErpZTyUGFCBzDGzAXmekyb7Hq8E7iwckNTSil1NPSfokopFSQ0oSulVJDQhK6UUkFCE7pSSgUJTehKKRUkNKErpVSQ0ISulFJBQhO6UkoFCU3oSikVJDShK6VUkNCErpRSQUITulJKBQlN6EopFSQ0oSulVJDQhK6UUkFCE7pSSgUJTehKKRUk/LpikVJKqeOUnQ4py2D7ImhzJpwyqNIXoQldKaWqwsFdNnlvWwzbF8OetYCBkDA4J0oTulJK1UjGwL6NsG2RTd7bFkH6NlsWXh/a9IL+D0O7PtD6dIioXyVhaEJXSqmjVVgAu1eXJu/tSyBrry2Ljoe2Z8IZd9v7Ft0gNLxawtKErpRSFcnLgh3JzvDJIkhZDvmHbVlcO+gwENr2gXZnQZOTQCQgYWpCV0opT1n7ba97u9P73rkSivIBgeZdoMcNdvikbR9o2CrQ0ZbwK6GLyCDgP0Ao8LoxZoJH+YPAja55dgKaGmP2V2KsSilVNdJTyg6fpP1qp4dGQKvT4KyR0PYsaNMb6sUFNlYfKkzoIhIKvAQMBFKB5SIy0xizrriOMeYZ4Bmn/mXAXzWZK1XHFeRB5h57yz1kk2NouL2FhDvPw+x9SHhpWfHzkCr6m0xREexdX7oDc/sSyEixZZENbdI+9Ro7fNLqNAiPqpo4qoA/PfTewEZjzGYAEZkODAHWlVP/euC9yglPKVXj5GbaJH1oN2TuhkN7XPd7Ssuyj7NPJ6GuBB/m+wvBnzoh4bB/M6QsgewDdhkxze2wyVmj7H3zLhASevxtFCD+JPTWQIrreSpwhreKIhINDAJGllM+HBgO0LZt26MKVKkaLWMHpCy1fxxJWWqPOQ6LhKhY2+uLalh6f8S0WO/1ImKqb+eaMXbcOHO3k6iLE/OeI5N28c5At9AImxxjmkPjE2xybNACYppBTAu7PoX59laUD4V5Xp4X2Pui/NKywjwoKvCvft5hKDzgo36+ja/jJXb4pF0faNQ+YDswq4I/Cd3b2ppy6l4G/FjecIsxZgowBSApKam8eShVsxXmw+41pck7ZRkcTLVlYVH2OONefwJTCDkHIfcg5GTAoV32p37xtKIC38uRUIhs4CT52HK+DDynedQLDYfMP8r2nN33JUl7j7PTz0NEA5uUG7SAlj3g5BY2KTbwuK/XKKgSY23lT0JPBdq4nicAO8upOwwdblHBJmt/2eS9YwUUZNuyhq3tmGubkfbe32OOjYH8LFfCPwi5GTbxl5nm3Odk2MfpKU49p8wUHds6RTexPecGzSH+ZO9JOqY5RMYc2/xVQPiT0JcDHUSkPbADm7Rv8KwkIrHAucBNlRqhUtWpqAj2/m6Td+oym8D3/m7LQsJswj79NieJ94bYhGNbjoj9t2BEfaDlsc3DGMjL9J74i+8L8qB+vJOknQRevxmERRzbMlWNVmFCN8YUiMhI4EvsYYtTjTFrRWSEUz7ZqXolMM8Y42WATakaKjfT9riLe+Cpy2wyBKjXGNqcAd2vt/etekJEdGDjdROxQzKRDbC7ulRdJ8YEZig7KSnJJCcnB2TZqo4yBtK3u4ZPlsKeX0qHLZp2cnreZ9hbkxN1XFjVOCKywhiT5K1M/ymqgldBnj3fRnHyTllmd0yCPWFSQhL0G22Td8LpdseeUrWYJnQVPHIPwZbv7XHGKctgx09QmGvL4tpBYr/SHnizzvb4ZKWCiG7RqvYyBtJ+gw1fwcav7ImTivLtMdEte0Dvu5zhk952p6BSQU4TuqpdcjNhy3dOEp9f+pftZp3hzD/bs94l9K5Vf9dWqrJoQlc1mzGQth42zCvbC4+IgRP6wzmj4aQLjv3wQaWCiCZ0VfP40wtvc6YeS62UB03oKvCKe+Ebv7I9cc9eeL//s0lce+FK+aQJXQVGbiZsWegMpbh64U07wZkjoMOF2gtX6ihpQlfVo0wv/Ct7HurCPNsLb3+u7YWfdAHEtal4XkoprzShq6pT3Avf+BVsmA8Z2+30pp3sBXRPcq7DqL1wpSqFJnRVeYyxJ7La4IyFF/fCw+s7Y+F/tUlce+FKVQlN6Or4ZaTCkldg3UxXL7wj9B5eejX0sMjAxqhUHaAJXR27fZvgh3/DqumAsb3vfn91xsL1ilRKVTdN6Oro7VkH3z8Laz+212k8/Tboe58mcaUCTBO68t+OFbDwWVg/xx6d0mekvTVoHujIlFJoQlcVMQa2/QgLJ8HmBRAVB+eOsUepRDcOdHRKKRdN6Mo7Y+zRKt8/a09HW78ZXDAOet3pXCFHKVXTaEJXZRUVwa8zbSLfvRoaJsDgZ+C0myG8XqCjU0r5oAldWYX5sOZD+OE5eyx54xNhyEtw6lD9449StYQm9LouPwdWvgs/Pm+vt9m8K1wzFTpfASGhgY5OKXUUNKHXVXmHIfkNWPRfyNwNrZNg8EQ4eZBeGFmpWkoTel2TnQ7LXoMlL0P2fnudzatetSfI0kSuVK2mCb2uyEyDJS/Bstch7xB0uMhe7adN70BHppSqJH4ldBEZBPwHCAVeN8ZM8FKnP/A8EA7sNcacW4lxqmOVsQMWvQAr3oKCHOg8xJ6qtmW3QEemlKpkFSZ0EQkFXgIGAqnAchGZaYxZ56oTB7wMDDLGbBeRZlUVsPLTvk12R+fK9wAD3a6Ds/8K8R0CHZlSqor400PvDWw0xmwGEJHpwBBgnavODcDHxpjtAMaYPyo7UOWnPevsoYe/fOScZ+VWOOs+aNQu0JEppaqYPwm9NZDiep4KnOFR52QgXES+BRoA/zHGvO05IxEZDgwHaNtWT+RUqXasgO+fg99m2/OP97nXOc9Ki0BHppSqJv4kdG+HPhgv8zkdGADUAxaLyBJjzO9lXmTMFGAKQFJSkuc81LFIXQHfPOWcZyUWzn0Izhih51lRqg7yJ6GnAu5LzCQAO73U2WuMOQwcFpGFQHfgd1TVyM+Gb56GxS9B/Xi4YCwk3QlRDQMdmVIqQPxJ6MuBDiLSHtgBDMOOmbt9BrwoImFABHZI5t+VGahy2b4EPrsX9m2EpDvsSbM0kStV51WY0I0xBSIyEvgSe9jiVGPMWhEZ4ZRPNsb8KiJfAKuBIuyhjb9UZeB1Ul6WHV5Z8grEtoFbPrPX6lRKKUCMCcxQdlJSkklOTg7IsmulbYtsr3z/Zuj1JzvEoqexVarOEZEVxpgkb2X6T9GaLu8wfP0kLH3VXuLt1lnQ/pxAR6WUqoE0oddkW3+wvfIDW6H3cBjwBETGBDoqpVQNpQm9JsrNhK/HwbIp0CgRbpsDiWcHOiqlVA2nCb2m2bIQPhtpz01+xp9hwGMQUT/QUSmlagFN6DVF7iH46glI/h80PgFunwvtzgp0VEqpWkQTek2w+Vv4bBRkpMCZ98L5f4eI6EBHpZSqZTShB1LOQfjqcVjxBjQ5Ce74Etp6niZHKaX8owk9UDZ9AzPvg4xUOGsUnPcohNcLdFRKqVpME3p1y8mAeY/BT29Bkw5w5zy9apBSqlJoQq9OG+bDrPvg0C7oez/0f1h75UqpSqMJvTpkp8O8R+HndyD+FLjzK0jw+s9dpZQ6ZprQq9rv82DW/ZC5G85+wJ6vPDwq0FEppYKQJvSqkn0AvnwUVr4LTTvBsHeg9emBjkopFcQ0oVeF9V/A7L9A5h/QbzSc+zcIiwx0VEqpIKcJvTJl7YcvHobV06FZF7j+PWjVM9BRKaXqCE3oleW3ubZXnrUPzvkbnPMghEUEOiqlVB2iCf14Ze2Hzx+CNTOg+alw4wfQsnugo1JK1UGa0I/Hr7Nh9l8he789pvzsB7RXrpQKGE3ox+q7ibBgPLQ4FW7+2N4rpVQAaUI/Fhu+ssm823Uw5CUIDQ90REopRUigA6h10lPg47ugeV/vRVwAABL/SURBVFe47D+azJVSNYYm9KNRkAcf3ApFhTD0bT0Pi1KqRtEhl6Mx7++wYwUMnQZNTgx0NEopVYb20P31y0ew7FXoMxI6Xx7oaJRS6gh+JXQRGSQi60Vko4iM8VLeX0QyRGSlc3u88kMNoLTf7cUo2pwBF4wNdDRKKeVVhUMuIhIKvAQMBFKB5SIy0xizzqPq98aYS6sgxsDKOwwzboawKLj2Td0JqpSqsfzpofcGNhpjNhtj8oDpwJCqDauGMAZm/QXS1sPVr0PDVoGOSCmlyuVPQm8NpLiepzrTPPURkVUi8rmIdPE2IxEZLiLJIpKclpZ2DOFWsxVv2L/0n/cInHheoKNRSimf/Eno4mWa8Xj+E9DOGNMd+C/wqbcZGWOmGGOSjDFJTZs2PbpIq9vOn+05Wk4cYE+Bq5RSNZw/CT0VaON6ngDsdFcwxhw0xmQ6j+cC4SISX2lRVrfsAzDjFqjfDK56DUL0YCClVM3nT6ZaDnQQkfYiEgEMA2a6K4hICxER53FvZ777KjvYalFUBJ+MgIO77E7Q+k0CHZFSSvmlwqNcjDEFIjIS+BIIBaYaY9aKyAinfDJwDfBnESkAsoFhxhjPYZnaYdF/4PcvYPBEaNMr0NEopZTfJFB5NykpySQnJwdk2eXa8j28fTl0vgKumQribfeBUkoFjoisMMYkeSvTweFih3bDh3dA4xPh8hc0mSulah09lwtAYQF8eCfkZcKtMyGyQaAjUkqpo6YJHeCbp2DbD3Dlq9CsU6CjUeqY5efnk5qaSk5OTqBDUccpKiqKhIQEwsP9/3e6JvTf5sKPz8Ppt0P3YYGORqnjkpqaSoMGDUhMTER02LDWMsawb98+UlNTad++vd+vq9tj6Pu3wKcj7EWdB00IdDRKHbecnByaNGmiybyWExGaNGly1L+06m5Cz8+xF6sA52IVUYGNR6lKosk8OBzL+1h3h1y+GAO7VsGw96BRYqCjUUqp41Y3e+irptsTb/X9C3S8ONDRKBU00tPTefnll4/ptRdffDHp6emVHFFgJCcnc99991X7cuteQt+zDmb/Fdr1hfMfC3Q0SgUVXwm9sLDQ52vnzp1LXFxcVYR1XIwxFBUVHdVrkpKSeOGFF6ooovLVrSGX3EP2pFsRMfafoKF1a/VV3TJu1lrW7TxYqfPs3KohT1zm9ezYAIwZM4ZNmzbRo0cPBg4cyCWXXMK4ceNo2bIlK1euZN26dVxxxRWkpKSQk5PD/fffz/DhwwFITEwkOTmZzMxMBg8ezNlnn82iRYto3bo1n332GfXqlb0o+6xZs3j66afJy8ujSZMmvPvuuzRv3pzMzExGjRpFcnIyIsITTzzB1VdfzRdffMEjjzxCYWEh8fHxfP3114wdO5aYmBhGj7ZnVO3atSuzZ88GYPDgwZx33nksXryYTz/9lAkTJrB8+XKys7O55pprGDduHADLly/n/vvv5/Dhw0RGRvL111+zYsUKJk2axOzZszl8+DCjRo1izZo1FBQUMHbsWIYMGcLatWu5/fbbycvLo6ioiI8++ogOHToc1/tTdzKaMTBzFOzfBLfMhAYtAh2RUkFnwoQJ/PLLL6xcuRKAb7/9lmXLlvHLL7+UHH43depUGjduTHZ2Nr169eLqq6+mSZOyJ8HbsGED7733Hq+99hpDhw7lo48+4qabbipT5+yzz2bJkiWICK+//joTJ07k2Wef5amnniI2NpY1a9YAcODAAdLS0rjrrrtYuHAh7du3Z//+/RWuy/r163njjTdKfnGMHz+exo0bU1hYyIABA1i9ejUdO3bkuuuu4/3336dXr14cPHjwiC+e8ePHc/755zN16lTS09Pp3bs3F1xwAZMnT+b+++/nxhtvJC8vr8JfMP6oOwl92Wuw9hMY8AS07xfoaJSqcr560tWpd+/eZY6lfuGFF/jkk08ASElJYcOGDUck9Pbt29OjRw8ATj/9dLZu3XrEfFNTU7nuuuvYtWsXeXl5JcuYP38+06dPL6nXqFEjZs2axTnnnFNSp3HjxhXG3a5dO84888yS5zNmzGDKlCkUFBSwa9cu1q1bh4jQsmVLevWyJ/Jr2LDhEfOZN28eM2fOZNKkSYA9tHT79u306dOH8ePHk5qaylVXXXXcvXOoK2Poqcnw5SNw8iC7I1QpVW3q169f8vjbb79l/vz5LF68mFWrVtGzZ0+vx1pHRkaWPA4NDaWgoOCIOqNGjWLkyJGsWbOGV199tWQ+xpgjDvnzNg0gLCyszPi4OxZ33Fu2bGHSpEl8/fXXrF69mksuuYScnJxy5+u57I8++oiVK1eycuVKtm/fTqdOnbjhhhuYOXMm9erV46KLLuKbb77xOR9/BH9Cz9oPM26Fhi3hysl6sQqlqlCDBg04dOhQueUZGRk0atSI6OhofvvtN5YsWXLMy8rIyKB1a3s1zLfeeqtk+oUXXsiLL75Y8vzAgQP06dOH7777ji1btgCUDLkkJiby008/AfDTTz+VlHs6ePAg9evXJzY2lj179vD5558D0LFjR3bu3Mny5csBOHTo0BFfPhdddBH//e9/KT6z7c8//wzA5s2bOeGEE7jvvvu4/PLLWb169TG3RbHgzm5FRfDxXXD4D/vnoXqNAh2RUkGtSZMm9O3bl65du/Lggw8eUT5o0CAKCgro1q0bjz32WJkhjaM1duxYrr32Wvr160d8fOkF0v7+979z4MABunbtSvfu3VmwYAFNmzZlypQpXHXVVXTv3p3rrrsOgKuvvpr9+/fTo0cPXnnlFU4++WSvy+revTs9e/akS5cu3HHHHfTt2xeAiIgI3n//fUaNGkX37t0ZOHDgEb84HnvsMfLz8+nWrRtdu3blscfs0XXvv/8+Xbt2pUePHvz222/ccsstx9wWxYL7fOjfTYQF4+HSf0PSHVW7LKVqgF9//ZVOnfQEc8HC2/tZN8+HvmkBLPgHdLvOnnhLKaWCXHAm9Iwd8NGd0LSj7Z3ruS2UUnVA8CX0wnz48HZ78q2hb0NE/Ypfo5RSQSD4jkOfPxZSlsLV/4Om3ndwKKVUMAquHvq6mbD4Reg9HE69JtDRKKVUtQqehL5vE3x2L7Q+HS58OtDRKKVUtQuOhJ6fbU+6FRIK174JYZEVvkQpVfmO5/S5AM8//zxZWVmVGFH1mDx5Mm+//Xagw/AvoYvIIBFZLyIbRWSMj3q9RKRQRKp3vGPuaNjzC1z1GsS1rdZFK6VKBUNC93aagYqMGDGiUv4YdLwq3CkqIqHAS8BAIBVYLiIzjTHrvNT7F/BlVQRarp+mwc/vwDkPQoeB1bpopWq0z8fA7jWVO88Wp8Lg8q+/63n63GeeeYZnnnmGGTNmkJuby5VXXsm4ceM4fPgwQ4cOJTU1lcLCQh577DH27NnDzp07Oe+884iPj2fBggVl5v3kk08ya9YssrOzOeuss3j11VcRETZu3MiIESNIS0sjNDSUDz74gBNPPJGJEycybdo0QkJCGDx4MBMmTKB///5MmjSJpKQk9u7dS1JSElu3buXNN99kzpw55OTkcPjwYWbOnMmQIUM4cOAA+fn5PP300wwZMgSAt99+m0mTJiEidOvWjWnTppU5De+mTZu49957SUtLIzo6mtdee42OHTvywQcfMG7cOEJDQ4mNjWXhwoWV+97g31EuvYGNxpjNACIyHRgCrPOoNwr4COhVqRH6snuN7Z23Pwf6P1xti1VKeed5+tx58+axYcMGli1bhjGGyy+/nIULF5KWlkarVq2YM2cOYM/LEhsby3PPPceCBQvK/JW/2MiRI3n88ccBuPnmm5k9ezaXXXYZN954I2PGjOHKK68kJyeHoqIiPv/8cz799FOWLl1KdHS0X6fLXbx4MatXr6Zx48YUFBTwySef0LBhQ/bu3cuZZ57J5Zdfzrp16xg/fjw//vgj8fHxXuc7fPhwJk+eTIcOHVi6dCn33HMP33zzDU8++SRffvklrVu3rrIrM/mT0FsDKa7nqcAZ7goi0hq4EjgfHwldRIYDwwHatj3OoZGcDDtuXq8RXD3Vjp8rpUr56ElXl3nz5jFv3jx69uwJQGZmJhs2bKBfv36MHj2ahx56iEsvvZR+/So+pfWCBQuYOHEiWVlZ7N+/ny5dutC/f3927NjBlVdeCUBUlL3Y+/z587n99tuJjo4G/Dtd7sCBA0vqGWN45JFHWLhwISEhIezYsYM9e/bwzTffcM0115R84XjONzMzk0WLFnHttdeWTMvNzQWgb9++3HbbbQwdOpSrrrqqwniOhT8J3dvfLD1PAPM88JAxptDXqSSNMVOAKWDP5eJvkF5mBJ/eAwe2wW1zIKbpMc9KKVV1jDE8/PDD3H333UeUrVixgrlz5/Lwww9z4YUXlvS+vcnJyeGee+4hOTmZNm3aMHbs2JLT15a33IpOl+t5Ei336XLfffdd0tLSWLFiBeHh4SQmJvp1utyioiLi4uJKfqG4TZ48maVLlzJnzhx69OjBypUrjzgP/PHyZ6doKtDG9TwB2OlRJwmYLiJbgWuAl0XkikqJ0JvFL8Fvs2HgOGjXp8oWo5Q6Op6nz73ooouYOnUqmZmZAOzYsYM//viDnTt3Eh0dzU033cTo0aNLTmFb3ul3i5NvfHw8mZmZfPjhh4C9oERCQgKffvopYHvDWVlZXHjhhUydOrVkB6v7dLkrVqwAKJmHNxkZGTRr1ozw8HAWLFjAtm3bABgwYAAzZsxg3759ZeZbrGHDhrRv354PPvgAsF8sq1atAmDTpk2cccYZPPnkk8THx5OSkkJl86eHvhzoICLtgR3AMOAGdwVjTMnlSETkTWC2MebTSoyz1LbF8NXj0PFS6DOyShahlDo27tPnDh48mGeeeYZff/2VPn1sxysmJoZ33nmHjRs38uCDDxISEkJ4eDivvPIKYMefBw8eTMuWLcvsFI2Li+Ouu+7i1FNPJTExseQKQQDTpk3j7rvv5vHHHyc8PJwPPviAQYMGsXLlSpKSkoiIiODiiy/mH//4B6NHj2bo0KFMmzaN888/v9z1uPHGG7nssstISkqiR48edOzYEYAuXbrw6KOPcu655xIaGkrPnj158803y7z23Xff5c9//jNPP/00+fn5DBs2jO7du/Pggw+yYcMGjDEMGDCA7t27V1azl/Dr9LkicjF2WCUUmGqMGS8iIwCMMZM96r6JTejlf/1xHKfP3bUa5j9hjzePij361ysVxPT0ucHlaE+f69e5XIwxc4G5HtMml1P3Nr8iPVYtu8HNn1TpIpRSqjYKjn+KKqWU0oSuVLAJ1FXIVOU6lvdRE7pSQSQqKop9+/ZpUq/ljDHs27ev5Lh6fwXf+dCVqsMSEhJITU0lLS0t0KGo4xQVFUVCQsJRvUYTulJBJDw8nPbt21dcUQUlHXJRSqkgoQldKaWChCZ0pZQKEn79U7RKFiySBmwLyMIrTzywN9BB1CDaHmVpe5TStijreNqjnTHG6xkJA5bQg4GIJJf3F9y6SNujLG2PUtoWZVVVe+iQi1JKBQlN6EopFSQ0oR+fKYEOoIbR9ihL26OUtkVZVdIeOoaulFJBQnvoSikVJDShK6VUkNCEfhREZKuIrBGRlSKS7ExrLCJficgG575RoOOsCiIyVUT+EJFfXNPKXXcReVhENorIehG5KDBRV51y2mOsiOxwto+VzpW+isuCtj1EpI2ILBCRX0VkrYjc70yvk9uHj/ao+u3DGKM3P2/AViDeY9pEYIzzeAzwr0DHWUXrfg5wGvBLResOdAZWAZFAe2ATEBrodaiG9hgLjPZSN6jbA2gJnOY8bgD87qxzndw+fLRHlW8f2kM/fkOAt5zHbwFXBDCWKmOMWQjs95hc3roPAaYbY3KNMVuAjUDvagm0mpTTHuUJ6vYwxuwyxvzkPD4E/Aq0po5uHz7aozyV1h6a0I+OAeaJyAoRGe5Ma26M2QX2jQSaBSy66lfeurcGUlz1UvG9QQeTkSKy2hmSKR5iqDPtISKJQE9gKbp9eLYHVPH2oQn96PQ1xpwGDAbuFZFzAh1QDSVeptWF42NfAU4EegC7gGed6XWiPUQkBvgI+Isx5qCvql6m1YX2qPLtQxP6UTDG7HTu/wA+wf4s2iMiLQGc+z8CF2G1K2/dU4E2rnoJwM5qjq3aGWP2GGMKjTFFwGuU/mwO+vYQkXBs8nrXGPOxM7nObh/e2qM6tg9N6H4Skfoi0qD4MXAh8AswE7jVqXYr8FlgIgyI8tZ9JjBMRCJFpD3QAVgWgPiqVXHyclyJ3T4gyNtDRAT4H/CrMeY5V1Gd3D7Ka49q2T4CvUe4ttyAE7B7olcBa4FHnelNgK+BDc5940DHWkXr/x72Z2I+tkdxp691Bx7F7q1fDwwOdPzV1B7TgDXAaudD2rIutAdwNnaIYDWw0rldXFe3Dx/tUeXbh/71XymlgoQOuSilVJDQhK6UUkFCE7pSSgUJTehKKRUkNKErpVSQ0ISulFJBQhO6UkoFif8P6ub31VEY+IMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Train accuracies: \")\n",
    "print(train_scores)\n",
    "print(\"Test accuracies: \")\n",
    "print(test_scores)\n",
    "\n",
    "# plot\n",
    "plt.plot(range(25, 251, 25), train_scores, label='train accuracies')\n",
    "plt.plot(range(25, 251, 25), test_scores, label='test accuracies')\n",
    "plt.legend()\n",
    "plt.title(\"Classification Accuracies over Time Period (CNN)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function of Time - Optimized CNN+LSTM (with preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_model(time_period=250):   \n",
    "    \n",
    "    # Building the CNN model using sequential class\n",
    "    hybrid_cnn_lstm_model = Sequential()\n",
    "\n",
    "    # Conv. block 1\n",
    "    hybrid_cnn_lstm_model.add(Conv2D(filters=100, kernel_size=(10,1), padding='same', activation='elu', input_shape=(time_period,1,22)))\n",
    "    hybrid_cnn_lstm_model.add(MaxPooling2D(pool_size=(3,1), padding='same')) # Read the keras documentation\n",
    "    hybrid_cnn_lstm_model.add(BatchNormalization())\n",
    "    hybrid_cnn_lstm_model.add(Dropout(0.5))\n",
    "\n",
    "    # Conv. block 2\n",
    "    hybrid_cnn_lstm_model.add(Conv2D(filters=100, kernel_size=(10,1), padding='same', activation='elu'))\n",
    "    hybrid_cnn_lstm_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "    hybrid_cnn_lstm_model.add(BatchNormalization())\n",
    "    hybrid_cnn_lstm_model.add(Dropout(0.5))\n",
    "\n",
    "    # Conv. block 3\n",
    "    hybrid_cnn_lstm_model.add(Conv2D(filters=100, kernel_size=(10,1), padding='same', activation='elu'))\n",
    "    hybrid_cnn_lstm_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "    hybrid_cnn_lstm_model.add(BatchNormalization())\n",
    "    hybrid_cnn_lstm_model.add(Dropout(0.5))\n",
    "\n",
    "    # Conv. block 4\n",
    "    #hybrid_cnn_lstm_model.add(Conv2D(filters=100, kernel_size=(10,1), padding='same', activation='elu'))\n",
    "    #hybrid_cnn_lstm_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "    #hybrid_cnn_lstm_model.add(BatchNormalization())\n",
    "    #hybrid_cnn_lstm_model.add(Dropout(0.5))\n",
    "\n",
    "    # FC+LSTM layers\n",
    "    hybrid_cnn_lstm_model.add(Flatten()) # Adding a flattening operation to the output of CNN block\n",
    "    hybrid_cnn_lstm_model.add(Dense((100))) # FC layer with 100 units\n",
    "    hybrid_cnn_lstm_model.add(Reshape((100,1))) # Reshape my output of FC layer so that it's compatible\n",
    "    hybrid_cnn_lstm_model.add(LSTM(100, dropout=0.5, recurrent_dropout=0.1, input_shape=(100,1), return_sequences=True))\n",
    "\n",
    "    hybrid_cnn_lstm_model.add(LSTM(70, dropout=0.5, recurrent_dropout=0.1, return_sequences=False))\n",
    "    # Output layer with Softmax activation \n",
    "    hybrid_cnn_lstm_model.add(Dense(4, activation='softmax')) # Output FC layer with softmax activation\n",
    "\n",
    "\n",
    "    hybrid_cnn_lstm_model.compile(loss='categorical_crossentropy', optimizer=hybrid_cnn_lstm_optimizer, metrics=['accuracy'])\n",
    "\n",
    "    # Printing the model summary\n",
    "    hybrid_cnn_lstm_model.summary()\n",
    "    \n",
    "    return hybrid_cnn_lstm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "learning_rate = 2e-3\n",
    "epochs = 50\n",
    "hybrid_cnn_lstm_optimizer = optimizers.Adam(lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_train_data(time_period=250):\n",
    "    # different period of time\n",
    "    x_train_time = x_train[:,:time_period,:,:]\n",
    "    y_train_time = y_train\n",
    "    x_valid_time = x_valid[:,:time_period,:,:]\n",
    "    y_valid_time = y_valid\n",
    "    x_test_time = x_test[:,:time_period,:,:]\n",
    "    y_test_time = y_test\n",
    "    \n",
    "    \n",
    "    model = hybrid_model(time_period)\n",
    "\n",
    "    # Training and validating the model\n",
    "    cnn_model_results = model.fit(x_train_time,\n",
    "                 y_train_time,\n",
    "                 batch_size=200,\n",
    "                 epochs=epochs,\n",
    "                 validation_data=(x_valid_time, y_valid_time), verbose=True)\n",
    "    \n",
    "    train_score = model.evaluate(x_train_time, y_train_time)\n",
    "    \n",
    "    test_score = model.evaluate(x_test_time, y_test_time)\n",
    "\n",
    "    print('train {:s}: {:.3f}%'.format(model.metrics_names[1], train_score[1]*100))\n",
    "    print('test {:s}: {:.3f}%'.format(model.metrics_names[1], test_score[1]*100))\n",
    "    #print(model.summary())\n",
    "    \n",
    "    return train_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================25===================\n",
      "Model: \"sequential_77\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_301 (Conv2D)          (None, 25, 1, 100)        22100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_301 (MaxPoolin (None, 9, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_301 (Bat (None, 9, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_301 (Dropout)        (None, 9, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_302 (Conv2D)          (None, 9, 1, 100)         100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_302 (MaxPoolin (None, 3, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_302 (Bat (None, 3, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_302 (Dropout)        (None, 3, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_303 (Conv2D)          (None, 3, 1, 100)         100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_303 (MaxPoolin (None, 1, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_303 (Bat (None, 1, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_303 (Dropout)        (None, 1, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_77 (Flatten)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "reshape_5 (Reshape)          (None, 100, 1)            0         \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 100, 100)          40800     \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 70)                47880     \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 4)                 284       \n",
      "=================================================================\n",
      "Total params: 322,564\n",
      "Trainable params: 321,964\n",
      "Non-trainable params: 600\n",
      "_________________________________________________________________\n",
      "Train on 6960 samples, validate on 1500 samples\n",
      "Epoch 1/50\n",
      "6960/6960 [==============================] - 31s 4ms/sample - loss: 1.3767 - acc: 0.2832 - val_loss: 1.3565 - val_acc: 0.3247\n",
      "Epoch 2/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 1.3637 - acc: 0.3049 - val_loss: 1.3690 - val_acc: 0.3273\n",
      "Epoch 3/50\n",
      "6960/6960 [==============================] - 27s 4ms/sample - loss: 1.3504 - acc: 0.3142 - val_loss: 1.2961 - val_acc: 0.3760\n",
      "Epoch 4/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 1.3150 - acc: 0.3632 - val_loss: 1.2859 - val_acc: 0.3713\n",
      "Epoch 5/50\n",
      "6960/6960 [==============================] - 25s 4ms/sample - loss: 1.3043 - acc: 0.3708 - val_loss: 1.2887 - val_acc: 0.3833\n",
      "Epoch 6/50\n",
      "6960/6960 [==============================] - 24s 3ms/sample - loss: 1.2875 - acc: 0.3805 - val_loss: 1.2734 - val_acc: 0.3813\n",
      "Epoch 7/50\n",
      "6960/6960 [==============================] - 26s 4ms/sample - loss: 1.2661 - acc: 0.3947 - val_loss: 1.2947 - val_acc: 0.3880\n",
      "Epoch 8/50\n",
      "6960/6960 [==============================] - 21s 3ms/sample - loss: 1.2677 - acc: 0.3945 - val_loss: 1.2361 - val_acc: 0.4033\n",
      "Epoch 9/50\n",
      "6960/6960 [==============================] - 21s 3ms/sample - loss: 1.2469 - acc: 0.4095 - val_loss: 1.2226 - val_acc: 0.4240\n",
      "Epoch 10/50\n",
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 1.2232 - acc: 0.4319 - val_loss: 1.1906 - val_acc: 0.4460\n",
      "Epoch 11/50\n",
      "6960/6960 [==============================] - 21s 3ms/sample - loss: 1.2062 - acc: 0.4445 - val_loss: 1.1975 - val_acc: 0.4727\n",
      "Epoch 12/50\n",
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 1.1903 - acc: 0.4499 - val_loss: 1.1495 - val_acc: 0.4927\n",
      "Epoch 13/50\n",
      "6960/6960 [==============================] - 26s 4ms/sample - loss: 1.1714 - acc: 0.4698 - val_loss: 1.1431 - val_acc: 0.4900\n",
      "Epoch 14/50\n",
      "6960/6960 [==============================] - 24s 3ms/sample - loss: 1.1610 - acc: 0.4708 - val_loss: 1.1245 - val_acc: 0.5107\n",
      "Epoch 15/50\n",
      "6960/6960 [==============================] - 21s 3ms/sample - loss: 1.1458 - acc: 0.4925 - val_loss: 1.1212 - val_acc: 0.4993\n",
      "Epoch 16/50\n",
      "6960/6960 [==============================] - 24s 3ms/sample - loss: 1.1337 - acc: 0.4914 - val_loss: 1.0830 - val_acc: 0.5253\n",
      "Epoch 17/50\n",
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 1.1167 - acc: 0.5072 - val_loss: 1.0657 - val_acc: 0.5447\n",
      "Epoch 18/50\n",
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 1.1219 - acc: 0.5006 - val_loss: 1.0673 - val_acc: 0.5280\n",
      "Epoch 19/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 1.0953 - acc: 0.5161 - val_loss: 1.0592 - val_acc: 0.5400\n",
      "Epoch 20/50\n",
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 1.0716 - acc: 0.5326 - val_loss: 1.0275 - val_acc: 0.5693\n",
      "Epoch 21/50\n",
      "6960/6960 [==============================] - 25s 4ms/sample - loss: 1.0516 - acc: 0.5445 - val_loss: 0.9906 - val_acc: 0.5927\n",
      "Epoch 22/50\n",
      "6960/6960 [==============================] - 24s 3ms/sample - loss: 1.0509 - acc: 0.5428 - val_loss: 0.9655 - val_acc: 0.6120\n",
      "Epoch 23/50\n",
      "6960/6960 [==============================] - 28s 4ms/sample - loss: 1.0360 - acc: 0.5552 - val_loss: 0.9483 - val_acc: 0.6207\n",
      "Epoch 24/50\n",
      "6960/6960 [==============================] - 26s 4ms/sample - loss: 1.0037 - acc: 0.5661 - val_loss: 0.9813 - val_acc: 0.5887\n",
      "Epoch 25/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 1.0293 - acc: 0.5614 - val_loss: 0.9235 - val_acc: 0.6387\n",
      "Epoch 26/50\n",
      "6960/6960 [==============================] - 21s 3ms/sample - loss: 0.9869 - acc: 0.5841 - val_loss: 0.9088 - val_acc: 0.6500\n",
      "Epoch 27/50\n",
      "6960/6960 [==============================] - 24s 3ms/sample - loss: 0.9836 - acc: 0.5802 - val_loss: 0.9156 - val_acc: 0.6307\n",
      "Epoch 28/50\n",
      "6960/6960 [==============================] - 24s 3ms/sample - loss: 0.9647 - acc: 0.5911 - val_loss: 0.8900 - val_acc: 0.6480\n",
      "Epoch 29/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 0.9494 - acc: 0.6063 - val_loss: 0.8490 - val_acc: 0.6587\n",
      "Epoch 30/50\n",
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 0.9543 - acc: 0.5981 - val_loss: 0.8708 - val_acc: 0.6633\n",
      "Epoch 31/50\n",
      "6960/6960 [==============================] - 21s 3ms/sample - loss: 0.9304 - acc: 0.6082 - val_loss: 0.8352 - val_acc: 0.6693\n",
      "Epoch 32/50\n",
      "6960/6960 [==============================] - 21s 3ms/sample - loss: 0.9310 - acc: 0.6055 - val_loss: 0.8474 - val_acc: 0.6760\n",
      "Epoch 33/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 0.9046 - acc: 0.6243 - val_loss: 0.8096 - val_acc: 0.6980\n",
      "Epoch 34/50\n",
      "6960/6960 [==============================] - 25s 4ms/sample - loss: 0.8970 - acc: 0.6227 - val_loss: 0.8096 - val_acc: 0.6973\n",
      "Epoch 35/50\n",
      "6960/6960 [==============================] - 25s 4ms/sample - loss: 0.9010 - acc: 0.6292 - val_loss: 0.7731 - val_acc: 0.7087\n",
      "Epoch 36/50\n",
      "6960/6960 [==============================] - 25s 4ms/sample - loss: 0.8767 - acc: 0.6359 - val_loss: 0.7749 - val_acc: 0.7180\n",
      "Epoch 37/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 0.8785 - acc: 0.6302 - val_loss: 0.7599 - val_acc: 0.7233\n",
      "Epoch 38/50\n",
      "6960/6960 [==============================] - 24s 4ms/sample - loss: 0.8552 - acc: 0.6466 - val_loss: 0.7387 - val_acc: 0.7353\n",
      "Epoch 39/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 0.8518 - acc: 0.6522 - val_loss: 0.7342 - val_acc: 0.7427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 0.8508 - acc: 0.6476 - val_loss: 0.7429 - val_acc: 0.7393\n",
      "Epoch 41/50\n",
      "6960/6960 [==============================] - 25s 4ms/sample - loss: 0.8259 - acc: 0.6632 - val_loss: 0.7200 - val_acc: 0.7373\n",
      "Epoch 42/50\n",
      "6960/6960 [==============================] - 26s 4ms/sample - loss: 0.8331 - acc: 0.6552 - val_loss: 0.7211 - val_acc: 0.7473\n",
      "Epoch 43/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 0.8126 - acc: 0.6648 - val_loss: 0.6939 - val_acc: 0.7487\n",
      "Epoch 44/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 0.8131 - acc: 0.6654 - val_loss: 0.6690 - val_acc: 0.7607\n",
      "Epoch 45/50\n",
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 0.7999 - acc: 0.6697 - val_loss: 0.6787 - val_acc: 0.7653\n",
      "Epoch 46/50\n",
      "6960/6960 [==============================] - 21s 3ms/sample - loss: 0.7901 - acc: 0.6737 - val_loss: 0.6778 - val_acc: 0.7507\n",
      "Epoch 47/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 0.7883 - acc: 0.6848 - val_loss: 0.6639 - val_acc: 0.7660\n",
      "Epoch 48/50\n",
      "6960/6960 [==============================] - 26s 4ms/sample - loss: 0.7714 - acc: 0.6892 - val_loss: 0.6355 - val_acc: 0.7873\n",
      "Epoch 49/50\n",
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 0.7781 - acc: 0.6803 - val_loss: 0.6439 - val_acc: 0.7787\n",
      "Epoch 50/50\n",
      "6960/6960 [==============================] - 24s 3ms/sample - loss: 0.7697 - acc: 0.6876 - val_loss: 0.6190 - val_acc: 0.7880\n",
      "6960/6960 [==============================] - 46s 7ms/sample - loss: 0.3660 - acc: 0.9167\n",
      "1772/1772 [==============================] - 11s 6ms/sample - loss: 1.6438 - acc: 0.3843\n",
      "train acc: 91.667%\n",
      "test acc: 38.431%\n",
      "=================50===================\n",
      "Model: \"sequential_78\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_304 (Conv2D)          (None, 50, 1, 100)        22100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_304 (MaxPoolin (None, 17, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_304 (Bat (None, 17, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_304 (Dropout)        (None, 17, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_305 (Conv2D)          (None, 17, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_305 (MaxPoolin (None, 6, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_305 (Bat (None, 6, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_305 (Dropout)        (None, 6, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_306 (Conv2D)          (None, 6, 1, 100)         100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_306 (MaxPoolin (None, 2, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_306 (Bat (None, 2, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_306 (Dropout)        (None, 2, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_78 (Flatten)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_84 (Dense)             (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "reshape_6 (Reshape)          (None, 100, 1)            0         \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 100, 100)          40800     \n",
      "_________________________________________________________________\n",
      "lstm_13 (LSTM)               (None, 70)                47880     \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, 4)                 284       \n",
      "=================================================================\n",
      "Total params: 332,564\n",
      "Trainable params: 331,964\n",
      "Non-trainable params: 600\n",
      "_________________________________________________________________\n",
      "Train on 6960 samples, validate on 1500 samples\n",
      "Epoch 1/50\n",
      "6960/6960 [==============================] - 39s 6ms/sample - loss: 1.3884 - acc: 0.2647 - val_loss: 1.4673 - val_acc: 0.2533\n",
      "Epoch 2/50\n",
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 1.3713 - acc: 0.3164 - val_loss: 1.3937 - val_acc: 0.3093\n",
      "Epoch 3/50\n",
      "6960/6960 [==============================] - 24s 4ms/sample - loss: 1.3392 - acc: 0.3545 - val_loss: 1.4008 - val_acc: 0.3293\n",
      "Epoch 4/50\n",
      "6960/6960 [==============================] - 21s 3ms/sample - loss: 1.2999 - acc: 0.3948 - val_loss: 1.2794 - val_acc: 0.4287\n",
      "Epoch 5/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 1.2741 - acc: 0.4164 - val_loss: 1.2254 - val_acc: 0.4587\n",
      "Epoch 6/50\n",
      "6960/6960 [==============================] - 21s 3ms/sample - loss: 1.2391 - acc: 0.4412 - val_loss: 1.1308 - val_acc: 0.5193\n",
      "Epoch 7/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 1.1994 - acc: 0.4685 - val_loss: 1.1106 - val_acc: 0.5180\n",
      "Epoch 8/50\n",
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 1.1532 - acc: 0.4994 - val_loss: 1.0585 - val_acc: 0.5540\n",
      "Epoch 9/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 1.1289 - acc: 0.5180 - val_loss: 0.9982 - val_acc: 0.5707\n",
      "Epoch 10/50\n",
      "6960/6960 [==============================] - 21s 3ms/sample - loss: 1.0878 - acc: 0.5313 - val_loss: 0.9512 - val_acc: 0.6033\n",
      "Epoch 11/50\n",
      "6960/6960 [==============================] - 26s 4ms/sample - loss: 1.0583 - acc: 0.5523 - val_loss: 0.9286 - val_acc: 0.6287\n",
      "Epoch 12/50\n",
      "6960/6960 [==============================] - 27s 4ms/sample - loss: 1.0178 - acc: 0.5705 - val_loss: 0.8929 - val_acc: 0.6453\n",
      "Epoch 13/50\n",
      "6960/6960 [==============================] - 24s 3ms/sample - loss: 0.9783 - acc: 0.5964 - val_loss: 0.8283 - val_acc: 0.6773\n",
      "Epoch 14/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 0.9723 - acc: 0.5938 - val_loss: 0.8164 - val_acc: 0.6860\n",
      "Epoch 15/50\n",
      "6960/6960 [==============================] - 24s 3ms/sample - loss: 0.9357 - acc: 0.6108 - val_loss: 0.7712 - val_acc: 0.7047\n",
      "Epoch 16/50\n",
      "6960/6960 [==============================] - 25s 4ms/sample - loss: 0.9214 - acc: 0.6185 - val_loss: 0.7694 - val_acc: 0.7073\n",
      "Epoch 17/50\n",
      "6960/6960 [==============================] - 24s 3ms/sample - loss: 0.8882 - acc: 0.6342 - val_loss: 0.7245 - val_acc: 0.7207\n",
      "Epoch 18/50\n",
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 0.8937 - acc: 0.6280 - val_loss: 0.7155 - val_acc: 0.7440\n",
      "Epoch 19/50\n",
      "6960/6960 [==============================] - 24s 3ms/sample - loss: 0.8559 - acc: 0.6464 - val_loss: 0.7435 - val_acc: 0.7240\n",
      "Epoch 20/50\n",
      "6960/6960 [==============================] - 24s 3ms/sample - loss: 0.8452 - acc: 0.6520 - val_loss: 0.6638 - val_acc: 0.7547\n",
      "Epoch 21/50\n",
      "6960/6960 [==============================] - 24s 3ms/sample - loss: 0.8137 - acc: 0.6690 - val_loss: 0.6093 - val_acc: 0.7813\n",
      "Epoch 22/50\n",
      "6960/6960 [==============================] - 25s 4ms/sample - loss: 0.8050 - acc: 0.6675 - val_loss: 0.6262 - val_acc: 0.7793\n",
      "Epoch 23/50\n",
      "6960/6960 [==============================] - 25s 4ms/sample - loss: 0.7881 - acc: 0.6763 - val_loss: 0.6116 - val_acc: 0.7760\n",
      "Epoch 24/50\n",
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 0.7480 - acc: 0.7010 - val_loss: 0.5660 - val_acc: 0.8047\n",
      "Epoch 25/50\n",
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 0.7595 - acc: 0.6889 - val_loss: 0.5561 - val_acc: 0.8187\n",
      "Epoch 26/50\n",
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 0.7341 - acc: 0.7019 - val_loss: 0.5741 - val_acc: 0.8173\n",
      "Epoch 27/50\n",
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 0.7123 - acc: 0.7114 - val_loss: 0.5611 - val_acc: 0.8047\n",
      "Epoch 28/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 0.7160 - acc: 0.7095 - val_loss: 0.5534 - val_acc: 0.8307\n",
      "Epoch 29/50\n",
      "6960/6960 [==============================] - 21s 3ms/sample - loss: 0.6968 - acc: 0.7152 - val_loss: 0.4849 - val_acc: 0.8520\n",
      "Epoch 30/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 0.6702 - acc: 0.7320 - val_loss: 0.5126 - val_acc: 0.8460\n",
      "Epoch 31/50\n",
      "6960/6960 [==============================] - 21s 3ms/sample - loss: 0.6751 - acc: 0.7243 - val_loss: 0.4990 - val_acc: 0.8520\n",
      "Epoch 32/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 0.6510 - acc: 0.7345 - val_loss: 0.4935 - val_acc: 0.8533\n",
      "Epoch 33/50\n",
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 0.6285 - acc: 0.7420 - val_loss: 0.4406 - val_acc: 0.8667\n",
      "Epoch 34/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 0.6484 - acc: 0.7425 - val_loss: 0.4331 - val_acc: 0.8753\n",
      "Epoch 35/50\n",
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 0.6172 - acc: 0.7460 - val_loss: 0.3931 - val_acc: 0.8827\n",
      "Epoch 36/50\n",
      "6960/6960 [==============================] - 26s 4ms/sample - loss: 0.6054 - acc: 0.7570 - val_loss: 0.3968 - val_acc: 0.8693\n",
      "Epoch 37/50\n",
      "6960/6960 [==============================] - 24s 4ms/sample - loss: 0.6161 - acc: 0.7451 - val_loss: 0.4181 - val_acc: 0.8753\n",
      "Epoch 38/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 0.5934 - acc: 0.7592 - val_loss: 0.4036 - val_acc: 0.8940\n",
      "Epoch 39/50\n",
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 0.5927 - acc: 0.7615 - val_loss: 0.3918 - val_acc: 0.8967\n",
      "Epoch 40/50\n",
      "6960/6960 [==============================] - 21s 3ms/sample - loss: 0.5769 - acc: 0.7665 - val_loss: 0.3771 - val_acc: 0.8993\n",
      "Epoch 41/50\n",
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 0.5766 - acc: 0.7667 - val_loss: 0.3610 - val_acc: 0.9087\n",
      "Epoch 42/50\n",
      "6960/6960 [==============================] - 24s 3ms/sample - loss: 0.5617 - acc: 0.7747 - val_loss: 0.3365 - val_acc: 0.9193\n",
      "Epoch 43/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 0.5731 - acc: 0.7652 - val_loss: 0.3546 - val_acc: 0.9033\n",
      "Epoch 44/50\n",
      "6960/6960 [==============================] - 25s 4ms/sample - loss: 0.5504 - acc: 0.7741 - val_loss: 0.3383 - val_acc: 0.9167\n",
      "Epoch 45/50\n",
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 0.5297 - acc: 0.7865 - val_loss: 0.3216 - val_acc: 0.9167\n",
      "Epoch 46/50\n",
      "6960/6960 [==============================] - 24s 3ms/sample - loss: 0.5372 - acc: 0.7892 - val_loss: 0.3255 - val_acc: 0.9240\n",
      "Epoch 47/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 0.5431 - acc: 0.7836 - val_loss: 0.3385 - val_acc: 0.9200\n",
      "Epoch 48/50\n",
      "6960/6960 [==============================] - 26s 4ms/sample - loss: 0.5154 - acc: 0.7892 - val_loss: 0.3029 - val_acc: 0.9280\n",
      "Epoch 49/50\n",
      "6960/6960 [==============================] - 25s 4ms/sample - loss: 0.5123 - acc: 0.7935 - val_loss: 0.2972 - val_acc: 0.9267\n",
      "Epoch 50/50\n",
      "6960/6960 [==============================] - 21s 3ms/sample - loss: 0.5259 - acc: 0.7934 - val_loss: 0.2883 - val_acc: 0.9293\n",
      "6960/6960 [==============================] - 44s 6ms/sample - loss: 0.1610 - acc: 0.9818\n",
      "1772/1772 [==============================] - 12s 7ms/sample - loss: 1.3225 - acc: 0.5000\n",
      "train acc: 98.175%\n",
      "test acc: 50.000%\n",
      "=================75===================\n",
      "Model: \"sequential_79\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_307 (Conv2D)          (None, 75, 1, 100)        22100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_307 (MaxPoolin (None, 25, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_307 (Bat (None, 25, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_307 (Dropout)        (None, 25, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_308 (Conv2D)          (None, 25, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_308 (MaxPoolin (None, 9, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_308 (Bat (None, 9, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_308 (Dropout)        (None, 9, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_309 (Conv2D)          (None, 9, 1, 100)         100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_309 (MaxPoolin (None, 3, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_309 (Bat (None, 3, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_309 (Dropout)        (None, 3, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_79 (Flatten)         (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "reshape_7 (Reshape)          (None, 100, 1)            0         \n",
      "_________________________________________________________________\n",
      "lstm_14 (LSTM)               (None, 100, 100)          40800     \n",
      "_________________________________________________________________\n",
      "lstm_15 (LSTM)               (None, 70)                47880     \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 4)                 284       \n",
      "=================================================================\n",
      "Total params: 342,564\n",
      "Trainable params: 341,964\n",
      "Non-trainable params: 600\n",
      "_________________________________________________________________\n",
      "Train on 6960 samples, validate on 1500 samples\n",
      "Epoch 1/50\n",
      "6960/6960 [==============================] - 36s 5ms/sample - loss: 1.3901 - acc: 0.2684 - val_loss: 1.3747 - val_acc: 0.3140\n",
      "Epoch 2/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 1.3482 - acc: 0.3374 - val_loss: 1.3524 - val_acc: 0.3227\n",
      "Epoch 3/50\n",
      "6960/6960 [==============================] - 25s 4ms/sample - loss: 1.3149 - acc: 0.3783 - val_loss: 1.3060 - val_acc: 0.3713\n",
      "Epoch 4/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 1.2820 - acc: 0.4023 - val_loss: 1.2639 - val_acc: 0.4360\n",
      "Epoch 5/50\n",
      "6960/6960 [==============================] - 26s 4ms/sample - loss: 1.2570 - acc: 0.4243 - val_loss: 1.2694 - val_acc: 0.4233\n",
      "Epoch 6/50\n",
      "6960/6960 [==============================] - 28s 4ms/sample - loss: 1.2363 - acc: 0.4365 - val_loss: 1.1394 - val_acc: 0.4813\n",
      "Epoch 7/50\n",
      "6960/6960 [==============================] - 26s 4ms/sample - loss: 1.1934 - acc: 0.4684 - val_loss: 1.0759 - val_acc: 0.5533\n",
      "Epoch 8/50\n",
      "6960/6960 [==============================] - 25s 4ms/sample - loss: 1.1572 - acc: 0.4881 - val_loss: 1.0389 - val_acc: 0.5440\n",
      "Epoch 9/50\n",
      "6960/6960 [==============================] - 24s 3ms/sample - loss: 1.1291 - acc: 0.5052 - val_loss: 1.0482 - val_acc: 0.5407\n",
      "Epoch 10/50\n",
      "6960/6960 [==============================] - 24s 3ms/sample - loss: 1.0919 - acc: 0.5204 - val_loss: 0.9330 - val_acc: 0.6300\n",
      "Epoch 11/50\n",
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 1.0629 - acc: 0.5342 - val_loss: 0.9173 - val_acc: 0.6193\n",
      "Epoch 12/50\n",
      "6960/6960 [==============================] - 24s 3ms/sample - loss: 1.0279 - acc: 0.5649 - val_loss: 0.8901 - val_acc: 0.6587\n",
      "Epoch 13/50\n",
      "6960/6960 [==============================] - 26s 4ms/sample - loss: 1.0079 - acc: 0.5764 - val_loss: 0.8720 - val_acc: 0.6720\n",
      "Epoch 14/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 0.9701 - acc: 0.5957 - val_loss: 0.7696 - val_acc: 0.7173\n",
      "Epoch 15/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 0.9416 - acc: 0.6135 - val_loss: 0.7941 - val_acc: 0.6827\n",
      "Epoch 16/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 0.8993 - acc: 0.6272 - val_loss: 0.7412 - val_acc: 0.7287\n",
      "Epoch 17/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 0.8735 - acc: 0.6455 - val_loss: 0.6772 - val_acc: 0.7640\n",
      "Epoch 18/50\n",
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 0.8464 - acc: 0.6497 - val_loss: 0.7482 - val_acc: 0.7187\n",
      "Epoch 19/50\n",
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 0.8483 - acc: 0.6526 - val_loss: 0.6755 - val_acc: 0.7627\n",
      "Epoch 20/50\n",
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 0.8073 - acc: 0.6654 - val_loss: 0.6168 - val_acc: 0.7813\n",
      "Epoch 21/50\n",
      "6960/6960 [==============================] - 24s 3ms/sample - loss: 0.7740 - acc: 0.6843 - val_loss: 0.5889 - val_acc: 0.8107\n",
      "Epoch 22/50\n",
      "6960/6960 [==============================] - 25s 4ms/sample - loss: 0.7540 - acc: 0.6970 - val_loss: 0.5574 - val_acc: 0.8187\n",
      "Epoch 23/50\n",
      "6960/6960 [==============================] - 25s 4ms/sample - loss: 0.7236 - acc: 0.7181 - val_loss: 0.5390 - val_acc: 0.8140\n",
      "Epoch 24/50\n",
      "6960/6960 [==============================] - 25s 4ms/sample - loss: 0.7271 - acc: 0.7078 - val_loss: 0.5040 - val_acc: 0.8367\n",
      "Epoch 25/50\n",
      "6960/6960 [==============================] - 24s 3ms/sample - loss: 0.6960 - acc: 0.7211 - val_loss: 0.4920 - val_acc: 0.8420\n",
      "Epoch 26/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 0.6874 - acc: 0.7220 - val_loss: 0.5213 - val_acc: 0.8380\n",
      "Epoch 27/50\n",
      "6960/6960 [==============================] - 25s 4ms/sample - loss: 0.6764 - acc: 0.7207 - val_loss: 0.5146 - val_acc: 0.8333\n",
      "Epoch 28/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 0.6639 - acc: 0.7296 - val_loss: 0.4647 - val_acc: 0.8700\n",
      "Epoch 29/50\n",
      "6960/6960 [==============================] - 25s 4ms/sample - loss: 0.6336 - acc: 0.7453 - val_loss: 0.4568 - val_acc: 0.8653\n",
      "Epoch 30/50\n",
      "6960/6960 [==============================] - 25s 4ms/sample - loss: 0.6206 - acc: 0.7493 - val_loss: 0.4049 - val_acc: 0.8787\n",
      "Epoch 31/50\n",
      "6960/6960 [==============================] - 24s 3ms/sample - loss: 0.6150 - acc: 0.7510 - val_loss: 0.4475 - val_acc: 0.8713\n",
      "Epoch 32/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 0.5924 - acc: 0.7647 - val_loss: 0.3793 - val_acc: 0.8913\n",
      "Epoch 33/50\n",
      "6960/6960 [==============================] - 26s 4ms/sample - loss: 0.5903 - acc: 0.7649 - val_loss: 0.3399 - val_acc: 0.9140\n",
      "Epoch 34/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 0.5742 - acc: 0.7763 - val_loss: 0.3130 - val_acc: 0.9140\n",
      "Epoch 35/50\n",
      "6960/6960 [==============================] - 25s 4ms/sample - loss: 0.5717 - acc: 0.7716 - val_loss: 0.3099 - val_acc: 0.9127\n",
      "Epoch 36/50\n",
      "6960/6960 [==============================] - 24s 3ms/sample - loss: 0.5434 - acc: 0.7819 - val_loss: 0.3190 - val_acc: 0.9153\n",
      "Epoch 37/50\n",
      "6960/6960 [==============================] - 27s 4ms/sample - loss: 0.5427 - acc: 0.7888 - val_loss: 0.3463 - val_acc: 0.9060\n",
      "Epoch 38/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 0.5348 - acc: 0.7816 - val_loss: 0.3027 - val_acc: 0.9400\n",
      "Epoch 39/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 0.5316 - acc: 0.7882 - val_loss: 0.3048 - val_acc: 0.9307\n",
      "Epoch 40/50\n",
      "6960/6960 [==============================] - 21s 3ms/sample - loss: 0.5152 - acc: 0.7881 - val_loss: 0.3067 - val_acc: 0.9320\n",
      "Epoch 41/50\n",
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 0.5020 - acc: 0.8016 - val_loss: 0.2639 - val_acc: 0.9327\n",
      "Epoch 42/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 0.4893 - acc: 0.8019 - val_loss: 0.2625 - val_acc: 0.9360\n",
      "Epoch 43/50\n",
      "6960/6960 [==============================] - 21s 3ms/sample - loss: 0.4938 - acc: 0.7999 - val_loss: 0.2802 - val_acc: 0.9327\n",
      "Epoch 44/50\n",
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 0.4879 - acc: 0.7977 - val_loss: 0.2270 - val_acc: 0.9487\n",
      "Epoch 45/50\n",
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 0.4826 - acc: 0.8103 - val_loss: 0.2588 - val_acc: 0.9540\n",
      "Epoch 46/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 0.4846 - acc: 0.8057 - val_loss: 0.2419 - val_acc: 0.9513\n",
      "Epoch 47/50\n",
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 0.4776 - acc: 0.8099 - val_loss: 0.2173 - val_acc: 0.9587\n",
      "Epoch 48/50\n",
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 0.4535 - acc: 0.8157 - val_loss: 0.2014 - val_acc: 0.9507\n",
      "Epoch 49/50\n",
      "6960/6960 [==============================] - 24s 3ms/sample - loss: 0.4458 - acc: 0.8164 - val_loss: 0.2280 - val_acc: 0.9460\n",
      "Epoch 50/50\n",
      "6960/6960 [==============================] - 21s 3ms/sample - loss: 0.4488 - acc: 0.8197 - val_loss: 0.2111 - val_acc: 0.9607\n",
      "6960/6960 [==============================] - 43s 6ms/sample - loss: 0.1215 - acc: 0.9884\n",
      "1772/1772 [==============================] - 11s 6ms/sample - loss: 1.1981 - acc: 0.5734\n",
      "train acc: 98.836%\n",
      "test acc: 57.336%\n",
      "=================100===================\n",
      "Model: \"sequential_80\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_310 (Conv2D)          (None, 100, 1, 100)       22100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_310 (MaxPoolin (None, 34, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_310 (Bat (None, 34, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_310 (Dropout)        (None, 34, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_311 (Conv2D)          (None, 34, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_311 (MaxPoolin (None, 12, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_311 (Bat (None, 12, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_311 (Dropout)        (None, 12, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_312 (Conv2D)          (None, 12, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_312 (MaxPoolin (None, 4, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_312 (Bat (None, 4, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_312 (Dropout)        (None, 4, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_80 (Flatten)         (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 100)               40100     \n",
      "_________________________________________________________________\n",
      "reshape_8 (Reshape)          (None, 100, 1)            0         \n",
      "_________________________________________________________________\n",
      "lstm_16 (LSTM)               (None, 100, 100)          40800     \n",
      "_________________________________________________________________\n",
      "lstm_17 (LSTM)               (None, 70)                47880     \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 4)                 284       \n",
      "=================================================================\n",
      "Total params: 352,564\n",
      "Trainable params: 351,964\n",
      "Non-trainable params: 600\n",
      "_________________________________________________________________\n",
      "Train on 6960 samples, validate on 1500 samples\n",
      "Epoch 1/50\n",
      "6960/6960 [==============================] - 42s 6ms/sample - loss: 1.3891 - acc: 0.2759 - val_loss: 1.3879 - val_acc: 0.2500\n",
      "Epoch 2/50\n",
      "6960/6960 [==============================] - 27s 4ms/sample - loss: 1.3503 - acc: 0.3305 - val_loss: 1.3840 - val_acc: 0.3440\n",
      "Epoch 3/50\n",
      "6960/6960 [==============================] - 26s 4ms/sample - loss: 1.2929 - acc: 0.3922 - val_loss: 1.2466 - val_acc: 0.4247\n",
      "Epoch 4/50\n",
      "6960/6960 [==============================] - 25s 4ms/sample - loss: 1.2491 - acc: 0.4305 - val_loss: 1.2138 - val_acc: 0.4500\n",
      "Epoch 5/50\n",
      "6960/6960 [==============================] - 26s 4ms/sample - loss: 1.1968 - acc: 0.4635 - val_loss: 1.1433 - val_acc: 0.4867\n",
      "Epoch 6/50\n",
      "6960/6960 [==============================] - 27s 4ms/sample - loss: 1.1578 - acc: 0.4858 - val_loss: 1.0883 - val_acc: 0.5240\n",
      "Epoch 7/50\n",
      "6960/6960 [==============================] - 30s 4ms/sample - loss: 1.1282 - acc: 0.4976 - val_loss: 1.0503 - val_acc: 0.5307\n",
      "Epoch 8/50\n",
      "6960/6960 [==============================] - 24s 3ms/sample - loss: 1.0947 - acc: 0.5155 - val_loss: 1.0121 - val_acc: 0.5660\n",
      "Epoch 9/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 1.0706 - acc: 0.5256 - val_loss: 0.9990 - val_acc: 0.5420\n",
      "Epoch 10/50\n",
      "6960/6960 [==============================] - 25s 4ms/sample - loss: 1.0371 - acc: 0.5420 - val_loss: 0.9176 - val_acc: 0.5973\n",
      "Epoch 11/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 1.0052 - acc: 0.5519 - val_loss: 0.9141 - val_acc: 0.6180\n",
      "Epoch 12/50\n",
      "6960/6960 [==============================] - 24s 3ms/sample - loss: 0.9838 - acc: 0.5657 - val_loss: 0.8456 - val_acc: 0.6220\n",
      "Epoch 13/50\n",
      "6960/6960 [==============================] - 21s 3ms/sample - loss: 0.9383 - acc: 0.5898 - val_loss: 0.8397 - val_acc: 0.6460\n",
      "Epoch 14/50\n",
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 0.9128 - acc: 0.6086 - val_loss: 0.7590 - val_acc: 0.6867\n",
      "Epoch 15/50\n",
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 0.8818 - acc: 0.6237 - val_loss: 0.7539 - val_acc: 0.6787\n",
      "Epoch 16/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 0.8592 - acc: 0.6365 - val_loss: 0.6696 - val_acc: 0.7593\n",
      "Epoch 17/50\n",
      "6960/6960 [==============================] - 21s 3ms/sample - loss: 0.8283 - acc: 0.6510 - val_loss: 0.7083 - val_acc: 0.7220\n",
      "Epoch 18/50\n",
      "6960/6960 [==============================] - 24s 3ms/sample - loss: 0.7924 - acc: 0.6693 - val_loss: 0.6844 - val_acc: 0.7407\n",
      "Epoch 19/50\n",
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 0.7811 - acc: 0.6776 - val_loss: 0.6534 - val_acc: 0.7740\n",
      "Epoch 20/50\n",
      "6960/6960 [==============================] - 24s 3ms/sample - loss: 0.7699 - acc: 0.6838 - val_loss: 0.6097 - val_acc: 0.7840\n",
      "Epoch 21/50\n",
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 0.7380 - acc: 0.6973 - val_loss: 0.6042 - val_acc: 0.7987\n",
      "Epoch 22/50\n",
      "6960/6960 [==============================] - 21s 3ms/sample - loss: 0.7082 - acc: 0.7138 - val_loss: 0.5470 - val_acc: 0.8327\n",
      "Epoch 23/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 0.6970 - acc: 0.7191 - val_loss: 0.5048 - val_acc: 0.8387\n",
      "Epoch 24/50\n",
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 0.6859 - acc: 0.7181 - val_loss: 0.5426 - val_acc: 0.8320\n",
      "Epoch 25/50\n",
      "6960/6960 [==============================] - 21s 3ms/sample - loss: 0.6544 - acc: 0.7309 - val_loss: 0.4334 - val_acc: 0.8573\n",
      "Epoch 26/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 0.6363 - acc: 0.7417 - val_loss: 0.4415 - val_acc: 0.8587\n",
      "Epoch 27/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 0.6081 - acc: 0.7550 - val_loss: 0.3989 - val_acc: 0.8920\n",
      "Epoch 28/50\n",
      "6960/6960 [==============================] - 21s 3ms/sample - loss: 0.6115 - acc: 0.7517 - val_loss: 0.4049 - val_acc: 0.8907\n",
      "Epoch 29/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 0.5955 - acc: 0.7585 - val_loss: 0.3719 - val_acc: 0.8800\n",
      "Epoch 30/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 0.5819 - acc: 0.7688 - val_loss: 0.3921 - val_acc: 0.9033\n",
      "Epoch 31/50\n",
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 0.5541 - acc: 0.7730 - val_loss: 0.3381 - val_acc: 0.9093\n",
      "Epoch 32/50\n",
      "6960/6960 [==============================] - 21s 3ms/sample - loss: 0.5416 - acc: 0.7839 - val_loss: 0.3361 - val_acc: 0.9033\n",
      "Epoch 33/50\n",
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 0.5350 - acc: 0.7835 - val_loss: 0.3069 - val_acc: 0.9127\n",
      "Epoch 34/50\n",
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 0.5208 - acc: 0.7932 - val_loss: 0.2989 - val_acc: 0.9173\n",
      "Epoch 35/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 0.4916 - acc: 0.8024 - val_loss: 0.2904 - val_acc: 0.9200\n",
      "Epoch 36/50\n",
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 0.5031 - acc: 0.7953 - val_loss: 0.2672 - val_acc: 0.9333\n",
      "Epoch 37/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 0.4876 - acc: 0.8023 - val_loss: 0.2749 - val_acc: 0.9320\n",
      "Epoch 38/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 0.4716 - acc: 0.8118 - val_loss: 0.2920 - val_acc: 0.9187\n",
      "Epoch 39/50\n",
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 0.4790 - acc: 0.8099 - val_loss: 0.2848 - val_acc: 0.9273\n",
      "Epoch 40/50\n",
      "6960/6960 [==============================] - 24s 3ms/sample - loss: 0.4494 - acc: 0.8193 - val_loss: 0.2290 - val_acc: 0.9473\n",
      "Epoch 41/50\n",
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 0.4708 - acc: 0.8128 - val_loss: 0.2523 - val_acc: 0.9380\n",
      "Epoch 42/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 0.4364 - acc: 0.8194 - val_loss: 0.2197 - val_acc: 0.9453\n",
      "Epoch 43/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 0.4636 - acc: 0.8112 - val_loss: 0.2598 - val_acc: 0.9367\n",
      "Epoch 44/50\n",
      "6960/6960 [==============================] - 21s 3ms/sample - loss: 0.4281 - acc: 0.8293 - val_loss: 0.2209 - val_acc: 0.9540\n",
      "Epoch 45/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.4341 - acc: 0.8227 - val_loss: 0.2205 - val_acc: 0.9500\n",
      "Epoch 46/50\n",
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 0.4244 - acc: 0.8263 - val_loss: 0.1869 - val_acc: 0.9567\n",
      "Epoch 47/50\n",
      "6960/6960 [==============================] - 21s 3ms/sample - loss: 0.4148 - acc: 0.8338 - val_loss: 0.2089 - val_acc: 0.9500\n",
      "Epoch 48/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 0.4082 - acc: 0.8332 - val_loss: 0.1778 - val_acc: 0.9520\n",
      "Epoch 49/50\n",
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 0.4055 - acc: 0.8374 - val_loss: 0.1952 - val_acc: 0.9500\n",
      "Epoch 50/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 0.4056 - acc: 0.8369 - val_loss: 0.1787 - val_acc: 0.9627\n",
      "6960/6960 [==============================] - 41s 6ms/sample - loss: 0.0962 - acc: 0.9935\n",
      "1772/1772 [==============================] - 11s 6ms/sample - loss: 1.0768 - acc: 0.5993\n",
      "train acc: 99.353%\n",
      "test acc: 59.932%\n",
      "=================125===================\n",
      "Model: \"sequential_81\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_313 (Conv2D)          (None, 125, 1, 100)       22100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_313 (MaxPoolin (None, 42, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_313 (Bat (None, 42, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_313 (Dropout)        (None, 42, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_314 (Conv2D)          (None, 42, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_314 (MaxPoolin (None, 14, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_314 (Bat (None, 14, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_314 (Dropout)        (None, 14, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_315 (Conv2D)          (None, 14, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_315 (MaxPoolin (None, 5, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_315 (Bat (None, 5, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_315 (Dropout)        (None, 5, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_81 (Flatten)         (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 100)               50100     \n",
      "_________________________________________________________________\n",
      "reshape_9 (Reshape)          (None, 100, 1)            0         \n",
      "_________________________________________________________________\n",
      "lstm_18 (LSTM)               (None, 100, 100)          40800     \n",
      "_________________________________________________________________\n",
      "lstm_19 (LSTM)               (None, 70)                47880     \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 4)                 284       \n",
      "=================================================================\n",
      "Total params: 362,564\n",
      "Trainable params: 361,964\n",
      "Non-trainable params: 600\n",
      "_________________________________________________________________\n",
      "Train on 6960 samples, validate on 1500 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "6960/6960 [==============================] - 34s 5ms/sample - loss: 1.3935 - acc: 0.2635 - val_loss: 1.3758 - val_acc: 0.3027\n",
      "Epoch 2/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 1.3637 - acc: 0.3073 - val_loss: 1.3742 - val_acc: 0.3247\n",
      "Epoch 3/50\n",
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 1.3429 - acc: 0.3338 - val_loss: 1.2850 - val_acc: 0.3927\n",
      "Epoch 4/50\n",
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 1.3096 - acc: 0.3723 - val_loss: 1.3102 - val_acc: 0.3873\n",
      "Epoch 5/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 1.2481 - acc: 0.4307 - val_loss: 1.3214 - val_acc: 0.4193\n",
      "Epoch 6/50\n",
      "6960/6960 [==============================] - 21s 3ms/sample - loss: 1.2032 - acc: 0.4596 - val_loss: 1.0932 - val_acc: 0.5220\n",
      "Epoch 7/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 1.1640 - acc: 0.4796 - val_loss: 1.1006 - val_acc: 0.5187\n",
      "Epoch 8/50\n",
      "6960/6960 [==============================] - 21s 3ms/sample - loss: 1.1258 - acc: 0.5037 - val_loss: 1.0025 - val_acc: 0.5733\n",
      "Epoch 9/50\n",
      "6960/6960 [==============================] - 21s 3ms/sample - loss: 1.0817 - acc: 0.5210 - val_loss: 0.9820 - val_acc: 0.5813\n",
      "Epoch 10/50\n",
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 1.0543 - acc: 0.5392 - val_loss: 0.9161 - val_acc: 0.6127\n",
      "Epoch 11/50\n",
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 1.0099 - acc: 0.5614 - val_loss: 0.8797 - val_acc: 0.6353\n",
      "Epoch 12/50\n",
      "6960/6960 [==============================] - 21s 3ms/sample - loss: 0.9856 - acc: 0.5720 - val_loss: 0.8676 - val_acc: 0.6220\n",
      "Epoch 13/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 0.9551 - acc: 0.6014 - val_loss: 0.7992 - val_acc: 0.6947\n",
      "Epoch 14/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 0.9312 - acc: 0.6022 - val_loss: 0.8002 - val_acc: 0.6807\n",
      "Epoch 15/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 0.8991 - acc: 0.6274 - val_loss: 0.7643 - val_acc: 0.7007\n",
      "Epoch 16/50\n",
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 0.8648 - acc: 0.6444 - val_loss: 0.7174 - val_acc: 0.7273\n",
      "Epoch 17/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 0.8573 - acc: 0.6457 - val_loss: 0.6847 - val_acc: 0.7380\n",
      "Epoch 18/50\n",
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 0.8067 - acc: 0.6717 - val_loss: 0.6411 - val_acc: 0.7827\n",
      "Epoch 19/50\n",
      "6960/6960 [==============================] - 27s 4ms/sample - loss: 0.8017 - acc: 0.6750 - val_loss: 0.6516 - val_acc: 0.7520\n",
      "Epoch 20/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 0.7754 - acc: 0.6853 - val_loss: 0.5654 - val_acc: 0.8167\n",
      "Epoch 21/50\n",
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 0.7472 - acc: 0.6904 - val_loss: 0.5519 - val_acc: 0.8127\n",
      "Epoch 22/50\n",
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 0.7238 - acc: 0.7092 - val_loss: 0.5087 - val_acc: 0.8167\n",
      "Epoch 23/50\n",
      "6960/6960 [==============================] - 21s 3ms/sample - loss: 0.7001 - acc: 0.7172 - val_loss: 0.4597 - val_acc: 0.8553\n",
      "Epoch 24/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 0.6816 - acc: 0.7302 - val_loss: 0.4668 - val_acc: 0.8567\n",
      "Epoch 25/50\n",
      "6960/6960 [==============================] - 21s 3ms/sample - loss: 0.6495 - acc: 0.7414 - val_loss: 0.4239 - val_acc: 0.8620\n",
      "Epoch 26/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 0.6372 - acc: 0.7418 - val_loss: 0.4092 - val_acc: 0.8780\n",
      "Epoch 27/50\n",
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 0.6030 - acc: 0.7615 - val_loss: 0.3855 - val_acc: 0.8813\n",
      "Epoch 28/50\n",
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 0.6212 - acc: 0.7563 - val_loss: 0.3825 - val_acc: 0.8787\n",
      "Epoch 29/50\n",
      "6960/6960 [==============================] - 28s 4ms/sample - loss: 0.5825 - acc: 0.7687 - val_loss: 0.3179 - val_acc: 0.9140\n",
      "Epoch 30/50\n",
      "6960/6960 [==============================] - 25s 4ms/sample - loss: 0.5770 - acc: 0.7734 - val_loss: 0.3619 - val_acc: 0.8927\n",
      "Epoch 31/50\n",
      "6960/6960 [==============================] - 24s 3ms/sample - loss: 0.5436 - acc: 0.7841 - val_loss: 0.3443 - val_acc: 0.8860\n",
      "Epoch 32/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 0.5567 - acc: 0.7780 - val_loss: 0.2879 - val_acc: 0.9260\n",
      "Epoch 33/50\n",
      "6960/6960 [==============================] - 26s 4ms/sample - loss: 0.5229 - acc: 0.7922 - val_loss: 0.2675 - val_acc: 0.9400\n",
      "Epoch 34/50\n",
      "6960/6960 [==============================] - 21s 3ms/sample - loss: 0.5248 - acc: 0.7931 - val_loss: 0.2622 - val_acc: 0.9447\n",
      "Epoch 35/50\n",
      "6960/6960 [==============================] - 26s 4ms/sample - loss: 0.5025 - acc: 0.8013 - val_loss: 0.2610 - val_acc: 0.9333\n",
      "Epoch 36/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 0.5126 - acc: 0.7940 - val_loss: 0.2382 - val_acc: 0.9400\n",
      "Epoch 37/50\n",
      "6960/6960 [==============================] - 21s 3ms/sample - loss: 0.4956 - acc: 0.8062 - val_loss: 0.2224 - val_acc: 0.9480\n",
      "Epoch 38/50\n",
      "6960/6960 [==============================] - 21s 3ms/sample - loss: 0.4824 - acc: 0.8055 - val_loss: 0.2114 - val_acc: 0.9520\n",
      "Epoch 39/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 0.4602 - acc: 0.8174 - val_loss: 0.1901 - val_acc: 0.9520\n",
      "Epoch 40/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 0.4640 - acc: 0.8135 - val_loss: 0.1869 - val_acc: 0.9573\n",
      "Epoch 41/50\n",
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 0.4510 - acc: 0.8208 - val_loss: 0.1752 - val_acc: 0.9667\n",
      "Epoch 42/50\n",
      "6960/6960 [==============================] - 21s 3ms/sample - loss: 0.4593 - acc: 0.8208 - val_loss: 0.1940 - val_acc: 0.9587\n",
      "Epoch 43/50\n",
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 0.4477 - acc: 0.8177 - val_loss: 0.1646 - val_acc: 0.9767\n",
      "Epoch 44/50\n",
      "6960/6960 [==============================] - 18s 3ms/sample - loss: 0.4201 - acc: 0.8297 - val_loss: 0.1426 - val_acc: 0.9700\n",
      "Epoch 45/50\n",
      "6960/6960 [==============================] - 18s 3ms/sample - loss: 0.4326 - acc: 0.8296 - val_loss: 0.1487 - val_acc: 0.9760\n",
      "Epoch 46/50\n",
      "6960/6960 [==============================] - 18s 3ms/sample - loss: 0.4080 - acc: 0.8328 - val_loss: 0.1464 - val_acc: 0.9733\n",
      "Epoch 47/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.4190 - acc: 0.8276 - val_loss: 0.1569 - val_acc: 0.9720\n",
      "Epoch 48/50\n",
      "6960/6960 [==============================] - 18s 3ms/sample - loss: 0.4159 - acc: 0.8318 - val_loss: 0.1420 - val_acc: 0.9727\n",
      "Epoch 49/50\n",
      "6960/6960 [==============================] - 18s 3ms/sample - loss: 0.3990 - acc: 0.8386 - val_loss: 0.1326 - val_acc: 0.9753\n",
      "Epoch 50/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 0.3971 - acc: 0.8323 - val_loss: 0.1236 - val_acc: 0.9807\n",
      "6960/6960 [==============================] - 40s 6ms/sample - loss: 0.0716 - acc: 0.9928\n",
      "1772/1772 [==============================] - 10s 5ms/sample - loss: 1.1441 - acc: 0.6106\n",
      "train acc: 99.282%\n",
      "test acc: 61.061%\n",
      "=================150===================\n",
      "Model: \"sequential_82\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_316 (Conv2D)          (None, 150, 1, 100)       22100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_316 (MaxPoolin (None, 50, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_316 (Bat (None, 50, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_316 (Dropout)        (None, 50, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_317 (Conv2D)          (None, 50, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_317 (MaxPoolin (None, 17, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_317 (Bat (None, 17, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_317 (Dropout)        (None, 17, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_318 (Conv2D)          (None, 17, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_318 (MaxPoolin (None, 6, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_318 (Bat (None, 6, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_318 (Dropout)        (None, 6, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_82 (Flatten)         (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 100)               60100     \n",
      "_________________________________________________________________\n",
      "reshape_10 (Reshape)         (None, 100, 1)            0         \n",
      "_________________________________________________________________\n",
      "lstm_20 (LSTM)               (None, 100, 100)          40800     \n",
      "_________________________________________________________________\n",
      "lstm_21 (LSTM)               (None, 70)                47880     \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 4)                 284       \n",
      "=================================================================\n",
      "Total params: 372,564\n",
      "Trainable params: 371,964\n",
      "Non-trainable params: 600\n",
      "_________________________________________________________________\n",
      "Train on 6960 samples, validate on 1500 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "6960/6960 [==============================] - 34s 5ms/sample - loss: 1.3909 - acc: 0.2654 - val_loss: 1.4594 - val_acc: 0.2487\n",
      "Epoch 2/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 1.3682 - acc: 0.2977 - val_loss: 1.4180 - val_acc: 0.2647\n",
      "Epoch 3/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 1.3406 - acc: 0.3361 - val_loss: 1.3352 - val_acc: 0.3460\n",
      "Epoch 4/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 1.2857 - acc: 0.4036 - val_loss: 1.2621 - val_acc: 0.4153\n",
      "Epoch 5/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 1.2220 - acc: 0.4448 - val_loss: 1.1425 - val_acc: 0.4853\n",
      "Epoch 6/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 1.1498 - acc: 0.4866 - val_loss: 1.1251 - val_acc: 0.5167\n",
      "Epoch 7/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 1.1074 - acc: 0.5162 - val_loss: 1.0506 - val_acc: 0.5560\n",
      "Epoch 8/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 1.0621 - acc: 0.5384 - val_loss: 0.9806 - val_acc: 0.6073\n",
      "Epoch 9/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 1.0215 - acc: 0.5608 - val_loss: 0.8979 - val_acc: 0.6380\n",
      "Epoch 10/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.9741 - acc: 0.5766 - val_loss: 0.8437 - val_acc: 0.6587\n",
      "Epoch 11/50\n",
      "6960/6960 [==============================] - 21s 3ms/sample - loss: 0.9451 - acc: 0.6000 - val_loss: 0.8312 - val_acc: 0.6660\n",
      "Epoch 12/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.9085 - acc: 0.6250 - val_loss: 0.7316 - val_acc: 0.7200\n",
      "Epoch 13/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.8800 - acc: 0.6349 - val_loss: 0.7286 - val_acc: 0.7213\n",
      "Epoch 14/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 0.8375 - acc: 0.6533 - val_loss: 0.6750 - val_acc: 0.7507\n",
      "Epoch 15/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.8001 - acc: 0.6733 - val_loss: 0.6246 - val_acc: 0.7793\n",
      "Epoch 16/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.7668 - acc: 0.6868 - val_loss: 0.6071 - val_acc: 0.8007\n",
      "Epoch 17/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 0.7379 - acc: 0.7060 - val_loss: 0.5819 - val_acc: 0.8013\n",
      "Epoch 18/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.7116 - acc: 0.7158 - val_loss: 0.4884 - val_acc: 0.8433\n",
      "Epoch 19/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 0.6817 - acc: 0.7306 - val_loss: 0.5113 - val_acc: 0.8380\n",
      "Epoch 20/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.6675 - acc: 0.7359 - val_loss: 0.4962 - val_acc: 0.8367\n",
      "Epoch 21/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.6360 - acc: 0.7458 - val_loss: 0.4040 - val_acc: 0.8813\n",
      "Epoch 22/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 0.6151 - acc: 0.7547 - val_loss: 0.3865 - val_acc: 0.8933\n",
      "Epoch 23/50\n",
      "6960/6960 [==============================] - 21s 3ms/sample - loss: 0.6003 - acc: 0.7677 - val_loss: 0.3994 - val_acc: 0.8813\n",
      "Epoch 24/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 0.5565 - acc: 0.7797 - val_loss: 0.3636 - val_acc: 0.8847\n",
      "Epoch 25/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.5463 - acc: 0.7819 - val_loss: 0.3696 - val_acc: 0.8820\n",
      "Epoch 26/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 0.5410 - acc: 0.7862 - val_loss: 0.3065 - val_acc: 0.9140\n",
      "Epoch 27/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.5108 - acc: 0.7971 - val_loss: 0.2900 - val_acc: 0.9193\n",
      "Epoch 28/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 0.5045 - acc: 0.8011 - val_loss: 0.2446 - val_acc: 0.9433\n",
      "Epoch 29/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.4994 - acc: 0.8052 - val_loss: 0.2851 - val_acc: 0.9267\n",
      "Epoch 30/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.4812 - acc: 0.8049 - val_loss: 0.2389 - val_acc: 0.9447\n",
      "Epoch 31/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 0.4631 - acc: 0.8142 - val_loss: 0.2257 - val_acc: 0.9413\n",
      "Epoch 32/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.4642 - acc: 0.8198 - val_loss: 0.2683 - val_acc: 0.9273\n",
      "Epoch 33/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 0.4510 - acc: 0.8224 - val_loss: 0.2360 - val_acc: 0.9327\n",
      "Epoch 34/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 0.4463 - acc: 0.8231 - val_loss: 0.2398 - val_acc: 0.9347\n",
      "Epoch 35/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.4402 - acc: 0.8240 - val_loss: 0.2133 - val_acc: 0.9553\n",
      "Epoch 36/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.4176 - acc: 0.8315 - val_loss: 0.1990 - val_acc: 0.9547\n",
      "Epoch 37/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 0.4043 - acc: 0.8417 - val_loss: 0.1874 - val_acc: 0.9540\n",
      "Epoch 38/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 0.4061 - acc: 0.8397 - val_loss: 0.1935 - val_acc: 0.9553\n",
      "Epoch 39/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.3962 - acc: 0.8418 - val_loss: 0.1643 - val_acc: 0.9640\n",
      "Epoch 40/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.4019 - acc: 0.8402 - val_loss: 0.1803 - val_acc: 0.9633\n",
      "Epoch 41/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 0.3803 - acc: 0.8486 - val_loss: 0.1415 - val_acc: 0.9693\n",
      "Epoch 42/50\n",
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 0.3747 - acc: 0.8511 - val_loss: 0.1337 - val_acc: 0.9680\n",
      "Epoch 43/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.3791 - acc: 0.8461 - val_loss: 0.1423 - val_acc: 0.9700\n",
      "Epoch 44/50\n",
      "6960/6960 [==============================] - 18s 3ms/sample - loss: 0.3505 - acc: 0.8608 - val_loss: 0.1268 - val_acc: 0.9647\n",
      "Epoch 45/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.3506 - acc: 0.8589 - val_loss: 0.1195 - val_acc: 0.9747\n",
      "Epoch 46/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 0.3510 - acc: 0.8576 - val_loss: 0.1137 - val_acc: 0.9733\n",
      "Epoch 47/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.3350 - acc: 0.8682 - val_loss: 0.1300 - val_acc: 0.9647\n",
      "Epoch 48/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 0.3436 - acc: 0.8625 - val_loss: 0.1286 - val_acc: 0.9713\n",
      "Epoch 49/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.3477 - acc: 0.8583 - val_loss: 0.0955 - val_acc: 0.9787\n",
      "Epoch 50/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 0.3172 - acc: 0.8698 - val_loss: 0.1017 - val_acc: 0.9787\n",
      "6960/6960 [==============================] - 37s 5ms/sample - loss: 0.0476 - acc: 0.9945\n",
      "1772/1772 [==============================] - 11s 6ms/sample - loss: 1.1225 - acc: 0.6546\n",
      "train acc: 99.454%\n",
      "test acc: 65.463%\n",
      "=================175===================\n",
      "Model: \"sequential_83\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_319 (Conv2D)          (None, 175, 1, 100)       22100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_319 (MaxPoolin (None, 59, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_319 (Bat (None, 59, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_319 (Dropout)        (None, 59, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_320 (Conv2D)          (None, 59, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_320 (MaxPoolin (None, 20, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_320 (Bat (None, 20, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_320 (Dropout)        (None, 20, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_321 (Conv2D)          (None, 20, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_321 (MaxPoolin (None, 7, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_321 (Bat (None, 7, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_321 (Dropout)        (None, 7, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_83 (Flatten)         (None, 700)               0         \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 100)               70100     \n",
      "_________________________________________________________________\n",
      "reshape_11 (Reshape)         (None, 100, 1)            0         \n",
      "_________________________________________________________________\n",
      "lstm_22 (LSTM)               (None, 100, 100)          40800     \n",
      "_________________________________________________________________\n",
      "lstm_23 (LSTM)               (None, 70)                47880     \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 4)                 284       \n",
      "=================================================================\n",
      "Total params: 382,564\n",
      "Trainable params: 381,964\n",
      "Non-trainable params: 600\n",
      "_________________________________________________________________\n",
      "Train on 6960 samples, validate on 1500 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "6960/6960 [==============================] - 33s 5ms/sample - loss: 1.3799 - acc: 0.2958 - val_loss: 1.4490 - val_acc: 0.3233\n",
      "Epoch 2/50\n",
      "6960/6960 [==============================] - 18s 3ms/sample - loss: 1.3218 - acc: 0.3639 - val_loss: 1.3001 - val_acc: 0.3847\n",
      "Epoch 3/50\n",
      "6960/6960 [==============================] - 18s 3ms/sample - loss: 1.2684 - acc: 0.3990 - val_loss: 1.1946 - val_acc: 0.4607\n",
      "Epoch 4/50\n",
      "6960/6960 [==============================] - 18s 3ms/sample - loss: 1.1949 - acc: 0.4494 - val_loss: 1.1772 - val_acc: 0.4653\n",
      "Epoch 5/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 1.1387 - acc: 0.4839 - val_loss: 1.0595 - val_acc: 0.5193\n",
      "Epoch 6/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 1.1063 - acc: 0.5036 - val_loss: 0.9890 - val_acc: 0.5673\n",
      "Epoch 7/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 1.0480 - acc: 0.5369 - val_loss: 0.9666 - val_acc: 0.5860\n",
      "Epoch 8/50\n",
      "6960/6960 [==============================] - 21s 3ms/sample - loss: 1.0384 - acc: 0.5414 - val_loss: 0.9314 - val_acc: 0.6080\n",
      "Epoch 9/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.9941 - acc: 0.5568 - val_loss: 0.9467 - val_acc: 0.5740\n",
      "Epoch 10/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.9586 - acc: 0.5842 - val_loss: 0.8296 - val_acc: 0.6647\n",
      "Epoch 11/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.9186 - acc: 0.5960 - val_loss: 0.7956 - val_acc: 0.6800\n",
      "Epoch 12/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 0.8974 - acc: 0.6105 - val_loss: 0.7697 - val_acc: 0.6893\n",
      "Epoch 13/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.8572 - acc: 0.6244 - val_loss: 0.7115 - val_acc: 0.7113\n",
      "Epoch 14/50\n",
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 0.8385 - acc: 0.6333 - val_loss: 0.6903 - val_acc: 0.7273\n",
      "Epoch 15/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.8189 - acc: 0.6441 - val_loss: 0.6804 - val_acc: 0.7387\n",
      "Epoch 16/50\n",
      "6960/6960 [==============================] - 18s 3ms/sample - loss: 0.7960 - acc: 0.6609 - val_loss: 0.6779 - val_acc: 0.7393\n",
      "Epoch 17/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.7789 - acc: 0.6655 - val_loss: 0.6697 - val_acc: 0.7480\n",
      "Epoch 18/50\n",
      "6960/6960 [==============================] - 25s 4ms/sample - loss: 0.7709 - acc: 0.6792 - val_loss: 0.6449 - val_acc: 0.7580\n",
      "Epoch 19/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.7249 - acc: 0.6935 - val_loss: 0.5602 - val_acc: 0.8133\n",
      "Epoch 20/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.7096 - acc: 0.7096 - val_loss: 0.5410 - val_acc: 0.7987\n",
      "Epoch 21/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.6966 - acc: 0.7073 - val_loss: 0.5304 - val_acc: 0.8193\n",
      "Epoch 22/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.6745 - acc: 0.7204 - val_loss: 0.5050 - val_acc: 0.8400\n",
      "Epoch 23/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.6716 - acc: 0.7237 - val_loss: 0.4666 - val_acc: 0.8513\n",
      "Epoch 24/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.6384 - acc: 0.7412 - val_loss: 0.4473 - val_acc: 0.8440\n",
      "Epoch 25/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 0.6301 - acc: 0.7414 - val_loss: 0.4164 - val_acc: 0.8640\n",
      "Epoch 26/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.6019 - acc: 0.7592 - val_loss: 0.3828 - val_acc: 0.8813\n",
      "Epoch 27/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 0.5908 - acc: 0.7565 - val_loss: 0.4259 - val_acc: 0.8560\n",
      "Epoch 28/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.5726 - acc: 0.7654 - val_loss: 0.3645 - val_acc: 0.8873\n",
      "Epoch 29/50\n",
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 0.5607 - acc: 0.7680 - val_loss: 0.3628 - val_acc: 0.8940\n",
      "Epoch 30/50\n",
      "6960/6960 [==============================] - 38s 5ms/sample - loss: 0.5491 - acc: 0.7790 - val_loss: 0.3447 - val_acc: 0.8960\n",
      "Epoch 31/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 0.5414 - acc: 0.7792 - val_loss: 0.3261 - val_acc: 0.9020\n",
      "Epoch 32/50\n",
      "6960/6960 [==============================] - 21s 3ms/sample - loss: 0.5368 - acc: 0.7832 - val_loss: 0.3194 - val_acc: 0.9133\n",
      "Epoch 33/50\n",
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 0.5207 - acc: 0.7843 - val_loss: 0.2920 - val_acc: 0.9247\n",
      "Epoch 34/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 0.4907 - acc: 0.8023 - val_loss: 0.2758 - val_acc: 0.9267\n",
      "Epoch 35/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 0.4984 - acc: 0.7971 - val_loss: 0.2479 - val_acc: 0.9393\n",
      "Epoch 36/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.4813 - acc: 0.8070 - val_loss: 0.2664 - val_acc: 0.9267\n",
      "Epoch 37/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 0.4674 - acc: 0.8128 - val_loss: 0.2163 - val_acc: 0.9427\n",
      "Epoch 38/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 0.4593 - acc: 0.8167 - val_loss: 0.2189 - val_acc: 0.9513\n",
      "Epoch 39/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.4664 - acc: 0.8095 - val_loss: 0.2103 - val_acc: 0.9467\n",
      "Epoch 40/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.4427 - acc: 0.8249 - val_loss: 0.2259 - val_acc: 0.9487\n",
      "Epoch 41/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 0.4433 - acc: 0.8221 - val_loss: 0.2194 - val_acc: 0.9413\n",
      "Epoch 42/50\n",
      "6960/6960 [==============================] - 21s 3ms/sample - loss: 0.4219 - acc: 0.8249 - val_loss: 0.1872 - val_acc: 0.9620\n",
      "Epoch 43/50\n",
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 0.4075 - acc: 0.8362 - val_loss: 0.1908 - val_acc: 0.9520\n",
      "Epoch 44/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.4002 - acc: 0.8394 - val_loss: 0.1739 - val_acc: 0.9653\n",
      "Epoch 45/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 0.3877 - acc: 0.8424 - val_loss: 0.1768 - val_acc: 0.9567\n",
      "Epoch 46/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.3843 - acc: 0.8422 - val_loss: 0.1580 - val_acc: 0.9620\n",
      "Epoch 47/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.3728 - acc: 0.8546 - val_loss: 0.1878 - val_acc: 0.9500\n",
      "Epoch 48/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.3650 - acc: 0.8529 - val_loss: 0.1485 - val_acc: 0.9720\n",
      "Epoch 49/50\n",
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 0.3626 - acc: 0.8517 - val_loss: 0.1435 - val_acc: 0.9667\n",
      "Epoch 50/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.3542 - acc: 0.8552 - val_loss: 0.1309 - val_acc: 0.9733\n",
      "6960/6960 [==============================] - 50s 7ms/sample - loss: 0.0721 - acc: 0.9943\n",
      "1772/1772 [==============================] - 16s 9ms/sample - loss: 1.0827 - acc: 0.6247\n",
      "train acc: 99.425%\n",
      "test acc: 62.472%\n",
      "=================200===================\n",
      "Model: \"sequential_84\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_322 (Conv2D)          (None, 200, 1, 100)       22100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_322 (MaxPoolin (None, 67, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_322 (Bat (None, 67, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_322 (Dropout)        (None, 67, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_323 (Conv2D)          (None, 67, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_323 (MaxPoolin (None, 23, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_323 (Bat (None, 23, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_323 (Dropout)        (None, 23, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_324 (Conv2D)          (None, 23, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_324 (MaxPoolin (None, 8, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_324 (Bat (None, 8, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_324 (Dropout)        (None, 8, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_84 (Flatten)         (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 100)               80100     \n",
      "_________________________________________________________________\n",
      "reshape_12 (Reshape)         (None, 100, 1)            0         \n",
      "_________________________________________________________________\n",
      "lstm_24 (LSTM)               (None, 100, 100)          40800     \n",
      "_________________________________________________________________\n",
      "lstm_25 (LSTM)               (None, 70)                47880     \n",
      "_________________________________________________________________\n",
      "dense_97 (Dense)             (None, 4)                 284       \n",
      "=================================================================\n",
      "Total params: 392,564\n",
      "Trainable params: 391,964\n",
      "Non-trainable params: 600\n",
      "_________________________________________________________________\n",
      "Train on 6960 samples, validate on 1500 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "6960/6960 [==============================] - 74s 11ms/sample - loss: 1.3708 - acc: 0.3030 - val_loss: 1.3778 - val_acc: 0.2800\n",
      "Epoch 2/50\n",
      "6960/6960 [==============================] - 45s 6ms/sample - loss: 1.2766 - acc: 0.3971 - val_loss: 1.2920 - val_acc: 0.3820\n",
      "Epoch 3/50\n",
      "6960/6960 [==============================] - 41s 6ms/sample - loss: 1.2035 - acc: 0.4432 - val_loss: 1.2206 - val_acc: 0.4367\n",
      "Epoch 4/50\n",
      "6960/6960 [==============================] - 40s 6ms/sample - loss: 1.1359 - acc: 0.4907 - val_loss: 1.1492 - val_acc: 0.4720\n",
      "Epoch 5/50\n",
      "6960/6960 [==============================] - 34s 5ms/sample - loss: 1.0736 - acc: 0.5164 - val_loss: 1.0206 - val_acc: 0.5580\n",
      "Epoch 6/50\n",
      "6960/6960 [==============================] - 38s 6ms/sample - loss: 1.0294 - acc: 0.5407 - val_loss: 0.9279 - val_acc: 0.5980\n",
      "Epoch 7/50\n",
      "6960/6960 [==============================] - 48s 7ms/sample - loss: 0.9850 - acc: 0.5662 - val_loss: 0.9467 - val_acc: 0.5693\n",
      "Epoch 8/50\n",
      "6960/6960 [==============================] - 42s 6ms/sample - loss: 0.9486 - acc: 0.5927 - val_loss: 0.8547 - val_acc: 0.6547\n",
      "Epoch 9/50\n",
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 0.8889 - acc: 0.6338 - val_loss: 0.7481 - val_acc: 0.7113\n",
      "Epoch 10/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 0.8419 - acc: 0.6471 - val_loss: 0.6919 - val_acc: 0.7560\n",
      "Epoch 11/50\n",
      "6960/6960 [==============================] - 21s 3ms/sample - loss: 0.8010 - acc: 0.6691 - val_loss: 0.6566 - val_acc: 0.7547\n",
      "Epoch 12/50\n",
      "6960/6960 [==============================] - 21s 3ms/sample - loss: 0.7528 - acc: 0.6966 - val_loss: 0.6512 - val_acc: 0.7387\n",
      "Epoch 13/50\n",
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 0.7277 - acc: 0.7053 - val_loss: 0.5534 - val_acc: 0.7947\n",
      "Epoch 14/50\n",
      "6960/6960 [==============================] - 24s 3ms/sample - loss: 0.6926 - acc: 0.7167 - val_loss: 0.4860 - val_acc: 0.8353\n",
      "Epoch 15/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 0.6732 - acc: 0.7299 - val_loss: 0.4850 - val_acc: 0.8367\n",
      "Epoch 16/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 0.6422 - acc: 0.7447 - val_loss: 0.4290 - val_acc: 0.8687\n",
      "Epoch 17/50\n",
      "6960/6960 [==============================] - 21s 3ms/sample - loss: 0.6014 - acc: 0.7629 - val_loss: 0.3986 - val_acc: 0.8800\n",
      "Epoch 18/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 0.5829 - acc: 0.7717 - val_loss: 0.4150 - val_acc: 0.8773\n",
      "Epoch 19/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 0.5620 - acc: 0.7744 - val_loss: 0.3476 - val_acc: 0.8993\n",
      "Epoch 20/50\n",
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 0.5350 - acc: 0.7892 - val_loss: 0.2876 - val_acc: 0.9207\n",
      "Epoch 21/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 0.4966 - acc: 0.8023 - val_loss: 0.2911 - val_acc: 0.9140\n",
      "Epoch 22/50\n",
      "6960/6960 [==============================] - 21s 3ms/sample - loss: 0.5018 - acc: 0.7976 - val_loss: 0.3041 - val_acc: 0.9100\n",
      "Epoch 23/50\n",
      "6960/6960 [==============================] - 21s 3ms/sample - loss: 0.4847 - acc: 0.8055 - val_loss: 0.3029 - val_acc: 0.9153\n",
      "Epoch 24/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 0.4567 - acc: 0.8182 - val_loss: 0.2229 - val_acc: 0.9453\n",
      "Epoch 25/50\n",
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 0.4306 - acc: 0.8266 - val_loss: 0.2367 - val_acc: 0.9500\n",
      "Epoch 26/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 0.4235 - acc: 0.8305 - val_loss: 0.1922 - val_acc: 0.9567\n",
      "Epoch 27/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 0.4292 - acc: 0.8266 - val_loss: 0.1968 - val_acc: 0.9547\n",
      "Epoch 28/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 0.3951 - acc: 0.8411 - val_loss: 0.1796 - val_acc: 0.9660\n",
      "Epoch 29/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 0.3791 - acc: 0.8460 - val_loss: 0.1720 - val_acc: 0.9733\n",
      "Epoch 30/50\n",
      "6960/6960 [==============================] - 37s 5ms/sample - loss: 0.3893 - acc: 0.8445 - val_loss: 0.1762 - val_acc: 0.9553\n",
      "Epoch 31/50\n",
      "6960/6960 [==============================] - 26s 4ms/sample - loss: 0.3869 - acc: 0.8414 - val_loss: 0.1753 - val_acc: 0.9653\n",
      "Epoch 32/50\n",
      "6960/6960 [==============================] - 25s 4ms/sample - loss: 0.3814 - acc: 0.8461 - val_loss: 0.1894 - val_acc: 0.9533\n",
      "Epoch 33/50\n",
      "6960/6960 [==============================] - 25s 4ms/sample - loss: 0.3584 - acc: 0.8552 - val_loss: 0.1369 - val_acc: 0.9753\n",
      "Epoch 34/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 0.3509 - acc: 0.8578 - val_loss: 0.1368 - val_acc: 0.9700\n",
      "Epoch 35/50\n",
      "6960/6960 [==============================] - 24s 3ms/sample - loss: 0.3465 - acc: 0.8572 - val_loss: 0.1239 - val_acc: 0.9787\n",
      "Epoch 36/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 0.3304 - acc: 0.8625 - val_loss: 0.1070 - val_acc: 0.9853\n",
      "Epoch 37/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 0.3349 - acc: 0.8615 - val_loss: 0.1250 - val_acc: 0.9773\n",
      "Epoch 38/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 0.3165 - acc: 0.8691 - val_loss: 0.1250 - val_acc: 0.9780\n",
      "Epoch 39/50\n",
      "6960/6960 [==============================] - 25s 4ms/sample - loss: 0.3084 - acc: 0.8761 - val_loss: 0.0939 - val_acc: 0.9847\n",
      "Epoch 40/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 0.3171 - acc: 0.8685 - val_loss: 0.1100 - val_acc: 0.9860\n",
      "Epoch 41/50\n",
      "6960/6960 [==============================] - 24s 3ms/sample - loss: 0.3110 - acc: 0.8741 - val_loss: 0.0988 - val_acc: 0.9740\n",
      "Epoch 42/50\n",
      "6960/6960 [==============================] - 24s 3ms/sample - loss: 0.3182 - acc: 0.8713 - val_loss: 0.1073 - val_acc: 0.9813\n",
      "Epoch 43/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 0.2950 - acc: 0.8751 - val_loss: 0.0785 - val_acc: 0.9880\n",
      "Epoch 44/50\n",
      "6960/6960 [==============================] - 24s 3ms/sample - loss: 0.2909 - acc: 0.8800 - val_loss: 0.0875 - val_acc: 0.9893\n",
      "Epoch 45/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 0.2693 - acc: 0.8874 - val_loss: 0.0652 - val_acc: 0.9920\n",
      "Epoch 46/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 0.2764 - acc: 0.8882 - val_loss: 0.0835 - val_acc: 0.9860\n",
      "Epoch 47/50\n",
      "6960/6960 [==============================] - 24s 3ms/sample - loss: 0.2915 - acc: 0.8786 - val_loss: 0.1013 - val_acc: 0.9913\n",
      "Epoch 48/50\n",
      "6960/6960 [==============================] - 25s 4ms/sample - loss: 0.2622 - acc: 0.8875 - val_loss: 0.0692 - val_acc: 0.9860\n",
      "Epoch 49/50\n",
      "6960/6960 [==============================] - 24s 4ms/sample - loss: 0.2770 - acc: 0.8853 - val_loss: 0.0869 - val_acc: 0.9873\n",
      "Epoch 50/50\n",
      "6960/6960 [==============================] - 24s 4ms/sample - loss: 0.2704 - acc: 0.8864 - val_loss: 0.0660 - val_acc: 0.9907\n",
      "6960/6960 [==============================] - 46s 7ms/sample - loss: 0.0311 - acc: 0.9983\n",
      "1772/1772 [==============================] - 12s 7ms/sample - loss: 1.0715 - acc: 0.6670\n",
      "train acc: 99.828%\n",
      "test acc: 66.704%\n",
      "=================225===================\n",
      "Model: \"sequential_85\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_325 (Conv2D)          (None, 225, 1, 100)       22100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_325 (MaxPoolin (None, 75, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_325 (Bat (None, 75, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_325 (Dropout)        (None, 75, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_326 (Conv2D)          (None, 75, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_326 (MaxPoolin (None, 25, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_326 (Bat (None, 25, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_326 (Dropout)        (None, 25, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_327 (Conv2D)          (None, 25, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_327 (MaxPoolin (None, 9, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_327 (Bat (None, 9, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "dropout_327 (Dropout)        (None, 9, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_85 (Flatten)         (None, 900)               0         \n",
      "_________________________________________________________________\n",
      "dense_98 (Dense)             (None, 100)               90100     \n",
      "_________________________________________________________________\n",
      "reshape_13 (Reshape)         (None, 100, 1)            0         \n",
      "_________________________________________________________________\n",
      "lstm_26 (LSTM)               (None, 100, 100)          40800     \n",
      "_________________________________________________________________\n",
      "lstm_27 (LSTM)               (None, 70)                47880     \n",
      "_________________________________________________________________\n",
      "dense_99 (Dense)             (None, 4)                 284       \n",
      "=================================================================\n",
      "Total params: 402,564\n",
      "Trainable params: 401,964\n",
      "Non-trainable params: 600\n",
      "_________________________________________________________________\n",
      "Train on 6960 samples, validate on 1500 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "6960/6960 [==============================] - 49s 7ms/sample - loss: 1.3816 - acc: 0.2961 - val_loss: 1.7049 - val_acc: 0.2587\n",
      "Epoch 2/50\n",
      "6960/6960 [==============================] - 25s 4ms/sample - loss: 1.3027 - acc: 0.3664 - val_loss: 1.2595 - val_acc: 0.3940\n",
      "Epoch 3/50\n",
      "6960/6960 [==============================] - 24s 3ms/sample - loss: 1.2255 - acc: 0.4378 - val_loss: 1.1519 - val_acc: 0.4827\n",
      "Epoch 4/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 1.1651 - acc: 0.4662 - val_loss: 1.1111 - val_acc: 0.5000\n",
      "Epoch 5/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 1.1366 - acc: 0.4829 - val_loss: 1.0353 - val_acc: 0.5373\n",
      "Epoch 6/50\n",
      "6960/6960 [==============================] - 24s 3ms/sample - loss: 1.2978 - acc: 0.3828 - val_loss: 1.1873 - val_acc: 0.4607\n",
      "Epoch 7/50\n",
      "6960/6960 [==============================] - 24s 3ms/sample - loss: 1.2076 - acc: 0.4484 - val_loss: 1.0832 - val_acc: 0.5087\n",
      "Epoch 8/50\n",
      "6960/6960 [==============================] - 24s 3ms/sample - loss: 1.1417 - acc: 0.4793 - val_loss: 1.0361 - val_acc: 0.5260\n",
      "Epoch 9/50\n",
      "6960/6960 [==============================] - 25s 4ms/sample - loss: 1.1007 - acc: 0.4953 - val_loss: 1.0068 - val_acc: 0.5367\n",
      "Epoch 10/50\n",
      "6960/6960 [==============================] - 26s 4ms/sample - loss: 1.0807 - acc: 0.5089 - val_loss: 0.9880 - val_acc: 0.5560\n",
      "Epoch 11/50\n",
      "6960/6960 [==============================] - 24s 3ms/sample - loss: 1.0564 - acc: 0.5273 - val_loss: 0.9996 - val_acc: 0.5380\n",
      "Epoch 12/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 1.0464 - acc: 0.5230 - val_loss: 0.9465 - val_acc: 0.5753\n",
      "Epoch 13/50\n",
      "6960/6960 [==============================] - 24s 3ms/sample - loss: 1.0115 - acc: 0.5493 - val_loss: 0.9582 - val_acc: 0.5687\n",
      "Epoch 14/50\n",
      "6960/6960 [==============================] - 24s 3ms/sample - loss: 0.9987 - acc: 0.5486 - val_loss: 0.9333 - val_acc: 0.5627\n",
      "Epoch 15/50\n",
      "6960/6960 [==============================] - 24s 3ms/sample - loss: 0.9889 - acc: 0.5507 - val_loss: 0.9335 - val_acc: 0.5640\n",
      "Epoch 16/50\n",
      "6960/6960 [==============================] - 24s 3ms/sample - loss: 0.9705 - acc: 0.5583 - val_loss: 0.8811 - val_acc: 0.5973\n",
      "Epoch 17/50\n",
      "6960/6960 [==============================] - 24s 3ms/sample - loss: 0.9550 - acc: 0.5700 - val_loss: 0.8533 - val_acc: 0.6267\n",
      "Epoch 18/50\n",
      "6960/6960 [==============================] - 24s 4ms/sample - loss: 0.9299 - acc: 0.5852 - val_loss: 0.8267 - val_acc: 0.6333\n",
      "Epoch 19/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 0.9190 - acc: 0.5872 - val_loss: 0.8069 - val_acc: 0.6460\n",
      "Epoch 20/50\n",
      "6960/6960 [==============================] - 24s 3ms/sample - loss: 0.8981 - acc: 0.6040 - val_loss: 0.7940 - val_acc: 0.6620\n",
      "Epoch 21/50\n",
      "6960/6960 [==============================] - 24s 3ms/sample - loss: 0.8969 - acc: 0.5999 - val_loss: 0.8064 - val_acc: 0.6647\n",
      "Epoch 22/50\n",
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 0.8770 - acc: 0.6089 - val_loss: 0.7731 - val_acc: 0.6587\n",
      "Epoch 23/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.8619 - acc: 0.6080 - val_loss: 0.7819 - val_acc: 0.6613\n",
      "Epoch 24/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.8434 - acc: 0.6287 - val_loss: 0.7423 - val_acc: 0.6967\n",
      "Epoch 25/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.8196 - acc: 0.6392 - val_loss: 0.7320 - val_acc: 0.6973\n",
      "Epoch 26/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.8121 - acc: 0.6438 - val_loss: 0.6998 - val_acc: 0.7193\n",
      "Epoch 27/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.7933 - acc: 0.6517 - val_loss: 0.6660 - val_acc: 0.7407\n",
      "Epoch 28/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.7834 - acc: 0.6611 - val_loss: 0.6664 - val_acc: 0.7247\n",
      "Epoch 29/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.7545 - acc: 0.6777 - val_loss: 0.6267 - val_acc: 0.7580\n",
      "Epoch 30/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.7391 - acc: 0.6902 - val_loss: 0.6014 - val_acc: 0.7507\n",
      "Epoch 31/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.7156 - acc: 0.7007 - val_loss: 0.6323 - val_acc: 0.7387\n",
      "Epoch 32/50\n",
      "6960/6960 [==============================] - 19s 3ms/sample - loss: 0.7302 - acc: 0.6917 - val_loss: 0.5669 - val_acc: 0.7820\n",
      "Epoch 33/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 0.6975 - acc: 0.7171 - val_loss: 0.5463 - val_acc: 0.8053\n",
      "Epoch 34/50\n",
      "6960/6960 [==============================] - 21s 3ms/sample - loss: 0.6622 - acc: 0.7307 - val_loss: 0.4942 - val_acc: 0.8193\n",
      "Epoch 35/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 0.6510 - acc: 0.7318 - val_loss: 0.4780 - val_acc: 0.8353\n",
      "Epoch 36/50\n",
      "6960/6960 [==============================] - 21s 3ms/sample - loss: 0.6319 - acc: 0.7477 - val_loss: 0.4742 - val_acc: 0.8433\n",
      "Epoch 37/50\n",
      "6960/6960 [==============================] - 21s 3ms/sample - loss: 0.6406 - acc: 0.7421 - val_loss: 0.4254 - val_acc: 0.8667\n",
      "Epoch 38/50\n",
      "6960/6960 [==============================] - 21s 3ms/sample - loss: 0.6201 - acc: 0.7464 - val_loss: 0.4684 - val_acc: 0.8507\n",
      "Epoch 39/50\n",
      "6960/6960 [==============================] - 21s 3ms/sample - loss: 0.5907 - acc: 0.7631 - val_loss: 0.3894 - val_acc: 0.8900\n",
      "Epoch 40/50\n",
      "6960/6960 [==============================] - 20s 3ms/sample - loss: 0.5813 - acc: 0.7698 - val_loss: 0.4344 - val_acc: 0.8640\n",
      "Epoch 41/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 0.5670 - acc: 0.7756 - val_loss: 0.3768 - val_acc: 0.8753\n",
      "Epoch 42/50\n",
      "6960/6960 [==============================] - 21s 3ms/sample - loss: 0.5511 - acc: 0.7861 - val_loss: 0.3466 - val_acc: 0.8987\n",
      "Epoch 43/50\n",
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 0.5110 - acc: 0.8009 - val_loss: 0.3298 - val_acc: 0.8987\n",
      "Epoch 44/50\n",
      "6960/6960 [==============================] - 21s 3ms/sample - loss: 0.5110 - acc: 0.7978 - val_loss: 0.2920 - val_acc: 0.9167\n",
      "Epoch 45/50\n",
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 0.5008 - acc: 0.7990 - val_loss: 0.2836 - val_acc: 0.9233\n",
      "Epoch 46/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 0.5029 - acc: 0.8000 - val_loss: 0.2690 - val_acc: 0.9307\n",
      "Epoch 47/50\n",
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 0.4862 - acc: 0.8122 - val_loss: 0.2763 - val_acc: 0.9273\n",
      "Epoch 48/50\n",
      "6960/6960 [==============================] - 21s 3ms/sample - loss: 0.4668 - acc: 0.8170 - val_loss: 0.2322 - val_acc: 0.9400\n",
      "Epoch 49/50\n",
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 0.4531 - acc: 0.8198 - val_loss: 0.2279 - val_acc: 0.9367\n",
      "Epoch 50/50\n",
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 0.4373 - acc: 0.8226 - val_loss: 0.2060 - val_acc: 0.9553\n",
      "6960/6960 [==============================] - 43s 6ms/sample - loss: 0.1406 - acc: 0.9734\n",
      "1772/1772 [==============================] - 11s 6ms/sample - loss: 0.9943 - acc: 0.6450\n",
      "train acc: 97.342%\n",
      "test acc: 64.503%\n",
      "=================250===================\n",
      "Model: \"sequential_86\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_328 (Conv2D)          (None, 250, 1, 100)       22100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_328 (MaxPoolin (None, 84, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_328 (Bat (None, 84, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_328 (Dropout)        (None, 84, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_329 (Conv2D)          (None, 84, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_329 (MaxPoolin (None, 28, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_329 (Bat (None, 28, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_329 (Dropout)        (None, 28, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_330 (Conv2D)          (None, 28, 1, 100)        100100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_330 (MaxPoolin (None, 10, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_330 (Bat (None, 10, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_330 (Dropout)        (None, 10, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "flatten_86 (Flatten)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_100 (Dense)            (None, 100)               100100    \n",
      "_________________________________________________________________\n",
      "reshape_14 (Reshape)         (None, 100, 1)            0         \n",
      "_________________________________________________________________\n",
      "lstm_28 (LSTM)               (None, 100, 100)          40800     \n",
      "_________________________________________________________________\n",
      "lstm_29 (LSTM)               (None, 70)                47880     \n",
      "_________________________________________________________________\n",
      "dense_101 (Dense)            (None, 4)                 284       \n",
      "=================================================================\n",
      "Total params: 412,564\n",
      "Trainable params: 411,964\n",
      "Non-trainable params: 600\n",
      "_________________________________________________________________\n",
      "Train on 6960 samples, validate on 1500 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "6960/6960 [==============================] - 41s 6ms/sample - loss: 1.3886 - acc: 0.2851 - val_loss: 1.5272 - val_acc: 0.2653\n",
      "Epoch 2/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 1.3034 - acc: 0.3786 - val_loss: 1.2530 - val_acc: 0.4120\n",
      "Epoch 3/50\n",
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 1.2079 - acc: 0.4422 - val_loss: 1.2539 - val_acc: 0.4553\n",
      "Epoch 4/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 1.1450 - acc: 0.4739 - val_loss: 1.0799 - val_acc: 0.5213\n",
      "Epoch 5/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 1.0883 - acc: 0.5057 - val_loss: 1.0616 - val_acc: 0.5447\n",
      "Epoch 6/50\n",
      "6960/6960 [==============================] - 24s 3ms/sample - loss: 1.0414 - acc: 0.5323 - val_loss: 0.9346 - val_acc: 0.6047\n",
      "Epoch 7/50\n",
      "6960/6960 [==============================] - 21s 3ms/sample - loss: 0.9894 - acc: 0.5583 - val_loss: 0.8898 - val_acc: 0.6273\n",
      "Epoch 8/50\n",
      "6960/6960 [==============================] - 24s 3ms/sample - loss: 0.9374 - acc: 0.5878 - val_loss: 0.8271 - val_acc: 0.6500\n",
      "Epoch 9/50\n",
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 0.9082 - acc: 0.5986 - val_loss: 0.7999 - val_acc: 0.6513\n",
      "Epoch 10/50\n",
      "6960/6960 [==============================] - 24s 3ms/sample - loss: 0.8618 - acc: 0.6191 - val_loss: 0.7800 - val_acc: 0.6773\n",
      "Epoch 11/50\n",
      "6960/6960 [==============================] - 24s 3ms/sample - loss: 0.8386 - acc: 0.6332 - val_loss: 0.7674 - val_acc: 0.6727\n",
      "Epoch 12/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 0.7994 - acc: 0.6550 - val_loss: 0.7610 - val_acc: 0.6913\n",
      "Epoch 13/50\n",
      "6960/6960 [==============================] - 25s 4ms/sample - loss: 0.7580 - acc: 0.6875 - val_loss: 0.6522 - val_acc: 0.7453\n",
      "Epoch 14/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 0.7338 - acc: 0.6953 - val_loss: 0.5994 - val_acc: 0.7840\n",
      "Epoch 15/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 0.7028 - acc: 0.7121 - val_loss: 0.5714 - val_acc: 0.8167\n",
      "Epoch 16/50\n",
      "6960/6960 [==============================] - 24s 3ms/sample - loss: 0.6576 - acc: 0.7338 - val_loss: 0.5542 - val_acc: 0.8020\n",
      "Epoch 17/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 0.6238 - acc: 0.7526 - val_loss: 0.4610 - val_acc: 0.8413\n",
      "Epoch 18/50\n",
      "6960/6960 [==============================] - 24s 3ms/sample - loss: 0.5827 - acc: 0.7668 - val_loss: 0.4809 - val_acc: 0.8520\n",
      "Epoch 19/50\n",
      "6960/6960 [==============================] - 24s 3ms/sample - loss: 0.5498 - acc: 0.7800 - val_loss: 0.4150 - val_acc: 0.8847\n",
      "Epoch 20/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 0.5311 - acc: 0.7894 - val_loss: 0.3376 - val_acc: 0.9087\n",
      "Epoch 21/50\n",
      "6960/6960 [==============================] - 24s 3ms/sample - loss: 0.5041 - acc: 0.8034 - val_loss: 0.3287 - val_acc: 0.9053\n",
      "Epoch 22/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 0.4816 - acc: 0.8057 - val_loss: 0.2807 - val_acc: 0.9287\n",
      "Epoch 23/50\n",
      "6960/6960 [==============================] - 24s 3ms/sample - loss: 0.4786 - acc: 0.8088 - val_loss: 0.2748 - val_acc: 0.9287\n",
      "Epoch 24/50\n",
      "6960/6960 [==============================] - 25s 4ms/sample - loss: 0.4549 - acc: 0.8187 - val_loss: 0.2488 - val_acc: 0.9360\n",
      "Epoch 25/50\n",
      "6960/6960 [==============================] - 25s 4ms/sample - loss: 0.4364 - acc: 0.8307 - val_loss: 0.2292 - val_acc: 0.9540\n",
      "Epoch 26/50\n",
      "6960/6960 [==============================] - 24s 3ms/sample - loss: 0.4165 - acc: 0.8349 - val_loss: 0.2486 - val_acc: 0.9373\n",
      "Epoch 27/50\n",
      "6960/6960 [==============================] - 24s 4ms/sample - loss: 0.3997 - acc: 0.8443 - val_loss: 0.2203 - val_acc: 0.9547\n",
      "Epoch 28/50\n",
      "6960/6960 [==============================] - 24s 4ms/sample - loss: 0.4000 - acc: 0.8365 - val_loss: 0.2315 - val_acc: 0.9227\n",
      "Epoch 29/50\n",
      "6960/6960 [==============================] - 24s 3ms/sample - loss: 0.3893 - acc: 0.8441 - val_loss: 0.1593 - val_acc: 0.9620\n",
      "Epoch 30/50\n",
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 0.3645 - acc: 0.8511 - val_loss: 0.1670 - val_acc: 0.9653\n",
      "Epoch 31/50\n",
      "6960/6960 [==============================] - 24s 3ms/sample - loss: 0.3610 - acc: 0.8569 - val_loss: 0.1382 - val_acc: 0.9700\n",
      "Epoch 32/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 0.3574 - acc: 0.8530 - val_loss: 0.1228 - val_acc: 0.9780\n",
      "Epoch 33/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 0.3287 - acc: 0.8636 - val_loss: 0.1294 - val_acc: 0.9747\n",
      "Epoch 34/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 0.3243 - acc: 0.8677 - val_loss: 0.1193 - val_acc: 0.9753\n",
      "Epoch 35/50\n",
      "6960/6960 [==============================] - 24s 3ms/sample - loss: 0.3351 - acc: 0.8638 - val_loss: 0.1111 - val_acc: 0.9800\n",
      "Epoch 36/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 0.3230 - acc: 0.8707 - val_loss: 0.1283 - val_acc: 0.9727\n",
      "Epoch 37/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 0.3219 - acc: 0.8658 - val_loss: 0.1023 - val_acc: 0.9847\n",
      "Epoch 38/50\n",
      "6960/6960 [==============================] - 25s 4ms/sample - loss: 0.3005 - acc: 0.8766 - val_loss: 0.0834 - val_acc: 0.9880\n",
      "Epoch 39/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 0.2964 - acc: 0.8799 - val_loss: 0.0886 - val_acc: 0.9913\n",
      "Epoch 40/50\n",
      "6960/6960 [==============================] - 24s 3ms/sample - loss: 0.3148 - acc: 0.8698 - val_loss: 0.0734 - val_acc: 0.9907\n",
      "Epoch 41/50\n",
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 0.2967 - acc: 0.8779 - val_loss: 0.0639 - val_acc: 0.9927\n",
      "Epoch 42/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 0.2905 - acc: 0.8864 - val_loss: 0.0786 - val_acc: 0.9860\n",
      "Epoch 43/50\n",
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 0.2857 - acc: 0.8820 - val_loss: 0.0810 - val_acc: 0.9840\n",
      "Epoch 44/50\n",
      "6960/6960 [==============================] - 25s 4ms/sample - loss: 0.2791 - acc: 0.8845 - val_loss: 0.0660 - val_acc: 0.9920\n",
      "Epoch 45/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 0.2674 - acc: 0.8897 - val_loss: 0.0631 - val_acc: 0.9887\n",
      "Epoch 46/50\n",
      "6960/6960 [==============================] - 22s 3ms/sample - loss: 0.2760 - acc: 0.8841 - val_loss: 0.0764 - val_acc: 0.9880\n",
      "Epoch 47/50\n",
      "6960/6960 [==============================] - 24s 3ms/sample - loss: 0.2664 - acc: 0.8888 - val_loss: 0.0632 - val_acc: 0.9860\n",
      "Epoch 48/50\n",
      "6960/6960 [==============================] - 23s 3ms/sample - loss: 0.2601 - acc: 0.8932 - val_loss: 0.0522 - val_acc: 0.9913\n",
      "Epoch 49/50\n",
      "6960/6960 [==============================] - 24s 3ms/sample - loss: 0.2667 - acc: 0.8866 - val_loss: 0.0473 - val_acc: 0.9947\n",
      "Epoch 50/50\n",
      "6960/6960 [==============================] - 25s 4ms/sample - loss: 0.2688 - acc: 0.8875 - val_loss: 0.0439 - val_acc: 0.9927\n",
      "6960/6960 [==============================] - 42s 6ms/sample - loss: 0.0211 - acc: 0.9993\n",
      "1772/1772 [==============================] - 12s 7ms/sample - loss: 1.1403 - acc: 0.6450\n",
      "train acc: 99.928%\n",
      "test acc: 64.503%\n"
     ]
    }
   ],
   "source": [
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "for time in range(25, 251, 25):\n",
    "    print(\"=================\" + str(time) + \"===================\")\n",
    "    train_score, test_score = hybrid_train_data(time_period=time)\n",
    "    train_scores.append(train_score[1])\n",
    "    test_scores.append(test_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracies: \n",
      "[0.9166667, 0.9817529, 0.9883621, 0.9935345, 0.9928161, 0.9945402, 0.99425286, 0.9982759, 0.97341955, 0.9992816]\n",
      "Test accuracies: \n",
      "[0.38431153, 0.5, 0.5733634, 0.5993228, 0.6106095, 0.65462756, 0.62471783, 0.6670429, 0.64503384, 0.64503384]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Train accuracies: \")\n",
    "print(train_scores)\n",
    "print(\"Test accuracies: \")\n",
    "print(test_scores)\n",
    "\n",
    "# plot\n",
    "plt.plot(range(25, 251, 25), train_scores, label='train accuracies')\n",
    "plt.plot(range(25, 251, 25), test_scores, label='test accuracies')\n",
    "plt.legend()\n",
    "plt.title(\"Classification Accuracies over Time Period (CNN+LSTM)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
